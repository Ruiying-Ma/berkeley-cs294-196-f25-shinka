<NAME>
segmented_lru_2q
</NAME>

<DESCRIPTION>
The previous algorithm was a plain LRU that tracks only the last access timestamp per key and evicts the globally least recently used item. While simple, LRU suffers from cache pollution on scan-heavy workloads (which explains many near-zero hit rates), because single-use items can evict frequently used ones.

I propose a 2Q-style segmented LRU:
- Maintain two segments:
  - Probationary (recently inserted, not yet proven useful)
  - Protected (promoted upon a hit, i.e., items with demonstrated reuse)
- On insert: place item into probationary.
- On hit: if in probationary, promote to protected; if in protected, just update recency.
- Evict: prefer evicting the oldest item from probationary; if empty, evict the oldest from protected; fallback to oldest globally if metadata is out of sync.

This approach is scan-resistant: single-use items tend to stay in the probationary segment and get evicted first, protecting frequently reused items in the protected segment. It retains LRU behavior within each segment, improving robustness across varied workloads without adding complex tuning. The metadata is kept consistent with the actual cache content and is lightweight (timestamps and two sets).
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
"""Cache eviction algorithm for optimizing hit rates across multiple workloads"""

m_key_timestamp = dict()

def evict(cache_snapshot, obj):
    '''
    This function defines how the algorithm chooses the eviction victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    candid_obj_key = None
    min_ts = min(m_key_timestamp.values())
    candid_obj_keys = list(key for key in cache_snapshot.cache if m_key_timestamp[key] == min_ts)
    candid_obj_key = candid_obj_keys[0]
    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the algorithm update the metadata it maintains immediately after a cache hit.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    global m_key_timestamp
    assert obj.key in m_key_timestamp
    m_key_timestamp[obj.key] = cache_snapshot.access_count

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    global m_key_timestamp
    assert obj.key not in m_key_timestamp
    m_key_timestamp[obj.key] = cache_snapshot.access_count

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    global m_key_timestamp
    assert obj.key not in m_key_timestamp
    assert evicted_obj.key in m_key_timestamp
    m_key_timestamp.pop(evicted_obj.key)
=======
"""Cache eviction algorithm for optimizing hit rates across multiple workloads"""

# Segmented LRU (2Q-like): probationary (recent) and protected (frequent) segments.
# - Newly inserted objects go to probationary.
# - On first hit, they are promoted to protected.
# - Evict from probationary first to resist scans; if empty, evict from protected.
m_ts = dict()             # key -> last access timestamp
m_probation = set()       # keys seen once (recently inserted)
m_protected = set()       # keys with demonstrated reuse (promoted on hit)

def evict(cache_snapshot, obj):
    '''
    This function defines how the algorithm chooses the eviction victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    global m_ts, m_probation, m_protected

    keys_in_cache = set(cache_snapshot.cache.keys())

    # Keep metadata consistent with actual cache content
    if m_probation:
        m_probation.intersection_update(keys_in_cache)
    if m_protected:
        m_protected.intersection_update(keys_in_cache)
    if m_ts:
        for k in list(m_ts.keys()):
            if k not in keys_in_cache:
                m_ts.pop(k, None)
                m_probation.discard(k)
                m_protected.discard(k)

    def oldest_key(candidates):
        # Return the key with the smallest timestamp among candidates
        return min(candidates, key=lambda k: m_ts.get(k, -1))

    probation_candidates = m_probation & keys_in_cache
    protected_candidates = m_protected & keys_in_cache

    # Prefer evicting from probationary segment to avoid polluting protected items
    if probation_candidates:
        return oldest_key(probation_candidates)
    if protected_candidates:
        return oldest_key(protected_candidates)

    # Fallback: evict the globally oldest if segmentation hasn't been set yet
    if keys_in_cache:
        return oldest_key(keys_in_cache)
    return None

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the algorithm update the metadata it maintains immediately after a cache hit.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    global m_ts, m_probation, m_protected
    now = cache_snapshot.access_count
    key = obj.key

    # Ensure timestamp exists
    if key not in m_ts:
        m_ts[key] = now

    # Promote on first hit; otherwise remain/update in protected
    if key in m_probation:
        m_probation.discard(key)
        m_protected.add(key)
    elif key not in m_protected:
        # If metadata was missing, treat as protected to avoid premature eviction
        m_protected.add(key)

    # Update recency timestamp
    m_ts[key] = now

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    global m_ts, m_probation, m_protected
    now = cache_snapshot.access_count
    key = obj.key

    # New insert starts in probationary segment
    m_ts[key] = now
    m_protected.discard(key)
    m_probation.add(key)

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    global m_ts, m_probation, m_protected
    evk = evicted_obj.key
    # Remove all metadata for the evicted object
    m_ts.pop(evk, None)
    m_probation.discard(evk)
    m_protected.discard(evk)
>>>>>>> REPLACE

</DIFF>