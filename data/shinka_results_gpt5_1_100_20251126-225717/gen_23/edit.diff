--- a/original.py
+++ b/original.py
@@ -1,319 +1,403 @@
 # EVOLVE-BLOCK-START
 """Cache eviction algorithm for optimizing hit rates across multiple workloads"""
 
 from collections import OrderedDict
 
 # Segmented LRU (SLRU) metadata:
 # - _probation: objects seen once (newly inserted), LRU-ordered
 # - _protected: objects that have been hit (promoted), LRU-ordered
 # We adapt the protected fraction slightly based on runtime signals.
 _probation = OrderedDict()   # key -> None (value unused)
 _protected = OrderedDict()   # key -> None (value unused)
 _key_seg = dict()            # key -> 'prob' or 'prot'
 
 # Ghost histories to recognize re-references to recently evicted items
 _ghost_probation = OrderedDict()  # key -> epoch of ghost insertion
 _ghost_protected = OrderedDict()  # key -> epoch of ghost insertion
 _GHOST_LIMIT_MULT = 2
 
 # TinyLFU-like lightweight decayed frequency
 _refcnt = {}                 # key -> (count, epoch)
 _epoch = 0
 _last_epoch_tick = 0
 _DECAY_WINDOW = 128          # accesses between epochs; adjusted using capacity
 _last_victim_score = 0.0
 
 _PROTECTED_FRAC = 0.8        # target fraction of cache to allocate to protected segment
 _ADAPT_STEP = 0.02           # step used to adjust protected fraction within [0.05, 0.95]
+
+# Scan detection window and state
+_SCAN_WINDOW_MULT = 2
+_win_ops = 0
+_win_hits = 0
+_win_inserts = 0
+_scan_ticks = 0  # >0 means scan mode active
+
+# Sampling sizes for victim selection
+_PROB_SAMPLE = 3
+_PROT_SAMPLE_BASE = 3
+
+
+def _in_scan_mode():
+    return _scan_ticks > 0
+
+
+def _scan_account(cache_snapshot, is_hit):
+    """Account an access in the sliding window and update scan mode."""
+    global _win_ops, _win_hits, _win_inserts, _scan_ticks
+    _win_ops += 1
+    if is_hit:
+        _win_hits += 1
+    else:
+        _win_inserts += 1
+    cap = max(cache_snapshot.capacity, 1)
+    W = max(32, _SCAN_WINDOW_MULT * cap)
+    # Naturally decay scan mode over time
+    if _scan_ticks > 0:
+        _scan_ticks -= 1
+    if _win_ops >= W:
+        hit_rate = _win_hits / max(1, _win_ops)
+        insert_rate = _win_inserts / max(1, _win_ops)
+        # Enter scan mode if window indicates a scan-like pattern
+        if insert_rate > 0.6 and hit_rate < 0.2:
+            _scan_ticks = W
+        # reset window counters
+        _win_ops = _win_hits = _win_inserts = 0
 
 
 def _increase_protected():
     global _PROTECTED_FRAC
     _PROTECTED_FRAC = min(0.95, _PROTECTED_FRAC + _ADAPT_STEP)
 
 
 def _decrease_protected():
     global _PROTECTED_FRAC
     _PROTECTED_FRAC = max(0.05, _PROTECTED_FRAC - _ADAPT_STEP)
 
 
 def _ensure_params(cache_snapshot):
     """Initialize/adjust parameters that depend on capacity."""
     global _DECAY_WINDOW
     cap = max(cache_snapshot.capacity, 1)
     # Tie decay window to capacity to align half-life with working-set size
     _DECAY_WINDOW = max(64, cap)
 
 
 def _maybe_age(cache_snapshot):
     """Advance epoch based on access_count, and trim ghost lists."""
     global _epoch, _last_epoch_tick
     _ensure_params(cache_snapshot)
     if cache_snapshot.access_count - _last_epoch_tick >= _DECAY_WINDOW:
         _epoch += 1
         _last_epoch_tick = cache_snapshot.access_count
         # Trim ghost histories to bounded size
         limit = max(1, _GHOST_LIMIT_MULT * max(cache_snapshot.capacity, 1))
         while len(_ghost_probation) > limit:
             _ghost_probation.popitem(last=False)
         while len(_ghost_protected) > limit:
             _ghost_protected.popitem(last=False)
 
 
 def _score(key):
     """Return decayed frequency score for a key."""
     ce = _refcnt.get(key)
     if ce is None:
         return 0
     c, e = ce
     de = _epoch - e
     if de > 0:
         # decay by halving per epoch (cap max shifts to avoid zeroing too fast)
         c = c >> min(6, de)
     return max(0, c)
 
 
 def _inc(key):
     """Increment decayed frequency count for a key."""
     c, e = _refcnt.get(key, (0, _epoch))
     if e != _epoch:
         c = c >> min(6, _epoch - e)
         e = _epoch
     # cap growth to avoid overflow
     c = min(c + 1, 1 << 30)
     _refcnt[key] = (c, e)
 
 
 def _sync_metadata(cache_snapshot):
     """Ensure SLRU metadata matches current cache content."""
     cached_keys = set(cache_snapshot.cache.keys())
 
     # Remove entries no longer in cache
     for k in list(_key_seg.keys()):
         if k not in cached_keys:
             if _key_seg.get(k) == 'prob':
                 _probation.pop(k, None)
             else:
                 _protected.pop(k, None)
             _key_seg.pop(k, None)
 
     # Add cached keys missing from metadata into probation MRU
     for k in cached_keys:
         if k not in _key_seg:
             _probation[k] = None
             _key_seg[k] = 'prob'
 
 
 def _rebalance(cache_snapshot):
     """Demote protected LRU entries if protected size exceeds target."""
     total = len(cache_snapshot.cache)
     if total <= 0:
         return
     target = max(1, int(total * _PROTECTED_FRAC))
 
     while len(_protected) > target:
         # Demote protected LRU to probation MRU
         k, _ = _protected.popitem(last=False)
         _probation[k] = None
         _key_seg[k] = 'prob'
 
 
 def evict(cache_snapshot, obj):
     '''
     This function defines how the algorithm chooses the eviction victim.
     - Args:
         - `cache_snapshot`: A snapshot of the current cache state.
         - `obj`: The new object that needs to be inserted into the cache.
     - Return:
         - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
     '''
     # Keep metadata consistent and properly segmented before choosing a victim
     _maybe_age(cache_snapshot)
     _sync_metadata(cache_snapshot)
     _rebalance(cache_snapshot)
 
-    candid_obj_key = None
-    victim_from_protected = False
+    # ARC-like adaptation using ghosts of the incoming object
+    if obj is not None:
+        k = obj.key
+        if k in _ghost_protected and k not in _ghost_probation:
+            _increase_protected()
+        elif k in _ghost_probation and k not in _ghost_protected:
+            _decrease_protected()
 
     # Clean up stale entries (if any)
     for k in list(_probation.keys()):
         if k not in cache_snapshot.cache:
             _probation.pop(k, None)
             _key_seg.pop(k, None)
     for k in list(_protected.keys()):
         if k not in cache_snapshot.cache:
             _protected.pop(k, None)
             _key_seg.pop(k, None)
 
-    # Identify LRU candidates from each segment
-    prob_lru = next(iter(_probation.keys()), None)
-    prot_lru = next(iter(_protected.keys()), None)
-
-    if prob_lru is None and prot_lru is None:
+    def _pick_sample(od, n):
+        """Pick the lowest decayed-frequency key among the n oldest entries of an OrderedDict."""
+        cand_key = None
+        cand_score = float('inf')
+        count = 0
+        for kk in od.keys():
+            s = _score(kk)
+            if s < cand_score:
+                cand_score = s
+                cand_key = kk
+            count += 1
+            if count >= n:
+                break
+        return cand_key, (0 if cand_key is None else cand_score)
+
+    total = max(1, len(cache_snapshot.cache))
+    prot_target = max(1, int(total * _PROTECTED_FRAC))
+    prot_overcrowded = len(_protected) > prot_target
+    prot_sample = _PROT_SAMPLE_BASE + (2 if prot_overcrowded else 0)
+
+    prob_cand, s_prob = _pick_sample(_probation, max(1, _PROB_SAMPLE))
+    prot_cand, s_prot = _pick_sample(_protected, max(1, prot_sample))
+
+    if prob_cand is None and prot_cand is None:
         # Fallback: pick any key from cache if metadata got desynced
         if cache_snapshot.cache:
             return next(iter(cache_snapshot.cache.keys()))
         return None
 
-    if prob_lru is None:
-        # Only protected has entries; must evict from protected
-        candid_obj_key = prot_lru
+    victim_from_protected = False
+    candid_obj_key = None
+
+    if prob_cand is None:
+        candid_obj_key = prot_cand
         victim_from_protected = True
-    elif prot_lru is None:
-        # Only probation has entries; evict from probation
-        candid_obj_key = prob_lru
+    elif prot_cand is None:
+        candid_obj_key = prob_cand
         victim_from_protected = False
     else:
-        # Both candidates exist. Prefer probation for scan resistance,
-        # but evict protected LRU if it's clearly colder by decayed frequency.
-        s_prob = _score(prob_lru)
-        s_prot = _score(prot_lru)
-        min_prot_size = max(1, int(0.2 * max(1, len(cache_snapshot.cache))))
-        if s_prot + 1 < s_prob and len(_protected) > min_prot_size:
-            candid_obj_key = prot_lru
+        # Default is to evict from probation for scan resistance
+        candid_obj_key = prob_cand
+        victim_from_protected = False
+
+        # But if the protected candidate is clearly colder, evict it instead.
+        min_prot_size = max(1, int(0.3 * total))
+        if (s_prot + 1 < s_prob) and (len(_protected) > min_prot_size):
+            candid_obj_key = prot_cand
             victim_from_protected = True
-        else:
-            candid_obj_key = prob_lru
-            victim_from_protected = False
 
     # Adaptive tuning: if we are forced to evict from protected, reduce its target fraction slightly
     if victim_from_protected:
         _decrease_protected()
 
     return candid_obj_key
 
 
 def update_after_hit(cache_snapshot, obj):
     '''
     This function defines how the algorithm update the metadata it maintains immediately after a cache hit.
     - Args:
         - `cache_snapshot`: A snapshot of the current cache state.
         - `obj`: The object accessed during the cache hit.
     - Return: `None`
     '''
     _maybe_age(cache_snapshot)
     _sync_metadata(cache_snapshot)
 
+    # Account hit in scan detector
+    _scan_account(cache_snapshot, is_hit=True)
+
     k = obj.key
     _inc(k)
     seg = _key_seg.get(k)
 
     if seg == 'prob':
-        # Promote to protected on first hit
-        _probation.pop(k, None)
-        _protected[k] = None  # inserted at MRU
-        _key_seg[k] = 'prot'
-        _increase_protected()  # hits in probation signal benefit from a larger protected segment
+        # In scan mode, require 2 touches before promotion; otherwise promote on first hit
+        if _in_scan_mode() and _score(k) < 2:
+            # Refresh probation recency
+            if k in _probation:
+                _probation.move_to_end(k, last=True)
+        else:
+            # Promote to protected
+            _probation.pop(k, None)
+            _protected[k] = None  # inserted at MRU
+            _key_seg[k] = 'prot'
+            _increase_protected()
     elif seg == 'prot':
         # Refresh recency in protected
         if k in _protected:
             _protected.move_to_end(k, last=True)
         else:
             # If somehow missing from the structure, reinsert into protected
             _protected[k] = None
             _key_seg[k] = 'prot'
     else:
         # Unknown key (shouldn't happen on hit) â€“ treat as probation then promote
         _probation[k] = None
         _key_seg[k] = 'prob'
         _probation.pop(k, None)
         _protected[k] = None
         _key_seg[k] = 'prot'
         _increase_protected()
 
     _rebalance(cache_snapshot)
 
 
 def update_after_insert(cache_snapshot, obj):
     '''
     This function defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
     - Args:
         - `cache_snapshot`: A snapshot of the current cache state.
         - `obj`: The object that was just inserted into the cache.
     - Return: `None`
     '''
     _maybe_age(cache_snapshot)
     _sync_metadata(cache_snapshot)
+
+    # Account miss/insert in scan detector
+    _scan_account(cache_snapshot, is_hit=False)
+
     k = obj.key
     _inc(k)
 
     # Decide segment placement using ghost history (segment-aware)
     g_prot_epoch = _ghost_protected.get(k)
+    g_prob_epoch = _ghost_probation.get(k)
     recent_prot_ghost = (g_prot_epoch is not None) and (_epoch - g_prot_epoch <= 2)
+    recent_prob_ghost = (g_prob_epoch is not None) and (_epoch - g_prob_epoch <= 2)
 
     # Reset any existing placement
     if _key_seg.get(k) == 'prot':
         _protected.pop(k, None)
     else:
         _probation.pop(k, None)
 
-    if recent_prot_ghost:
-        # Re-admit into protected due to recent protected ghost hit
-        _protected[k] = None
-        _key_seg[k] = 'prot'
-        _increase_protected()
-    else:
-        # Default admission into probation
+    if _in_scan_mode():
+        # During scans, avoid admitting directly to protected; keep in probation
         _probation[k] = None
         _key_seg[k] = 'prob'
+        _decrease_protected()
+    else:
+        if recent_prot_ghost and not recent_prob_ghost:
+            # Re-admit into protected due to recent protected ghost hit
+            _protected[k] = None
+            _key_seg[k] = 'prot'
+            _increase_protected()
+        else:
+            # Default admission into probation; adjust partition if B1 ghost suggests recency
+            _probation[k] = None
+            _key_seg[k] = 'prob'
+            if recent_prob_ghost and not recent_prot_ghost:
+                _decrease_protected()
 
     _rebalance(cache_snapshot)
 
 
 def update_after_evict(cache_snapshot, obj, evicted_obj):
     '''
     This function defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
     - Args:
         - `cache_snapshot`: A snapshot of the current cache state.
         - `obj`: The object to be inserted into the cache.
         - `evicted_obj`: The object that was just evicted from the cache.
     - Return: `None`
     '''
     _maybe_age(cache_snapshot)
     # Record into ghost according to the segment it was evicted from
     k = evicted_obj.key
     seg = _key_seg.get(k, None)
     # Store last victim score for potential future enhancements
     global _last_victim_score
     _last_victim_score = _score(k)
 
     if seg == 'prob':
         _ghost_probation[k] = _epoch
         _probation.pop(k, None)
     elif seg == 'prot':
         _ghost_protected[k] = _epoch
         _protected.pop(k, None)
 
     _key_seg.pop(k, None)
 
     # Trim ghost histories to bounded size
     limit = max(1, _GHOST_LIMIT_MULT * max(cache_snapshot.capacity, 1))
     while len(_ghost_probation) > limit:
         _ghost_probation.popitem(last=False)
     while len(_ghost_protected) > limit:
         _ghost_protected.popitem(last=False)
 
     # After an eviction, ensure protected segment still respects target (it might shrink due to target change)
     _rebalance(cache_snapshot)
 
 # EVOLVE-BLOCK-END
 
 # This part remains fixed (not evolved)
 def run_caching(trace_path: str, copy_code_dst: str):
     """Run the caching algorithm on a trace"""
     import os
     with open(os.path.abspath(__file__), 'r', encoding="utf-8") as f:
         code_str = f.read()
     with open(os.path.join(copy_code_dst), 'w') as f:
         f.write(code_str)
     from cache_utils import Cache, CacheConfig, CacheObj, Trace
     trace = Trace(trace_path=trace_path)
     cache_capacity = max(int(trace.get_ndv() * 0.1), 1)
     cache = Cache(CacheConfig(cache_capacity))
     for entry in trace.entries:
         obj = CacheObj(key=str(entry.key))
         cache.get(obj)
     with open(copy_code_dst, 'w') as f:
         f.write("")
     hit_rate = round(cache.hit_count / cache.access_count, 6)
     return hit_rate