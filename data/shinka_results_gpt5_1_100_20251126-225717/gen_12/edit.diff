--- a/original.py
+++ b/original.py
@@ -1,79 +1,236 @@
 # EVOLVE-BLOCK-START
-"""Cache eviction algorithm for optimizing hit rates across multiple workloads"""
-
+"""Adaptive ARC-like cache eviction with SLRU segments and ghost history"""
+
+from collections import OrderedDict
+
+# Segment structures
+_T1_probation = OrderedDict()   # keys in cache, 1st-touch (recency-biased)
+_T2_protected = OrderedDict()   # keys in cache, 2nd+ touch (frequency-biased)
+
+# Ghost history (recently evicted keys) for adaptation
+_B1_ghost = OrderedDict()       # evicted from T1
+_B2_ghost = OrderedDict()       # evicted from T2
+
+# Adaptive target size for probation (ARC's p). Float to allow smooth adjust.
+_p_target = 0.0
+
+# Estimated capacity (number of objects). Initialize lazily.
+_cap_est = 0
+
+# Fallback LRU timestamps if metadata desync occurs
 m_key_timestamp = dict()
 
+# Tunable parameters
+_P_INIT_RATIO = 0.3  # initial share for probation (T1)
+# On ghost hits, adjust p by this delta rule (ARC-like):
+# delta = max(1, len(other_ghost) // max(1, len(this_ghost)))
+
+def _ensure_capacity(cache_snapshot):
+    """Initialize or update capacity estimate and clamp p."""
+    global _cap_est, _p_target
+    cap = getattr(cache_snapshot, "capacity", None)
+    # Some runners define capacity as number of objects; if absent, infer
+    if isinstance(cap, int) and cap > 0:
+        _cap_est = cap
+    else:
+        _cap_est = max(_cap_est, len(cache_snapshot.cache))
+    if _cap_est <= 0:
+        _cap_est = max(1, len(cache_snapshot.cache))
+    # Initialize p if never set (zero and empty metadata)
+    if _p_target == 0.0 and not _T1_probation and not _T2_protected and not _B1_ghost and not _B2_ghost:
+        _p_target = max(0.0, min(float(_cap_est), float(_cap_est) * _P_INIT_RATIO))
+    # Clamp p
+    if _p_target < 0.0:
+        _p_target = 0.0
+    if _p_target > float(_cap_est):
+        _p_target = float(_cap_est)
+
+def _ghost_trim():
+    """Limit ghost lists to capacity each (ARC-style bound)."""
+    global _B1_ghost, _B2_ghost
+    # Trim oldest entries beyond capacity
+    while len(_B1_ghost) > _cap_est:
+        _B1_ghost.popitem(last=False)
+    while len(_B2_ghost) > _cap_est:
+        _B2_ghost.popitem(last=False)
+
+def _fallback_choose(cache_snapshot):
+    """Fallback victim: global LRU by timestamp among cached keys."""
+    # Prefer the minimum timestamp; if unknown, pick arbitrary
+    keys = list(cache_snapshot.cache.keys())
+    if not keys:
+        return None
+    # Filter to known timestamps
+    known = [(k, m_key_timestamp.get(k, None)) for k in keys]
+    known_ts = [x for x in known if x[1] is not None]
+    if known_ts:
+        k = min(known_ts, key=lambda kv: kv[1])[0]
+        return k
+    return keys[0]
+
 def evict(cache_snapshot, obj):
     '''
-    This function defines how the algorithm chooses the eviction victim.
-    - Args:
-        - `cache_snapshot`: A snapshot of the current cache state.
-        - `obj`: The new object that needs to be inserted into the cache.
-    - Return:
-        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
-    '''
-    candid_obj_key = None
-    min_ts = min(m_key_timestamp.values())
-    candid_obj_keys = list(key for key in cache_snapshot.cache if m_key_timestamp[key] == min_ts)
-    candid_obj_key = candid_obj_keys[0]
-    return candid_obj_key
+    Choose victim key using adaptive ARC-like policy.
+    Prefer evicting from probation (T1) when it exceeds target p;
+    otherwise evict from protected (T2). Fall back to global LRU.
+    '''
+    _ensure_capacity(cache_snapshot)
+
+    # If metadata perfectly mirrors cache, choose from segments.
+    t1_size = len(_T1_probation)
+    t2_size = len(_T2_protected)
+
+    # Primary ARC eviction choice
+    # Evict from T1 if it is "too big" relative to target p
+    # Otherwise evict from T2 (if non-empty), else from T1, else fallback.
+    victim_key = None
+    t1_over = t1_size > max(1, int(_p_target))
+    if t1_size > 0 and (t1_over or t2_size == 0):
+        # LRU from T1
+        victim_key = next(iter(_T1_probation.keys()))
+        if victim_key not in cache_snapshot.cache:
+            victim_key = None
+    if victim_key is None and t2_size > 0:
+        # LRU from T2
+        victim_key = next(iter(_T2_protected.keys()))
+        if victim_key not in cache_snapshot.cache:
+            victim_key = None
+    if victim_key is None and t1_size > 0:
+        victim_key = next(iter(_T1_probation.keys()))
+        if victim_key not in cache_snapshot.cache:
+            victim_key = None
+    if victim_key is None:
+        # Fallback to global LRU if metadata desync
+        victim_key = _fallback_choose(cache_snapshot)
+    return victim_key
 
 def update_after_hit(cache_snapshot, obj):
     '''
-    This function defines how the algorithm update the metadata it maintains immediately after a cache hit.
-    - Args:
-        - `cache_snapshot`: A snapshot of the current cache state.
-        - `obj`: The object accessed during the cache hit.
-    - Return: `None`
-    '''
-    global m_key_timestamp
-    assert obj.key in m_key_timestamp
-    m_key_timestamp[obj.key] = cache_snapshot.access_count
+    Update metadata after cache hit.
+    - If hit in probation (T1), promote to protected (T2).
+    - If hit in protected, refresh recency.
+    - Maintain fallback timestamp map.
+    '''
+    _ensure_capacity(cache_snapshot)
+    key = obj.key
+    # Update fallback LRU timestamp
+    m_key_timestamp[key] = cache_snapshot.access_count
+
+    # If the key exists in our segments, update positions
+    if key in _T2_protected:
+        # Refresh to MRU
+        _T2_protected.move_to_end(key, last=True)
+    elif key in _T1_probation:
+        # Promote from probation to protected
+        _T1_probation.pop(key, None)
+        _T2_protected[key] = True  # insert as MRU
+    else:
+        # Metadata miss: cache has it but we don't; treat as frequent and add to protected
+        _T2_protected[key] = True
+    # Touch ghosts cleanup if any stale
+    if key in _B1_ghost:
+        _B1_ghost.pop(key, None)
+    if key in _B2_ghost:
+        _B2_ghost.pop(key, None)
+    _ghost_trim()
 
 def update_after_insert(cache_snapshot, obj):
     '''
-    This function defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
-    - Args:
-        - `cache_snapshot`: A snapshot of the current cache state.
-        - `obj`: The object that was just inserted into the cache.
-    - Return: `None`
-    '''
-    global m_key_timestamp
-    assert obj.key not in m_key_timestamp
-    m_key_timestamp[obj.key] = cache_snapshot.access_count
+    Update metadata on insertion (cache miss path).
+    - If the key is in ghost lists, adjust p (ARC adaptation) and insert into protected.
+    - Otherwise insert into probation as MRU.
+    - Maintain fallback timestamp map.
+    '''
+    _ensure_capacity(cache_snapshot)
+    key = obj.key
+    m_key_timestamp[key] = cache_snapshot.access_count
+
+    in_b1 = key in _B1_ghost
+    in_b2 = key in _B2_ghost
+
+    if in_b1 or in_b2:
+        # ARC adaptation of p
+        global _p_target
+        if in_b1:
+            # Favor recency: increase p
+            inc = max(1, len(_B2_ghost) // max(1, len(_B1_ghost)))
+            _p_target = min(float(_cap_est), _p_target + float(inc))
+            _B1_ghost.pop(key, None)
+        else:
+            # Favor frequency: decrease p
+            dec = max(1, len(_B1_ghost) // max(1, len(_B2_ghost)))
+            _p_target = max(0.0, _p_target - float(dec))
+            _B2_ghost.pop(key, None)
+        # Insert into protected (seen before, effectively 2nd touch)
+        if key in _T1_probation:
+            _T1_probation.pop(key, None)
+        _T2_protected[key] = True
+    else:
+        # New to cache and ghosts: insert into probation (T1)
+        if key in _T2_protected:
+            # Rare desync; ensure consistency (shouldn't happen on miss)
+            _T2_protected.move_to_end(key, last=True)
+        else:
+            _T1_probation[key] = True
+
+    # Avoid duplicates across structures
+    if key in _T1_probation and key in _T2_protected:
+        _T1_probation.pop(key, None)
+    if key in _B1_ghost:
+        _B1_ghost.pop(key, None)
+    if key in _B2_ghost:
+        _B2_ghost.pop(key, None)
+    _ghost_trim()
 
 def update_after_evict(cache_snapshot, obj, evicted_obj):
     '''
-    This function defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
-    - Args:
-        - `cache_snapshot`: A snapshot of the current cache state.
-        - `obj`: The object to be inserted into the cache.
-        - `evicted_obj`: The object that was just evicted from the cache.
-    - Return: `None`
-    '''
-    global m_key_timestamp
-    assert obj.key not in m_key_timestamp
-    assert evicted_obj.key in m_key_timestamp
-    m_key_timestamp.pop(evicted_obj.key)
-
+    Update metadata after eviction.
+    - Remove victim from its resident segment.
+    - Add to corresponding ghost list (B1 if from probation, B2 if from protected).
+    - Trim ghost lists to capacity.
+    - Maintain fallback timestamp map.
+    '''
+    _ensure_capacity(cache_snapshot)
+    victim_key = evicted_obj.key
+
+    was_t1 = victim_key in _T1_probation
+    was_t2 = victim_key in _T2_protected
+
+    # Remove from resident segments
+    if was_t1:
+        _T1_probation.pop(victim_key, None)
+        _B1_ghost[victim_key] = True  # insert as MRU
+    elif was_t2:
+        _T2_protected.pop(victim_key, None)
+        _B2_ghost[victim_key] = True  # insert as MRU
+    else:
+        # Unknown location; put in B1 by default
+        _B1_ghost[victim_key] = True
+
+    # Remove fallback timestamp for evicted key
+    if victim_key in m_key_timestamp:
+        m_key_timestamp.pop(victim_key, None)
+
+    # If inserting obj is accidentally in ghosts, let insert handle cleanup next
+    _ghost_trim()
 # EVOLVE-BLOCK-END
 
 # This part remains fixed (not evolved)
 def run_caching(trace_path: str, copy_code_dst: str):
     """Run the caching algorithm on a trace"""
     import os
     with open(os.path.abspath(__file__), 'r', encoding="utf-8") as f:
         code_str = f.read()
     with open(os.path.join(copy_code_dst), 'w') as f:
         f.write(code_str)
     from cache_utils import Cache, CacheConfig, CacheObj, Trace
     trace = Trace(trace_path=trace_path)
     cache_capacity = max(int(trace.get_ndv() * 0.1), 1)
     cache = Cache(CacheConfig(cache_capacity))
     for entry in trace.entries:
         obj = CacheObj(key=str(entry.key))
         cache.get(obj)
     with open(copy_code_dst, 'w') as f:
         f.write("")
     hit_rate = round(cache.hit_count / cache.access_count, 6)
     return hit_rate