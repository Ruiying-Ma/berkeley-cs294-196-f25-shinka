--- a/original.py
+++ b/original.py
@@ -1,413 +1,517 @@
 # EVOLVE-BLOCK-START
 """Scan-aware ARC+SLRU with freshness-aware ghosts, momentum p-updates, and aging LRFU sampling"""
 
 from collections import OrderedDict
 
 # Segments (resident)
 _T1_probation = OrderedDict()   # first-touch, recency-biased
 _T2_protected = OrderedDict()   # multi-touch, frequency-biased
 
 # Ghost histories (evicted keys) store eviction timestamps for freshness
 _B1_ghost = OrderedDict()       # from T1: key -> evict_ts
 _B2_ghost = OrderedDict()       # from T2: key -> evict_ts
 
 # ARC's adaptive target (float) for T1 size
 _p_target = 0.0
 _cap_est = 0
 
 # Fallback timestamp ledger and lightweight frequency
 m_key_timestamp = dict()        # key -> last access time (for tie-breaking)
 _freq = dict()                  # key -> small counter (saturating)
 _last_age_tick = 0
 
 # Admission guard based on last victim strength and a short scan window
 _last_victim_strength = 0.0
 _VICTIM_GUARD_THRESH = 2.0
 _guard_until = 0
 
 # Scan detection and momentum for p updates
 _hit_ewma = 0.0
 _ins_ewma = 0.0
 _EWMA_ALPHA = 0.05
 _scan_until = 0
 _p_momentum = 0.0
 _p_last_update_tick = 0
 
 # Tunables
 _P_INIT_RATIO = 0.30             # initial share for T1
 _FREQ_MAX = 7                    # 3-bit saturating counter
 _FRESH_WINDOW_RATIO = 0.5        # ghost freshness window = 0.5 * cap
 _SCAN_TRIGGER_INS = 0.7          # insert EWMA threshold
 _SCAN_TRIGGER_HIT = 0.15         # hit EWMA threshold
 _SCAN_WINDOW_MULT = 1.0          # scan window length ~= cap accesses
 _P_COOLDOWN_DIV = 10             # min spacing between non-ghost p-updates (~cap/10 accesses) for faster adaptation
 _CROSS_EVICT_FREQ_MARGIN = 0     # allow override on equal-or-better frequency if overall colder
+
+# Added adaptive helpers and shields
+_fast_promote_until = {}
+_no_demote_until = {}
+_last_p_sign = 0                 # track last sign for momentum stability
+_ghost_b1_hits = 0.0
+_ghost_b2_hits = 0.0
+_ghost_hits_last_tick = 0
 
 def _ensure_capacity(cache_snapshot):
     """Initialize capacity and clamp p within [0, cap]."""
     global _cap_est, _p_target
     cap = getattr(cache_snapshot, "capacity", None)
     if isinstance(cap, int) and cap > 0:
         _cap_est = cap
     else:
         _cap_est = max(_cap_est, len(cache_snapshot.cache))
     if _cap_est <= 0:
         _cap_est = max(1, len(cache_snapshot.cache))
     if _p_target == 0.0 and not _T1_probation and not _T2_protected and not _B1_ghost and not _B2_ghost:
         _p_target = min(float(_cap_est), max(0.0, float(_cap_est) * _P_INIT_RATIO))
     if _p_target < 0.0:
         _p_target = 0.0
     if _p_target > float(_cap_est):
         _p_target = float(_cap_est)
 
 def _ghost_trim():
     """Bound ghosts by capacity."""
     while len(_B1_ghost) > _cap_est:
         _B1_ghost.popitem(last=False)
     while len(_B2_ghost) > _cap_est:
         _B2_ghost.popitem(last=False)
 
 def _maybe_age(cache_snapshot):
-    """Periodically age frequencies to avoid stale bias."""
-    global _last_age_tick
+    """Periodically age frequencies to avoid stale bias, and decay ghost-hit stats."""
+    global _last_age_tick, _ghost_b1_hits, _ghost_b2_hits
     _ensure_capacity(cache_snapshot)
     now = cache_snapshot.access_count
-    if now - _last_age_tick >= max(1, _cap_est):
+    # Age faster during scans / poor locality
+    interval = max(1, (_cap_est // 2) if (now <= _scan_until or _hit_ewma < 0.2) else _cap_est)
+    if now - _last_age_tick >= interval:
+        # Global freq halving
         for k in list(_freq.keys()):
             newf = _freq.get(k, 0) // 2
             if newf <= 0:
                 _freq.pop(k, None)
             else:
                 _freq[k] = newf
+        # Additionally shed the bottom 10% of T2 tail during poor locality
+        if _T2_protected and (now <= _scan_until or _hit_ewma < 0.2):
+            tail_count = max(1, int(0.1 * len(_T2_protected)))
+            cnt = 0
+            for k in _lru_iter(_T2_protected):
+                if cnt >= tail_count:
+                    break
+                fv = _freq.get(k, 0)
+                if fv > 0:
+                    _freq[k] = fv - 1
+                    if _freq[k] <= 0:
+                        _freq.pop(k, None)
+                cnt += 1
+        # Decay ghost hit counters
+        _ghost_b1_hits *= 0.5
+        _ghost_b2_hits *= 0.5
         _last_age_tick = now
 
 def _update_activity(is_hit, cache_snapshot):
     """Track recent hit/miss behavior and activate scan window if needed."""
     global _hit_ewma, _ins_ewma, _scan_until
     alpha = _EWMA_ALPHA
     _hit_ewma = (1.0 - alpha) * _hit_ewma + alpha * (1.0 if is_hit else 0.0)
     _ins_ewma = (1.0 - alpha) * _ins_ewma + alpha * (0.0 if is_hit else 1.0)
     if (_ins_ewma > _SCAN_TRIGGER_INS) and (_hit_ewma < _SCAN_TRIGGER_HIT):
         _scan_until = cache_snapshot.access_count + int(max(1, _SCAN_WINDOW_MULT * _cap_est))
 
 def _adjust_p(sign, step, now, freshness_scale=1.0, force=False):
-    """Momentum-based adjustment of ARC's p with cooldown and clamping."""
-    global _p_target, _p_momentum, _p_last_update_tick
-    # Throttle non-ghost adjustments to avoid oscillation
+    """Momentum-based adjustment of ARC's p with cooldown, sign-sensitive momentum, and clamping."""
+    global _p_target, _p_momentum, _p_last_update_tick, _last_p_sign
+    # Throttle non-ghost/background adjustments to avoid oscillation
     if not force:
         cool = max(1, int(max(1, _cap_est) // max(1, _P_COOLDOWN_DIV)))
         if now - _p_last_update_tick < cool:
             return
-    # Scale step by freshness and bound to 0.25*cap to avoid wild swings
-    bounded = min(max(1.0, float(step) * float(freshness_scale)), max(1.0, 0.25 * float(_cap_est)))
-    # Momentum update with clamp
-    _p_momentum = 0.5 * _p_momentum + float(sign) * bounded
+    # Î² controls aggressiveness: stronger for ghost-driven updates
+    beta = 0.7 if force else 0.3
+    eff_step = float(max(1.0, step)) * float(max(0.5, freshness_scale)) * beta
+    # Bound the step to avoid wild swings
+    eff_step = min(eff_step, max(1.0, 0.25 * float(_cap_est)))
+    # Reduce momentum on sign flip for stability
+    sgn = 1 if sign >= 0 else -1
+    if _last_p_sign != 0 and sgn != _last_p_sign:
+        _p_momentum *= 0.5
+    # Momentum update and clamp
+    _p_momentum = 0.5 * _p_momentum + sgn * eff_step
     max_mom = 0.25 * float(_cap_est)
     if _p_momentum > max_mom:
         _p_momentum = max_mom
     elif _p_momentum < -max_mom:
         _p_momentum = -max_mom
     # Apply and clamp p
     _p_target += _p_momentum
     if _p_target < 0.0:
         _p_target = 0.0
         _p_momentum = 0.0
     if _p_target > float(_cap_est):
         _p_target = float(_cap_est)
         _p_momentum = 0.0
     _p_last_update_tick = now
+    _last_p_sign = sgn
 
 def _fallback_choose(cache_snapshot):
     """LRU fallback using timestamps."""
     keys = list(cache_snapshot.cache.keys())
     if not keys:
         return None
     known = [(k, m_key_timestamp.get(k, None)) for k in keys]
     known_ts = [x for x in known if x[1] is not None]
     if known_ts:
         return min(known_ts, key=lambda kv: kv[1])[0]
     return keys[0]
 
 def _lru_iter(od):
     """Iterate keys from LRU to MRU for an OrderedDict."""
     for k in od.keys():
         yield k
 
 def _score_key(k):
     """Compute victim score: lower is better (less frequent, older)."""
     return (_freq.get(k, 0), m_key_timestamp.get(k, 0))
 
 def _pick_from(od, sample_n, cache_snapshot):
     """Pick victim from first few LRU entries by (freq asc, timestamp asc)."""
     if not od:
         return None
     cnt = 0
     best_k = None
     best_sc = None
     for k in _lru_iter(od):
         if k not in cache_snapshot.cache:
             continue
         sc = _score_key(k)
         if best_sc is None or sc < best_sc:
             best_sc = sc
             best_k = k
         cnt += 1
         if cnt >= sample_n:
             break
     return best_k
 
 def _demote_protected_if_needed(cache_snapshot, avoid_key=None):
-    """Keep T2 size within ARC target by demoting LRU entries to T1 MRU."""
+    """Keep T2 size within ARC target by demoting LRU entries to T1 MRU with median guard and shielding."""
     _ensure_capacity(cache_snapshot)
+    now = cache_snapshot.access_count
     t1_target = int(round(_p_target))
     t2_target = max(_cap_est - t1_target, 0)
     while len(_T2_protected) > t2_target:
-        # LRU of T2
-        lru = None
+        # Choose an eligible LRU candidate not shielded and not avoid_key
+        candidate = None
+        sample_keys = []
         for k in _lru_iter(_T2_protected):
-            if k != avoid_key and k in cache_snapshot.cache:
-                lru = k
+            if k == avoid_key or k not in cache_snapshot.cache:
+                continue
+            # Collect sample of LRU tail for median computation (up to 5)
+            if len(sample_keys) < 5:
+                sample_keys.append(k)
+            # Pick first eligible candidate that is not within no-demote shield
+            if candidate is None and now > _no_demote_until.get(k, 0):
+                candidate = k
+            # Stop if we have enough sample
+            if len(sample_keys) >= 5 and candidate is not None:
                 break
-        if lru is None:
+        if candidate is None:
             break
-        _T2_protected.pop(lru, None)
-        _T1_probation[lru] = True  # demoted MRU in T1
+        # Compute median freq and age across sample
+        if not sample_keys:
+            sample_keys = [candidate]
+        freqs = [ _freq.get(k, 0) for k in sample_keys ]
+        ages = [ max(0, now - m_key_timestamp.get(k, now)) for k in sample_keys ]
+        freqs_sorted = sorted(freqs)
+        ages_sorted = sorted(ages)
+        med_f = freqs_sorted[len(freqs_sorted)//2]
+        med_age = ages_sorted[len(ages_sorted)//2]
+        cand_f = _freq.get(candidate, 0)
+        cand_age = max(0, now - m_key_timestamp.get(candidate, now))
+        # Guard: only demote if truly cold relative to local tail distribution
+        if (cand_f <= med_f) and (cand_age >= med_age):
+            _T2_protected.pop(candidate, None)
+            _T1_probation[candidate] = True  # demoted MRU in T1
+        else:
+            break
 
 def evict(cache_snapshot, obj):
     '''
     Evict using ARC replace with dynamic sampling and scan bias:
     - Prefer T1 when |T1| > p or when upcoming key is in B2 and |T1| == p.
     - During scan window, always prefer T1 if non-empty.
     - Cross-segment override: pick the globally colder candidate by (freq, age) when reasonable.
     '''
     _ensure_capacity(cache_snapshot)
 
     t1_size = len(_T1_probation)
     t2_size = len(_T2_protected)
     x_in_b2 = (obj is not None) and (obj.key in _B2_ghost)
     choose_t1 = (t1_size >= 1) and ((x_in_b2 and t1_size == int(round(_p_target))) or (t1_size > _p_target))
 
     # Scan bias: keep evictions in probation when scanning
     if cache_snapshot.access_count <= _scan_until and t1_size > 0:
         choose_t1 = True
 
     # Adaptive sampling sizes based on pressure and scan
     cap = max(1, _cap_est)
     t1_pressure = (t1_size > _p_target + 0.1 * cap) or (cache_snapshot.access_count <= _scan_until)
     t2_pressure = (t2_size > (cap - int(round(_p_target)))) or False
 
     T1_SAMPLE = 1 if t1_pressure else 2
     if cache_snapshot.access_count <= _scan_until:
         T1_SAMPLE = 1
     T2_SAMPLE = 5 if t2_pressure else 3
     if _hit_ewma < 0.2:
         T2_SAMPLE = max(2, T2_SAMPLE - 1)
 
     # Sample candidates from both segments
     cand_t1 = _pick_from(_T1_probation, T1_SAMPLE, cache_snapshot) if t1_size > 0 else None
     cand_t2 = _pick_from(_T2_protected, T2_SAMPLE, cache_snapshot) if t2_size > 0 else None
 
     # Initial choice by ARC
     if choose_t1:
         victim_key = cand_t1 if cand_t1 is not None else cand_t2
     else:
         victim_key = cand_t2 if cand_t2 is not None else cand_t1
 
     # Cross-segment override: prefer globally colder by (freq asc, timestamp asc)
     if cand_t1 is not None and cand_t2 is not None:
         sc1 = _score_key(cand_t1)
         sc2 = _score_key(cand_t2)
-        min_seg = max(1, int(0.3 * cap))
-        # If ARC chose T1 but T2 candidate is strictly colder overall, and T2 has enough items, override
-        if choose_t1 and (sc2 < sc1) and (len(_T2_protected) > min_seg):
-            victim_key = cand_t2
-        # If ARC chose T2 but T1 candidate is strictly colder overall, and T1 has enough items, override
-        elif (not choose_t1) and (sc1 < sc2) and (len(_T1_probation) > min_seg):
-            victim_key = cand_t1
+        # Dynamic minimum segment occupancy
+        min_seg = max(1, int(0.2 * cap), int(0.5 * max(1, min(len(_T1_probation), len(_T2_protected)))))
+        # Stronger margin when locality is poor
+        freq_margin = 2 if _hit_ewma < 0.2 else _CROSS_EVICT_FREQ_MARGIN
+        # Ghost-ratio gating: if B2 ghost hits dominate, avoid draining T2
+        disable_t2_override = (_ghost_b2_hits > 1.2 * max(1.0, _ghost_b1_hits))
+
+        if choose_t1:
+            # If T2 candidate is strictly colder overall and T2 has enough items, override unless gated
+            if (sc2 < sc1) and (len(_T2_protected) > min_seg) and not disable_t2_override:
+                victim_key = cand_t2
+            else:
+                f1, f2 = sc1[0], sc2[0]
+                if (f2 + freq_margin < f1) and (len(_T2_protected) > min_seg) and not disable_t2_override:
+                    victim_key = cand_t2
         else:
-            # Fall back to frequency-gap rule (margin may be zero)
-            f1, f2 = sc1[0], sc2[0]
-            if choose_t1 and (f2 + _CROSS_EVICT_FREQ_MARGIN < f1) and (len(_T2_protected) > min_seg):
-                victim_key = cand_t2
-            elif (not choose_t1) and (f1 + _CROSS_EVICT_FREQ_MARGIN < f2) and (len(_T1_probation) > min_seg):
+            # If T1 candidate is strictly colder overall and T1 has enough items, override
+            if (sc1 < sc2) and (len(_T1_probation) > min_seg):
                 victim_key = cand_t1
+            else:
+                f1, f2 = sc1[0], sc2[0]
+                if (f1 + freq_margin < f2) and (len(_T1_probation) > min_seg):
+                    victim_key = cand_t1
 
     if victim_key is None:
         victim_key = _fallback_choose(cache_snapshot)
     return victim_key
 
 def update_after_hit(cache_snapshot, obj):
     '''
     On hit:
     - Update EWMA and age frequencies.
     - Increment frequency (saturating).
-    - Two-touch promotion from T1 when locality is poor (scan or low hit EWMA) or T1 is over target.
-    - Otherwise: first hit in T1 promotes to T2.
-    - Keep T2 within its ARC target via demotion.
+    - Two-touch promotion from T1 when locality is poor (scan or low hit EWMA) or T1 is over target,
+      with fast-promotion bypass if within grace window.
+    - Keep T2 within its ARC target via demotion (with guard).
     - Remove any ghost entries for this key.
     '''
     _ensure_capacity(cache_snapshot)
     _maybe_age(cache_snapshot)
     _update_activity(True, cache_snapshot)
 
     key = obj.key
     now = cache_snapshot.access_count
     m_key_timestamp[key] = now
     _freq[key] = min(_FREQ_MAX, _freq.get(key, 0) + 1)
 
     in_scan = now <= _scan_until
     t1_over = len(_T1_probation) > int(round(_p_target))
     poor_locality = (_hit_ewma < 0.2)
 
     if key in _T2_protected:
         _T2_protected.move_to_end(key, last=True)
     elif key in _T1_probation:
-        require_two_touch = in_scan or t1_over or poor_locality
-        if require_two_touch and _freq.get(key, 0) < 2:
-            # Keep in T1 and move to MRU until proven by second touch
-            _T1_probation.move_to_end(key, last=True)
-        else:
-            # Promote to protected
+        # Fast-promotion grace: bypass two-touch if within window
+        if now <= _fast_promote_until.get(key, 0):
             _T1_probation.pop(key, None)
             _T2_protected[key] = True
+            _fast_promote_until.pop(key, None)
+            _no_demote_until[key] = now + max(1, int(_FRESH_WINDOW_RATIO * _cap_est))
+        else:
+            require_two_touch = in_scan or t1_over or poor_locality
+            if require_two_touch and _freq.get(key, 0) < 2:
+                # Keep in T1 and move to MRU until proven by second touch
+                _T1_probation.move_to_end(key, last=True)
+            else:
+                # Promote to protected
+                _T1_probation.pop(key, None)
+                _T2_protected[key] = True
+                _no_demote_until[key] = now + max(1, int(_FRESH_WINDOW_RATIO * _cap_est))
     else:
-        # Metadata miss: treat as hot and place in T2
+        # Metadata miss: treat as hot and place in T2 with short no-demote shield
         _T2_protected[key] = True
+        _no_demote_until[key] = now + max(1, int(_FRESH_WINDOW_RATIO * _cap_est))
 
     _demote_protected_if_needed(cache_snapshot, avoid_key=key)
 
     # Ghost cleanup
     if key in _B1_ghost:
         _B1_ghost.pop(key, None)
     if key in _B2_ghost:
         _B2_ghost.pop(key, None)
     _ghost_trim()
 
 def update_after_insert(cache_snapshot, obj):
     '''
     On miss and insert:
     - Update EWMA and age frequencies.
-    - If key in ghosts: momentum-adjust p; fresh ghosts re-admit to T2 (seed freq), stale to T1.
-    - Else: insert to T1; during guard/scan or poor locality, place at T1 LRU; gently lower p in these phases (with cooldown).
+    - If key in ghosts: momentum-adjust p using freshness-weighted steps; admit based on freshness tiers.
+    - Else: insert to T1; during guard/scan or poor locality, place at T1 LRU and gently lower p (cooldowned).
     '''
     _ensure_capacity(cache_snapshot)
     _maybe_age(cache_snapshot)
     _update_activity(False, cache_snapshot)
 
     key = obj.key
     now = cache_snapshot.access_count
     m_key_timestamp[key] = now
 
     in_b1 = key in _B1_ghost
     in_b2 = key in _B2_ghost
 
     fresh_window = max(1, int(_FRESH_WINDOW_RATIO * _cap_est))
 
     if in_b1 or in_b2:
-        # Compute step based on opposing ghost sizes
+        # Compute freshness w in [0,1]
         if in_b1:
-            step = max(1.0, float(len(_B2_ghost)) / max(1.0, float(len(_B1_ghost))))
             ev_ts = _B1_ghost.get(key, None)
             age = (now - ev_ts) if isinstance(ev_ts, int) else (fresh_window + 1)
-            fresh = age <= fresh_window
-            _adjust_p(+1, step, now, freshness_scale=(1.2 if fresh else 1.0), force=True)
+            w = max(0.0, min(1.0, 1.0 - (age / float(max(1, fresh_window)))))
+            # Record recent ghost hit mix
+            global _ghost_b1_hits
+            _ghost_b1_hits += 1.0
+            # Step based on opposing ghost sizes and freshness; damp during scans
+            base = max(1.0, float(len(_B2_ghost)) / max(1.0, float(len(_B1_ghost))))
+            step = base * (1.0 + 2.0 * w)
+            if now <= _scan_until:
+                step *= 0.5
+            _adjust_p(+1, step, now, freshness_scale=(1.0 + w), force=True)
             _B1_ghost.pop(key, None)
-            if fresh:
-                # Admit to T2 as recently valuable
+            # Freshness-tiered readmission
+            if w >= 0.66:
                 _T2_protected[key] = True
-                _freq[key] = max(3, min(_FREQ_MAX, _freq.get(key, 0) + 2))
+                _freq[key] = max(_freq.get(key, 0), min(_FREQ_MAX, 1 + int(round(4 * w))))
+                _no_demote_until[key] = now + fresh_window
                 _demote_protected_if_needed(cache_snapshot, avoid_key=key)
+            elif w >= 0.33:
+                _T1_probation[key] = True
+                _fast_promote_until[key] = now + fresh_window
+                _freq[key] = max(_freq.get(key, 0), 1)
             else:
                 _T1_probation[key] = True
-                _freq[key] = _freq.get(key, 0)
+                _T1_probation.move_to_end(key, last=False)
         else:
-            step = max(1.0, float(len(_B1_ghost)) / max(1.0, float(len(_B2_ghost))))
             ev_ts = _B2_ghost.get(key, None)
             age = (now - ev_ts) if isinstance(ev_ts, int) else (fresh_window + 1)
-            fresh = age <= fresh_window
-            _adjust_p(-1, step, now, freshness_scale=(1.2 if fresh else 1.0), force=True)
+            w = max(0.0, min(1.0, 1.0 - (age / float(max(1, fresh_window)))))
+            # Record recent ghost hit mix
+            global _ghost_b2_hits
+            _ghost_b2_hits += 1.0
+            # Step based on opposing ghost sizes and freshness; amplify during scans
+            base = max(1.0, float(len(_B1_ghost)) / max(1.0, float(len(_B2_ghost))))
+            step = base * (1.0 + 2.0 * w)
+            if now <= _scan_until:
+                step *= 1.2
+            _adjust_p(-1, step, now, freshness_scale=(1.0 + w), force=True)
             _B2_ghost.pop(key, None)
-            if fresh:
+            if w >= 0.66:
                 _T2_protected[key] = True
-                _freq[key] = max(3, min(_FREQ_MAX, _freq.get(key, 0) + 2))
+                _freq[key] = max(_freq.get(key, 0), min(_FREQ_MAX, 1 + int(round(4 * w))))
+                _no_demote_until[key] = now + fresh_window
                 _demote_protected_if_needed(cache_snapshot, avoid_key=key)
+            elif w >= 0.33:
+                _T1_probation[key] = True
+                _fast_promote_until[key] = now + fresh_window
+                _freq[key] = max(_freq.get(key, 0), 1)
             else:
                 _T1_probation[key] = True
-                _freq[key] = _freq.get(key, 0)
     else:
         # New key: insert into T1
         _T1_probation[key] = True
         _freq[key] = _freq.get(key, 0)
         # Guard, scan and poor-locality handling: bias newcomer colder
         t1_over = len(_T1_probation) > int(round(_p_target))
         poor_locality = (_hit_ewma < 0.2)
         if (_last_victim_strength >= _VICTIM_GUARD_THRESH) or (now <= _scan_until) or poor_locality or t1_over:
             _T1_probation.move_to_end(key, last=False)
             # Gently lower p in scan or poor-locality phases to keep pressure in T1 (cooldowned)
             if (now <= _scan_until) or poor_locality:
                 _adjust_p(-1, max(1.0, 0.05 * float(_cap_est)), now, force=False)
 
     # Avoid duplicates across structures
     if key in _T1_probation and key in _T2_protected:
         _T1_probation.pop(key, None)
     if key in _B1_ghost:
         _B1_ghost.pop(key, None)
     if key in _B2_ghost:
         _B2_ghost.pop(key, None)
     _ghost_trim()
 
 def update_after_evict(cache_snapshot, obj, evicted_obj):
     '''
     After eviction:
     - Remove from resident segment and put into the appropriate ghost with timestamp.
     - Track victim strength and set a short admission guard when a strong T2 victim is evicted.
-    - Clean frequency and timestamp entries.
+    - Clean frequency and timestamp entries and any transient shields.
     '''
     _ensure_capacity(cache_snapshot)
     key = evicted_obj.key
     now = cache_snapshot.access_count
 
     was_t1 = key in _T1_probation
     was_t2 = key in _T2_protected
 
     fval = _freq.get(key, 0)
     strength = float(fval) + (2.0 if was_t2 else 0.0)
     global _last_victim_strength, _guard_until
     _last_victim_strength = strength
 
     if was_t1:
         _T1_probation.pop(key, None)
         _B1_ghost[key] = now
     elif was_t2:
         _T2_protected.pop(key, None)
         _B2_ghost[key] = now
         if fval >= 2:
             _guard_until = now + max(1, _cap_est // 2)
     else:
         # Unknown residency; default to B1 ghost
         _B1_ghost[key] = now
 
+    # Clear per-key auxiliary state
     m_key_timestamp.pop(key, None)
     _freq.pop(key, None)
+    _fast_promote_until.pop(key, None)
+    _no_demote_until.pop(key, None)
     _ghost_trim()
 # EVOLVE-BLOCK-END
 
 # This part remains fixed (not evolved)
 def run_caching(trace_path: str, copy_code_dst: str):
     """Run the caching algorithm on a trace"""
     import os
     with open(os.path.abspath(__file__), 'r', encoding="utf-8") as f:
         code_str = f.read()
     with open(os.path.join(copy_code_dst), 'w') as f:
         f.write(code_str)
     from cache_utils import Cache, CacheConfig, CacheObj, Trace
     trace = Trace(trace_path=trace_path)
     cache_capacity = max(int(trace.get_ndv() * 0.1), 1)
     cache = Cache(CacheConfig(cache_capacity))
     for entry in trace.entries:
         obj = CacheObj(key=str(entry.key))
         cache.get(obj)
     with open(copy_code_dst, 'w') as f:
         f.write("")
     hit_rate = round(cache.hit_count / cache.access_count, 6)
     return hit_rate