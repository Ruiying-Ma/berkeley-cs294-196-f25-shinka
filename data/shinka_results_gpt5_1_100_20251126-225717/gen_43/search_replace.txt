<NAME>
arc_plus_fresh_ghosts_guarded_promo
</NAME>

<DESCRIPTION>
I propose three synergistic improvements grounded in cache replacement research to further lower miss rates:

1) Freshness-aware ghost re-admission: Store timestamps in B1/B2 ghosts and only admit ghost hits directly into protected (T2) when their ghost is fresh (age â‰¤ ~cap/2). Stale ghosts re-enter via probation (T1). This reduces over-protection of old items, improving phase adaptability.

2) Guarded promotion and p-bias after strong evictions: When a strong protected item is evicted (our existing guard), for the duration of the guard window, require two touches before promoting T1 items to T2 and modestly bias REPLACE to evict from T1. This resists scan pollution and protects hot sets during adverse phases.

3) Smarter demotion when protected exceeds target: Instead of demoting the single LRU blindly, sample a few oldest T2 candidates and demote the lowest-frequency/oldest among them. This preserves truly hot items in T2 while still honoring target sizes.

These changes are small and consistent with the existing ARC/SLRU framework, requiring only local updates to evict/update functions and minor metadata changes. They should improve robustness across mixed workloads without adding heavy overhead.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
# Eviction sampling (number of LRU candidates to compare by frequency)
_T1_SAMPLE = 2
_T2_SAMPLE = 3
=======
# Eviction sampling (number of LRU candidates to compare by frequency)
_T1_SAMPLE = 2
_T2_SAMPLE = 3
# Demotion sampling for protected overflow
_DEMOTE_SAMPLE = 3
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
def _demote_protected_if_needed(cache_snapshot, avoid_key=None):
    """Ensure protected size does not exceed its ARC target by demoting LRU to T1."""
    _, t2_target = _get_targets(cache_snapshot)
    if t2_target <= 0:
        return
    # Demote until within target
    while len(_T2_protected) > t2_target:
        # Find the LRU that is not the avoid_key
        chosen = None
        for k in _T2_protected.keys():
            if avoid_key is not None and k == avoid_key:
                continue
            chosen = k
            break
        if chosen is None:
            break
        _T2_protected.pop(chosen, None)
        _T1_probation[chosen] = True  # demoted reinserted as MRU in T1
=======
def _demote_protected_if_needed(cache_snapshot, avoid_key=None):
    """Ensure protected size does not exceed its ARC target by demoting low-quality LRU to T1."""
    _, t2_target = _get_targets(cache_snapshot)
    if t2_target <= 0:
        return
    # Demote until within target
    while len(_T2_protected) > t2_target:
        # Sample a few oldest (LRU side) excluding avoid_key, choose by (freq asc, timestamp asc)
        candidates = []
        for k in _T2_protected.keys():
            if avoid_key is not None and k == avoid_key:
                continue
            if k in m_key_timestamp:
                candidates.append(k)
            else:
                candidates.append(k)
            if len(candidates) >= _DEMOTE_SAMPLE:
                break
        if not candidates:
            break
        def demote_score(k):
            return (_freq.get(k, 0), m_key_timestamp.get(k, 0))
        chosen = min(candidates, key=demote_score)
        _T2_protected.pop(chosen, None)
        _T1_probation[chosen] = True  # demoted reinserted as MRU in T1
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
def evict(cache_snapshot, obj):
    '''
    Choose victim key using adaptive ARC-like policy with small frequency-aware sampling.
    REPLACE(x): if |T1|>=1 and ((x in B2 and |T1| == p) or |T1| > p) -> evict from T1 else from T2.
    Within the chosen segment, pick the lowest-frequency among a few LRU candidates.
    '''
    _ensure_capacity(cache_snapshot)

    t1_size = len(_T1_probation)
    t2_size = len(_T2_protected)
    x_in_b2 = (obj is not None) and (obj.key in _B2_ghost)
    p_int = int(round(_p_target))
    choose_t1 = (t1_size >= 1) and ((x_in_b2 and t1_size == p_int) or (t1_size > _p_target))

    # Dynamic sampling based on segment pressure
    _, t2_target = _get_targets(cache_snapshot)
    t1_pressure = t1_size > (int(round(_p_target)) + max(1, _cap_est // 10))
    t1_sample = 1 if t1_pressure else _T1_SAMPLE
    t2_sample = 5 if t2_size > t2_target else _T2_SAMPLE

    def _pick_from(od, sample_n):
        # Sample the first few LRU keys that are present in cache and pick by (freq asc, timestamp asc)
        if not od:
            return None
        candidates = []
        for k in od.keys():
            if k in cache_snapshot.cache:
                candidates.append(k)
                if len(candidates) >= sample_n:
                    break
        if not candidates:
            return None
        def score(k):
            # Lower freq better; older (smaller timestamp) better
            return (_freq.get(k, 0), m_key_timestamp.get(k, 0))
        return min(candidates, key=score)

    victim_key = None
    if choose_t1 and t1_size > 0:
        victim_key = _pick_from(_T1_probation, t1_sample)
    if victim_key is None and t2_size > 0:
        victim_key = _pick_from(_T2_protected, t2_sample)
    if victim_key is None and t1_size > 0:
        victim_key = _pick_from(_T1_probation, t1_sample)
    if victim_key is None:
        # Fallback to global LRU if metadata desync
        victim_key = _fallback_choose(cache_snapshot)
    return victim_key
=======
def evict(cache_snapshot, obj):
    '''
    Choose victim key using adaptive ARC-like policy with small frequency-aware sampling.
    REPLACE(x): if |T1|>=1 and ((x in B2 and |T1| == p) or |T1| > p) -> evict from T1 else from T2.
    Additionally, during a guard window (after evicting a strong protected item), prefer evicting from T1.
    Within the chosen segment, pick the lowest-frequency among a few LRU candidates.
    '''
    _ensure_capacity(cache_snapshot)

    t1_size = len(_T1_probation)
    t2_size = len(_T2_protected)
    x_in_b2 = (obj is not None) and (obj.key in _B2_ghost)
    p_int = int(round(_p_target))
    choose_t1 = (t1_size >= 1) and ((x_in_b2 and t1_size == p_int) or (t1_size > _p_target))
    # Guard window: tilt eviction toward T1 to protect hot T2 during scans/phase shifts
    if (t1_size >= 1) and (cache_snapshot.access_count <= _guard_until):
        choose_t1 = True

    # Dynamic sampling based on segment pressure
    _, t2_target = _get_targets(cache_snapshot)
    t1_pressure = t1_size > (int(round(_p_target)) + max(1, _cap_est // 10))
    t1_sample = 1 if t1_pressure else _T1_SAMPLE
    t2_sample = 5 if t2_size > t2_target else _T2_SAMPLE

    def _pick_from(od, sample_n):
        # Sample the first few LRU keys that are present in cache and pick by (freq asc, timestamp asc)
        if not od:
            return None
        candidates = []
        for k in od.keys():
            if k in cache_snapshot.cache:
                candidates.append(k)
                if len(candidates) >= sample_n:
                    break
        if not candidates:
            return None
        def score(k):
            # Lower freq better; older (smaller timestamp) better
            return (_freq.get(k, 0), m_key_timestamp.get(k, 0))
        return min(candidates, key=score)

    victim_key = None
    if choose_t1 and t1_size > 0:
        victim_key = _pick_from(_T1_probation, t1_sample)
    if victim_key is None and t2_size > 0:
        victim_key = _pick_from(_T2_protected, t2_sample)
    if victim_key is None and t1_size > 0:
        victim_key = _pick_from(_T1_probation, t1_sample)
    if victim_key is None:
        # Fallback to global LRU if metadata desync
        victim_key = _fallback_choose(cache_snapshot)
    return victim_key
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
def update_after_hit(cache_snapshot, obj):
    '''
    Update metadata after cache hit.
    - If hit in probation (T1), promote to protected (T2).
    - If hit in protected, refresh recency.
    - Maintain fallback timestamp map and per-key frequency.
    '''
    _ensure_capacity(cache_snapshot)
    _maybe_age(cache_snapshot)
    key = obj.key
    # Update fallback LRU timestamp
    m_key_timestamp[key] = cache_snapshot.access_count
    # Increment frequency counter
    _freq[key] = _freq.get(key, 0) + 1

    # If the key exists in our segments, update positions
    if key in _T2_protected:
        # Refresh to MRU
        _T2_protected.move_to_end(key, last=True)
    elif key in _T1_probation:
        # Promote from probation to protected
        _T1_probation.pop(key, None)
        _T2_protected[key] = True  # insert as MRU
    else:
        # Metadata miss: cache has it but we don't; treat as frequent and add to protected
        _T2_protected[key] = True

    # Enforce protected target by demoting its LRU if needed
    _demote_protected_if_needed(cache_snapshot, avoid_key=key)

    # Touch ghosts cleanup if any stale
    if key in _B1_ghost:
        _B1_ghost.pop(key, None)
    if key in _B2_ghost:
        _B2_ghost.pop(key, None)
    _ghost_trim()
=======
def update_after_hit(cache_snapshot, obj):
    '''
    Update metadata after cache hit.
    - If hit in probation (T1), promote to protected (T2) unless guard window requires two touches.
    - If hit in protected, refresh recency.
    - Maintain fallback timestamp map and per-key frequency.
    '''
    _ensure_capacity(cache_snapshot)
    _maybe_age(cache_snapshot)
    key = obj.key
    now = cache_snapshot.access_count
    # Update fallback LRU timestamp
    m_key_timestamp[key] = now
    # Increment frequency counter
    _freq[key] = _freq.get(key, 0) + 1

    # If the key exists in our segments, update positions
    if key in _T2_protected:
        # Refresh to MRU
        _T2_protected.move_to_end(key, last=True)
    elif key in _T1_probation:
        # During guard window, require two touches to promote to protect T2
        if now <= _guard_until and _freq.get(key, 0) < 2:
            # Refresh within T1
            try:
                _T1_probation.move_to_end(key, last=True)
            except Exception:
                # Fallback: remove+reinsert at MRU
                _T1_probation.pop(key, None)
                _T1_probation[key] = True
        else:
            # Promote from probation to protected
            _T1_probation.pop(key, None)
            _T2_protected[key] = True  # insert as MRU
    else:
        # Metadata miss: cache has it but we don't; treat as frequent and add to protected
        _T2_protected[key] = True

    # Enforce protected target by demoting its LRU if needed
    _demote_protected_if_needed(cache_snapshot, avoid_key=key)

    # Touch ghosts cleanup if any stale
    if key in _B1_ghost:
        _B1_ghost.pop(key, None)
    if key in _B2_ghost:
        _B2_ghost.pop(key, None)
    _ghost_trim()
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
def update_after_insert(cache_snapshot, obj):
    '''
    Update metadata on insertion (cache miss path).
    - If the key is in ghost lists, adjust p (ARC adaptation) and insert into protected.
    - Otherwise insert into probation as MRU, unless guarded by a strong last victim (insert at LRU).
    - Maintain fallback timestamp map and seed frequency.
    '''
    _ensure_capacity(cache_snapshot)
    _maybe_age(cache_snapshot)
    key = obj.key
    now = cache_snapshot.access_count
    m_key_timestamp[key] = now

    in_b1 = key in _B1_ghost
    in_b2 = key in _B2_ghost

    if in_b1 or in_b2:
        # ARC adaptation of p (smooth float-based steps)
        global _p_target
        if in_b1:
            # Favor recency: increase p
            inc = max(1.0, float(len(_B2_ghost)) / max(1.0, float(len(_B1_ghost))))
            _p_target = min(float(_cap_est), _p_target + float(inc))
            _B1_ghost.pop(key, None)
        else:
            # Favor frequency: decrease p
            dec = max(1.0, float(len(_B1_ghost)) / max(1.0, float(len(_B2_ghost))))
            _p_target = max(0.0, _p_target - float(dec))
            _B2_ghost.pop(key, None)
        # Insert into protected (seen before, effectively 2nd touch)
        if key in _T1_probation:
            _T1_probation.pop(key, None)
        _T2_protected[key] = True
        # Seed frequency as at least 2 for re-referenced keys
        _freq[key] = max(_freq.get(key, 0) + 1, 2)

        # Keep protected within its target by demoting its LRU if necessary
        _demote_protected_if_needed(cache_snapshot, avoid_key=key)
    else:
        # New to cache and ghosts: insert into probation (T1)
        if key in _T2_protected:
            # Rare desync; ensure consistency (shouldn't happen on miss)
            _T2_protected.move_to_end(key, last=True)
        else:
            _T1_probation[key] = True
            # Admission guard: if last victim was strong OR we are within guard window, bias newcomer cold
            if (_last_victim_strength >= _VICTIM_GUARD_THRESH) or (now <= _guard_until):
                _T1_probation.move_to_end(key, last=False)
        # Seed minimal frequency for new items
        _freq[key] = _freq.get(key, 0)

    # Avoid duplicates across structures
    if key in _T1_probation and key in _T2_protected:
        _T1_probation.pop(key, None)
    if key in _B1_ghost:
        _B1_ghost.pop(key, None)
    if key in _B2_ghost:
        _B2_ghost.pop(key, None)
    _ghost_trim()
=======
def update_after_insert(cache_snapshot, obj):
    '''
    Update metadata on insertion (cache miss path).
    - If the key is in ghost lists, adjust p (ARC adaptation) and insert into protected only if its ghost is fresh.
    - Otherwise insert into probation as MRU, unless guarded by a strong last victim (insert at LRU).
    - Maintain fallback timestamp map and seed frequency.
    '''
    _ensure_capacity(cache_snapshot)
    _maybe_age(cache_snapshot)
    key = obj.key
    now = cache_snapshot.access_count
    m_key_timestamp[key] = now

    in_b1 = key in _B1_ghost
    in_b2 = key in _B2_ghost

    if in_b1 or in_b2:
        # ARC adaptation of p (smooth float-based steps)
        global _p_target
        last = None
        if in_b1:
            # Favor recency: increase p
            inc = max(1.0, float(len(_B2_ghost)) / max(1.0, float(len(_B1_ghost))))
            _p_target = min(float(_cap_est), _p_target + float(inc))
            last = _B1_ghost.pop(key, None)
        else:
            # Favor frequency: decrease p
            dec = max(1.0, float(len(_B1_ghost)) / max(1.0, float(len(_B2_ghost))))
            _p_target = max(0.0, _p_target - float(dec))
            last = _B2_ghost.pop(key, None)

        # Freshness-aware admission: only place directly into T2 if ghost is fresh and not in guard window
        age = (now - last) if isinstance(last, int) else (_cap_est * 10)
        fresh = age <= max(1, _cap_est // 2)
        if fresh and not (now <= _guard_until):
            if key in _T1_probation:
                _T1_probation.pop(key, None)
            _T2_protected[key] = True
            # Seed stronger frequency on re-admission
            _freq[key] = max(_freq.get(key, 0) + 1, 2)
            # Keep protected within its target by demoting its LRU if necessary
            _demote_protected_if_needed(cache_snapshot, avoid_key=key)
        else:
            # Stale ghost or during guard: insert into T1
            _T1_probation[key] = True
            _freq.setdefault(key, 0)
            # Bias new insertions during guard by slightly decreasing p to prefer T1
            if now <= _guard_until:
                _p_target = max(0.0, _p_target - 1.0)
    else:
        # New to cache and ghosts: insert into probation (T1)
        if key in _T2_protected:
            # Rare desync; ensure consistency (shouldn't happen on miss)
            _T2_protected.move_to_end(key, last=True)
        else:
            _T1_probation[key] = True
            # Admission guard: if last victim was strong OR we are within guard window, bias newcomer cold
            if (_last_victim_strength >= _VICTIM_GUARD_THRESH) or (now <= _guard_until):
                _T1_probation.move_to_end(key, last=False)
        # Seed minimal frequency for new items
        _freq[key] = _freq.get(key, 0)

    # Avoid duplicates across structures
    if key in _T1_probation and key in _T2_protected:
        _T1_probation.pop(key, None)
    if key in _B1_ghost:
        _B1_ghost.pop(key, None)
    if key in _B2_ghost:
        _B2_ghost.pop(key, None)
    _ghost_trim()
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    Update metadata after eviction.
    - Remove victim from its resident segment.
    - Add to corresponding ghost list (B1 if from probation, B2 if from protected).
    - Track last victim strength for admission guard and enable a short guard window if needed.
    - Trim ghost lists to capacity and clean timestamps/frequency.
    '''
    _ensure_capacity(cache_snapshot)
    victim_key = evicted_obj.key

    was_t1 = victim_key in _T1_probation
    was_t2 = victim_key in _T2_protected

    # Track strength of the evicted item before removing counters
    fval = _freq.get(victim_key, 0)
    base_strength = float(fval)
    if was_t2:
        base_strength += 2.0  # extra credit for protected residency
    global _last_victim_strength, _guard_until
    _last_victim_strength = base_strength

    # Remove from resident segments and add to ghosts
    if was_t1:
        _T1_probation.pop(victim_key, None)
        _B1_ghost[victim_key] = True  # insert as MRU
    elif was_t2:
        _T2_protected.pop(victim_key, None)
        _B2_ghost[victim_key] = True  # insert as MRU
        # If we had to evict a strong protected item, enable a short guard window
        if fval >= 2:
            _guard_until = cache_snapshot.access_count + max(1, _cap_est // 2)
    else:
        # Unknown location; put in B1 by default
        _B1_ghost[victim_key] = True

    # Remove fallback timestamp and frequency for evicted key
    if victim_key in m_key_timestamp:
        m_key_timestamp.pop(victim_key, None)
    if victim_key in _freq:
        _freq.pop(victim_key, None)

    # If inserting obj is accidentally in ghosts, let insert handle cleanup next
    _ghost_trim()
=======
def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    Update metadata after eviction.
    - Remove victim from its resident segment.
    - Add to corresponding ghost list (B1 if from probation, B2 if from protected) with timestamp.
    - Track last victim strength for admission guard and enable a short guard window if needed.
    - Trim ghost lists to capacity and clean timestamps/frequency.
    '''
    _ensure_capacity(cache_snapshot)
    victim_key = evicted_obj.key
    now = cache_snapshot.access_count

    was_t1 = victim_key in _T1_probation
    was_t2 = victim_key in _T2_protected

    # Track strength of the evicted item before removing counters
    fval = _freq.get(victim_key, 0)
    base_strength = float(fval)
    if was_t2:
        base_strength += 2.0  # extra credit for protected residency
    global _last_victim_strength, _guard_until
    _last_victim_strength = base_strength

    # Remove from resident segments and add to ghosts with timestamp
    if was_t1:
        _T1_probation.pop(victim_key, None)
        _B1_ghost[victim_key] = now  # insert as MRU with timestamp
    elif was_t2:
        _T2_protected.pop(victim_key, None)
        _B2_ghost[victim_key] = now  # insert as MRU with timestamp
        # If we had to evict a strong protected item, enable a short guard window
        if fval >= 2:
            _guard_until = now + max(1, _cap_est // 2)
    else:
        # Unknown location; put in B1 by default
        _B1_ghost[victim_key] = now

    # Remove fallback timestamp and frequency for evicted key
    if victim_key in m_key_timestamp:
        m_key_timestamp.pop(victim_key, None)
    if victim_key in _freq:
        _freq.pop(victim_key, None)

    # If inserting obj is accidentally in ghosts, let insert handle cleanup next
    _ghost_trim()
>>>>>>> REPLACE

</DIFF>