--- a/original.py
+++ b/original.py
@@ -1,172 +1,237 @@
 # EVOLVE-BLOCK-START
 """Cache eviction algorithm for optimizing hit rates across multiple workloads"""
 
 # Segmented LRU (2Q-like) with a protected quota (SLRU-style) and conditional two-touch promotion:
 # - Newly inserted objects go to probationary.
 # - Promote to protected on hit; if protected is at/over target, require two touches to promote.
 # - Demote protected LRU when protected exceeds target to keep a healthy probation space.
-# - Evict: if protected exceeds target, evict protected LRU; else evict probation LRU first.
+# - Evict: if protected exceeds target, evict protected LRU; else evict probation LRU first with age-aware override.
 m_ts = dict()                  # key -> last access timestamp
 m_probation = set()            # keys seen once (recently inserted)
 m_protected = set()            # keys with demonstrated reuse (promoted on hit)
 
 # Protected quota control
 m_target_protected = None      # target number of protected entries
 m_last_capacity = None         # last observed capacity (to re-init when changed)
 m_probation_hits = dict()      # key -> hit count while in probation (for two-touch when needed)
+
+# Lightweight ARC-style ghost histories to adapt protected target
+m_ghost_probation = dict()     # key -> eviction timestamp (from probation)
+m_ghost_protected = dict()     # key -> eviction timestamp (from protected)
+m_GHOST_LIMIT_MULT = 2         # keep up to 2x capacity ghosts
 
 def _init_targets(cache_snapshot):
     global m_target_protected, m_last_capacity
     cap = cache_snapshot.capacity or max(len(cache_snapshot.cache), 1)
     if m_target_protected is None or m_last_capacity != cap:
         m_target_protected = max(1, int(0.5 * cap))  # start balanced (50% protected)
         m_last_capacity = cap
 
 def _oldest_key(candidates):
     # Return the key with the smallest timestamp among candidates
     return min(candidates, key=lambda k: m_ts.get(k, -1))
 
 def _enforce_protected_quota():
     # Demote LRU from protected to probation until target is met
     while m_target_protected is not None and len(m_protected) > m_target_protected:
         demote_key = _oldest_key(m_protected)
         m_protected.discard(demote_key)
         m_probation.add(demote_key)
         m_probation_hits.setdefault(demote_key, 0)
 
 def evict(cache_snapshot, obj):
     '''
     This function defines how the algorithm chooses the eviction victim.
     - Args:
         - `cache_snapshot`: A snapshot of the current cache state.
         - `obj`: The new object that needs to be inserted into the cache.
     - Return:
         - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
     '''
     global m_ts, m_probation, m_protected
     _init_targets(cache_snapshot)
 
     keys_in_cache = set(cache_snapshot.cache.keys())
 
     # Keep metadata consistent with actual cache content
     if m_probation:
         m_probation.intersection_update(keys_in_cache)
     if m_protected:
         m_protected.intersection_update(keys_in_cache)
     if m_ts:
         for k in list(m_ts.keys()):
             if k not in keys_in_cache:
                 m_ts.pop(k, None)
                 m_probation.discard(k)
                 m_protected.discard(k)
                 m_probation_hits.pop(k, None)
 
     probation_candidates = m_probation & keys_in_cache
     protected_candidates = m_protected & keys_in_cache
 
+    cap = m_last_capacity or max(len(cache_snapshot.cache), 1)
+    now = cache_snapshot.access_count
+
     # If protected is oversized vs target, evict its oldest to reduce over-protection.
     if protected_candidates and m_target_protected is not None and len(m_protected) > m_target_protected:
         return _oldest_key(protected_candidates)
-    # Prefer evicting from probationary segment to avoid polluting protected items
+
+    # If both segments have candidates, use age-aware override: evict from protected
+    # when its LRU is much staler than probation's LRU (prevents stale protected pollution).
+    if probation_candidates and protected_candidates:
+        prob_key = _oldest_key(probation_candidates)
+        prot_key = _oldest_key(protected_candidates)
+        tp = m_ts.get(prob_key, now)
+        tr = m_ts.get(prot_key, now)
+        age_prob = now - tp
+        age_prot = now - tr
+        slack = max(1, cap // 2)          # relative slack
+        stale_abs = max(1, cap)           # absolute staleness threshold
+        if (age_prot > age_prob + slack) or (age_prot > stale_abs):
+            return prot_key
+        else:
+            return prob_key
+
+    # Otherwise prefer evicting from probation; if empty, evict from protected.
     if probation_candidates:
         return _oldest_key(probation_candidates)
     if protected_candidates:
         return _oldest_key(protected_candidates)
 
     # Fallback: evict the globally oldest if segmentation hasn't been set yet
     if keys_in_cache:
         return _oldest_key(keys_in_cache)
     return None
 
 def update_after_hit(cache_snapshot, obj):
     '''
     This function defines how the algorithm update the metadata it maintains immediately after a cache hit.
     - Args:
         - `cache_snapshot`: A snapshot of the current cache state.
         - `obj`: The object accessed during the cache hit.
     - Return: `None`
     '''
     global m_ts, m_probation, m_protected, m_probation_hits
     _init_targets(cache_snapshot)
     now = cache_snapshot.access_count
     key = obj.key
 
     # Ensure timestamp exists
     if key not in m_ts:
         m_ts[key] = now
 
     # Conditional promotion: if protected is at/over target, require two touches in probation
     if key in m_probation:
         m_probation_hits[key] = m_probation_hits.get(key, 0) + 1
         needs_two = (m_target_protected is not None and len(m_protected) >= m_target_protected)
         if (not needs_two) or (m_probation_hits[key] >= 2):
             m_probation.discard(key)
             m_protected.add(key)
             m_probation_hits.pop(key, None)
             # Enforce quota in case we exceeded it due to promotion
             _enforce_protected_quota()
     elif key not in m_protected:
         # If metadata was missing, treat as protected to avoid premature eviction
         m_protected.add(key)
         _enforce_protected_quota()
 
     # Update recency timestamp
     m_ts[key] = now
 
 def update_after_insert(cache_snapshot, obj):
     '''
     This function defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
     - Args:
         - `cache_snapshot`: A snapshot of the current cache state.
         - `obj`: The object that was just inserted into the cache.
     - Return: `None`
     '''
     global m_ts, m_probation, m_protected, m_probation_hits
+    global m_ghost_probation, m_ghost_protected, m_target_protected
     _init_targets(cache_snapshot)
     now = cache_snapshot.access_count
     key = obj.key
+    cap = m_last_capacity or max(len(cache_snapshot.cache), 1)
+
+    # ARC-like adaptation based on ghost re-reference
+    step = max(1, cap // 16)
+    if key in m_ghost_protected:
+        m_target_protected = min(cap, m_target_protected + step)
+        m_ghost_protected.pop(key, None)
+    elif key in m_ghost_probation:
+        m_target_protected = max(1, m_target_protected - step)
+        m_ghost_probation.pop(key, None)
 
     # New insert starts in probationary segment
     m_ts[key] = now
     m_protected.discard(key)
     m_probation.add(key)
     m_probation_hits[key] = 0
 
+    # Trim ghost histories to bounded size
+    limit = max(1, m_GHOST_LIMIT_MULT * cap)
+    while len(m_ghost_probation) > limit:
+        kmin = min(m_ghost_probation, key=lambda k: m_ghost_probation[k])
+        m_ghost_probation.pop(kmin, None)
+    while len(m_ghost_protected) > limit:
+        kmin = min(m_ghost_protected, key=lambda k: m_ghost_protected[k])
+        m_ghost_protected.pop(kmin, None)
+
 def update_after_evict(cache_snapshot, obj, evicted_obj):
     '''
     This function defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
     - Args:
         - `cache_snapshot`: A snapshot of the current cache state.
         - `obj`: The object to be inserted into the cache.
         - `evicted_obj`: The object that was just evicted from the cache.
     - Return: `None`
     '''
     global m_ts, m_probation, m_protected, m_probation_hits
+    global m_ghost_probation, m_ghost_protected
     evk = evicted_obj.key
+    now = cache_snapshot.access_count
+    cap = m_last_capacity or max(len(cache_snapshot.cache), 1)
+
+    # Determine segment before removal and record ghost
+    was_protected = evk in m_protected
+    if was_protected:
+        m_ghost_protected[evk] = now
+    else:
+        m_ghost_probation[evk] = now
+
     # Remove all metadata for the evicted object
     m_ts.pop(evk, None)
     m_probation.discard(evk)
     m_protected.discard(evk)
     m_probation_hits.pop(evk, None)
+
+    # Trim ghosts to bounded size
+    limit = max(1, m_GHOST_LIMIT_MULT * cap)
+    while len(m_ghost_probation) > limit:
+        kmin = min(m_ghost_probation, key=lambda k: m_ghost_probation[k])
+        m_ghost_probation.pop(kmin, None)
+    while len(m_ghost_protected) > limit:
+        kmin = min(m_ghost_protected, key=lambda k: m_ghost_protected[k])
+        m_ghost_protected.pop(kmin, None)
 
 # EVOLVE-BLOCK-END
 
 # This part remains fixed (not evolved)
 def run_caching(trace_path: str, copy_code_dst: str):
     """Run the caching algorithm on a trace"""
     import os
     with open(os.path.abspath(__file__), 'r', encoding="utf-8") as f:
         code_str = f.read()
     with open(os.path.join(copy_code_dst), 'w') as f:
         f.write(code_str)
     from cache_utils import Cache, CacheConfig, CacheObj, Trace
     trace = Trace(trace_path=trace_path)
     cache_capacity = max(int(trace.get_ndv() * 0.1), 1)
     cache = Cache(CacheConfig(cache_capacity))
     for entry in trace.entries:
         obj = CacheObj(key=str(entry.key))
         cache.get(obj)
     with open(copy_code_dst, 'w') as f:
         f.write("")
     hit_rate = round(cache.hit_count / cache.access_count, 6)
     return hit_rate