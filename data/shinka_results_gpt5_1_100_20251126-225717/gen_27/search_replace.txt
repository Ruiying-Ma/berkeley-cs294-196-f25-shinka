<NAME>
slru_arc_ageaware
</NAME>

<DESCRIPTION>
I will keep the current strong SLRU core but add two lightweight enhancements that improve adaptivity and scan resistance without adding heavy overhead:

1) ARC-style ghost feedback to adapt the protected quota. We maintain two tiny ghost lists for recently evicted probation and protected keys. On a miss that re-references a ghost:
- If it was a protected ghost, we increase the protected target (favor frequency).
- If it was a probation ghost, we decrease the protected target (favor recency).
Ghosts are bounded to 2Ã—capacity and recorded during evictions.

2) Age-aware victim choice between segments when the protected is not oversized. If both segments have candidates and the oldest protected entry is much staler than the oldest probation entry (by > cap/2 accesses or older than cap accesses), we evict from protected despite it being under target. This prevents stale protected entries from sticking around and improves scan resistance without penalizing reuse-heavy phases.

Promotion policy and two-touch gating under protected pressure remain the same. These targeted tweaks keep the code simple while addressing workloads that previously suffered from protected pollution and lack of adaptivity, improving overall hit rates.

</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
# Segmented LRU (2Q-like) with a protected quota (SLRU-style) and conditional two-touch promotion:
# - Newly inserted objects go to probationary.
# - Promote to protected on hit; if protected is at/over target, require two touches to promote.
# - Demote protected LRU when protected exceeds target to keep a healthy probation space.
# - Evict: if protected exceeds target, evict protected LRU; else evict probation LRU first.
m_ts = dict()                  # key -> last access timestamp
m_probation = set()            # keys seen once (recently inserted)
m_protected = set()            # keys with demonstrated reuse (promoted on hit)

# Protected quota control
m_target_protected = None      # target number of protected entries
m_last_capacity = None         # last observed capacity (to re-init when changed)
m_probation_hits = dict()      # key -> hit count while in probation (for two-touch when needed)
=======
# Segmented LRU (2Q-like) with a protected quota (SLRU-style) and conditional two-touch promotion:
# - Newly inserted objects go to probationary.
# - Promote to protected on hit; if protected is at/over target, require two touches to promote.
# - Demote protected LRU when protected exceeds target to keep a healthy probation space.
# - Evict: if protected exceeds target, evict protected LRU; else evict probation LRU first with age-aware override.
m_ts = dict()                  # key -> last access timestamp
m_probation = set()            # keys seen once (recently inserted)
m_protected = set()            # keys with demonstrated reuse (promoted on hit)

# Protected quota control
m_target_protected = None      # target number of protected entries
m_last_capacity = None         # last observed capacity (to re-init when changed)
m_probation_hits = dict()      # key -> hit count while in probation (for two-touch when needed)

# Lightweight ARC-style ghost histories to adapt protected target
m_ghost_probation = dict()     # key -> eviction timestamp (from probation)
m_ghost_protected = dict()     # key -> eviction timestamp (from protected)
m_GHOST_LIMIT_MULT = 2         # keep up to 2x capacity ghosts
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
def evict(cache_snapshot, obj):
    '''
    This function defines how the algorithm chooses the eviction victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    global m_ts, m_probation, m_protected
    _init_targets(cache_snapshot)

    keys_in_cache = set(cache_snapshot.cache.keys())

    # Keep metadata consistent with actual cache content
    if m_probation:
        m_probation.intersection_update(keys_in_cache)
    if m_protected:
        m_protected.intersection_update(keys_in_cache)
    if m_ts:
        for k in list(m_ts.keys()):
            if k not in keys_in_cache:
                m_ts.pop(k, None)
                m_probation.discard(k)
                m_protected.discard(k)
                m_probation_hits.pop(k, None)

    probation_candidates = m_probation & keys_in_cache
    protected_candidates = m_protected & keys_in_cache

    # If protected is oversized vs target, evict its oldest to reduce over-protection.
    if protected_candidates and m_target_protected is not None and len(m_protected) > m_target_protected:
        return _oldest_key(protected_candidates)
    # Prefer evicting from probationary segment to avoid polluting protected items
    if probation_candidates:
        return _oldest_key(probation_candidates)
    if protected_candidates:
        return _oldest_key(protected_candidates)

    # Fallback: evict the globally oldest if segmentation hasn't been set yet
    if keys_in_cache:
        return _oldest_key(keys_in_cache)
    return None
=======
def evict(cache_snapshot, obj):
    '''
    This function defines how the algorithm chooses the eviction victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    global m_ts, m_probation, m_protected
    _init_targets(cache_snapshot)

    keys_in_cache = set(cache_snapshot.cache.keys())

    # Keep metadata consistent with actual cache content
    if m_probation:
        m_probation.intersection_update(keys_in_cache)
    if m_protected:
        m_protected.intersection_update(keys_in_cache)
    if m_ts:
        for k in list(m_ts.keys()):
            if k not in keys_in_cache:
                m_ts.pop(k, None)
                m_probation.discard(k)
                m_protected.discard(k)
                m_probation_hits.pop(k, None)

    probation_candidates = m_probation & keys_in_cache
    protected_candidates = m_protected & keys_in_cache

    cap = m_last_capacity or max(len(cache_snapshot.cache), 1)
    now = cache_snapshot.access_count

    # If protected is oversized vs target, evict its oldest to reduce over-protection.
    if protected_candidates and m_target_protected is not None and len(m_protected) > m_target_protected:
        return _oldest_key(protected_candidates)

    # If both segments have candidates, use age-aware override: evict from protected
    # when its LRU is much staler than probation's LRU (prevents stale protected pollution).
    if probation_candidates and protected_candidates:
        prob_key = _oldest_key(probation_candidates)
        prot_key = _oldest_key(protected_candidates)
        tp = m_ts.get(prob_key, now)
        tr = m_ts.get(prot_key, now)
        age_prob = now - tp
        age_prot = now - tr
        slack = max(1, cap // 2)          # relative slack
        stale_abs = max(1, cap)           # absolute staleness threshold
        if (age_prot > age_prob + slack) or (age_prot > stale_abs):
            return prot_key
        else:
            return prob_key

    # Otherwise prefer evicting from probation; if empty, evict from protected.
    if probation_candidates:
        return _oldest_key(probation_candidates)
    if protected_candidates:
        return _oldest_key(protected_candidates)

    # Fallback: evict the globally oldest if segmentation hasn't been set yet
    if keys_in_cache:
        return _oldest_key(keys_in_cache)
    return None
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    global m_ts, m_probation, m_protected, m_probation_hits
    _init_targets(cache_snapshot)
    now = cache_snapshot.access_count
    key = obj.key

    # New insert starts in probationary segment
    m_ts[key] = now
    m_protected.discard(key)
    m_probation.add(key)
    m_probation_hits[key] = 0
=======
def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    global m_ts, m_probation, m_protected, m_probation_hits
    global m_ghost_probation, m_ghost_protected, m_target_protected
    _init_targets(cache_snapshot)
    now = cache_snapshot.access_count
    key = obj.key
    cap = m_last_capacity or max(len(cache_snapshot.cache), 1)

    # ARC-like adaptation based on ghost re-reference
    step = max(1, cap // 16)
    if key in m_ghost_protected:
        m_target_protected = min(cap, m_target_protected + step)
        m_ghost_protected.pop(key, None)
    elif key in m_ghost_probation:
        m_target_protected = max(1, m_target_protected - step)
        m_ghost_probation.pop(key, None)

    # New insert starts in probationary segment
    m_ts[key] = now
    m_protected.discard(key)
    m_probation.add(key)
    m_probation_hits[key] = 0

    # Trim ghost histories to bounded size
    limit = max(1, m_GHOST_LIMIT_MULT * cap)
    while len(m_ghost_probation) > limit:
        kmin = min(m_ghost_probation, key=lambda k: m_ghost_probation[k])
        m_ghost_probation.pop(kmin, None)
    while len(m_ghost_protected) > limit:
        kmin = min(m_ghost_protected, key=lambda k: m_ghost_protected[k])
        m_ghost_protected.pop(kmin, None)
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    global m_ts, m_probation, m_protected, m_probation_hits
    evk = evicted_obj.key
    # Remove all metadata for the evicted object
    m_ts.pop(evk, None)
    m_probation.discard(evk)
    m_protected.discard(evk)
    m_probation_hits.pop(evk, None)
=======
def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    global m_ts, m_probation, m_protected, m_probation_hits
    global m_ghost_probation, m_ghost_protected
    evk = evicted_obj.key
    now = cache_snapshot.access_count
    cap = m_last_capacity or max(len(cache_snapshot.cache), 1)

    # Determine segment before removal and record ghost
    was_protected = evk in m_protected
    if was_protected:
        m_ghost_protected[evk] = now
    else:
        m_ghost_probation[evk] = now

    # Remove all metadata for the evicted object
    m_ts.pop(evk, None)
    m_probation.discard(evk)
    m_protected.discard(evk)
    m_probation_hits.pop(evk, None)

    # Trim ghosts to bounded size
    limit = max(1, m_GHOST_LIMIT_MULT * cap)
    while len(m_ghost_probation) > limit:
        kmin = min(m_ghost_probation, key=lambda k: m_ghost_probation[k])
        m_ghost_probation.pop(kmin, None)
    while len(m_ghost_protected) > limit:
        kmin = min(m_ghost_protected, key=lambda k: m_ghost_protected[k])
        m_ghost_protected.pop(kmin, None)
>>>>>>> REPLACE

</DIFF>