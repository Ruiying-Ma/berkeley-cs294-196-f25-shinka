# EVOLVE-BLOCK-START
"""F-ARC: Freshness-weighted ARC with sampled-LRFU demotion and scan-aware gating"""

from collections import OrderedDict

# Resident segments (LRU->MRU order)
_T1_probation = OrderedDict()   # first-touch, recency-biased
_T2_protected = OrderedDict()   # multi-touch, frequency-biased

# Ghost histories (evicted keys) store eviction timestamps for freshness
_B1_ghost = OrderedDict()       # from T1: key -> evict_ts
_B2_ghost = OrderedDict()       # from T2: key -> evict_ts

# ARC's adaptive target for |T1|
_p_target = 0.0
_cap_est = 0

# Recency timestamps and small saturating counters
m_key_timestamp = dict()        # key -> last access time (for LRU tie-break)
_freq = dict()                  # key -> small counter (saturating, 3-bit)
_FREQ_MAX = 7

# Decayed-frequency (TinyLFU-like) counters with epoch-based halving
_refcnt = {}                    # key -> (count, epoch)
_epoch_df = 0
_last_epoch_tick_df = 0
_DECAY_WINDOW = 128             # accesses per epoch; tied to capacity and scan state

# Two-touch gating memory (time-bounded)
_touched_once_ts = {}           # key -> access_count at first touch in T1

# Ghost freshness window (adaptive) and reuse age samples
_fresh_window = 0               # dynamic; defaults to 0.5*cap
_ghost_age_samples = []         # rolling sample of ghost reuse ages

# Activity tracking and scan/guard windows
_hit_ewma = 0.0
_ins_ewma = 0.0
_EWMA_ALPHA = 0.05
_SCAN_TRIGGER_INS = 0.7
_SCAN_TRIGGER_HIT = 0.15
_scan_until = 0
_guard_until = 0

# Momentum on p updates
_p_momentum = 0.0
_p_last_update_tick = 0

# Last victim strength for admission guard on inserts
_last_victim_strength = 0.0

# Tunables
_P_INIT_RATIO = 0.30
_GHOST_BOUND_MULT = 1           # bound each ghost list to ≈ cap
_SAMPLE_T1_BASE = 2
_SAMPLE_T2_BASE = 3


def _ensure_capacity(cache_snapshot):
    """Initialize capacity, p, and tie decay window and fresh window to capacity and scan."""
    global _cap_est, _p_target, _DECAY_WINDOW, _fresh_window
    cap = getattr(cache_snapshot, "capacity", None)
    if isinstance(cap, int) and cap > 0:
        _cap_est = cap
    else:
        _cap_est = max(_cap_est, len(cache_snapshot.cache))
    if _cap_est <= 0:
        _cap_est = max(1, len(cache_snapshot.cache))

    if _p_target == 0.0 and not _T1_probation and not _T2_protected and not _B1_ghost and not _B2_ghost:
        _p_target = min(float(_cap_est), max(0.0, float(_cap_est) * _P_INIT_RATIO))
    if _p_target < 0.0:
        _p_target = 0.0
    if _p_target > float(_cap_est):
        _p_target = float(_cap_est)

    # Adjust decay window: faster during scan, slower otherwise
    now = cache_snapshot.access_count
    in_scan = now <= max(_scan_until, _guard_until)
    if in_scan:
        _DECAY_WINDOW = max(32, int(_cap_est // 2) or 1)
    else:
        _DECAY_WINDOW = max(64, int(_cap_est))

    # Initialize fresh window if unset
    if _fresh_window <= 0:
        _fresh_window = max(1, int(0.5 * _cap_est))


def _ghost_trim():
    """Bound ghosts by capacity multiplier."""
    limit = max(1, _GHOST_BOUND_MULT * max(_cap_est, 1))
    while len(_B1_ghost) > limit:
        _B1_ghost.popitem(last=False)
    while len(_B2_ghost) > limit:
        _B2_ghost.popitem(last=False)


def _maybe_age(cache_snapshot):
    """Advance TinyLFU epoch and age simple saturating counters."""
    global _epoch_df, _last_epoch_tick_df
    _ensure_capacity(cache_snapshot)
    now = cache_snapshot.access_count

    # Simple saturating frequency aging every cap accesses
    # Faster under scan due to smaller _DECAY_WINDOW
    # Age TinyLFU epoch
    if now - _last_epoch_tick_df >= _DECAY_WINDOW:
        _epoch_df += 1
        _last_epoch_tick_df = now
        # Also halve the small saturating counters occasionally
        for k in list(_freq.keys()):
            newf = _freq.get(k, 0) // 2
            if newf <= 0:
                _freq.pop(k, None)
            else:
                _freq[k] = newf


def _update_activity(is_hit, cache_snapshot):
    """Track recent hit/miss behavior, adapt EWMA alpha, and activate scan window if needed."""
    global _hit_ewma, _ins_ewma, _scan_until, _EWMA_ALPHA
    # Adaptive alpha: faster when scan-like patterns suspected
    tentative_alpha = 0.15 if (_ins_ewma > _SCAN_TRIGGER_INS and _hit_ewma < _SCAN_TRIGGER_HIT) else 0.05
    _EWMA_ALPHA = tentative_alpha

    alpha = _EWMA_ALPHA
    _hit_ewma = (1.0 - alpha) * _hit_ewma + alpha * (1.0 if is_hit else 0.0)
    _ins_ewma = (1.0 - alpha) * _ins_ewma + alpha * (0.0 if is_hit else 1.0)

    # Enter scan window when inserts surge and hits are low
    if (_ins_ewma > _SCAN_TRIGGER_INS) and (_hit_ewma < _SCAN_TRIGGER_HIT):
        _scan_until = cache_snapshot.access_count + int(max(1, 1.0 * _cap_est))


def _adjust_p(sign, step, now):
    """Momentum-based adjustment of ARC's p with clamping."""
    global _p_target, _p_momentum, _p_last_update_tick
    bounded = min(max(0.5, float(step)), max(1.0, 0.25 * float(_cap_est)))
    _p_momentum = 0.5 * _p_momentum + float(sign) * bounded
    _p_target += _p_momentum
    if _p_target < 0.0:
        _p_target = 0.0
        _p_momentum = 0.0
    if _p_target > float(_cap_est):
        _p_target = float(_cap_est)
        _p_momentum = 0.0
    _p_last_update_tick = now


def _decayed_score(key):
    """Return decayed reference score for a key."""
    ce = _refcnt.get(key)
    if ce is None:
        return 0
    c, e = ce
    de = _epoch_df - e
    if de > 0:
        c = c >> min(6, de)
    return max(0, c)


def _inc_decayed(key):
    """Increment decayed reference count for a key (epoch-aware)."""
    c, e = _refcnt.get(key, (0, _epoch_df))
    if e != _epoch_df:
        c = c >> min(6, _epoch_df - e)
        e = _epoch_df
    _refcnt[key] = (min(c + 1, 1 << 30), e)


def _update_fresh_window_sample(age, cache_snapshot):
    """Update rolling sample of ghost reuse ages and recompute fresh_window periodically."""
    global _fresh_window
    try:
        _ghost_age_samples.append(int(max(0, age)))
        # Trim to about capacity
        if len(_ghost_age_samples) > max(1, _cap_est):
            # keep most recent ~cap samples
            del _ghost_age_samples[0:len(_ghost_age_samples) - _cap_est]
        # Recompute median every ~cap/2 samples
        if len(_ghost_age_samples) >= max(4, _cap_est // 2):
            arr = sorted(_ghost_age_samples)
            mid = len(arr) // 2
            median_age = arr[mid] if len(arr) % 2 == 1 else (arr[mid - 1] + arr[mid]) // 2
            lo = max(1, int(0.25 * _cap_est))
            hi = max(1, int(1.00 * _cap_est))
            _fresh_window = max(lo, min(hi, int(median_age)))
    except Exception:
        # Fallback to static window if anything goes wrong
        _fresh_window = max(1, int(0.5 * _cap_est))


def _lru_iter(od):
    """Iterate keys from LRU to MRU for an OrderedDict."""
    for k in od.keys():
        yield k


def _pick_with_guard(od, sample_n, cache_snapshot, incoming_key):
    """Pick victim from LRU side with admission guard: avoid evicting hotter than incoming if possible."""
    if not od:
        return None
    inc_score = _decayed_score(incoming_key) if incoming_key is not None else 0
    cnt = 0
    best = None
    best_tuple = None
    now = cache_snapshot.access_count
    for k in _lru_iter(od):
        if k not in cache_snapshot.cache:
            continue
        s = _decayed_score(k)
        hotter = 1 if s > inc_score else 0
        tup = (hotter, s, m_key_timestamp.get(k, now), k)
        if best_tuple is None or tup < best_tuple:
            best_tuple = tup
            best = k
        cnt += 1
        if cnt >= sample_n:
            break
    return best


def _demote_protected_if_needed(cache_snapshot, avoid_key=None):
    """Keep T2 size within ARC target by demoting sampled LRFU LRU entries to T1 MRU with a protected floor."""
    _ensure_capacity(cache_snapshot)
    t1_target = int(round(_p_target))
    t2_target = max(_cap_est - t1_target, 0)
    # Protected floor: ≥ 10% of T2 target preserved
    t2_floor = max(0, int(0.1 * t2_target))
    if t2_target < t2_floor:
        t2_target = t2_floor

    # Demote until within target, but not below floor
    while len(_T2_protected) > t2_target and len(_T2_protected) > t2_floor:
        # Sample first few LRU entries and pick coldest by (freq asc, timestamp asc)
        sample = []
        cnt = 0
        for k in _lru_iter(_T2_protected):
            if k != avoid_key and k in cache_snapshot.cache:
                sample.append(k)
                cnt += 1
                if cnt >= 4:
                    break
        if not sample:
            break
        coldest = min(sample, key=lambda kk: (_freq.get(kk, 0), m_key_timestamp.get(kk, 0)))
        _T2_protected.pop(coldest, None)
        _T1_probation[coldest] = True  # demoted MRU in T1


def evict(cache_snapshot, obj):
    '''
    Evict using ARC replace with freshness-aware, scan-aware decisions and admission guard.
    - Prefer T1 when |T1| > p or when upcoming key is in B2 and |T1| == p.
    - During scan/guard windows, always evict from T1 if non-empty.
    - Within chosen segment, sample a few LRU entries and pick by (hotter_flag, decayed_score asc, recency asc).
    '''
    _ensure_capacity(cache_snapshot)
    _maybe_age(cache_snapshot)

    t1_size = len(_T1_probation)
    t2_size = len(_T2_protected)
    incoming_key = obj.key if obj is not None else None
    now = cache_snapshot.access_count

    in_scan = now <= max(_scan_until, _guard_until)

    # ARC replace policy baseline
    x_in_b2 = (obj is not None) and (obj.key in _B2_ghost)
    choose_t1 = (t1_size >= 1) and ((x_in_b2 and t1_size == int(round(_p_target))) or (t1_size > _p_target))
    # Scan/guard bias: keep evictions in probation when scanning
    if in_scan and t1_size > 0:
        choose_t1 = True

    # Adaptive sampling sizes based on pressure and scan
    cap = max(1, _cap_est)
    t1_pressure = (t1_size > _p_target + 0.1 * cap) or in_scan
    t2_pressure = (t2_size > (cap - int(round(_p_target))))
    T1_SAMPLE = 1 if t1_pressure else _SAMPLE_T1_BASE
    T2_SAMPLE = (_SAMPLE_T2_BASE + 1) if t2_pressure else _SAMPLE_T2_BASE
    if _hit_ewma < 0.2:
        T2_SAMPLE = max(2, T2_SAMPLE - 1)

    victim_key = None
    if choose_t1 and t1_size > 0:
        victim_key = _pick_with_guard(_T1_probation, T1_SAMPLE, cache_snapshot, incoming_key)
    if victim_key is None and t2_size > 0:
        # Only evict from protected if T1 is empty or target requires it
        victim_key = _pick_with_guard(_T2_protected, T2_SAMPLE, cache_snapshot, incoming_key)
    if victim_key is None and t1_size > 0:
        victim_key = _pick_with_guard(_T1_probation, T1_SAMPLE, cache_snapshot, incoming_key)
    if victim_key is None:
        victim_key = next(iter(cache_snapshot.cache.keys()))
    return victim_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
    - Update EWMA and age counters.
    - Increment decayed frequency and saturating counter; refresh timestamps.
    - Promotions from T1 require a second touch within fresh_window (time-bounded),
      or clearly hot by decayed score, or a recent B2 ghost.
      Strict rule applies when hit EWMA is low or T1 exceeds target.
    - T2 hits refresh MRU.
    - Keep T2 within ARC target via sampled-LRFU demotion with a floor.
    - Clean ghosts for this key.
    '''
    _ensure_capacity(cache_snapshot)
    _maybe_age(cache_snapshot)
    _update_activity(True, cache_snapshot)

    key = obj.key
    now = cache_snapshot.access_count
    m_key_timestamp[key] = now
    _freq[key] = min(_FREQ_MAX, _freq.get(key, 0) + 1)
    _inc_decayed(key)

    in_scan = now <= max(_scan_until, _guard_until)
    fresh_window = max(1, int(_fresh_window))

    if key in _T2_protected:
        _T2_protected.move_to_end(key, last=True)
        _touched_once_ts.pop(key, None)
    elif key in _T1_probation:
        strict = in_scan or (_hit_ewma < 0.25) or (len(_T1_probation) > int(round(_p_target)))
        last_ts = _touched_once_ts.get(key)
        promote = False

        # Recent B2 ghost
        ev_ts_b2 = _B2_ghost.get(key)
        recent_b2 = isinstance(ev_ts_b2, int) and ((now - ev_ts_b2) <= fresh_window)

        hot_decayed = (_decayed_score(key) >= 2)

        if strict:
            if last_ts is not None and (now - last_ts) <= fresh_window:
                promote = True
            elif hot_decayed or recent_b2:
                promote = True
            else:
                _touched_once_ts[key] = now
        else:
            # More permissive in good locality: allow first hit to promote
            if last_ts is not None or hot_decayed or recent_b2:
                promote = True
            else:
                _touched_once_ts[key] = now

        if promote:
            _touched_once_ts.pop(key, None)
            _T1_probation.pop(key, None)
            _T2_protected[key] = True  # MRU in T2
        else:
            _T1_probation.move_to_end(key, last=True)
    else:
        # Metadata miss on hit (shouldn't happen): treat as hot
        _T2_protected[key] = True
        _touched_once_ts.pop(key, None)

    _demote_protected_if_needed(cache_snapshot, avoid_key=key)

    # Ghost cleanup
    _B1_ghost.pop(key, None)
    _B2_ghost.pop(key, None)
    _ghost_trim()


def update_after_insert(cache_snapshot, obj):
    '''
    On miss and insert:
    - Update EWMA and age counters.
    - If key in ghosts: compute freshness w = max(0, 1 - age/fresh_window), scale ARC p-step by (1 + 2w).
      While scanning, damp B1-driven increases (×0.5) and amplify B2-driven decreases (×1.2).
      Admit to T2 if w ≥ 0.5 else T1. Seed frequency as freq = max(freq, 1 + round(4w)).
      Add reuse age to rolling sample to adapt fresh_window.
    - Else new: insert to T1 MRU; during scan/guard insert at T1 LRU and gently bias p down.
    '''
    _ensure_capacity(cache_snapshot)
    _maybe_age(cache_snapshot)
    _update_activity(False, cache_snapshot)

    key = obj.key
    now = cache_snapshot.access_count
    m_key_timestamp[key] = now
    _inc_decayed(key)  # count the access leading to insertion

    in_scan = now <= max(_scan_until, _guard_until)

    in_b1 = key in _B1_ghost
    in_b2 = key in _B2_ghost

    fresh_window = max(1, int(_fresh_window))

    if in_b1 or in_b2:
        if in_b1:
            ev_ts = _B1_ghost.get(key)
            age = (now - ev_ts) if isinstance(ev_ts, int) else (fresh_window + 1)
            _update_fresh_window_sample(age, cache_snapshot)
            w = max(0.0, 1.0 - float(age) / float(fresh_window))
            # ARC p update toward recency
            base_step = max(1.0, float(len(_B2_ghost)) / max(1.0, float(len(_B1_ghost))))
            step = base_step * (1.0 + 2.0 * w)
            if in_scan:
                step *= 0.5  # damp during scans
            _adjust_p(+1, step, now)
            _B1_ghost.pop(key, None)
            # Admission and seeding
            _freq[key] = max(_freq.get(key, 0), 1 + int(round(4.0 * w)))
            if w >= 0.5:
                _T2_protected[key] = True
                _demote_protected_if_needed(cache_snapshot, avoid_key=key)
            else:
                _T1_probation[key] = True
        else:
            ev_ts = _B2_ghost.get(key)
            age = (now - ev_ts) if isinstance(ev_ts, int) else (fresh_window + 1)
            _update_fresh_window_sample(age, cache_snapshot)
            w = max(0.0, 1.0 - float(age) / float(fresh_window))
            # ARC p update toward frequency
            base_step = max(1.0, float(len(_B1_ghost)) / max(1.0, float(len(_B2_ghost))))
            step = base_step * (1.0 + 2.0 * w)
            if in_scan:
                step *= 1.2  # amplify decrease during scans
            _adjust_p(-1, step, now)
            _B2_ghost.pop(key, None)
            _freq[key] = max(_freq.get(key, 0), 1 + int(round(4.0 * w)))
            if w >= 0.5:
                _T2_protected[key] = True
                _demote_protected_if_needed(cache_snapshot, avoid_key=key)
            else:
                _T1_probation[key] = True
    else:
        # New key: insert into T1; scan/guard: insert at LRU to avoid polluting MRU
        _T1_probation[key] = True
        if in_scan:
            # Gently lower p to keep more in T1 during scans
            _adjust_p(-1, max(1.0, 0.1 * float(_cap_est)), now)
            _T1_probation.move_to_end(key, last=False)
        else:
            _T1_probation.move_to_end(key, last=True)

    # Avoid duplicates across structures and trim ghosts
    if key in _T1_probation and key in _T2_protected:
        _T1_probation.pop(key, None)
    _B1_ghost.pop(key, None)
    _B2_ghost.pop(key, None)
    _ghost_trim()


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After eviction:
    - Remove from resident segment and put into the appropriate ghost with timestamp.
    - Track victim strength (decayed + bonus for T2) and set a short guard when a strong T2 victim is evicted.
    - Clean per-key state and maintain ghost bounds.
    '''
    _ensure_capacity(cache_snapshot)
    key = evicted_obj.key
    now = cache_snapshot.access_count

    was_t1 = key in _T1_probation
    was_t2 = key in _T2_protected

    fval_dec = _decayed_score(key)
    strength = float(fval_dec) + (2.0 if was_t2 else 0.0)
    global _last_victim_strength, _guard_until
    _last_victim_strength = strength

    if was_t1:
        _T1_probation.pop(key, None)
        _B1_ghost[key] = now
    elif was_t2:
        _T2_protected.pop(key, None)
        _B2_ghost[key] = now
        # Extend guard if we evicted something fairly hot from T2
        if fval_dec >= 2:
            _guard_until = now + max(1, _cap_est // 2)
    else:
        # Unknown residency; default to B1 ghost
        _B1_ghost[key] = now

    # Clean per-key state
    m_key_timestamp.pop(key, None)
    _freq.pop(key, None)
    _refcnt.pop(key, None)
    _touched_once_ts.pop(key, None)

    _ghost_trim()
# EVOLVE-BLOCK-END