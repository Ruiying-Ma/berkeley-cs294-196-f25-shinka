<NAME>
arc_scan_guard_momentum
</NAME>

<DESCRIPTION>
I introduce three targeted improvements inspired by adaptive caching research (ARC, TinyLFU, and scan-resistant policies) to reduce miss rates across diverse traces while keeping the current architecture:

1) Freshness-aware ghost admission and momentum-based p adaptation:
   - Store ghost entries with timestamps (access_count) instead of booleans.
   - On re-reference from ghosts, scale the ARC p step by ghost freshness and apply a small momentum term to stabilize p against oscillations.
   - Fresh ghost hits get direct admission to T2 with higher seeded frequency; stale ghost hits fall back to T1.

2) Lightweight scan detector and guard:
   - Maintain EWMA of hit rate and insertion rate. When the insertion rate is high and hit rate low, enter a short scan mode window.
   - While in scan mode, bias REPLACE to evict from T1, place newcomers at T1 LRU, and gently nudge p downward. This protects T2 against scans and reduces pollution.

3) Minor evict bias under scan:
   - If in scan mode, force REPLACE to choose probation when possible, keeping hot protected items safe.

These changes remain lightweight and do not disturb the existing demotion logic, frequency aging, or ARC core rules, but they respond better to phase shifts and scans and reduce overreaction through p momentum. This should improve hit rates on workloads with bursts, scans, or phase changes without harming steady-state workloads.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
# Tunable parameters
_P_INIT_RATIO = 0.33  # initial share for probation (T1)

def _ensure_capacity(cache_snapshot):
    """Initialize or update capacity estimate and clamp p."""
    global _cap_est, _p_target
    cap = getattr(cache_snapshot, "capacity", None)
    if isinstance(cap, int) and cap > 0:
        _cap_est = cap
    else:
        _cap_est = max(_cap_est, len(cache_snapshot.cache))
    if _cap_est <= 0:
        _cap_est = max(1, len(cache_snapshot.cache))
    # Initialize p if never set (zero and empty metadata)
    if _p_target == 0.0 and not _T1_probation and not _T2_protected and not _B1_ghost and not _B2_ghost:
        _p_target = max(0.0, min(float(_cap_est), float(_cap_est) * _P_INIT_RATIO))
    # Clamp p
    if _p_target < 0.0:
        _p_target = 0.0
    if _p_target > float(_cap_est):
        _p_target = float(_cap_est)

def _get_targets(cache_snapshot):
    """Compute ARC targets from p: T1 target = round(p), T2 target = cap - T1 target."""
    _ensure_capacity(cache_snapshot)
    t1_target = int(round(_p_target))
    t2_target = max(_cap_est - t1_target, 0)
    return t1_target, t2_target

def _ghost_trim():
    """Limit ghost lists to capacity each (ARC-style bound)."""
    global _B1_ghost, _B2_ghost
    while len(_B1_ghost) > _cap_est:
        _B1_ghost.popitem(last=False)
    while len(_B2_ghost) > _cap_est:
        _B2_ghost.popitem(last=False)
=======
# Tunable parameters
_P_INIT_RATIO = 0.33  # initial share for probation (T1)

# Momentum and scan detection controls
_p_momentum = 0.0
_p_last_update_tick = 0
_EWMA_ALPHA = 0.05
_hit_ewma = 0.0
_ins_ewma = 0.0
_scan_until = 0

def _ensure_capacity(cache_snapshot):
    """Initialize or update capacity estimate and clamp p."""
    global _cap_est, _p_target
    cap = getattr(cache_snapshot, "capacity", None)
    if isinstance(cap, int) and cap > 0:
        _cap_est = cap
    else:
        _cap_est = max(_cap_est, len(cache_snapshot.cache))
    if _cap_est <= 0:
        _cap_est = max(1, len(cache_snapshot.cache))
    # Initialize p if never set (zero and empty metadata)
    if _p_target == 0.0 and not _T1_probation and not _T2_protected and not _B1_ghost and not _B2_ghost:
        _p_target = max(0.0, min(float(_cap_est), float(_cap_est) * _P_INIT_RATIO))
    # Clamp p
    if _p_target < 0.0:
        _p_target = 0.0
    if _p_target > float(_cap_est):
        _p_target = float(_cap_est)

def _get_targets(cache_snapshot):
    """Compute ARC targets from p: T1 target = round(p), T2 target = cap - T1 target."""
    _ensure_capacity(cache_snapshot)
    t1_target = int(round(_p_target))
    t2_target = max(_cap_est - t1_target, 0)
    return t1_target, t2_target

def _ghost_trim():
    """Limit ghost lists to capacity each (ARC-style bound)."""
    global _B1_ghost, _B2_ghost
    while len(_B1_ghost) > _cap_est:
        _B1_ghost.popitem(last=False)
    while len(_B2_ghost) > _cap_est:
        _B2_ghost.popitem(last=False)

def _adjust_p(sign, step, now, freshness_scale=1.0):
    """Momentum-based adjustment of ARC's p with clamping."""
    global _p_target, _p_momentum, _p_last_update_tick
    # Bound the step to avoid wild swings
    bounded = min(max(1.0, step * freshness_scale), max(1.0, 0.25 * float(_cap_est)))
    # Exponential momentum to smooth oscillations
    _p_momentum = 0.5 * _p_momentum + float(sign) * bounded
    _p_target += _p_momentum
    # Clamp to [0, cap]
    if _p_target < 0.0:
        _p_target = 0.0
    if _p_target > float(_cap_est):
        _p_target = float(_cap_est)
    _p_last_update_tick = now

def _update_activity(is_hit, cache_snapshot):
    """Update EWMA of hits and insertions, and engage short scan guard if needed."""
    global _hit_ewma, _ins_ewma, _scan_until
    alpha = _EWMA_ALPHA
    _hit_ewma = (1.0 - alpha) * _hit_ewma + alpha * (1.0 if is_hit else 0.0)
    _ins_ewma = (1.0 - alpha) * _ins_ewma + alpha * (0.0 if is_hit else 1.0)
    # If many inserts and few hits recently, treat as scan for about 1 capacity worth of accesses
    if _ins_ewma > 0.7 and _hit_ewma < 0.2:
        _scan_until = cache_snapshot.access_count + max(1, _cap_est)
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
def evict(cache_snapshot, obj):
    '''
    Choose victim key using adaptive ARC replace policy with frequency-aware selection.
    REPLACE(x): if |T1|>=1 and ((x in B2 and |T1| == p) or |T1| > p) -> evict from T1 else from T2.
    Within the chosen segment, pick the lowest-frequency (ties by older timestamp).
    '''
    _ensure_capacity(cache_snapshot)

    t1_size = len(_T1_probation)
    t2_size = len(_T2_protected)
    x_in_b2 = (obj is not None) and (obj.key in _B2_ghost)
    p_int = int(round(_p_target))
    choose_t1 = (t1_size >= 1) and ((x_in_b2 and t1_size == p_int) or (t1_size > _p_target))

    victim_key = None
    if choose_t1 and t1_size > 0:
        victim_key = _min_by_freq_ts(_T1_probation, cache_snapshot)
    if victim_key is None and t2_size > 0:
        victim_key = _min_by_freq_ts(_T2_protected, cache_snapshot)
    if victim_key is None and t1_size > 0:
        victim_key = _min_by_freq_ts(_T1_probation, cache_snapshot)
    if victim_key is None:
        victim_key = _fallback_choose(cache_snapshot)
    return victim_key
=======
def evict(cache_snapshot, obj):
    '''
    Choose victim key using adaptive ARC replace policy with frequency-aware selection.
    REPLACE(x): if |T1|>=1 and ((x in B2 and |T1| == p) or |T1| > p) -> evict from T1 else from T2.
    Within the chosen segment, pick the lowest-frequency (ties by older timestamp).
    While in scan mode, bias eviction to T1 to protect T2.
    '''
    _ensure_capacity(cache_snapshot)

    t1_size = len(_T1_probation)
    t2_size = len(_T2_protected)
    x_in_b2 = (obj is not None) and (obj.key in _B2_ghost)
    p_int = int(round(_p_target))
    choose_t1 = (t1_size >= 1) and ((x_in_b2 and t1_size == p_int) or (t1_size > _p_target))

    # Scan bias: during scan guard window, evict from probation whenever possible
    if cache_snapshot.access_count <= _scan_until and t1_size > 0:
        choose_t1 = True

    victim_key = None
    if choose_t1 and t1_size > 0:
        victim_key = _min_by_freq_ts(_T1_probation, cache_snapshot)
    if victim_key is None and t2_size > 0:
        victim_key = _min_by_freq_ts(_T2_protected, cache_snapshot)
    if victim_key is None and t1_size > 0:
        victim_key = _min_by_freq_ts(_T1_probation, cache_snapshot)
    if victim_key is None:
        victim_key = _fallback_choose(cache_snapshot)
    return victim_key
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
def update_after_hit(cache_snapshot, obj):
    '''
    Update metadata after cache hit.
    - If hit in probation (T1), promote to protected (T2).
    - If hit in protected, refresh recency.
    - Maintain timestamps and frequency with periodic aging.
    - Keep protected within ARC target via demotion of its LRU.
    '''
    _ensure_capacity(cache_snapshot)
    _maybe_age(cache_snapshot)
    key = obj.key
    now = cache_snapshot.access_count
    # Update fallback LRU timestamp
    m_key_timestamp[key] = now
    # Increment frequency counter
    _freq[key] = _freq.get(key, 0) + 1

    if key in _T2_protected:
        # Refresh to MRU
        _T2_protected.move_to_end(key, last=True)
    elif key in _T1_probation:
        # Promote from probation to protected
        _T1_probation.pop(key, None)
        _T2_protected[key] = True  # insert as MRU
    else:
        # Metadata miss (hit without segment record): treat as frequent
        _T2_protected[key] = True

    # Respect ARC protected target by demoting its LRU if needed
    _demote_protected_if_needed(cache_snapshot, avoid_key=key)

    # Cleanup ghosts if any stale
    if key in _B1_ghost:
        _B1_ghost.pop(key, None)
    if key in _B2_ghost:
        _B2_ghost.pop(key, None)
    _ghost_trim()
=======
def update_after_hit(cache_snapshot, obj):
    '''
    Update metadata after cache hit.
    - If hit in probation (T1), promote to protected (T2).
    - If hit in protected, refresh recency.
    - Maintain timestamps and frequency with periodic aging.
    - Keep protected within ARC target via demotion of its LRU.
    - Update EWMA activity metrics.
    '''
    _ensure_capacity(cache_snapshot)
    _maybe_age(cache_snapshot)
    _update_activity(True, cache_snapshot)

    key = obj.key
    now = cache_snapshot.access_count
    # Update fallback LRU timestamp
    m_key_timestamp[key] = now
    # Increment frequency counter
    _freq[key] = _freq.get(key, 0) + 1

    if key in _T2_protected:
        # Refresh to MRU
        _T2_protected.move_to_end(key, last=True)
    elif key in _T1_probation:
        # Promote from probation to protected
        _T1_probation.pop(key, None)
        _T2_protected[key] = True  # insert as MRU
    else:
        # Metadata miss (hit without segment record): treat as frequent
        _T2_protected[key] = True

    # Respect ARC protected target by demoting its LRU if needed
    _demote_protected_if_needed(cache_snapshot, avoid_key=key)

    # Cleanup ghosts if any stale
    if key in _B1_ghost:
        _B1_ghost.pop(key, None)
    if key in _B2_ghost:
        _B2_ghost.pop(key, None)
    _ghost_trim()
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
def update_after_insert(cache_snapshot, obj):
    '''
    Update metadata on insertion (miss path).
    - If the key is in ghost lists, adjust p (ARC adaptation) and insert into protected.
    - Otherwise insert into probation as MRU; if within guard window, place at LRU to resist scans.
    - Maintain timestamps, seed frequency minimally, and enforce protected target.
    '''
    _ensure_capacity(cache_snapshot)
    _maybe_age(cache_snapshot)
    key = obj.key
    now = cache_snapshot.access_count
    m_key_timestamp[key] = now

    in_b1 = key in _B1_ghost
    in_b2 = key in _B2_ghost

    if in_b1 or in_b2:
        # ARC adaptation of p (smooth float-based steps)
        global _p_target
        if in_b1:
            inc = max(1.0, float(len(_B2_ghost)) / max(1.0, float(len(_B1_ghost))))
            _p_target = min(float(_cap_est), _p_target + float(inc))
            _B1_ghost.pop(key, None)
        else:
            dec = max(1.0, float(len(_B1_ghost)) / max(1.0, float(len(_B2_ghost))))
            _p_target = max(0.0, _p_target - float(dec))
            _B2_ghost.pop(key, None)
        # Insert into protected (seen before)
        if key in _T1_probation:
            _T1_probation.pop(key, None)
        _T2_protected[key] = True
        # Seed frequency as at least 2 for re-referenced keys
        _freq[key] = max(_freq.get(key, 0) + 1, 2)

        # Keep protected within its target by demoting its LRU if necessary
        _demote_protected_if_needed(cache_snapshot, avoid_key=key)
    else:
        # New to cache and ghosts: insert into probation (T1)
        if key in _T2_protected:
            # Rare desync; ensure consistency (shouldn't happen on miss)
            _T2_protected.move_to_end(key, last=True)
        else:
            _T1_probation[key] = True
            # Admission guard: if we recently evicted strong protected, bias newcomer cold
            if now <= _guard_until or _last_victim_strength >= _VICTIM_GUARD_THRESH:
                _T1_probation.move_to_end(key, last=False)
        # Seed minimal frequency for new items
        _freq[key] = _freq.get(key, 0)

    # Avoid duplicates across structures
    if key in _T1_probation and key in _T2_protected:
        _T1_probation.pop(key, None)
    if key in _B1_ghost:
        _B1_ghost.pop(key, None)
    if key in _B2_ghost:
        _B2_ghost.pop(key, None)
    _ghost_trim()
=======
def update_after_insert(cache_snapshot, obj):
    '''
    Update metadata on insertion (miss path).
    - If the key is in ghost lists, adjust p with momentum and freshness (ARC adaptation) and admit accordingly.
    - Otherwise insert into probation as MRU; if within guard/scan window, place at LRU to resist scans.
    - Maintain timestamps, seed frequency minimally, and enforce protected target.
    '''
    _ensure_capacity(cache_snapshot)
    _maybe_age(cache_snapshot)
    _update_activity(False, cache_snapshot)

    key = obj.key
    now = cache_snapshot.access_count
    m_key_timestamp[key] = now

    in_b1 = key in _B1_ghost
    in_b2 = key in _B2_ghost

    if in_b1 or in_b2:
        # ARC adaptation of p (smooth float-based steps with momentum and freshness)
        if in_b1:
            inc = max(1.0, float(len(_B2_ghost)) / max(1.0, float(len(_B1_ghost))))
            # Freshness-aware: prefer larger step for fresh B1 items
            val = _B1_ghost.get(key, None)
            age = now - val if isinstance(val, int) else (_cap_est + 1)
            fresh = age <= max(1, _cap_est // 2)
            _adjust_p(+1, inc, now, freshness_scale=(1.2 if fresh else 1.0))
            _B1_ghost.pop(key, None)
            # Admission: fresh -> T2, stale -> T1
            if fresh:
                if key in _T1_probation:
                    _T1_probation.pop(key, None)
                _T2_protected[key] = True
                _freq[key] = max(_freq.get(key, 0) + 1, 3)
                _demote_protected_if_needed(cache_snapshot, avoid_key=key)
            else:
                _T1_probation[key] = True
                _freq[key] = _freq.get(key, 0)
        else:
            dec = max(1.0, float(len(_B1_ghost)) / max(1.0, float(len(_B2_ghost))))
            val = _B2_ghost.get(key, None)
            age = now - val if isinstance(val, int) else (_cap_est + 1)
            fresh = age <= max(1, _cap_est // 2)
            _adjust_p(-1, dec, now, freshness_scale=(1.2 if fresh else 1.0))
            _B2_ghost.pop(key, None)
            if fresh:
                if key in _T1_probation:
                    _T1_probation.pop(key, None)
                _T2_protected[key] = True
                _freq[key] = max(_freq.get(key, 0) + 1, 3)
                _demote_protected_if_needed(cache_snapshot, avoid_key=key)
            else:
                _T1_probation[key] = True
                _freq[key] = _freq.get(key, 0)
    else:
        # New to cache and ghosts: insert into probation (T1)
        if key in _T2_protected:
            # Rare desync; ensure consistency (shouldn't happen on miss)
            _T2_protected.move_to_end(key, last=True)
        else:
            _T1_probation[key] = True
            # Admission guard: if we recently evicted strong protected or in scan, bias newcomer cold
            if now <= _guard_until or _last_victim_strength >= _VICTIM_GUARD_THRESH or now <= _scan_until:
                _T1_probation.move_to_end(key, last=False)
                # While scanning, gently reduce p to keep evictions in T1
                if now <= _scan_until:
                    _adjust_p(-1, max(1.0, 0.1 * float(_cap_est)), now)
        # Seed minimal frequency for new items
        _freq[key] = _freq.get(key, 0)

    # Avoid duplicates across structures
    if key in _T1_probation and key in _T2_protected:
        _T1_probation.pop(key, None)
    if key in _B1_ghost:
        _B1_ghost.pop(key, None)
    if key in _B2_ghost:
        _B2_ghost.pop(key, None)
    _ghost_trim()
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    Update metadata after eviction.
    - Remove victim from its resident segment.
    - Add to corresponding ghost list (B1 if from probation, B2 if from protected).
    - Track victim strength and open a short guard window if protected item with reuse was evicted.
    - Trim ghost lists and clean timestamps/frequency.
    '''
    _ensure_capacity(cache_snapshot)
    victim_key = evicted_obj.key

    was_t1 = victim_key in _T1_probation
    was_t2 = victim_key in _T2_protected

    # Track strength of the evicted item before removing counters
    fval = _freq.get(victim_key, 0)
    base_strength = float(fval)
    if was_t2:
        base_strength += 2.0  # extra credit for protected residency
    global _last_victim_strength, _guard_until
    _last_victim_strength = base_strength

    # Remove from resident segments and add to ghosts
    if was_t1:
        _T1_probation.pop(victim_key, None)
        _B1_ghost[victim_key] = True  # insert as MRU
    elif was_t2:
        _T2_protected.pop(victim_key, None)
        _B2_ghost[victim_key] = True  # insert as MRU
        # If we had to evict a strong protected item, enable a short guard window
        if fval >= 2:
            _guard_until = cache_snapshot.access_count + max(1, _cap_est // 2)
    else:
        # Unknown location; put in B1 by default
        _B1_ghost[victim_key] = True

    # Remove fallback timestamp and frequency for evicted key
    m_key_timestamp.pop(victim_key, None)
    _freq.pop(victim_key, None)

    _ghost_trim()
=======
def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    Update metadata after eviction.
    - Remove victim from its resident segment.
    - Add to corresponding ghost list (B1 if from probation, B2 if from protected) with timestamp.
    - Track victim strength and open a short guard window if protected item with reuse was evicted.
    - Trim ghost lists and clean timestamps/frequency.
    '''
    _ensure_capacity(cache_snapshot)
    victim_key = evicted_obj.key
    now = cache_snapshot.access_count

    was_t1 = victim_key in _T1_probation
    was_t2 = victim_key in _T2_protected

    # Track strength of the evicted item before removing counters
    fval = _freq.get(victim_key, 0)
    base_strength = float(fval)
    if was_t2:
        base_strength += 2.0  # extra credit for protected residency
    global _last_victim_strength, _guard_until
    _last_victim_strength = base_strength

    # Remove from resident segments and add to ghosts with timestamp for freshness
    if was_t1:
        _T1_probation.pop(victim_key, None)
        _B1_ghost[victim_key] = now  # insert as MRU with timestamp
    elif was_t2:
        _T2_protected.pop(victim_key, None)
        _B2_ghost[victim_key] = now  # insert as MRU with timestamp
        # If we had to evict a strong protected item, enable a short guard window
        if fval >= 2:
            _guard_until = cache_snapshot.access_count + max(1, _cap_est // 2)
    else:
        # Unknown location; put in B1 by default
        _B1_ghost[victim_key] = now

    # Remove fallback timestamp and frequency for evicted key
    m_key_timestamp.pop(victim_key, None)
    _freq.pop(victim_key, None)

    _ghost_trim()
>>>>>>> REPLACE

</DIFF>