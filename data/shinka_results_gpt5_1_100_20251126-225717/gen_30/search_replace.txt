<NAME>
slru_tinylfu_scan_sampling
</NAME>

<DESCRIPTION>
I introduce three complementary improvements to the existing SLRU design to reduce miss rates across diverse workloads:

1) Gentle scan detection and two-touch gating:
   - Maintain a low-cost epoch-level scan detector using a capacity-sized decay window. When the unique density in the last window is high and the global hit rate is low, enter a short scan_mode.
   - In scan_mode, new items are inserted at the probation LRU (to be evicted quickly), and probation promotions require two touches before entering protected. This prevents destructive cache pollution under scans.
   - Protected fraction is gently reduced when we have to evict from protected or when scan_mode persists.

2) Smarter eviction via lightweight LRFU sampling:
   - Instead of always evicting the single LRU in a segment, sample a few LRU keys from both probation and protected and choose the victim with the minimal tuple (decayed frequency, segment priority, recency index). This approximates LRFU and better identifies cold entries while remaining scan-resistant (favoring probation victims on ties and generally).
   - Sampling sizes adapt to segment pressure and scan_mode.

3) Better ghost-aware admission and adaptive protected sizing:
   - Re-admission from protected ghost remains, but probation ghost re-admission now seeds a small bonus and ensures MRU placement to speed up promotion for recently-evicted once-touched items (without immediately protecting them).
   - After evicting from probation, if the incoming object is hotter than the victim, we increase the protected fraction slightly; eviction from protected still reduces it. This feedback stabilizes the split and adapts to workload shifts.

All changes are local to metadata updates (hit/insert/evict) and preserve correctness. They add minimal overhead and are designed to be robust across traces with scans, bursts, and mixed temporal locality by combining SLRU segmentation, TinyLFU-like decayed frequency, and small-window sampling.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
_PROTECTED_FRAC = 0.8        # target fraction of cache to allocate to protected segment
_ADAPT_STEP = 0.02           # step used to adjust protected fraction within [0.05, 0.95]


def _increase_protected():
    global _PROTECTED_FRAC
    _PROTECTED_FRAC = min(0.95, _PROTECTED_FRAC + _ADAPT_STEP)


def _decrease_protected():
    global _PROTECTED_FRAC
    _PROTECTED_FRAC = max(0.05, _PROTECTED_FRAC - _ADAPT_STEP)


def _ensure_params(cache_snapshot):
    """Initialize/adjust parameters that depend on capacity."""
    global _DECAY_WINDOW
    cap = max(cache_snapshot.capacity, 1)
    # Tie decay window to capacity to align half-life with working-set size
    _DECAY_WINDOW = max(64, cap)


def _maybe_age(cache_snapshot):
    """Advance epoch based on access_count, and trim ghost lists."""
    global _epoch, _last_epoch_tick
    _ensure_params(cache_snapshot)
    if cache_snapshot.access_count - _last_epoch_tick >= _DECAY_WINDOW:
        _epoch += 1
        _last_epoch_tick = cache_snapshot.access_count
        # Trim ghost histories to bounded size
        limit = max(1, _GHOST_LIMIT_MULT * max(cache_snapshot.capacity, 1))
        while len(_ghost_probation) > limit:
            _ghost_probation.popitem(last=False)
        while len(_ghost_protected) > limit:
            _ghost_protected.popitem(last=False)


def _score(key):
    """Return decayed frequency score for a key."""
    ce = _refcnt.get(key)
    if ce is None:
        return 0
    c, e = ce
    de = _epoch - e
    if de > 0:
        # decay by halving per epoch (cap max shifts to avoid zeroing too fast)
        c = c >> min(6, de)
    return max(0, c)


def _inc(key):
    """Increment decayed frequency count for a key."""
    c, e = _refcnt.get(key, (0, _epoch))
    if e != _epoch:
        c = c >> min(6, _epoch - e)
        e = _epoch
    # cap growth to avoid overflow
    c = min(c + 1, 1 << 30)
    _refcnt[key] = (c, e)


def _sync_metadata(cache_snapshot):
    """Ensure SLRU metadata matches current cache content."""
    cached_keys = set(cache_snapshot.cache.keys())

    # Remove entries no longer in cache
    for k in list(_key_seg.keys()):
        if k not in cached_keys:
            if _key_seg.get(k) == 'prob':
                _probation.pop(k, None)
            else:
                _protected.pop(k, None)
            _key_seg.pop(k, None)

    # Add cached keys missing from metadata into probation MRU
    for k in cached_keys:
        if k not in _key_seg:
            _probation[k] = None
            _key_seg[k] = 'prob'


def _rebalance(cache_snapshot):
    """Demote protected LRU entries if protected size exceeds target."""
    total = len(cache_snapshot.cache)
    if total <= 0:
        return
    target = max(1, int(total * _PROTECTED_FRAC))

    while len(_protected) > target:
        # Demote protected LRU to probation MRU
        k, _ = _protected.popitem(last=False)
        _probation[k] = None
        _key_seg[k] = 'prob'
=======
_PROTECTED_FRAC = 0.8        # target fraction of cache to allocate to protected segment
_ADAPT_STEP = 0.02           # step used to adjust protected fraction within [0.05, 0.95]

# Scan-resistance and two-touch gating (epoch-scoped, low overhead)
_scan_mode = False
_scan_mode_epochs_left = 0
_epoch_unique = set()        # unique keys observed within the current decay window
_touched_once = {}           # key -> epoch when first touched in probation (for two-touch in scan mode)

# Sampling parameters for LRFU-like victim selection
_BASE_PROB_SAMPLE = 3
_BASE_PROT_SAMPLE = 2


def _increase_protected():
    global _PROTECTED_FRAC
    _PROTECTED_FRAC = min(0.95, _PROTECTED_FRAC + _ADAPT_STEP)


def _decrease_protected():
    global _PROTECTED_FRAC
    _PROTECTED_FRAC = max(0.05, _PROTECTED_FRAC - _ADAPT_STEP)


def _ensure_params(cache_snapshot):
    """Initialize/adjust parameters that depend on capacity."""
    global _DECAY_WINDOW
    cap = max(cache_snapshot.capacity, 1)
    # Tie decay window to capacity to align half-life with working-set size
    _DECAY_WINDOW = max(64, cap)


def _maybe_age(cache_snapshot):
    """Advance epoch based on access_count, and trim ghost lists and manage scan mode."""
    global _epoch, _last_epoch_tick, _scan_mode, _scan_mode_epochs_left, _epoch_unique
    _ensure_params(cache_snapshot)
    if cache_snapshot.access_count - _last_epoch_tick >= _DECAY_WINDOW:
        # Evaluate the last window's uniqueness and hit rate to detect scans
        window = max(1, _DECAY_WINDOW)
        unique_density = min(1.0, len(_epoch_unique) / float(window))
        hit_rate = cache_snapshot.hit_count / max(1, float(cache_snapshot.access_count))
        if unique_density > 0.7 and hit_rate < 0.2:
            _scan_mode = True
            _scan_mode_epochs_left = 1
            # During scans, lean away from protected a bit
            _decrease_protected()
        else:
            if _scan_mode_epochs_left > 0:
                _scan_mode_epochs_left -= 1
            _scan_mode = _scan_mode_epochs_left > 0
        # Reset unique tracker for the new window
        _epoch_unique.clear()

        _epoch += 1
        _last_epoch_tick = cache_snapshot.access_count
        # Trim ghost histories to bounded size
        limit = max(1, _GHOST_LIMIT_MULT * max(cache_snapshot.capacity, 1))
        while len(_ghost_probation) > limit:
            _ghost_probation.popitem(last=False)
        while len(_ghost_protected) > limit:
            _ghost_protected.popitem(last=False)


def _score(key):
    """Return decayed frequency score for a key."""
    ce = _refcnt.get(key)
    if ce is None:
        return 0
    c, e = ce
    de = _epoch - e
    if de > 0:
        # decay by halving per epoch (cap max shifts to avoid zeroing too fast)
        c = c >> min(6, de)
    return max(0, c)


def _inc(key):
    """Increment decayed frequency count for a key."""
    c, e = _refcnt.get(key, (0, _epoch))
    if e != _epoch:
        c = c >> min(6, _epoch - e)
        e = _epoch
    # cap growth to avoid overflow
    c = min(c + 1, 1 << 30)
    _refcnt[key] = (c, e)


def _sync_metadata(cache_snapshot):
    """Ensure SLRU metadata matches current cache content."""
    cached_keys = set(cache_snapshot.cache.keys())

    # Remove entries no longer in cache
    for k in list(_key_seg.keys()):
        if k not in cached_keys:
            if _key_seg.get(k) == 'prob':
                _probation.pop(k, None)
            else:
                _protected.pop(k, None)
            _key_seg.pop(k, None)

    # Add cached keys missing from metadata into probation MRU
    for k in cached_keys:
        if k not in _key_seg:
            _probation[k] = None
            _key_seg[k] = 'prob'


def _rebalance(cache_snapshot):
    """Demote protected LRU entries if protected size exceeds target."""
    total = len(cache_snapshot.cache)
    if total <= 0:
        return
    target = max(1, int(total * _PROTECTED_FRAC))

    while len(_protected) > target:
        # Demote protected LRU to probation MRU
        k, _ = _protected.popitem(last=False)
        _probation[k] = None
        _key_seg[k] = 'prob'


def _sample_lru_keys(od, n):
    """Return up to n keys from the LRU side (front) of an OrderedDict."""
    res = []
    it = iter(od.keys())
    for i in range(n):
        try:
            res.append(next(it))
        except StopIteration:
            break
    return res


def _victim_tuple(key, seg, rec_idx):
    """Tuple for comparing eviction candidates. Lower is colder."""
    # Prefer lower frequency; tie-break by segment (probation preferred), then by older recency (smaller index)
    return (_score(key), 0 if seg == 'prob' else 1, rec_idx, key)
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
def evict(cache_snapshot, obj):
    '''
    This function defines how the algorithm chooses the eviction victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    # Keep metadata consistent and properly segmented before choosing a victim
    _maybe_age(cache_snapshot)
    _sync_metadata(cache_snapshot)
    _rebalance(cache_snapshot)

    candid_obj_key = None
    victim_from_protected = False

    # Clean up stale entries (if any)
    for k in list(_probation.keys()):
        if k not in cache_snapshot.cache:
            _probation.pop(k, None)
            _key_seg.pop(k, None)
    for k in list(_protected.keys()):
        if k not in cache_snapshot.cache:
            _protected.pop(k, None)
            _key_seg.pop(k, None)

    # Identify LRU candidates from each segment
    prob_lru = next(iter(_probation.keys()), None)
    prot_lru = next(iter(_protected.keys()), None)

    if prob_lru is None and prot_lru is None:
        # Fallback: pick any key from cache if metadata got desynced
        if cache_snapshot.cache:
            return next(iter(cache_snapshot.cache.keys()))
        return None

    if prob_lru is None:
        # Only protected has entries; must evict from protected
        candid_obj_key = prot_lru
        victim_from_protected = True
    elif prot_lru is None:
        # Only probation has entries; evict from probation
        candid_obj_key = prob_lru
        victim_from_protected = False
    else:
        # Both candidates exist. Prefer probation for scan resistance,
        # but evict protected LRU if it's clearly colder by decayed frequency.
        s_prob = _score(prob_lru)
        s_prot = _score(prot_lru)
        min_prot_size = max(1, int(0.2 * max(1, len(cache_snapshot.cache))))
        if s_prot + 1 < s_prob and len(_protected) > min_prot_size:
            candid_obj_key = prot_lru
            victim_from_protected = True
        else:
            candid_obj_key = prob_lru
            victim_from_protected = False

    # Adaptive tuning: if we are forced to evict from protected, reduce its target fraction slightly
    if victim_from_protected:
        _decrease_protected()

    return candid_obj_key
=======
def evict(cache_snapshot, obj):
    '''
    This function defines how the algorithm chooses the eviction victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    # Keep metadata consistent and properly segmented before choosing a victim
    _maybe_age(cache_snapshot)
    _sync_metadata(cache_snapshot)
    _rebalance(cache_snapshot)

    # Track key for scan detection unique density
    try:
        _epoch_unique.add(obj.key)
    except Exception:
        pass

    # Clean up stale entries (if any)
    for k in list(_probation.keys()):
        if k not in cache_snapshot.cache:
            _probation.pop(k, None)
            _key_seg.pop(k, None)
    for k in list(_protected.keys()):
        if k not in cache_snapshot.cache:
            _protected.pop(k, None)
            _key_seg.pop(k, None)

    # If metadata is empty, fallback
    if not cache_snapshot.cache:
        return None

    # Adaptive sampling sizes
    prob_sample = _BASE_PROB_SAMPLE
    prot_sample = _BASE_PROT_SAMPLE
    if _scan_mode:
        prob_sample += 1
        prot_sample = max(1, prot_sample - 1)
    if len(_probation) > len(_protected) + 2:
        prob_sample += 1

    # Build candidate tuples from both segments' LRU sides
    candidates = []
    # Probation candidates
    pkeys = _sample_lru_keys(_probation, prob_sample)
    for idx, pk in enumerate(pkeys):
        if pk in cache_snapshot.cache:
            candidates.append(_victim_tuple(pk, 'prob', idx))
    # Protected candidates
    tkeys = _sample_lru_keys(_protected, prot_sample)
    for idx, tk in enumerate(tkeys):
        if tk in cache_snapshot.cache:
            candidates.append(_victim_tuple(tk, 'prot', idx))

    if not candidates:
        # Fallback: pick any key from cache if metadata got desynced
        return next(iter(cache_snapshot.cache.keys()))

    # Choose coldest by (score, segment preference, recency)
    best = min(candidates)
    candid_obj_key = best[3]
    victim_from_protected = (_key_seg.get(candid_obj_key) == 'prot')

    # Adaptive tuning: if we are forced to evict from protected, reduce its target fraction slightly
    if victim_from_protected:
        _decrease_protected()

    return candid_obj_key
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the algorithm update the metadata it maintains immediately after a cache hit.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    _maybe_age(cache_snapshot)
    _sync_metadata(cache_snapshot)

    k = obj.key
    _inc(k)
    seg = _key_seg.get(k)

    if seg == 'prob':
        # Promote to protected on first hit
        _probation.pop(k, None)
        _protected[k] = None  # inserted at MRU
        _key_seg[k] = 'prot'
        _increase_protected()  # hits in probation signal benefit from a larger protected segment
    elif seg == 'prot':
        # Refresh recency in protected
        if k in _protected:
            _protected.move_to_end(k, last=True)
        else:
            # If somehow missing from the structure, reinsert into protected
            _protected[k] = None
            _key_seg[k] = 'prot'
    else:
        # Unknown key (shouldn't happen on hit) â€“ treat as probation then promote
        _probation[k] = None
        _key_seg[k] = 'prob'
        _probation.pop(k, None)
        _protected[k] = None
        _key_seg[k] = 'prot'
        _increase_protected()

    _rebalance(cache_snapshot)
=======
def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the algorithm update the metadata it maintains immediately after a cache hit.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    _maybe_age(cache_snapshot)
    _sync_metadata(cache_snapshot)

    k = obj.key
    _inc(k)
    try:
        _epoch_unique.add(k)
    except Exception:
        pass

    seg = _key_seg.get(k)

    if seg == 'prob':
        if _scan_mode:
            # Two-touch gating under scans: first hit refreshes probation,
            # second hit within a short epoch window promotes to protected.
            last = _touched_once.get(k)
            if last is not None and (_epoch - last) <= 1:
                _touched_once.pop(k, None)
                _probation.pop(k, None)
                _protected[k] = None  # MRU
                _key_seg[k] = 'prot'
            else:
                _touched_once[k] = _epoch
                # Refresh to MRU of probation
                if k in _probation:
                    _probation.move_to_end(k, last=True)
                else:
                    _probation[k] = None
                # Avoid immediate expansion of protected during scans
        else:
            # Promote to protected on first hit
            _probation.pop(k, None)
            _protected[k] = None  # inserted at MRU
            _key_seg[k] = 'prot'
            _increase_protected()  # hits in probation signal benefit from a larger protected segment
    elif seg == 'prot':
        # Refresh recency in protected
        if k in _protected:
            _protected.move_to_end(k, last=True)
        else:
            # If somehow missing from the structure, reinsert into protected
            _protected[k] = None
            _key_seg[k] = 'prot'
        # Clear any stale two-touch marker
        _touched_once.pop(k, None)
    else:
        # Unknown key (shouldn't happen on hit).
        # In scan mode, keep in probation with refresh; otherwise, promote.
        if _scan_mode:
            _probation[k] = None
            _key_seg[k] = 'prob'
            _probation.move_to_end(k, last=True)
        else:
            _probation[k] = None
            _key_seg[k] = 'prob'
            _probation.pop(k, None)
            _protected[k] = None
            _key_seg[k] = 'prot'
            _increase_protected()

    _rebalance(cache_snapshot)
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    _maybe_age(cache_snapshot)
    _sync_metadata(cache_snapshot)
    k = obj.key
    _inc(k)

    # Decide segment placement using ghost history (segment-aware)
    g_prot_epoch = _ghost_protected.get(k)
    recent_prot_ghost = (g_prot_epoch is not None) and (_epoch - g_prot_epoch <= 2)

    # Reset any existing placement
    if _key_seg.get(k) == 'prot':
        _protected.pop(k, None)
    else:
        _probation.pop(k, None)

    if recent_prot_ghost:
        # Re-admit into protected due to recent protected ghost hit
        _protected[k] = None
        _key_seg[k] = 'prot'
        _increase_protected()
    else:
        # Default admission into probation
        _probation[k] = None
        _key_seg[k] = 'prob'

    _rebalance(cache_snapshot)
=======
def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    _maybe_age(cache_snapshot)
    _sync_metadata(cache_snapshot)
    k = obj.key
    _inc(k)
    try:
        _epoch_unique.add(k)
    except Exception:
        pass

    # Decide segment placement using ghost history (segment-aware)
    g_prot_epoch = _ghost_protected.get(k)
    g_prob_epoch = _ghost_probation.get(k)
    recent_prot_ghost = (g_prot_epoch is not None) and (_epoch - g_prot_epoch <= 2)
    recent_prob_ghost = (g_prob_epoch is not None) and (_epoch - g_prob_epoch <= 2)

    # Reset any existing placement
    if _key_seg.get(k) == 'prot':
        _protected.pop(k, None)
    else:
        _probation.pop(k, None)

    if _scan_mode:
        # Scan resistance: insert at probation LRU to minimize pollution,
        # require two-touch before promotion via update_after_hit.
        _probation[k] = None
        _probation.move_to_end(k, last=False)  # LRU side
        _key_seg[k] = 'prob'
    else:
        if recent_prot_ghost:
            # Re-admit into protected due to recent protected ghost hit
            _protected[k] = None
            _key_seg[k] = 'prot'
            _increase_protected()
        else:
            # Default admission into probation
            _probation[k] = None
            _key_seg[k] = 'prob'
            if recent_prob_ghost:
                # Slight boost for recently evicted probation ghost to accelerate useful re-references
                _probation.move_to_end(k, last=True)  # ensure MRU
                _inc(k)

    _rebalance(cache_snapshot)
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    _maybe_age(cache_snapshot)
    # Record into ghost according to the segment it was evicted from
    k = evicted_obj.key
    seg = _key_seg.get(k, None)
    # Store last victim score for potential future enhancements
    global _last_victim_score
    _last_victim_score = _score(k)

    if seg == 'prob':
        _ghost_probation[k] = _epoch
        _probation.pop(k, None)
    elif seg == 'prot':
        _ghost_protected[k] = _epoch
        _protected.pop(k, None)

    _key_seg.pop(k, None)

    # Trim ghost histories to bounded size
    limit = max(1, _GHOST_LIMIT_MULT * max(cache_snapshot.capacity, 1))
    while len(_ghost_probation) > limit:
        _ghost_probation.popitem(last=False)
    while len(_ghost_protected) > limit:
        _ghost_protected.popitem(last=False)

    # After an eviction, ensure protected segment still respects target (it might shrink due to target change)
    _rebalance(cache_snapshot)
=======
def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    _maybe_age(cache_snapshot)
    # Record into ghost according to the segment it was evicted from
    k = evicted_obj.key
    seg = _key_seg.get(k, None)
    # Store last victim score for potential future enhancements
    global _last_victim_score
    _last_victim_score = _score(k)

    if seg == 'prob':
        _ghost_probation[k] = _epoch
        _probation.pop(k, None)
    elif seg == 'prot':
        _ghost_protected[k] = _epoch
        _protected.pop(k, None)

    # Clean any stale two-touch markers
    _touched_once.pop(k, None)

    _key_seg.pop(k, None)

    # Trim ghost histories to bounded size
    limit = max(1, _GHOST_LIMIT_MULT * max(cache_snapshot.capacity, 1))
    while len(_ghost_probation) > limit:
        _ghost_probation.popitem(last=False)
    while len(_ghost_protected) > limit:
        _ghost_protected.popitem(last=False)

    # Adaptive protected tuning: if we evicted from probation but the incoming object is hotter,
    # increase protected to preserve hot items better.
    try:
        if seg == 'prob' and _score(obj.key) > _last_victim_score:
            _increase_protected()
    except Exception:
        pass

    # After an eviction, ensure protected segment still respects target (it might shrink due to target change)
    _rebalance(cache_snapshot)
>>>>>>> REPLACE

</DIFF>