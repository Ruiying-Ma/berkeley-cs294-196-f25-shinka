<NAME>
fresh_window_lrfu_sampling
</NAME>

<DESCRIPTION>
I introduce a dynamic freshness window and access-time tracking to better align promotions and evictions with current reuse distances, and improve protected demotion and victim selection by sampling and LRFU cues. Concretely:

1) Track last access time per key and record ghost eviction timestamps (in access_count units). Maintain a rolling sample of ghost ages to compute a dynamic fresh_window ≈ median reuse distance clamped to [0.25×capacity, 1.0×capacity]. This calibrates two-touch gating and ghost-driven adaptation to the workload.

2) Make two-touch promotion time-bounded using the fresh_window and switch _touched_once to store access_count timestamps. This curbs scan pollution while still promoting items that exhibit timely reuse.

3) Make ghost readmission and protected fraction tuning freshness-weighted. Compute w = max(0, 1 − age/fresh_window) from ghost timestamps: admit to protected aggressively when w is high (recent protected ghost); decrease protected more when probation ghosts are fresh.

4) Use access-time aware LRFU sampling in evict: among LRU samples from segments, select by (decayed freq asc, segment pref, older-by-time first). This yields more robust choices than LRU index alone.

5) Improve _rebalance demotions from protected via sampled LRFU: sample a few LRU entries and demote the coldest by (decayed freq asc, age asc older first), preserving truly hot protected entries.

6) Keep ghost timestamp dicts and rolling ghost ages bounded, trimming in sync with existing ghost limits.

These changes maintain low overhead, improve scan resistance, and adapt quickly to phase shifts, which should reduce miss rates across diverse traces.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
_ghost_protected = OrderedDict()  # key -> epoch of ghost insertion
_GHOST_LIMIT_MULT = 2
=======
_ghost_protected = OrderedDict()  # key -> epoch of ghost insertion
# Extra timestamp ghosts in access_count units for freshness-weighted decisions
_ghost_probation_ts = OrderedDict()  # key -> access_count at eviction
_ghost_protected_ts = OrderedDict()  # key -> access_count at eviction
_GHOST_LIMIT_MULT = 2

# Access-time tracking for better age sensitivity and dynamic freshness window
_last_access = {}             # key -> last access_count seen
_fresh_window = 0             # in access_count units; dynamically adapted
_recent_ghost_ages = []       # recent reuse distances in accesses
_MAX_GHOST_AGE_SAMPLES = 2048
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
def _maybe_age(cache_snapshot):
    """Advance epoch based on access_count, and trim ghost lists and manage scan mode."""
    global _epoch, _last_epoch_tick, _scan_mode, _scan_mode_epochs_left, _epoch_unique
    _ensure_params(cache_snapshot)
    if cache_snapshot.access_count - _last_epoch_tick >= _DECAY_WINDOW:
        # Evaluate the last window's uniqueness and hit rate to detect scans
        window = max(1, _DECAY_WINDOW)
        unique_density = min(1.0, len(_epoch_unique) / float(window))
        hit_rate = cache_snapshot.hit_count / max(1, float(cache_snapshot.access_count))
        if unique_density > 0.7 and hit_rate < 0.2:
            _scan_mode = True
            _scan_mode_epochs_left = 1
            # During scans, lean away from protected a bit
            _decrease_protected()
        else:
            if _scan_mode_epochs_left > 0:
                _scan_mode_epochs_left -= 1
            _scan_mode = _scan_mode_epochs_left > 0
        # Reset unique tracker for the new window
        _epoch_unique.clear()

        _epoch += 1
        _last_epoch_tick = cache_snapshot.access_count
        # Trim ghost histories to bounded size
        limit = max(1, _GHOST_LIMIT_MULT * max(cache_snapshot.capacity, 1))
        while len(_ghost_probation) > limit:
            _ghost_probation.popitem(last=False)
        while len(_ghost_protected) > limit:
            _ghost_protected.popitem(last=False)
=======
def _maybe_age(cache_snapshot):
    """Advance epoch based on access_count, and trim ghost lists and manage scan mode."""
    global _epoch, _last_epoch_tick, _scan_mode, _scan_mode_epochs_left, _epoch_unique, _fresh_window
    _ensure_params(cache_snapshot)
    if cache_snapshot.access_count - _last_epoch_tick >= _DECAY_WINDOW:
        # Evaluate the last window's uniqueness and hit rate to detect scans
        window = max(1, _DECAY_WINDOW)
        unique_density = min(1.0, len(_epoch_unique) / float(window))
        hit_rate = cache_snapshot.hit_count / max(1, float(cache_snapshot.access_count))
        if unique_density > 0.7 and hit_rate < 0.2:
            _scan_mode = True
            _scan_mode_epochs_left = 1
            # During scans, lean away from protected a bit
            _decrease_protected()
        else:
            if _scan_mode_epochs_left > 0:
                _scan_mode_epochs_left -= 1
            _scan_mode = _scan_mode_epochs_left > 0
        # Reset unique tracker for the new window
        _epoch_unique.clear()

        _epoch += 1
        _last_epoch_tick = cache_snapshot.access_count
        # Trim ghost histories to bounded size and keep timestamp ghosts in sync
        limit = max(1, _GHOST_LIMIT_MULT * max(cache_snapshot.capacity, 1))
        while len(_ghost_probation) > limit:
            k, _ = _ghost_probation.popitem(last=False)
            _ghost_probation_ts.pop(k, None)
        while len(_ghost_protected) > limit:
            k, _ = _ghost_protected.popitem(last=False)
            _ghost_protected_ts.pop(k, None)

        # Recompute dynamic freshness window from recent ghost ages (reuse distances)
        if _recent_ghost_ages:
            try:
                ages_sorted = sorted(_recent_ghost_ages)
                m = ages_sorted[len(ages_sorted) // 2]
                cap = max(int(cache_snapshot.capacity), 1)
                lo = max(1, int(0.25 * cap))
                hi = max(1, int(1.0 * cap))
                _fresh_window = max(lo, min(int(m), hi))
            except Exception:
                # Fallback to decay window if any issue
                _fresh_window = max(1, _DECAY_WINDOW)
        else:
            _fresh_window = max(1, _DECAY_WINDOW)
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
def _rebalance(cache_snapshot):
    """Demote protected LRU entries if protected size exceeds target."""
    total = len(cache_snapshot.cache)
    if total <= 0:
        return
    target = max(1, int(total * _PROTECTED_FRAC))

    while len(_protected) > target:
        # Demote protected LRU to probation MRU
        k, _ = _protected.popitem(last=False)
        _probation[k] = None
        _key_seg[k] = 'prob'
=======
def _rebalance(cache_snapshot):
    """Demote protected LRU entries if protected size exceeds target."""
    total = len(cache_snapshot.cache)
    if total <= 0:
        return
    target = max(1, int(total * _PROTECTED_FRAC))

    while len(_protected) > target:
        # Sample a few LRU candidates from protected and demote the coldest by LRFU-like criteria
        sample_keys = _sample_lru_keys(_protected, 4)
        if not sample_keys:
            break
        cold_key = None
        cold_tuple = None
        for sk in sample_keys:
            # Age in access_count units; older preferred for demotion
            try:
                age = max(0, cache_snapshot.access_count - _last_access.get(sk, cache_snapshot.access_count))
            except Exception:
                age = 0
            tup = (_score(sk), -age, sk)  # lower score first; then older (more negative -age)
            if cold_tuple is None or tup < cold_tuple:
                cold_tuple = tup
                cold_key = sk
        if cold_key in _protected:
            _protected.pop(cold_key, None)
            _probation[cold_key] = None
            _key_seg[cold_key] = 'prob'
        else:
            break
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
    # Build candidate tuples from both segments' LRU sides
    candidates = []
    # Probation candidates
    pkeys = _sample_lru_keys(_probation, prob_sample)
    for idx, pk in enumerate(pkeys):
        if pk in cache_snapshot.cache:
            candidates.append(_victim_tuple(pk, 'prob', idx))
    # Protected candidates
    tkeys = _sample_lru_keys(_protected, prot_sample)
    for idx, tk in enumerate(tkeys):
        if tk in cache_snapshot.cache:
            candidates.append(_victim_tuple(tk, 'prot', idx))
=======
    # Build candidate tuples from both segments' LRU sides with access-time-aware age
    candidates = []
    now = cache_snapshot.access_count
    # Probation candidates
    pkeys = _sample_lru_keys(_probation, prob_sample)
    for idx, pk in enumerate(pkeys):
        if pk in cache_snapshot.cache:
            age = max(0, now - _last_access.get(pk, now))
            candidates.append((_score(pk), 0, -age, idx, pk))
    # Protected candidates
    tkeys = _sample_lru_keys(_protected, prot_sample)
    for idx, tk in enumerate(tkeys):
        if tk in cache_snapshot.cache:
            age = max(0, now - _last_access.get(tk, now))
            candidates.append((_score(tk), 1, -age, idx, tk))
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
    best = min(candidates)
    candid_obj_key = best[3]
=======
    best = min(candidates)
    candid_obj_key = best[4]
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the algorithm update the metadata it maintains immediately after a cache hit.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    _maybe_age(cache_snapshot)
    _sync_metadata(cache_snapshot)

    k = obj.key
    _inc(k)
    try:
        _epoch_unique.add(k)
    except Exception:
        pass

    seg = _key_seg.get(k)

    # Determine if locality is poor: low hit rate or high uniqueness in window
    window = max(1, _DECAY_WINDOW)
    try:
        current_hit_rate = cache_snapshot.hit_count / max(1.0, float(cache_snapshot.access_count))
    except Exception:
        current_hit_rate = 0.0
    unique_density = min(1.0, len(_epoch_unique) / float(window))
    use_two_touch = _scan_mode or (current_hit_rate < 0.25) or (unique_density > 0.6)

    if seg == 'prob':
        if use_two_touch:
            # Time-bounded two-touch gating: second touch within one epoch promotes
            last = _touched_once.get(k)
            if last is not None and (_epoch - last) <= 1:
                _touched_once.pop(k, None)
                _probation.pop(k, None)
                _protected[k] = None  # MRU
                _key_seg[k] = 'prot'
            else:
                _touched_once[k] = _epoch
                # Refresh to MRU of probation
                if k in _probation:
                    _probation.move_to_end(k, last=True)
                else:
                    _probation[k] = None
        else:
            # Promote to protected on first hit when locality is decent
            _probation.pop(k, None)
            _protected[k] = None  # inserted at MRU
            _key_seg[k] = 'prot'
            _increase_protected()  # hits in probation signal benefit from a larger protected segment
    elif seg == 'prot':
        # Refresh recency in protected
        if k in _protected:
            _protected.move_to_end(k, last=True)
        else:
            # If somehow missing from the structure, reinsert into protected
            _protected[k] = None
            _key_seg[k] = 'prot'
        # Clear any stale two-touch marker
        _touched_once.pop(k, None)
    else:
        # Unknown key (shouldn't happen on hit).
        # In poor locality, keep in probation with refresh; otherwise, promote.
        if use_two_touch:
            _probation[k] = None
            _key_seg[k] = 'prob'
            _probation.move_to_end(k, last=True)
        else:
            _probation[k] = None
            _key_seg[k] = 'prob'
            _probation.pop(k, None)
            _protected[k] = None
            _key_seg[k] = 'prot'
            _increase_protected()

    _rebalance(cache_snapshot)
=======
def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the algorithm update the metadata it maintains immediately after a cache hit.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    _maybe_age(cache_snapshot)
    _sync_metadata(cache_snapshot)

    k = obj.key
    _inc(k)
    now = cache_snapshot.access_count
    _last_access[k] = now
    try:
        _epoch_unique.add(k)
    except Exception:
        pass

    seg = _key_seg.get(k)

    # Determine if locality is poor: low hit rate or high uniqueness in window
    window = max(1, _DECAY_WINDOW)
    try:
        current_hit_rate = cache_snapshot.hit_count / max(1.0, float(cache_snapshot.access_count))
    except Exception:
        current_hit_rate = 0.0
    unique_density = min(1.0, len(_epoch_unique) / float(window))
    use_two_touch = _scan_mode or (current_hit_rate < 0.25) or (unique_density > 0.6)

    if seg == 'prob':
        if use_two_touch:
            # Time-bounded two-touch gating: second touch within fresh_window promotes
            last = _touched_once.get(k)
            thresh = max(1, int(max(1, _fresh_window)))
            if last is not None and (now - last) <= thresh:
                _touched_once.pop(k, None)
                _probation.pop(k, None)
                _protected[k] = None  # MRU
                _key_seg[k] = 'prot'
            else:
                _touched_once[k] = now
                # Refresh to MRU of probation
                if k in _probation:
                    _probation.move_to_end(k, last=True)
                else:
                    _probation[k] = None
        else:
            # Promote to protected on first hit when locality is decent
            _probation.pop(k, None)
            _protected[k] = None  # inserted at MRU
            _key_seg[k] = 'prot'
            _increase_protected()  # hits in probation signal benefit from a larger protected segment
    elif seg == 'prot':
        # Refresh recency in protected
        if k in _protected:
            _protected.move_to_end(k, last=True)
        else:
            # If somehow missing from the structure, reinsert into protected
            _protected[k] = None
            _key_seg[k] = 'prot'
        # Clear any stale two-touch marker
        _touched_once.pop(k, None)
    else:
        # Unknown key (shouldn't happen on hit).
        # In poor locality, keep in probation with refresh; otherwise, promote.
        if use_two_touch:
            _probation[k] = None
            _key_seg[k] = 'prob'
            _probation.move_to_end(k, last=True)
        else:
            _probation[k] = None
            _key_seg[k] = 'prob'
            _probation.pop(k, None)
            _protected[k] = None
            _key_seg[k] = 'prot'
            _increase_protected()

    _rebalance(cache_snapshot)
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    _maybe_age(cache_snapshot)
    _sync_metadata(cache_snapshot)
    k = obj.key
    _inc(k)
    try:
        _epoch_unique.add(k)
    except Exception:
        pass

    # Decide segment placement using ghost history (segment-aware)
    g_prot_epoch = _ghost_protected.get(k)
    g_prob_epoch = _ghost_probation.get(k)
    recent_prot_ghost = (g_prot_epoch is not None) and (_epoch - g_prot_epoch <= 2)
    recent_prob_ghost = (g_prob_epoch is not None) and (_epoch - g_prob_epoch <= 2)

    # Reset any existing placement
    if _key_seg.get(k) == 'prot':
        _protected.pop(k, None)
    else:
        _probation.pop(k, None)

    # Adjust protected fraction based on ghost admissions (ARC-like tuning)
    if recent_prot_ghost:
        _increase_protected()
    elif recent_prob_ghost:
        _decrease_protected()

    # Locality signal from current window
    window = max(1, _DECAY_WINDOW)
    try:
        current_hit_rate = cache_snapshot.hit_count / max(1.0, float(cache_snapshot.access_count))
    except Exception:
        current_hit_rate = 0.0
    unique_density = min(1.0, len(_epoch_unique) / float(window))
    high_uniqueness = unique_density > 0.6
    poor_locality = current_hit_rate < 0.25 or high_uniqueness

    s = _score(k)

    if _scan_mode:
        # Scan resistance: insert at probation LRU to minimize pollution,
        # require two-touch before promotion via update_after_hit.
        _probation[k] = None
        _probation.move_to_end(k, last=False)  # LRU side
        _key_seg[k] = 'prob'
    else:
        if recent_prot_ghost or s >= 2:
            # Re-admit into protected due to recent protected ghost hit or strong frequency
            _protected[k] = None
            _key_seg[k] = 'prot'
            _increase_protected()
        else:
            # Default admission into probation
            _probation[k] = None
            _key_seg[k] = 'prob'
            if recent_prob_ghost:
                # Slight boost for recently evicted probation ghost to accelerate useful re-references
                _probation.move_to_end(k, last=True)  # ensure MRU
                _inc(k)
            elif poor_locality and s == 0:
                # Bias towards LRU position when locality is poor and item is cold
                _probation.move_to_end(k, last=False)
            else:
                # Keep MRU position
                _probation.move_to_end(k, last=True)

    _rebalance(cache_snapshot)
=======
def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    _maybe_age(cache_snapshot)
    _sync_metadata(cache_snapshot)
    k = obj.key
    _inc(k)
    now = cache_snapshot.access_count
    _last_access[k] = now
    try:
        _epoch_unique.add(k)
    except Exception:
        pass

    # Decide segment placement using ghost history (segment-aware)
    g_prot_epoch = _ghost_protected.get(k)
    g_prob_epoch = _ghost_probation.get(k)
    recent_prot_ghost = (g_prot_epoch is not None) and (_epoch - g_prot_epoch <= 2)
    recent_prob_ghost = (g_prob_epoch is not None) and (_epoch - g_prob_epoch <= 2)

    # Freshness-weighted ghost recency using access_count timestamps
    fw = max(1, int(max(1, _fresh_window)))
    gp_ts = _ghost_protected_ts.get(k)
    gb_ts = _ghost_probation_ts.get(k)
    w_prot = 0.0
    w_prob = 0.0
    if gp_ts is not None:
        agep = max(0, now - gp_ts)
        w_prot = max(0.0, 1.0 - (agep / float(fw)))
    if gb_ts is not None:
        ageb = max(0, now - gb_ts)
        w_prob = max(0.0, 1.0 - (ageb / float(fw)))

    # Reset any existing placement
    if _key_seg.get(k) == 'prot':
        _protected.pop(k, None)
    else:
        _probation.pop(k, None)

    # Adjust protected fraction based on ghost admissions (ARC-like tuning, freshness-weighted)
    if recent_prot_ghost or w_prot > 0:
        steps = 1 + int(2 * w_prot)
        for _ in range(steps):
            _increase_protected()
    elif recent_prob_ghost or w_prob > 0:
        steps = 1 + int(2 * w_prob)
        for _ in range(steps):
            _decrease_protected()

    # Locality signal from current window
    window = max(1, _DECAY_WINDOW)
    try:
        current_hit_rate = cache_snapshot.hit_count / max(1.0, float(cache_snapshot.access_count))
    except Exception:
        current_hit_rate = 0.0
    unique_density = min(1.0, len(_epoch_unique) / float(window))
    high_uniqueness = unique_density > 0.6
    poor_locality = current_hit_rate < 0.25 or high_uniqueness

    s = _score(k)

    if _scan_mode:
        # Scan resistance: insert at probation LRU to minimize pollution,
        # require two-touch before promotion via update_after_hit.
        _probation[k] = None
        _probation.move_to_end(k, last=False)  # LRU side
        _key_seg[k] = 'prob'
    else:
        if recent_prot_ghost or w_prot >= 0.5 or s >= 3:
            # Re-admit into protected due to recent protected ghost hit, strong freshness, or strong frequency
            _protected[k] = None
            _key_seg[k] = 'prot'
            _increase_protected()
        else:
            # Default admission into probation
            _probation[k] = None
            _key_seg[k] = 'prob'
            if recent_prob_ghost or w_prob >= 0.5:
                # Slight boost for recently evicted probation ghost to accelerate useful re-references
                _probation.move_to_end(k, last=True)  # ensure MRU
                _inc(k)
            elif poor_locality and s == 0:
                # Bias towards LRU position when locality is poor and item is cold
                _probation.move_to_end(k, last=False)
            else:
                # Keep MRU position
                _probation.move_to_end(k, last=True)

    _rebalance(cache_snapshot)
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    _maybe_age(cache_snapshot)
    # Record into ghost according to the segment it was evicted from
    k = evicted_obj.key
    seg = _key_seg.get(k, None)
    # Store last victim score for potential future enhancements
    global _last_victim_score
    _last_victim_score = _score(k)

    if seg == 'prob':
        _ghost_probation[k] = _epoch
        _probation.pop(k, None)
    elif seg == 'prot':
        _ghost_protected[k] = _epoch
        _protected.pop(k, None)

    # Clean any stale two-touch markers
    _touched_once.pop(k, None)

    _key_seg.pop(k, None)

    # Trim ghost histories to bounded size
    limit = max(1, _GHOST_LIMIT_MULT * max(cache_snapshot.capacity, 1))
    while len(_ghost_probation) > limit:
        _ghost_probation.popitem(last=False)
    while len(_ghost_protected) > limit:
        _ghost_protected.popitem(last=False)

    # Adaptive protected tuning:
    try:
        new_score = _score(obj.key)
        if seg == 'prob' and new_score > _last_victim_score:
            # Incoming appears hotter than evicted probation item: expand protected a bit
            _increase_protected()
        elif seg == 'prot' and new_score <= _last_victim_score:
            # Evicted from protected for an item no hotter: shrink protected slightly
            _decrease_protected()
    except Exception:
        pass

    # After an eviction, ensure protected segment still respects target (it might shrink due to target change)
    _rebalance(cache_snapshot)
=======
def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    _maybe_age(cache_snapshot)
    # Record into ghost according to the segment it was evicted from
    k = evicted_obj.key
    seg = _key_seg.get(k, None)
    # Store last victim score for potential future enhancements
    global _last_victim_score
    _last_victim_score = _score(k)

    # Compute age since last access in access_count units for reuse distance sampling
    now = cache_snapshot.access_count
    age = max(0, now - _last_access.get(k, now))
    try:
        _recent_ghost_ages.append(age)
        if len(_recent_ghost_ages) > _MAX_GHOST_AGE_SAMPLES:
            # keep a rolling window
            del _recent_ghost_ages[0:len(_recent_ghost_ages) - _MAX_GHOST_AGE_SAMPLES]
    except Exception:
        pass

    if seg == 'prob':
        _ghost_probation[k] = _epoch
        _ghost_probation_ts[k] = now
        _probation.pop(k, None)
    elif seg == 'prot':
        _ghost_protected[k] = _epoch
        _ghost_protected_ts[k] = now
        _protected.pop(k, None)

    # Clean any stale two-touch markers
    _touched_once.pop(k, None)

    _key_seg.pop(k, None)

    # Trim ghost histories to bounded size and keep timestamp ghosts in sync
    limit = max(1, _GHOST_LIMIT_MULT * max(cache_snapshot.capacity, 1))
    while len(_ghost_probation) > limit:
        oldk, _ = _ghost_probation.popitem(last=False)
        _ghost_probation_ts.pop(oldk, None)
    while len(_ghost_protected) > limit:
        oldk, _ = _ghost_protected.popitem(last=False)
        _ghost_protected_ts.pop(oldk, None)

    # Adaptive protected tuning:
    try:
        new_score = _score(obj.key)
        if seg == 'prob' and new_score > _last_victim_score:
            # Incoming appears hotter than evicted probation item: expand protected a bit
            _increase_protected()
        elif seg == 'prot' and new_score <= _last_victim_score:
            # Evicted from protected for an item no hotter: shrink protected slightly
            _decrease_protected()
    except Exception:
        pass

    # After an eviction, ensure protected segment still respects target (it might shrink due to target change)
    _rebalance(cache_snapshot)
>>>>>>> REPLACE

</DIFF>