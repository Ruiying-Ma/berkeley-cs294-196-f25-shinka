<NAME>
arc_lrfu_freq_guard
</NAME>

<DESCRIPTION>
I improve the current ARC-like algorithm in three complementary ways to reduce miss rates across diverse workloads:

1) Lightweight frequency awareness with aging (LRFU-ish): Maintain a tiny per-key frequency counter (_freq) incremented on hits and modestly seeded on ghost re-admissions. Eviction, within the ARC-chosen segment (T1 or T2), selects the candidate with minimum (frequency, timestamp), avoiding eviction of hot items even if they are older. To prevent stale bias, apply periodic aging every capacity accesses by halving all frequencies.

2) Frequency-aware eviction: Replace pure-LRU victim selection with a frequency-aware LRU that scans the chosen segment and picks the lowest-frequency and oldest key. This maintains ARC’s adaptive replacement behavior while better protecting genuinely reused items.

3) Gentle scan guard: When we are forced to evict a protected, high-frequency item, enable a short-lived guard window during which brand-new items (not in ghosts) are inserted “cold” into probation (artificially older timestamps). This quickly sheds scan-induced pollution without heavy-handed admission control, and automatically expires.

These changes preserve the ARC ghost-driven adaptation of p and all existing metadata maintenance while improving resilience against scans and better retaining hot items. The modifications are contained to evict, update_after_hit, update_after_insert, and update_after_evict, plus small helper functions and globals.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
# Legacy timestamp dictionary kept for compatibility; used as a general access ledger.
m_key_timestamp = dict()

# Segmented LRU metadata: probation and protected segments (key -> last access time)
_probation = dict()
_protected = dict()

# ARC-style ghost histories (recently evicted):
_B1_ghost = OrderedDict()  # evicted from probation
_B2_ghost = OrderedDict()  # evicted from protected

# Adaptive target for probation share (ARC's p) and capacity estimate
_p_target = 0.0
_cap_est = 0
=======
# Legacy timestamp dictionary kept for compatibility; used as a general access ledger.
m_key_timestamp = dict()

# Segmented LRU metadata: probation and protected segments (key -> last access time)
_probation = dict()
_protected = dict()

# ARC-style ghost histories (recently evicted):
_B1_ghost = OrderedDict()  # evicted from probation
_B2_ghost = OrderedDict()  # evicted from protected

# Adaptive target for probation share (ARC's p) and capacity estimate
_p_target = 0.0
_cap_est = 0

# Lightweight per-key frequency with periodic aging
_freq = dict()           # key -> small integer frequency
_last_age_tick = 0       # last access_count when we aged

# Short-lived guard to resist scans after evicting strong protected entries
_guard_until = 0         # access_count until which we bias new insertions as cold
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
def _lru_key_in(seg_dict, cache_snapshot):
    """Return the LRU key from seg_dict that is currently in the cache."""
    min_key = None
    min_ts = None
    # Iterate only over keys that are in the current cache snapshot
    cache_keys = cache_snapshot.cache.keys()
    for k, ts in seg_dict.items():
        if k in cache_keys:
            if (min_ts is None) or (ts < min_ts):
                min_ts = ts
                min_key = k
    return min_key
=======
def _lru_key_in(seg_dict, cache_snapshot):
    """Return the LRU key from seg_dict that is currently in the cache."""
    min_key = None
    min_ts = None
    # Iterate only over keys that are in the current cache snapshot
    cache_keys = cache_snapshot.cache.keys()
    for k, ts in seg_dict.items():
        if k in cache_keys:
            if (min_ts is None) or (ts < min_ts):
                min_ts = ts
                min_key = k
    return min_key

def _min_by_freq_ts(seg_dict, cache_snapshot):
    """Pick a victim by (frequency asc, timestamp asc) among keys present in cache."""
    best_k = None
    best_score = None
    cache_keys = cache_snapshot.cache.keys()
    for k, ts in seg_dict.items():
        if k in cache_keys:
            f = _freq.get(k, 0)
            score = (f, ts)
            if best_score is None or score < best_score:
                best_score = score
                best_k = k
    return best_k

def _maybe_age(cache_snapshot):
    """Periodically age frequencies to avoid stale bias."""
    global _last_age_tick
    _ensure_capacity(cache_snapshot)
    now = cache_snapshot.access_count
    if now - _last_age_tick >= max(1, _cap_est):
        # Halve all frequencies (simple exponential decay)
        for k in list(_freq.keys()):
            newf = _freq.get(k, 0) // 2
            if newf <= 0:
                _freq.pop(k, None)
            else:
                _freq[k] = newf
        _last_age_tick = now
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
def evict(cache_snapshot, obj):
    '''
    This function defines how the algorithm chooses the eviction victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    _ensure_capacity(cache_snapshot)

    # ARC REPLACE(x): if |T1|>=1 and ((x in B2 and |T1| == p) or |T1| > p) -> evict from T1 else from T2
    t1_size = len(_probation)
    x_in_b2 = (obj is not None) and (obj.key in _B2_ghost)
    p_int = int(round(_p_target))
    choose_t1 = (t1_size >= 1) and ((x_in_b2 and t1_size == p_int) or (t1_size > _p_target))

    candid_obj_key = None
    if choose_t1:
        candid_obj_key = _lru_key_in(_probation, cache_snapshot)
    if candid_obj_key is None:
        candid_obj_key = _lru_key_in(_protected, cache_snapshot)
    if candid_obj_key is None:
        # Last-resort fallback: pick any key from the cache (should rarely happen).
        for k in cache_snapshot.cache:
            candid_obj_key = k
            break
    return candid_obj_key
=======
def evict(cache_snapshot, obj):
    '''
    This function defines how the algorithm chooses the eviction victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    _ensure_capacity(cache_snapshot)

    # ARC REPLACE(x): if |T1|>=1 and ((x in B2 and |T1| == p) or |T1| > p) -> evict from T1 else from T2
    t1_size = len(_probation)
    x_in_b2 = (obj is not None) and (obj.key in _B2_ghost)
    p_int = int(round(_p_target))
    choose_t1 = (t1_size >= 1) and ((x_in_b2 and t1_size == p_int) or (t1_size > _p_target))

    # Frequency-aware candidate selection within the chosen segment
    candid_obj_key = None
    if choose_t1:
        candid_obj_key = _min_by_freq_ts(_probation, cache_snapshot)
    if candid_obj_key is None:
        candid_obj_key = _min_by_freq_ts(_protected, cache_snapshot)
    if candid_obj_key is None:
        # Last-resort fallback: pick any key from the cache (should rarely happen).
        for k in cache_snapshot.cache:
            candid_obj_key = k
            break
    return candid_obj_key
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the algorithm update the metadata it maintains immediately after a cache hit.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    global m_key_timestamp, _probation, _protected
    _ensure_capacity(cache_snapshot)
    current_ts = cache_snapshot.access_count
    k = obj.key

    # Maintain a general timestamp ledger for robustness.
    m_key_timestamp[k] = current_ts

    if k in _probation:
        # Promote to protected on second touch.
        _probation.pop(k, None)
        _protected[k] = current_ts
    elif k in _protected:
        # Refresh recency within protected.
        _protected[k] = current_ts
    else:
        # Metadata miss: treat as a re-reference and place in protected.
        _protected[k] = current_ts

    # Respect ARC target for protected by demoting its LRU if needed.
    _, t2_target = _get_targets(cache_snapshot)
    if len(_protected) > t2_target:
        demote_key = _lru_key_in(_protected, cache_snapshot)
        if demote_key is not None and demote_key != k:
            demote_ts = _protected.pop(demote_key)
            _probation[demote_key] = demote_ts

    # If present in ghosts, clear and bound ghost history
    if k in _B1_ghost:
        _B1_ghost.pop(k, None)
    if k in _B2_ghost:
        _B2_ghost.pop(k, None)
    _ghost_trim()
=======
def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the algorithm update the metadata it maintains immediately after a cache hit.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    global m_key_timestamp, _probation, _protected, _freq
    _ensure_capacity(cache_snapshot)
    _maybe_age(cache_snapshot)
    current_ts = cache_snapshot.access_count
    k = obj.key

    # Maintain a general timestamp ledger for robustness.
    m_key_timestamp[k] = current_ts

    # Increment lightweight frequency counter
    _freq[k] = _freq.get(k, 0) + 1

    if k in _probation:
        # Promote to protected on second touch.
        _probation.pop(k, None)
        _protected[k] = current_ts
    elif k in _protected:
        # Refresh recency within protected.
        _protected[k] = current_ts
    else:
        # Metadata miss: treat as a re-reference and place in protected.
        _protected[k] = current_ts

    # Respect ARC target for protected by demoting its LRU if needed.
    _, t2_target = _get_targets(cache_snapshot)
    if len(_protected) > t2_target:
        demote_key = _lru_key_in(_protected, cache_snapshot)
        if demote_key is not None and demote_key != k:
            demote_ts = _protected.pop(demote_key)
            _probation[demote_key] = demote_ts

    # If present in ghosts, clear and bound ghost history
    if k in _B1_ghost:
        _B1_ghost.pop(k, None)
    if k in _B2_ghost:
        _B2_ghost.pop(k, None)
    _ghost_trim()
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    global m_key_timestamp, _probation, _protected, _p_target
    _ensure_capacity(cache_snapshot)
    current_ts = cache_snapshot.access_count
    k = obj.key

    # Record in general ledger
    m_key_timestamp[k] = current_ts

    in_b1 = k in _B1_ghost
    in_b2 = k in _B2_ghost

    if in_b1 or in_b2:
        # ARC adaptation of p and re-admit into protected
        if in_b1:
            inc = max(1.0, float(len(_B2_ghost)) / max(1.0, float(len(_B1_ghost))))
            _p_target = min(float(_cap_est), _p_target + inc)
            _B1_ghost.pop(k, None)
        else:
            dec = max(1.0, float(len(_B1_ghost)) / max(1.0, float(len(_B2_ghost))))
            _p_target = max(0.0, _p_target - dec)
            _B2_ghost.pop(k, None)
        _protected[k] = current_ts

        # Keep protected within its target by demoting its LRU if necessary
        _, t2_target = _get_targets(cache_snapshot)
        if len(_protected) > t2_target:
            demote_key = _lru_key_in(_protected, cache_snapshot)
            if demote_key is not None and demote_key != k:
                demote_ts = _protected.pop(demote_key)
                _probation[demote_key] = demote_ts
    else:
        # New to cache and ghosts: insert into probation
        _probation[k] = current_ts

    _ghost_trim()
=======
def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    global m_key_timestamp, _probation, _protected, _p_target, _freq, _guard_until
    _ensure_capacity(cache_snapshot)
    _maybe_age(cache_snapshot)
    current_ts = cache_snapshot.access_count
    k = obj.key

    # Record in general ledger
    m_key_timestamp[k] = current_ts

    in_b1 = k in _B1_ghost
    in_b2 = k in _B2_ghost

    if in_b1 or in_b2:
        # ARC adaptation of p and re-admit into protected
        if in_b1:
            inc = max(1.0, float(len(_B2_ghost)) / max(1.0, float(len(_B1_ghost))))
            _p_target = min(float(_cap_est), _p_target + inc)
            _B1_ghost.pop(k, None)
        else:
            dec = max(1.0, float(len(_B1_ghost)) / max(1.0, float(len(_B2_ghost))))
            _p_target = max(0.0, _p_target - dec)
            _B2_ghost.pop(k, None)
        _protected[k] = current_ts
        # Seed frequency as reused
        _freq[k] = max(_freq.get(k, 0) + 1, 2)

        # Keep protected within its target by demoting its LRU if necessary
        _, t2_target = _get_targets(cache_snapshot)
        if len(_protected) > t2_target:
            demote_key = _lru_key_in(_protected, cache_snapshot)
            if demote_key is not None and demote_key != k:
                demote_ts = _protected.pop(demote_key)
                _probation[demote_key] = demote_ts
    else:
        # New to cache and ghosts: insert into probation
        # If we recently had to evict a strong protected item, bias this newcomer as cold.
        if current_ts <= _guard_until:
            _probation[k] = current_ts - max(1, _cap_est)  # artificially older to prefer early eviction
        else:
            _probation[k] = current_ts
        # Seed minimal frequency for new items
        _freq[k] = _freq.get(k, 0)

    _ghost_trim()
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    global m_key_timestamp, _probation, _protected
    _ensure_capacity(cache_snapshot)
    # Remove evicted key from segments and add to appropriate ghost history.
    if evicted_obj is not None:
        k = evicted_obj.key
        was_t1 = k in _probation
        was_t2 = k in _protected

        _probation.pop(k, None)
        _protected.pop(k, None)
        m_key_timestamp.pop(k, None)

        if was_t1:
            _B1_ghost[k] = True  # insert as MRU in ghost
        elif was_t2:
            _B2_ghost[k] = True
        else:
            # Unknown residency; default to B1
            _B1_ghost[k] = True

        _ghost_trim()
    # Do not add obj here; it will be handled in update_after_insert.
=======
def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    global m_key_timestamp, _probation, _protected, _freq, _guard_until
    _ensure_capacity(cache_snapshot)
    # Remove evicted key from segments and add to appropriate ghost history.
    if evicted_obj is not None:
        k = evicted_obj.key
        was_t1 = k in _probation
        was_t2 = k in _protected
        fval = _freq.get(k, 0)

        _probation.pop(k, None)
        _protected.pop(k, None)
        m_key_timestamp.pop(k, None)
        _freq.pop(k, None)

        if was_t1:
            _B1_ghost[k] = True  # insert as MRU in ghost
        elif was_t2:
            _B2_ghost[k] = True
            # If we had to evict a strong protected item, enable a short guard window.
            if fval >= 2:
                _guard_until = cache_snapshot.access_count + max(1, _cap_est // 2)
        else:
            # Unknown residency; default to B1
            _B1_ghost[k] = True

        _ghost_trim()
    # Do not add obj here; it will be handled in update_after_insert.
>>>>>>> REPLACE

</DIFF>