--- a/original.py
+++ b/original.py
@@ -1,430 +1,589 @@
 # EVOLVE-BLOCK-START
-"""ARC + decayed-frequency hybrid with admission-guarded eviction and scan-aware two-touch gating"""
+"""ARC+TinyLFU+FreshScan v2:
+- ARC backbone with momentum-tuned p and sign-sensitive decay.
+- TinyLFU decayed counters for admission guard and eviction choice.
+- Adaptive fresh-window ghosts (median reuse age) and scan/guard windows.
+- Sampled-LRFU demotion with protected floor and readmission immunity.
+- Cross-segment override in evict() to avoid evicting items hotter than the incoming key.
+"""
 
 from collections import OrderedDict
 
-# Segments (resident)
-_T1_probation = OrderedDict()   # first-touch, recency-biased (LRU->MRU order)
-_T2_protected = OrderedDict()   # multi-touch, frequency-biased (LRU->MRU order)
-
-# Ghost histories (evicted keys) store eviction timestamps for freshness
-_B1_ghost = OrderedDict()       # from T1: key -> evict_ts
-_B2_ghost = OrderedDict()       # from T2: key -> evict_ts
-
-# ARC's adaptive target (float) for T1 size
-_p_target = 0.0
+# ---------------- Resident segments (LRU->MRU) ----------------
+_T1_probation = OrderedDict()   # first-touch, recency-biased
+_T2_protected = OrderedDict()   # multi-touch, frequency-biased
+
+# ---------------- Ghost histories (key -> evict_ts) ----------------
+_B1_ghost = OrderedDict()       # evicted from T1
+_B2_ghost = OrderedDict()       # evicted from T2
+
+# ---------------- Core state ----------------
+_p_target = 0.0                 # ARC adaptive target for |T1|
 _cap_est = 0
 
-# Recency timestamp (access time) and a small saturating counter (kept for guard heuristics)
-m_key_timestamp = dict()        # key -> last access time
-_freq = dict()                  # key -> small counter (saturating)
+m_key_timestamp = dict()        # key -> last access tick (for tie-break)
+_freq = dict()                  # small saturating counter for quick hotness guard
+_FREQ_MAX = 7
 _last_age_tick = 0
 
-# Decayed-frequency (TinyLFU-like) counters with epoch-based halving
+# TinyLFU decayed reference counters
 _refcnt = {}                    # key -> (count, epoch)
 _epoch_df = 0
 _last_epoch_tick_df = 0
-_DECAY_WINDOW = 128             # accesses per epoch; tied to capacity
+_DECAY_WINDOW = 128
+
+# Fresh-window adaptation via ghost age sampling
+_fresh_window = 0               # dynamic; defaults to ~0.5*cap
+_ghost_age_samples = []         # rolling sample of reuse ages
+
+# Activity tracking and scan/guard windows
+_hit_ewma = 0.0
+_ins_ewma = 0.0
+_EWMA_ALPHA = 0.05
+_SCAN_TRIGGER_INS = 0.7
+_SCAN_TRIGGER_HIT = 0.15
+_scan_until = 0
+_guard_until = 0
+
+# ARC p momentum with sign-sensitive decay
+_p_momentum = 0.0
+_p_last_update_tick = 0
+_p_last_sign = 0
+
+# Admission guard based on last victim strength
+_last_victim_strength = 0.0
+_VICTIM_GUARD_THRESH = 2.0
+
+# Two-touch gating memory (time-bounded by fresh_window)
+_first_touch_ts = {}            # key -> first touch tick in T1
+
+# Demotion immunity for fresh readmissions
+_no_demote_until = {}           # key -> tick until which demotion is blocked
+
+# Tunables
+_P_INIT_RATIO = 0.30
+_GHOST_BOUND_MULT = 1           # each ghost bounded to ≈cap
+_SAMPLE_T1_BASE = 2
+_SAMPLE_T2_BASE = 3
+
+
+# ---------------- Utilities ----------------
+
+def _ensure_capacity(cache_snapshot):
+    """Initialize capacity, p bounds, decay window, and fresh window."""
+    global _cap_est, _p_target, _DECAY_WINDOW, _fresh_window
+    cap = getattr(cache_snapshot, "capacity", None)
+    if isinstance(cap, int) and cap > 0:
+        _cap_est = cap
+    else:
+        _cap_est = max(_cap_est, len(cache_snapshot.cache))
+    if _cap_est <= 0:
+        _cap_est = max(1, len(cache_snapshot.cache))
+
+    # Initialize p share once
+    if _p_target == 0.0 and not _T1_probation and not _T2_protected and not _B1_ghost and not _B2_ghost:
+        _p_target = min(float(_cap_est), max(0.0, float(_cap_est) * _P_INIT_RATIO))
+    if _p_target < 0.0:
+        _p_target = 0.0
+    if _p_target > float(_cap_est):
+        _p_target = float(_cap_est)
+
+    # Adjust decay window: faster during scan/guard, slower otherwise
+    now = cache_snapshot.access_count
+    in_scan_guard = now <= max(_scan_until, _guard_until)
+    if in_scan_guard:
+        _DECAY_WINDOW = max(32, int(_cap_est // 2) or 1)
+    else:
+        _DECAY_WINDOW = max(64, int(_cap_est))
+
+    # Initialize fresh window if unset
+    if _fresh_window <= 0:
+        _fresh_window = max(1, int(0.5 * _cap_est))
+
+
+def _ghost_trim():
+    """Bound ghost lists by a multiple of capacity."""
+    limit = max(1, _GHOST_BOUND_MULT * max(_cap_est, 1))
+    while len(_B1_ghost) > limit:
+        _B1_ghost.popitem(last=False)
+    while len(_B2_ghost) > limit:
+        _B2_ghost.popitem(last=False)
+
+
+def _maybe_age(cache_snapshot):
+    """Age small counters and advance TinyLFU epoch periodically."""
+    global _last_age_tick, _epoch_df, _last_epoch_tick_df
+    _ensure_capacity(cache_snapshot)
+    now = cache_snapshot.access_count
+
+    # Age small saturating freq every ~cap accesses
+    if now - _last_age_tick >= max(1, _cap_est):
+        for k in list(_freq.keys()):
+            nf = _freq.get(k, 0) // 2
+            if nf <= 0:
+                _freq.pop(k, None)
+            else:
+                _freq[k] = nf
+        _last_age_tick = now
+
+    # Advance TinyLFU epoch at decay-window cadence
+    if now - _last_epoch_tick_df >= _DECAY_WINDOW:
+        _epoch_df += 1
+        _last_epoch_tick_df = now
+
+
+def _update_activity(is_hit, cache_snapshot):
+    """Track hit/insert EWMAs, set dynamic alpha, and detect scans."""
+    global _hit_ewma, _ins_ewma, _scan_until, _EWMA_ALPHA
+    # Faster adaptation when scan-like behavior suspected
+    tentative_alpha = 0.15 if (_ins_ewma > _SCAN_TRIGGER_INS and _hit_ewma < _SCAN_TRIGGER_HIT) else 0.05
+    _EWMA_ALPHA = tentative_alpha
+
+    alpha = _EWMA_ALPHA
+    _hit_ewma = (1.0 - alpha) * _hit_ewma + alpha * (1.0 if is_hit else 0.0)
+    _ins_ewma = (1.0 - alpha) * _ins_ewma + alpha * (0.0 if is_hit else 1.0)
+
+    if (_ins_ewma > _SCAN_TRIGGER_INS) and (_hit_ewma < _SCAN_TRIGGER_HIT):
+        _scan_until = cache_snapshot.access_count + int(max(1, 1.0 * _cap_est))
+
+
+def _adjust_p(sign, step, now):
+    """Momentum-based ARC p adjustment with sign-sensitive decay and clamping."""
+    global _p_target, _p_momentum, _p_last_update_tick, _p_last_sign
+    # Damp/amplify step indirectly bounded by capacity
+    bounded = min(max(0.5, float(step)), max(1.0, 0.25 * float(_cap_est)))
+    # If sign flips, decay momentum to curb overshoot
+    if _p_last_sign != 0 and int(sign) != _p_last_sign:
+        _p_momentum *= 0.5
+    _p_momentum = 0.5 * _p_momentum + float(sign) * bounded
+    _p_target += _p_momentum
+    if _p_target < 0.0:
+        _p_target = 0.0
+        _p_momentum = 0.0
+    if _p_target > float(_cap_est):
+        _p_target = float(_cap_est)
+        _p_momentum = 0.0
+    _p_last_sign = int(sign)
+    _p_last_update_tick = now
+
+
+# ---------------- TinyLFU helpers ----------------
 
 def _decayed_score(key):
-    """Return decayed reference score for a key."""
+    """Return decayed reference score for a key (epoch-aware)."""
     ce = _refcnt.get(key)
     if ce is None:
         return 0
     c, e = ce
     de = _epoch_df - e
     if de > 0:
         c = c >> min(6, de)
     return max(0, c)
 
+
 def _inc_decayed(key):
     """Increment decayed reference count for a key (epoch-aware)."""
     c, e = _refcnt.get(key, (0, _epoch_df))
     if e != _epoch_df:
         c = c >> min(6, _epoch_df - e)
         e = _epoch_df
     _refcnt[key] = (min(c + 1, 1 << 30), e)
 
-# Admission guard based on last victim strength and a short scan window
-_last_victim_strength = 0.0
-_VICTIM_GUARD_THRESH = 2.0
-_guard_until = 0
-
-# Scan detection and momentum for p updates
-_hit_ewma = 0.0
-_ins_ewma = 0.0
-_EWMA_ALPHA = 0.05
-_scan_until = 0
-_p_momentum = 0.0
-_p_last_update_tick = 0
-
-# Two-touch gating memory (epoch-based)
-_touched_once = {}  # key -> epoch when first touched in T1
-
-# Tunables
-_P_INIT_RATIO = 0.30             # initial share for T1
-_FREQ_MAX = 7                    # 3-bit saturating counter
-_FRESH_WINDOW_RATIO = 0.5        # ghost freshness window = 0.5 * cap
-_SCAN_TRIGGER_INS = 0.7          # insert EWMA threshold
-_SCAN_TRIGGER_HIT = 0.15         # hit EWMA threshold
-_SCAN_WINDOW_MULT = 1.0          # scan window length ~= cap accesses
-
-def _ensure_capacity(cache_snapshot):
-    """Initialize capacity and clamp p within [0, cap]. Also tie decay window to capacity."""
-    global _cap_est, _p_target, _DECAY_WINDOW
-    cap = getattr(cache_snapshot, "capacity", None)
-    if isinstance(cap, int) and cap > 0:
-        _cap_est = cap
-    else:
-        _cap_est = max(_cap_est, len(cache_snapshot.cache))
-    if _cap_est <= 0:
-        _cap_est = max(1, len(cache_snapshot.cache))
-    if _p_target == 0.0 and not _T1_probation and not _T2_protected and not _B1_ghost and not _B2_ghost:
-        _p_target = min(float(_cap_est), max(0.0, float(_cap_est) * _P_INIT_RATIO))
-    if _p_target < 0.0:
-        _p_target = 0.0
-    if _p_target > float(_cap_est):
-        _p_target = float(_cap_est)
-    # Decay window aligned with capacity to reflect working-set half-life
-    _DECAY_WINDOW = max(64, int(_cap_est))
-
-def _ghost_trim():
-    """Bound ghosts by capacity."""
-    while len(_B1_ghost) > _cap_est:
-        _B1_ghost.popitem(last=False)
-    while len(_B2_ghost) > _cap_est:
-        _B2_ghost.popitem(last=False)
-
-def _maybe_age(cache_snapshot):
-    """Periodically age frequency counters and advance the decayed epoch."""
-    global _last_age_tick, _epoch_df, _last_epoch_tick_df
-    _ensure_capacity(cache_snapshot)
-    now = cache_snapshot.access_count
-    # Age simple saturating counters
-    if now - _last_age_tick >= max(1, _cap_est):
-        for k in list(_freq.keys()):
-            newf = _freq.get(k, 0) // 2
-            if newf <= 0:
-                _freq.pop(k, None)
-            else:
-                _freq[k] = newf
-        _last_age_tick = now
-    # Advance decayed-frequency epoch
-    if now - _last_epoch_tick_df >= _DECAY_WINDOW:
-        _epoch_df += 1
-        _last_epoch_tick_df = now
-
-def _update_activity(is_hit, cache_snapshot):
-    """Track recent hit/miss behavior and activate scan window if needed."""
-    global _hit_ewma, _ins_ewma, _scan_until
-    alpha = _EWMA_ALPHA
-    _hit_ewma = (1.0 - alpha) * _hit_ewma + alpha * (1.0 if is_hit else 0.0)
-    _ins_ewma = (1.0 - alpha) * _ins_ewma + alpha * (0.0 if is_hit else 1.0)
-    if (_ins_ewma > _SCAN_TRIGGER_INS) and (_hit_ewma < _SCAN_TRIGGER_HIT):
-        _scan_until = cache_snapshot.access_count + int(max(1, _SCAN_WINDOW_MULT * _cap_est))
-
-def _adjust_p(sign, step, now, freshness_scale=1.0):
-    """Momentum-based adjustment of ARC's p with clamping."""
-    global _p_target, _p_momentum, _p_last_update_tick
-    bounded = min(max(1.0, float(step) * float(freshness_scale)), max(1.0, 0.25 * float(_cap_est)))
-    _p_momentum = 0.5 * _p_momentum + float(sign) * bounded
-    _p_target += _p_momentum
-    if _p_target < 0.0:
-        _p_target = 0.0
-        _p_momentum = 0.0
-    if _p_target > float(_cap_est):
-        _p_target = float(_cap_est)
-        _p_momentum = 0.0
-    _p_last_update_tick = now
+
+# ---------------- Fresh-window adaptation ----------------
+
+def _update_fresh_window_sample(age, cache_snapshot):
+    """Collect ghost reuse ages and adapt fresh window to rolling median."""
+    global _fresh_window
+    try:
+        _ghost_age_samples.append(int(max(0, age)))
+        if len(_ghost_age_samples) > max(1, _cap_est):
+            del _ghost_age_samples[0:len(_ghost_age_samples) - _cap_est]
+        if len(_ghost_age_samples) >= max(4, _cap_est // 2):
+            arr = sorted(_ghost_age_samples)
+            mid = len(arr) // 2
+            median_age = arr[mid] if len(arr) % 2 == 1 else (arr[mid - 1] + arr[mid]) // 2
+            lo = max(1, int(0.25 * _cap_est))
+            hi = max(1, int(1.00 * _cap_est))
+            _fresh_window = max(lo, min(hi, int(median_age)))
+    except Exception:
+        _fresh_window = max(1, int(0.5 * _cap_est))
+
+
+# ---------------- Eviction helpers ----------------
+
+def _lru_iter(od):
+    """Iterate keys from LRU to MRU for an OrderedDict."""
+    for k in od.keys():
+        yield k
+
+
+def _pick_candidate(od, sample_n, cache_snapshot, incoming_key):
+    """Pick best victim from LRU side by tuple: (hotter_flag, decayed_score, recency)."""
+    if not od:
+        return (None, None)
+    inc_score = _decayed_score(incoming_key) if incoming_key is not None else 0
+    cnt = 0
+    best_key = None
+    best_tuple = None
+    now = cache_snapshot.access_count
+    for k in _lru_iter(od):
+        if k not in cache_snapshot.cache:
+            continue
+        s = _decayed_score(k)
+        hotter = 1 if s > inc_score else 0
+        tup = (hotter, s, m_key_timestamp.get(k, now))
+        if best_tuple is None or tup < best_tuple:
+            best_tuple = tup
+            best_key = k
+        cnt += 1
+        if cnt >= sample_n:
+            break
+    return best_key, best_tuple
+
 
 def _fallback_choose(cache_snapshot):
-    """LRU fallback using timestamps."""
+    """LRU fallback using timestamps if structures desync."""
     keys = list(cache_snapshot.cache.keys())
     if not keys:
         return None
     known = [(k, m_key_timestamp.get(k, None)) for k in keys]
     known_ts = [x for x in known if x[1] is not None]
     if known_ts:
         return min(known_ts, key=lambda kv: kv[1])[0]
     return keys[0]
 
-def _lru_iter(od):
-    """Iterate keys from LRU to MRU for an OrderedDict."""
-    for k in od.keys():
-        yield k
-
-def _pick_with_guard(od, sample_n, cache_snapshot, incoming_key):
-    """Pick victim from LRU side with admission guard: avoid evicting hotter than incoming if possible."""
-    if not od:
-        return None
-    inc_score = _decayed_score(incoming_key) if incoming_key is not None else 0
-    cnt = 0
-    best = None
-    best_tuple = None
-    for k in _lru_iter(od):
-        if k not in cache_snapshot.cache:
-            continue
-        s = _decayed_score(k)
-        hotter = 1 if s > inc_score else 0
-        tup = (hotter, s, m_key_timestamp.get(k, 0))
-        if best_tuple is None or tup < best_tuple:
-            best_tuple = tup
-            best = k
-        cnt += 1
-        if cnt >= sample_n:
-            break
-    return best
 
 def _demote_protected_if_needed(cache_snapshot, avoid_key=None):
-    """Keep T2 size within ARC target by demoting LRU entries to T1 MRU."""
+    """Keep T2 within ARC target via sampled-LRFU demotion with protected floor and immunity."""
     _ensure_capacity(cache_snapshot)
+    now = cache_snapshot.access_count
     t1_target = int(round(_p_target))
     t2_target = max(_cap_est - t1_target, 0)
-    while len(_T2_protected) > t2_target:
-        # LRU of T2
-        lru = None
+
+    # Dynamic protected floor: ≥10% normally, 15% when locality is good
+    floor_ratio = 0.15 if _hit_ewma > 0.35 else 0.10
+    t2_floor = max(0, int(floor_ratio * t2_target))
+    if t2_target < t2_floor:
+        t2_target = t2_floor
+
+    while len(_T2_protected) > t2_target and len(_T2_protected) > t2_floor:
+        # Sample 4-5 from LRU and compute median of saturating freq
+        sample = []
         for k in _lru_iter(_T2_protected):
             if k != avoid_key and k in cache_snapshot.cache:
-                lru = k
-                break
-        if lru is None:
-            break        # nothing to demote
-        _T2_protected.pop(lru, None)
-        _T1_probation[lru] = True  # demoted MRU in T1
+                # Respect demotion immunity
+                if _no_demote_until.get(k, 0) > now:
+                    continue
+                sample.append(k)
+                if len(sample) >= 5:
+                    break
+        if not sample:
+            break
+
+        freqs = sorted([_freq.get(kk, 0) for kk in sample])
+        med = freqs[len(freqs) // 2]
+        # Candidates with freq <= median; choose coldest by (decayed_score, ts)
+        cands = [kk for kk in sample if _freq.get(kk, 0) <= med]
+        pick_pool = cands if cands else sample
+        victim = min(pick_pool, key=lambda kk: (_decayed_score(kk), m_key_timestamp.get(kk, now)))
+        _T2_protected.pop(victim, None)
+        _T1_probation[victim] = True  # demoted MRU
+
+
+# ---------------- Public API: evict + updates ----------------
 
 def evict(cache_snapshot, obj):
-    '''
-    Evict using ARC replace with decayed-frequency, admission guard, and scan bias:
-    - Prefer T1 when |T1| > p or when upcoming key is in B2 and |T1| == p.
-    - During scan window, always prefer T1 if non-empty.
-    - Within the chosen segment, sample a few LRU entries and pick (hotter_flag, decayed_score asc, timestamp asc).
-    '''
+    """
+    ARC replace with scan/guard bias, admission guard, and cross-segment override:
+    - Baseline chooses T1 when |T1| > p (or key in B2 and |T1| == p).
+    - In scan/guard window: prefer T1 if non-empty.
+    - Within segment: sample LRU side and pick by (hotter_flag, decayed_score, recency).
+    - Cross-segment override: if chosen victim is hotter than incoming while the other segment
+      offers a clearly colder candidate and segments aren't tiny, switch segments.
+    """
     _ensure_capacity(cache_snapshot)
     _maybe_age(cache_snapshot)
 
     t1_size = len(_T1_probation)
     t2_size = len(_T2_protected)
+    now = cache_snapshot.access_count
+    in_scan_guard = now <= max(_scan_until, _guard_until)
+    incoming_key = obj.key if obj is not None else None
     x_in_b2 = (obj is not None) and (obj.key in _B2_ghost)
+
+    # ARC baseline
     choose_t1 = (t1_size >= 1) and ((x_in_b2 and t1_size == int(round(_p_target))) or (t1_size > _p_target))
-
-    # Scan bias: keep evictions in probation when scanning
-    if cache_snapshot.access_count <= _scan_until and t1_size > 0:
+    if in_scan_guard and t1_size > 0:
         choose_t1 = True
 
-    # Adaptive sampling sizes based on pressure and scan
+    # Adaptive sampling sizes and pressure-based tweaks
     cap = max(1, _cap_est)
-    t1_pressure = (t1_size > _p_target + 0.1 * cap) or (cache_snapshot.access_count <= _scan_until)
-    t2_pressure = (t2_size > (cap - int(round(_p_target)))) or False
-
-    T1_SAMPLE = 1 if t1_pressure else 3
-    if cache_snapshot.access_count <= _scan_until:
+    t1_pressure = (t1_size > _p_target + 0.1 * cap) or in_scan_guard
+    t2_pressure = (t2_size > (cap - int(round(_p_target))))
+    T1_SAMPLE = 1 if t1_pressure else _SAMPLE_T1_BASE
+    if in_scan_guard:
         T1_SAMPLE = 1
-    T2_SAMPLE = 5 if t2_pressure else 3
+    T2_SAMPLE = (_SAMPLE_T2_BASE + 1) if t2_pressure else _SAMPLE_T2_BASE
     if _hit_ewma < 0.2:
         T2_SAMPLE = max(2, T2_SAMPLE - 1)
 
-    incoming_key = obj.key if obj is not None else None
-
+    # Compute candidates for potential cross override
+    cand_t1_key, cand_t1_tuple = (None, None)
+    cand_t2_key, cand_t2_tuple = (None, None)
+    if t1_size > 0:
+        cand_t1_key, cand_t1_tuple = _pick_candidate(_T1_probation, T1_SAMPLE, cache_snapshot, incoming_key)
+    if t2_size > 0:
+        cand_t2_key, cand_t2_tuple = _pick_candidate(_T2_protected, T2_SAMPLE, cache_snapshot, incoming_key)
+
+    # Cross override policy
     victim_key = None
-    if choose_t1 and t1_size > 0:
-        victim_key = _pick_with_guard(_T1_probation, T1_SAMPLE, cache_snapshot, incoming_key)
-    if victim_key is None and t2_size > 0:
-        victim_key = _pick_with_guard(_T2_protected, T2_SAMPLE, cache_snapshot, incoming_key)
-    if victim_key is None and t1_size > 0:
-        victim_key = _pick_with_guard(_T1_probation, T1_SAMPLE, cache_snapshot, incoming_key)
+    if choose_t1 and cand_t1_key is not None:
+        victim_key = cand_t1_key
+        # Consider evicting from T2 instead if it's clearly colder and segments aren't tiny
+        if cand_t2_key is not None and len(_T2_protected) > max(1, int(0.1 * cap)):
+            # Require strict margin when locality is poor
+            freq_margin = 1 if _hit_ewma < 0.2 else 0
+            hotter1, s1, _ts1 = cand_t1_tuple
+            hotter2, s2, _ts2 = cand_t2_tuple
+            if (hotter1 > hotter2) or ((s1 - s2) >= freq_margin and cand_t2_tuple < cand_t1_tuple):
+                victim_key = cand_t2_key
+    elif not choose_t1 and cand_t2_key is not None:
+        victim_key = cand_t2_key
+        # Consider evicting from T1 instead if it's clearly colder
+        if cand_t1_key is not None and len(_T1_probation) > 0:
+            freq_margin = 1 if _hit_ewma < 0.2 else 0
+            hotter2, s2, _ts2 = cand_t2_tuple
+            hotter1, s1, _ts1 = cand_t1_tuple
+            if (hotter2 > hotter1) or ((s2 - s1) >= freq_margin and cand_t1_tuple < cand_t2_tuple):
+                victim_key = cand_t1_key
+
+    # Fallbacks if candidate selection failed
+    if victim_key is None and cand_t1_key is not None:
+        victim_key = cand_t1_key
+    if victim_key is None and cand_t2_key is not None:
+        victim_key = cand_t2_key
     if victim_key is None:
         victim_key = _fallback_choose(cache_snapshot)
     return victim_key
 
+
 def update_after_hit(cache_snapshot, obj):
-    '''
+    """
     On hit:
-    - Update EWMA and age counters.
-    - Increment decayed frequency and saturating counter.
-    - In scan mode: require two touches in T1 before promotion (epoch-gated).
-    - Otherwise: first hit in T1 promotes to T2 if already touched once, or clearly hot by decayed score, or recent B2 ghost.
-    - Keep T2 within its ARC target via demotion.
-    - Remove any ghost entries for this key.
-    '''
+    - Update activity EWMAs and aging; bump decayed and saturating counters; refresh timestamp.
+    - T2 hits: move to MRU.
+    - T1 hits: two-touch promotion time-bounded by fresh_window; stricter during scan/poor locality or T1>p.
+      Reset stale frequency if second touch is too late. Allow eager promotion when locality is good.
+    - Keep T2 within target via sampled-LRFU demotion with protected floor and immunity.
+    - Clean ghosts for this key.
+    """
     _ensure_capacity(cache_snapshot)
     _maybe_age(cache_snapshot)
     _update_activity(True, cache_snapshot)
 
     key = obj.key
     now = cache_snapshot.access_count
     m_key_timestamp[key] = now
     _freq[key] = min(_FREQ_MAX, _freq.get(key, 0) + 1)
     _inc_decayed(key)
 
-    in_scan = now <= _scan_until
-    fresh_window = max(1, int(_FRESH_WINDOW_RATIO * _cap_est))
+    fresh_window = max(1, int(_fresh_window))
+    in_scan_guard = now <= max(_scan_until, _guard_until)
 
     if key in _T2_protected:
         _T2_protected.move_to_end(key, last=True)
-        _touched_once.pop(key, None)
+        _first_touch_ts.pop(key, None)
     elif key in _T1_probation:
-        last_epoch = _touched_once.get(key)
+        strict = in_scan_guard or (_hit_ewma < 0.25) or (len(_T1_probation) > int(round(_p_target)))
+        first_ts = _first_touch_ts.get(key)
         promote = False
-        if in_scan:
-            if last_epoch is not None and (_epoch_df - last_epoch) <= 1:
+
+        # Consider hotness and recent B2 ghost
+        hot_decayed = (_decayed_score(key) >= 2)
+        ev_ts_b2 = _B2_ghost.get(key, None)
+        recent_b2 = isinstance(ev_ts_b2, int) and ((now - ev_ts_b2) <= fresh_window)
+
+        if strict:
+            if first_ts is not None and (now - first_ts) <= fresh_window:
+                promote = True
+            elif hot_decayed or recent_b2:
                 promote = True
             else:
-                _touched_once[key] = _epoch_df
+                # Start two-touch timer and reset stale freq if late
+                if first_ts is None:
+                    _first_touch_ts[key] = now
+                else:
+                    if (now - first_ts) > fresh_window:
+                        _freq[key] = 1
+                _T1_probation.move_to_end(key, last=True)
         else:
-            hot_freq = (_decayed_score(key) >= 2)
-            ev_ts = _B2_ghost.get(key, None)
-            recent_b2 = (isinstance(ev_ts, int) and (now - ev_ts) <= fresh_window)
-            if (last_epoch is not None) or hot_freq or recent_b2:
+            # Good locality: allow eager promotions
+            if first_ts is not None or hot_decayed or recent_b2:
                 promote = True
             else:
-                _touched_once[key] = _epoch_df
+                _first_touch_ts[key] = now
+                _T1_probation.move_to_end(key, last=True)
 
         if promote:
-            _touched_once.pop(key, None)
+            _first_touch_ts.pop(key, None)
             _T1_probation.pop(key, None)
-            _T2_protected[key] = True  # MRU in T2
-        else:
-            _T1_probation.move_to_end(key, last=True)
+            _T2_protected[key] = True  # MRU
     else:
-        # Metadata miss: treat as hot and place in T2
+        # Metadata miss on hit: treat as hot
         _T2_protected[key] = True
-        _touched_once.pop(key, None)
+        _first_touch_ts.pop(key, None)
 
     _demote_protected_if_needed(cache_snapshot, avoid_key=key)
 
     # Ghost cleanup
-    if key in _B1_ghost:
-        _B1_ghost.pop(key, None)
-    if key in _B2_ghost:
-        _B2_ghost.pop(key, None)
+    _B1_ghost.pop(key, None)
+    _B2_ghost.pop(key, None)
     _ghost_trim()
 
+
 def update_after_insert(cache_snapshot, obj):
-    '''
-    On miss and insert:
-    - Update EWMA, age counters, and decayed frequency.
-    - If key in ghosts: momentum-adjust p; fresh ghosts re-admit to T2 (seed decayed freq), stale to T1.
-    - Else: insert to T1; during guard/scan, place at T1 LRU and gently lower p in scan to bias T1 evictions.
-    '''
+    """
+    On miss/insert:
+    - Update activity and aging; increment decayed on access that led to miss.
+    - Ghost hit:
+        * Compute age and freshness w = max(0, 1 - age/fresh_window).
+        * Update ARC p with momentum; during scan, damp B1 increases (x0.5) and amplify B2 decreases (x1.2).
+        * If w>=0.5: admit to T2, seed freq and grant demotion immunity for fresh_window.
+          Else: admit to T1 and start two-touch timer.
+        * Record reuse age sample to adapt fresh_window.
+    - New key:
+        * Admit to T1 MRU; during scan/guard insert at T1 LRU and gently lower p to bias T1 evictions.
+    """
     _ensure_capacity(cache_snapshot)
     _maybe_age(cache_snapshot)
     _update_activity(False, cache_snapshot)
 
     key = obj.key
     now = cache_snapshot.access_count
     m_key_timestamp[key] = now
-    _inc_decayed(key)  # count the access producing this insert
+    _inc_decayed(key)  # count the current access
+
+    fresh_window = max(1, int(_fresh_window))
+    in_scan_guard = now <= max(_scan_until, _guard_until)
 
     in_b1 = key in _B1_ghost
     in_b2 = key in _B2_ghost
 
-    fresh_window = max(1, int(_FRESH_WINDOW_RATIO * _cap_est))
-
     if in_b1 or in_b2:
         if in_b1:
-            step = max(1.0, float(len(_B2_ghost)) / max(1.0, float(len(_B1_ghost))))
-            ev_ts = _B1_ghost.get(key, None)
+            ev_ts = _B1_ghost.get(key)
             age = (now - ev_ts) if isinstance(ev_ts, int) else (fresh_window + 1)
-            fresh = age <= fresh_window
-            _adjust_p(+1, step, now, freshness_scale=(1.2 if fresh else 1.0))
+            _update_fresh_window_sample(age, cache_snapshot)
+            w = max(0.0, 1.0 - float(age) / float(fresh_window))
+            base_step = max(1.0, float(len(_B2_ghost)) / max(1.0, float(len(_B1_ghost))))
+            step = base_step * (1.0 + 2.0 * w)
+            if in_scan_guard:
+                step *= 0.5  # damp increases during scans
+            _adjust_p(+1, step, now)
             _B1_ghost.pop(key, None)
-            if fresh:
+            # Admission and seeding
+            if w >= 0.5:
                 _T2_protected[key] = True
-                # Seed some frequency to stabilize against immediate eviction
-                _freq[key] = min(_FREQ_MAX, _freq.get(key, 0) + 2)
-                _inc_decayed(key)
+                _freq[key] = max(_freq.get(key, 0), 1 + int(round(4.0 * w)))
+                _no_demote_until[key] = now + fresh_window
                 _demote_protected_if_needed(cache_snapshot, avoid_key=key)
             else:
                 _T1_probation[key] = True
+                _first_touch_ts[key] = now
         else:
-            step = max(1.0, float(len(_B1_ghost)) / max(1.0, float(len(_B2_ghost))))
-            ev_ts = _B2_ghost.get(key, None)
+            ev_ts = _B2_ghost.get(key)
             age = (now - ev_ts) if isinstance(ev_ts, int) else (fresh_window + 1)
-            fresh = age <= fresh_window
-            _adjust_p(-1, step, now, freshness_scale=(1.2 if fresh else 1.0))
+            _update_fresh_window_sample(age, cache_snapshot)
+            w = max(0.0, 1.0 - float(age) / float(fresh_window))
+            base_step = max(1.0, float(len(_B1_ghost)) / max(1.0, float(len(_B2_ghost))))
+            step = base_step * (1.0 + 2.0 * w)
+            if in_scan_guard:
+                step *= 1.2  # amplify decreases during scans
+            _adjust_p(-1, step, now)
             _B2_ghost.pop(key, None)
-            if fresh:
+            if w >= 0.5:
                 _T2_protected[key] = True
-                _freq[key] = min(_FREQ_MAX, _freq.get(key, 0) + 2)
-                _inc_decayed(key)
+                _freq[key] = max(_freq.get(key, 0), 1 + int(round(4.0 * w)))
+                _no_demote_until[key] = now + fresh_window
                 _demote_protected_if_needed(cache_snapshot, avoid_key=key)
             else:
                 _T1_probation[key] = True
+                _first_touch_ts[key] = now
     else:
-        # New key: insert into T1
+        # New admission: T1; scan/guard -> insert at LRU and nudge p toward frequency
         _T1_probation[key] = True
-        # Guard and scan handling: bias newcomer colder
-        if (_last_victim_strength >= _VICTIM_GUARD_THRESH) or (now <= _scan_until):
+        if in_scan_guard or (_last_victim_strength >= _VICTIM_GUARD_THRESH):
             _T1_probation.move_to_end(key, last=False)
-            # During scan, gently lower p to keep pressure in T1
-            if now <= _scan_until:
+            if in_scan_guard:
                 _adjust_p(-1, max(1.0, 0.1 * float(_cap_est)), now)
-
-    # Avoid duplicates across structures
+        else:
+            _T1_probation.move_to_end(key, last=True)
+
+    # Avoid duplicates across structures and trim ghosts
     if key in _T1_probation and key in _T2_protected:
         _T1_probation.pop(key, None)
-    if key in _B1_ghost:
-        _B1_ghost.pop(key, None)
-    if key in _B2_ghost:
-        _B2_ghost.pop(key, None)
+    _B1_ghost.pop(key, None)
+    _B2_ghost.pop(key, None)
     _ghost_trim()
 
+
 def update_after_evict(cache_snapshot, obj, evicted_obj):
-    '''
+    """
     After eviction:
-    - Remove from resident segment and put into the appropriate ghost with timestamp.
-    - Track victim strength (decayed) and set a short admission guard when a strong T2 victim is evicted.
-    - Clean frequency, timestamp, and two-touch entries.
-    '''
+    - Move victim to corresponding ghost with timestamp.
+    - Track victim strength (decayed + T2 bonus) and set a short guard if hot T2 victim was evicted.
+    - Clean per-key state; maintain ghost bounds.
+    """
     _ensure_capacity(cache_snapshot)
     key = evicted_obj.key
     now = cache_snapshot.access_count
 
     was_t1 = key in _T1_probation
     was_t2 = key in _T2_protected
 
     fval_dec = _decayed_score(key)
     strength = float(fval_dec) + (2.0 if was_t2 else 0.0)
     global _last_victim_strength, _guard_until
     _last_victim_strength = strength
 
     if was_t1:
         _T1_probation.pop(key, None)
         _B1_ghost[key] = now
     elif was_t2:
         _T2_protected.pop(key, None)
         _B2_ghost[key] = now
         if fval_dec >= 2:
             _guard_until = now + max(1, _cap_est // 2)
     else:
-        # Unknown residency; default to B1 ghost
         _B1_ghost[key] = now
 
     # Clean per-key state
     m_key_timestamp.pop(key, None)
     _freq.pop(key, None)
     _refcnt.pop(key, None)
-    _touched_once.pop(key, None)
+    _first_touch_ts.pop(key, None)
+    _no_demote_until.pop(key, None)
 
     _ghost_trim()
 # EVOLVE-BLOCK-END
 
 # This part remains fixed (not evolved)
 def run_caching(trace_path: str, copy_code_dst: str):
     """Run the caching algorithm on a trace"""
     import os
     with open(os.path.abspath(__file__), 'r', encoding="utf-8") as f:
         code_str = f.read()
     with open(os.path.join(copy_code_dst), 'w') as f:
         f.write(code_str)
     from cache_utils import Cache, CacheConfig, CacheObj, Trace
     trace = Trace(trace_path=trace_path)
     cache_capacity = max(int(trace.get_ndv() * 0.1), 1)
     cache = Cache(CacheConfig(cache_capacity))
     for entry in trace.entries:
         obj = CacheObj(key=str(entry.key))
         cache.get(obj)
     with open(copy_code_dst, 'w') as f:
         f.write("")
     hit_rate = round(cache.hit_count / cache.access_count, 6)
     return hit_rate