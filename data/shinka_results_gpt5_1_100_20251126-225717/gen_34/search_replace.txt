<NAME>
arc_slfu_ghost_strength_and_target_enforce
</NAME>

<DESCRIPTION>
I introduce three synergistic improvements that reduce miss rate across diverse workloads while keeping complexity low:

1) Ghost-strength memory for frequency seeding: When an item is evicted, we remember its tiny LFU counter in a new _ghost_strength map. On reinsertion via ghost hits, we seed its tiny LFU (_freq) using its remembered strength (decayed), which makes previously hot items regain protection faster. This particularly helps long-range reuse traces where re-reference distance exceeds the initial fresh-ghost window.

2) Segment target enforcement via demotion: I add _enforce_segment_targets() to gently demote the LRU of T2 to T1 when T2 exceeds its budget (capacity minus p). This keeps the protected segment from growing stale and makes it easier to evict genuinely cold items from T1, stabilizing the balance between recency and frequency.

3) Better T2 sampling and scan-aware conservatism: I adjust T2 sampling size based on recent hit rate (from the sliding window) and segment pressure, using fewer samples in low-hit or scan-like periods and more samples when T2 is crowded. I also expand the “fresh ghost” window from cap/2 to cap accesses to correctly re-admit items with medium-range reuse distances, and limit over-eager seeding in scan periods.

These changes are modest, orthogonal to existing logic, and improve protection for true hot items while resisting scan pollution. They also include housekeeping: ghost trimming now removes stale strength entries to prevent unbounded growth.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
# Ghost history (recently evicted keys) for adaptation; store last-evict timestamp
_B1_ghost = OrderedDict()       # evicted from T1: key -> last_evicted_ts
_B2_ghost = OrderedDict()       # evicted from T2: key -> last_evicted_ts

# Adaptive target size for probation (ARC's p). Float to allow smooth adjust.
_p_target = 0.0
=======
# Ghost history (recently evicted keys) for adaptation; store last-evict timestamp
_B1_ghost = OrderedDict()       # evicted from T1: key -> last_evicted_ts
_B2_ghost = OrderedDict()       # evicted from T2: key -> last_evicted_ts
# Remember ghost strength (tiny LFU at eviction) to seed on re-admission
_ghost_strength = dict()        # key -> tiny LFU counter at eviction

# Adaptive target size for probation (ARC's p). Float to allow smooth adjust.
_p_target = 0.0
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
def _ghost_trim():
    """Limit ghost lists to capacity each (ARC-style bound)."""
    global _B1_ghost, _B2_ghost
    # Trim oldest entries beyond capacity
    while len(_B1_ghost) > _cap_est:
        _B1_ghost.popitem(last=False)
    while len(_B2_ghost) > _cap_est:
        _B2_ghost.popitem(last=False)
=======
def _ghost_trim():
    """Limit ghost lists to capacity each (ARC-style bound). Also trim remembered strengths."""
    global _B1_ghost, _B2_ghost, _ghost_strength
    # Trim oldest entries beyond capacity and drop their remembered strengths
    while len(_B1_ghost) > _cap_est:
        k, _ = _B1_ghost.popitem(last=False)
        _ghost_strength.pop(k, None)
    while len(_B2_ghost) > _cap_est:
        k, _ = _B2_ghost.popitem(last=False)
        _ghost_strength.pop(k, None)
    # Periodically sanitize ghost_strength to avoid buildup of keys no longer in ghosts
    if len(_ghost_strength) > 4 * _cap_est:
        for k in list(_ghost_strength.keys()):
            if k not in _B1_ghost and k not in _B2_ghost:
                _ghost_strength.pop(k, None)
                if len(_ghost_strength) <= 2 * _cap_est:
                    break
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
def _t2_sample_size():
    """Adaptive sampling size for T2 victim selection."""
    target_t1 = int(max(0, round(_p_target)))
    crowded = len(_T2_protected) > max(0, _cap_est - target_t1)
    return 5 if crowded else 3
=======
def _t2_sample_size():
    """Adaptive sampling size for T2 victim selection based on segment pressure and recent hits."""
    target_t1 = int(max(0, round(_p_target)))
    crowded = len(_T2_protected) > max(0, _cap_est - target_t1)
    total = len(_win_hits)
    recent_hit_rate = (sum(_win_hits) / float(total)) if total > 0 else 0.0
    if recent_hit_rate < 0.2:
        return 2
    return 6 if crowded else 3
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
def evict(cache_snapshot, obj):
=======
def _enforce_segment_targets():
    """Demote oldest from T2 into T1 to respect target split between segments."""
    target_t1 = int(max(0, round(_p_target)))
    max_t2 = max(0, _cap_est - target_t1)
    # Demote until T2 is within its budget and T1 has space relative to its target
    while len(_T2_protected) > max_t2 and len(_T1_probation) < target_t1:
        try:
            k = next(iter(_T2_protected.keys()))
        except StopIteration:
            break
        _T2_protected.pop(k, None)
        _T1_probation[k] = True

def evict(cache_snapshot, obj):
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
def update_after_hit(cache_snapshot, obj):
    '''
    Update metadata after cache hit.
    - If hit in probation (T1), promote to protected (T2) unless scan mode requires two touches.
    - If hit in protected, refresh recency.
    - Maintain fallback timestamp map and scan stats.
    '''
    _ensure_capacity(cache_snapshot)
    _freq_age(cache_snapshot)
    key = obj.key
    now = cache_snapshot.access_count
    # Update fallback LRU timestamp and tiny frequency
    m_key_timestamp[key] = now
    _freq_bump(key)

    was_hit = True

    if key in _T2_protected:
        # Refresh to MRU
        _T2_protected.move_to_end(key, last=True)
    elif key in _T1_probation:
        # In scan mode, require two touches before promotion
        if _in_scan_mode(cache_snapshot) and _freq.get(key, 0) < 2:
            _T1_probation.move_to_end(key, last=True)
        else:
            _T1_probation.pop(key, None)
            _T2_protected[key] = True  # insert as MRU
    else:
        # Metadata miss: cache has it but we don't; treat as frequent and add to protected
        _T2_protected[key] = True

    # Touch ghosts cleanup if any stale
    if key in _B1_ghost:
        _B1_ghost.pop(key, None)
    if key in _B2_ghost:
        _B2_ghost.pop(key, None)

    # Sliding window tracking and scan mode upkeep
    _record_access(cache_snapshot, key, was_hit=was_hit)
    _maybe_update_scan_mode(cache_snapshot)

    # In scan mode, gradually tilt p downward to resist pollution
    global _last_scan_adjust_at, _p_target
    if _in_scan_mode(cache_snapshot) and now - _last_scan_adjust_at >= max(32, _cap_est // 2):
        b1 = len(_B1_ghost)
        b2 = len(_B2_ghost)
        other_over_this = (b2 / max(1.0, b1)) if b1 > 0 else 1.0
        step = min(max(1.0, other_over_this), 0.25 * float(_cap_est))
        _p_target = max(0.0, _p_target - step)
        _last_scan_adjust_at = now

    _ghost_trim()
=======
def update_after_hit(cache_snapshot, obj):
    '''
    Update metadata after cache hit.
    - If hit in probation (T1), promote to protected (T2) unless scan mode requires two touches.
    - If hit in protected, refresh recency.
    - Maintain fallback timestamp map and scan stats.
    '''
    _ensure_capacity(cache_snapshot)
    _freq_age(cache_snapshot)
    key = obj.key
    now = cache_snapshot.access_count
    # Update fallback LRU timestamp and tiny frequency
    m_key_timestamp[key] = now
    _freq_bump(key)

    was_hit = True

    if key in _T2_protected:
        # Refresh to MRU
        _T2_protected.move_to_end(key, last=True)
    elif key in _T1_probation:
        # In scan mode, require two touches before promotion
        if _in_scan_mode(cache_snapshot) and _freq.get(key, 0) < 2:
            _T1_probation.move_to_end(key, last=True)
        else:
            _T1_probation.pop(key, None)
            _T2_protected[key] = True  # insert as MRU
            # Reward promotion with an extra tiny-LFU bump to reflect 2nd touch
            _freq_bump(key)
    else:
        # Metadata miss: cache has it but we don't; treat as frequent and add to protected
        _T2_protected[key] = True

    # Touch ghosts cleanup if any stale
    if key in _B1_ghost:
        _B1_ghost.pop(key, None)
    if key in _B2_ghost:
        _B2_ghost.pop(key, None)

    # Sliding window tracking and scan mode upkeep
    _record_access(cache_snapshot, key, was_hit=was_hit)
    _maybe_update_scan_mode(cache_snapshot)

    # In scan mode, gradually tilt p downward to resist pollution
    global _last_scan_adjust_at, _p_target
    if _in_scan_mode(cache_snapshot) and now - _last_scan_adjust_at >= max(32, _cap_est // 2):
        b1 = len(_B1_ghost)
        b2 = len(_B2_ghost)
        other_over_this = (b2 / max(1.0, b1)) if b1 > 0 else 1.0
        step = min(max(1.0, other_over_this), 0.25 * float(_cap_est))
        _p_target = max(0.0, _p_target - step)
        _last_scan_adjust_at = now

    # Keep segment sizes close to target to prevent protected from stagnating
    _enforce_segment_targets()
    _ghost_trim()
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
def update_after_insert(cache_snapshot, obj):
    '''
    Update metadata on insertion (cache miss path).
    - If the key is in ghost lists, adjust p (ARC adaptation) and insert into protected only if ghost is fresh.
    - Otherwise insert into probation as MRU.
    - Maintain fallback timestamp map and scan stats.
    '''
    _ensure_capacity(cache_snapshot)
    _freq_age(cache_snapshot)
    key = obj.key
    now = cache_snapshot.access_count
    m_key_timestamp[key] = now

    in_b1 = key in _B1_ghost
    in_b2 = key in _B2_ghost

    placed_in_t2 = False

    if in_b1 or in_b2:
        # ARC adaptation of p
        global _p_target
        if in_b1:
            # Favor recency: increase p
            inc = max(1, len(_B2_ghost) // max(1, len(_B1_ghost)))
            _p_target = min(float(_cap_est), _p_target + float(inc))
            last = _B1_ghost.get(key, None)
            _B1_ghost.pop(key, None)
        else:
            # Favor frequency: decrease p
            dec = max(1, len(_B1_ghost) // max(1, len(_B2_ghost)))
            _p_target = max(0.0, _p_target - float(dec))
            last = _B2_ghost.get(key, None)
            _B2_ghost.pop(key, None)

        # Admission: only place directly into T2 if ghost is fresh and not in scan mode
        # Handle legacy True values by treating them as stale
        age = None
        if isinstance(last, int):
            age = now - last
        else:
            age = _cap_est * 10  # treat as stale if no timestamp
        if (age <= max(1, _cap_est // 2)) and (not _in_scan_mode(cache_snapshot)):
            if key in _T1_probation:
                _T1_probation.pop(key, None)
            _T2_protected[key] = True
            placed_in_t2 = True
            # Seed stronger frequency on re-admission
            _freq[key] = max(_freq.get(key, 0), 3 if in_b2 else 2)
        else:
            # Stale ghost or during scan: insert into T1
            _T1_probation[key] = True
            _freq.setdefault(key, 0)
    else:
        # New to cache and ghosts: insert into probation (T1)
        if key in _T2_protected:
            # Rare desync; ensure consistency (shouldn't happen on miss)
            _T2_protected.move_to_end(key, last=True)
        else:
            _T1_probation[key] = True
        _freq.setdefault(key, 0)

    # Avoid duplicates across structures
    if placed_in_t2 and key in _T1_probation:
        _T1_probation.pop(key, None)
    if not placed_in_t2 and key in _T2_protected:
        _T2_protected.pop(key, None)

    # Sliding window tracking and scan mode upkeep (miss)
    _record_access(cache_snapshot, key, was_hit=False)
    _maybe_update_scan_mode(cache_snapshot)
    _ghost_trim()
=======
def update_after_insert(cache_snapshot, obj):
    '''
    Update metadata on insertion (cache miss path).
    - If the key is in ghost lists, adjust p (ARC adaptation) and insert into protected only if ghost is fresh.
    - Otherwise insert into probation as MRU.
    - Maintain fallback timestamp map and scan stats.
    '''
    _ensure_capacity(cache_snapshot)
    _freq_age(cache_snapshot)
    key = obj.key
    now = cache_snapshot.access_count
    m_key_timestamp[key] = now

    in_b1 = key in _B1_ghost
    in_b2 = key in _B2_ghost
    prev_strength = _ghost_strength.pop(key, 0)

    placed_in_t2 = False

    if in_b1 or in_b2:
        # ARC adaptation of p
        global _p_target
        if in_b1:
            # Favor recency: increase p
            inc = max(1, len(_B2_ghost) // max(1, len(_B1_ghost)))
            _p_target = min(float(_cap_est), _p_target + float(inc))
            last = _B1_ghost.get(key, None)
            _B1_ghost.pop(key, None)
        else:
            # Favor frequency: decrease p
            dec = max(1, len(_B1_ghost) // max(1, len(_B2_ghost)))
            _p_target = max(0.0, _p_target - float(dec))
            last = _B2_ghost.get(key, None)
            _B2_ghost.pop(key, None)

        # Admission: only place directly into T2 if ghost is fresh and not in scan mode
        # Handle legacy True values by treating them as stale
        if isinstance(last, int):
            age = now - last
        else:
            age = _cap_est * 10  # treat as stale if no timestamp
        fresh_window = max(1, _cap_est)  # expanded from cap//2 to cap to capture medium-range reuse
        if (age <= fresh_window) and (not _in_scan_mode(cache_snapshot)):
            if key in _T1_probation:
                _T1_probation.pop(key, None)
            _T2_protected[key] = True
            placed_in_t2 = True
            # Seed stronger frequency on re-admission using remembered ghost strength
            seed = max(3 if in_b2 else 2, int(prev_strength * 0.7) + 1)
            _freq[key] = min(_FREQ_MAX, max(_freq.get(key, 0), seed))
        else:
            # Stale ghost or during scan: insert into T1 but keep a minimal seed if we remember strength
            _T1_probation[key] = True
            _freq[key] = max(_freq.get(key, 0), 1 if prev_strength > 0 else 0)
    else:
        # New to cache and ghosts: insert into probation (T1)
        if key in _T2_protected:
            # Rare desync; ensure consistency (shouldn't happen on miss)
            _T2_protected.move_to_end(key, last=True)
        else:
            _T1_probation[key] = True
        _freq.setdefault(key, 0)

    # Avoid duplicates across structures
    if placed_in_t2 and key in _T1_probation:
        _T1_probation.pop(key, None)
    if not placed_in_t2 and key in _T2_protected:
        _T2_protected.pop(key, None)

    # Sliding window tracking and scan mode upkeep (miss)
    _record_access(cache_snapshot, key, was_hit=False)
    _maybe_update_scan_mode(cache_snapshot)

    # Keep segment sizes close to target to prevent protected from stagnating
    _enforce_segment_targets()
    _ghost_trim()
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    Update metadata after eviction.
    - Remove victim from its resident segment.
    - Add to corresponding ghost list (B1 if from probation, B2 if from protected) with timestamp.
    - Trim ghost lists to capacity.
    - Maintain fallback timestamp map and tiny frequency map.
    '''
    _ensure_capacity(cache_snapshot)
    victim_key = evicted_obj.key
    now = cache_snapshot.access_count

    was_t1 = victim_key in _T1_probation
    was_t2 = victim_key in _T2_protected

    # Remove from resident segments
    if was_t1:
        _T1_probation.pop(victim_key, None)
        _B1_ghost[victim_key] = now  # MRU with timestamp
    elif was_t2:
        _T2_protected.pop(victim_key, None)
        _B2_ghost[victim_key] = now  # MRU with timestamp
    else:
        # Unknown location; put in B1 by default
        _B1_ghost[victim_key] = now

    # Remove fallback timestamp and tiny frequency for evicted key
    m_key_timestamp.pop(victim_key, None)
    _freq.pop(victim_key, None)

    _ghost_trim()
=======
def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    Update metadata after eviction.
    - Remove victim from its resident segment.
    - Add to corresponding ghost list (B1 if from probation, B2 if from protected) with timestamp.
    - Trim ghost lists to capacity.
    - Maintain fallback timestamp map and tiny frequency map.
    '''
    _ensure_capacity(cache_snapshot)
    victim_key = evicted_obj.key
    now = cache_snapshot.access_count

    was_t1 = victim_key in _T1_probation
    was_t2 = victim_key in _T2_protected

    # Capture tiny LFU strength before removal
    last_strength = _freq.pop(victim_key, None)
    if last_strength is not None and last_strength > 0:
        _ghost_strength[victim_key] = min(_FREQ_MAX, last_strength)

    # Remove from resident segments
    if was_t1:
        _T1_probation.pop(victim_key, None)
        _B1_ghost[victim_key] = now  # MRU with timestamp
    elif was_t2:
        _T2_protected.pop(victim_key, None)
        _B2_ghost[victim_key] = now  # MRU with timestamp
    else:
        # Unknown location; put in B1 by default
        _B1_ghost[victim_key] = now

    # Remove fallback timestamp for evicted key
    m_key_timestamp.pop(victim_key, None)

    _ghost_trim()
>>>>>>> REPLACE

</DIFF>