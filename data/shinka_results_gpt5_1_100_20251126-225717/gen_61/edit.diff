--- a/original.py
+++ b/original.py
@@ -1,340 +1,383 @@
 # EVOLVE-BLOCK-START
 """Cache eviction algorithm for optimizing hit rates across multiple workloads"""
 
 from collections import OrderedDict
 
 # Legacy timestamp dictionary kept for compatibility; used as a general access ledger.
 m_key_timestamp = dict()
 
 # Segmented LRU metadata: probation and protected segments (key -> last access time)
 _probation = dict()
 _protected = dict()
 
 # ARC-style ghost histories (recently evicted):
 _B1_ghost = OrderedDict()  # evicted from probation
 _B2_ghost = OrderedDict()  # evicted from protected
 
 # Adaptive target for probation share (ARC's p) and capacity estimate
 _p_target = 0.0
 _cap_est = 0
 
 # Lightweight per-key frequency with periodic aging
 _freq = dict()           # key -> small integer frequency
 _last_age_tick = 0       # last access_count when we aged
 
 # Short-lived guard to resist scans after evicting strong protected entries
 _guard_until = 0         # access_count until which we bias new insertions as cold
 
 def _ensure_capacity(cache_snapshot):
     """Initialize/refresh capacity estimate and clamp p within [0, cap]."""
     global _cap_est, _p_target
     cap = getattr(cache_snapshot, "capacity", None)
     if isinstance(cap, int) and cap > 0:
         _cap_est = cap
     if _cap_est <= 0:
         _cap_est = max(1, len(cache_snapshot.cache))
     # Initialize p only once when metadata is empty
     if _p_target == 0.0 and not _probation and not _protected and not _B1_ghost and not _B2_ghost:
         # Start with modest probation share
         _p_target = min(float(_cap_est), max(0.0, float(_cap_est) * 0.33))
     # Clamp p
     if _p_target < 0.0:
         _p_target = 0.0
     if _p_target > float(_cap_est):
         _p_target = float(_cap_est)
 
 def _ghost_trim():
     """Bound ghost lists by capacity."""
     while len(_B1_ghost) > _cap_est:
         _B1_ghost.popitem(last=False)
     while len(_B2_ghost) > _cap_est:
         _B2_ghost.popitem(last=False)
 
 def _get_caps(cache_snapshot):
     """Compute static target sizes for probation and protected segments (legacy helper)."""
     total_cap = max(int(getattr(cache_snapshot, "capacity", 1)), 1)
     # Favor protected segment to keep repeatedly used items
     prot_cap = max(int(total_cap * 0.66), 1 if total_cap > 1 else 0)
     prob_cap = max(total_cap - prot_cap, 1)
     return prob_cap, prot_cap
 
 def _get_targets(cache_snapshot):
     """Compute ARC targets from p: T1 target = round(p), T2 target = cap - T1 target."""
     _ensure_capacity(cache_snapshot)
     t1_target = int(round(_p_target))
     t2_target = max(_cap_est - t1_target, 0)
     return t1_target, t2_target
 
 def _lru_key_in(seg_dict, cache_snapshot):
     """Return the LRU key from seg_dict that is currently in the cache."""
     min_key = None
     min_ts = None
     # Iterate only over keys that are in the current cache snapshot
     cache_keys = cache_snapshot.cache.keys()
     for k, ts in seg_dict.items():
         if k in cache_keys:
             if (min_ts is None) or (ts < min_ts):
                 min_ts = ts
                 min_key = k
     return min_key
 
 def _min_by_freq_ts(seg_dict, cache_snapshot):
     """Pick a victim by (frequency asc, timestamp asc) among keys present in cache."""
     best_k = None
     best_score = None
     cache_keys = cache_snapshot.cache.keys()
     for k, ts in seg_dict.items():
         if k in cache_keys:
             f = _freq.get(k, 0)
             score = (f, ts)
             if best_score is None or score < best_score:
                 best_score = score
                 best_k = k
     return best_k
 
 def _maybe_age(cache_snapshot):
     """Periodically age frequencies to avoid stale bias."""
     global _last_age_tick
     _ensure_capacity(cache_snapshot)
     now = cache_snapshot.access_count
     if now - _last_age_tick >= max(1, _cap_est):
         # Halve all frequencies (simple exponential decay)
         for k in list(_freq.keys()):
             newf = _freq.get(k, 0) // 2
             if newf <= 0:
                 _freq.pop(k, None)
             else:
                 _freq[k] = newf
         _last_age_tick = now
 
 def evict(cache_snapshot, obj):
     '''
     This function defines how the algorithm chooses the eviction victim.
     - Args:
         - `cache_snapshot`: A snapshot of the current cache state.
         - `obj`: The new object that needs to be inserted into the cache.
     - Return:
         - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
     '''
     _ensure_capacity(cache_snapshot)
     now = cache_snapshot.access_count
 
+    # Detect scan-like phases via hit-rate EWMA (set in updates)
+    scan_mode = ('_hit_ewma' in globals()) and (globals()['_hit_ewma'] < 0.12)
+
     # ARC REPLACE(x): if |T1|>=1 and ((x in B2 and |T1| == p) or |T1| > p) -> evict from T1 else from T2
     t1_size = len(_probation)
     x_in_b2 = (obj is not None) and (obj.key in _B2_ghost)
     p_int = int(round(_p_target))
     choose_t1 = (t1_size >= 1) and ((x_in_b2 and t1_size == p_int) or (t1_size > _p_target))
+    # In scans, always prefer evicting from probation when available.
+    if scan_mode and t1_size >= 1:
+        choose_t1 = True
 
     # Heat-based selection within chosen segment: heat = freq - lambda*age (min heat evicted)
     def _pick_by_heat(seg_dict, lam):
         best_k, best_heat, best_ts = None, None, None
         cache_keys = cache_snapshot.cache.keys()
         for k, ts in seg_dict.items():
             if k in cache_keys:
                 last_ts = ts if ts is not None else m_key_timestamp.get(k, now)
                 age = max(0, now - last_ts)
                 f = _freq.get(k, 0)
                 heat = float(f) - lam * float(age)
                 if (best_heat is None) or (heat < best_heat) or (heat == best_heat and last_ts < best_ts):
                     best_heat = heat
                     best_ts = last_ts
                     best_k = k
         return best_k
 
     lam_base = 1.0 / max(1, _cap_est)
+    # Stronger recency penalty in probation under scans; further protect protected
+    lam_prob = (3.0 if scan_mode else 1.8) * lam_base
+    lam_prot = (0.4 if scan_mode else 0.5) * lam_base
+
     candid_obj_key = None
     if choose_t1:
-        candid_obj_key = _pick_by_heat(_probation, lam=1.5 * lam_base)
+        candid_obj_key = _pick_by_heat(_probation, lam=lam_prob)
     if candid_obj_key is None:
-        candid_obj_key = _pick_by_heat(_protected, lam=0.5 * lam_base)
+        candid_obj_key = _pick_by_heat(_protected, lam=lam_prot)
     if candid_obj_key is None:
         # Last-resort fallback: pick any key from the cache (should rarely happen).
         for k in cache_snapshot.cache:
             candid_obj_key = k
             break
     return candid_obj_key
 
 def update_after_hit(cache_snapshot, obj):
     '''
     This function defines how the algorithm update the metadata it maintains immediately after a cache hit.
     - Args:
         - `cache_snapshot`: A snapshot of the current cache state.
         - `obj`: The object accessed during the cache hit.
     - Return: `None`
     '''
     global m_key_timestamp, _probation, _protected, _freq, _p_target, _guard_until
     _ensure_capacity(cache_snapshot)
     _maybe_age(cache_snapshot)
     current_ts = cache_snapshot.access_count
     k = obj.key
 
     # Maintain a general timestamp ledger for robustness.
     m_key_timestamp[k] = current_ts
 
     # Update simple hit EWMA to manage guard cooldown
     global _hit_ewma
     if '_hit_ewma' not in globals():
         _hit_ewma = 0.0
     alpha = 0.1
     _hit_ewma = (1.0 - alpha) * _hit_ewma + alpha * 1.0
     if _hit_ewma > 0.3:
         _guard_until = 0  # clear guard once hit rate rebounds
 
-    # Increment lightweight frequency counter
-    _freq[k] = _freq.get(k, 0) + 1
-
     was_prob = k in _probation
     was_prot = k in _protected
 
+    fresh_window = max(1, _cap_est)  # time-bounded two-touch window
+
     if was_prob:
-        # Promote to protected on reuse.
-        _probation.pop(k, None)
+        # Decide promotion by recency of second touch
+        prev_ts = _probation.get(k, current_ts)
+        age = max(0, current_ts - prev_ts)
+        if age <= fresh_window:
+            # Timely reuse: promote and boost frequency
+            _probation.pop(k, None)
+            _protected[k] = current_ts
+            _freq[k] = _freq.get(k, 0) + 2
+            # Prefer a larger T2 when probation reuses are timely
+            _p_target = min(float(_cap_est), _p_target + 0.3)
+        else:
+            # Stale reuse: keep in probation and damp frequency growth
+            _probation[k] = current_ts
+            _freq[k] = max(1, _freq.get(k, 0))  # avoid runaway freq
+            # Slightly favor more probation capacity for long-gap reuses
+            _p_target = max(0.0, _p_target - 0.05)
+    elif was_prot:
+        # Refresh recency within protected and gently increase frequency
         _protected[k] = current_ts
-    elif was_prot:
-        # Refresh recency within protected.
-        _protected[k] = current_ts
+        _freq[k] = _freq.get(k, 0) + 1
+        # Protected hits imply T1 can be smaller
+        _p_target = max(0.0, _p_target - 0.1)
     else:
         # Metadata miss: treat as a re-reference and place in protected.
         _protected[k] = current_ts
-
-    # Gentle ARC-style p adaptation: probation hits -> increase p; protected hits -> decrease p.
-    if was_prob:
-        _p_target = min(float(_cap_est), _p_target + 0.2)
-    elif was_prot:
-        _p_target = max(0.0, _p_target - 0.1)
-
-    # Respect ARC target for protected by demoting its LRU if needed.
+        _freq[k] = _freq.get(k, 0) + 1
+
+    # Keep protected within its target by demoting the coldest (freq/ts), not strict LRU.
     _, t2_target = _get_targets(cache_snapshot)
     if len(_protected) > t2_target:
-        demote_key = _lru_key_in(_protected, cache_snapshot)
+        demote_key = _min_by_freq_ts(_protected, cache_snapshot)
         if demote_key is not None and demote_key != k:
             demote_ts = _protected.pop(demote_key)
             _probation[demote_key] = demote_ts
 
     # If present in ghosts, clear and bound ghost history
     if k in _B1_ghost:
         _B1_ghost.pop(k, None)
     if k in _B2_ghost:
         _B2_ghost.pop(k, None)
     _ghost_trim()
 
 def update_after_insert(cache_snapshot, obj):
     '''
     This function defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
     - Args:
         - `cache_snapshot`: A snapshot of the current cache state.
         - `obj`: The object that was just inserted into the cache.
     - Return: `None`
     '''
     global m_key_timestamp, _probation, _protected, _p_target, _freq, _guard_until
     _ensure_capacity(cache_snapshot)
     _maybe_age(cache_snapshot)
     current_ts = cache_snapshot.access_count
     k = obj.key
 
     # Record in general ledger
     m_key_timestamp[k] = current_ts
 
     # Update hit EWMA with a miss signal to allow guard cooldown
     global _hit_ewma
     if '_hit_ewma' not in globals():
         _hit_ewma = 0.0
     _hit_ewma = (1.0 - 0.1) * _hit_ewma  # alpha=0.1, y=0 for miss
 
     in_b1 = k in _B1_ghost
     in_b2 = k in _B2_ghost
+    fresh_window = max(1, _cap_est)
+    now = current_ts
 
     if in_b1 or in_b2:
-        # ARC adaptation of p and re-admit into protected
+        # ARC adaptation of p scaled by ghost recency, and re-admit into protected
         if in_b1:
-            inc = max(1.0, float(len(_B2_ghost)) / max(1.0, float(len(_B1_ghost))))
+            g_age = max(0, now - _B1_ghost.get(k, now))
+            w = max(0.5, 1.5 - (g_age / float(fresh_window)))  # 1.5 when very recent, >=0.5 if stale
+            inc = max(1.0, float(len(_B2_ghost)) / max(1.0, float(len(_B1_ghost)))) * w
             _p_target = min(float(_cap_est), _p_target + inc)
             _B1_ghost.pop(k, None)
         else:
-            dec = max(1.0, float(len(_B1_ghost)) / max(1.0, float(len(_B2_ghost))))
+            g_age = max(0, now - _B2_ghost.get(k, now))
+            w = max(0.5, 1.5 - (g_age / float(fresh_window)))
+            dec = max(1.0, float(len(_B1_ghost)) / max(1.0, float(len(_B2_ghost)))) * w
             _p_target = max(0.0, _p_target - dec)
             _B2_ghost.pop(k, None)
         _protected[k] = current_ts
-        # Seed frequency as reused
-        _freq[k] = max(_freq.get(k, 0) + 1, 2)
-
-        # Keep protected within its target by demoting its LRU if necessary
+        # Seed frequency as reused, more if very recent in ghost
+        _freq[k] = max(_freq.get(k, 0), 2 + (1 if w > 1.0 else 0))
+
+        # Keep protected within its target by demoting the coldest if necessary
         _, t2_target = _get_targets(cache_snapshot)
         if len(_protected) > t2_target:
-            demote_key = _lru_key_in(_protected, cache_snapshot)
+            demote_key = _min_by_freq_ts(_protected, cache_snapshot)
             if demote_key is not None and demote_key != k:
                 demote_ts = _protected.pop(demote_key)
                 _probation[demote_key] = demote_ts
     else:
-        # New to cache and ghosts: insert into probation with moderated LIP bias.
+        # New to cache and ghosts: insert into probation with scan-aware LIP bias.
         lip_bias = 0
+        scan_mode = ('_hit_ewma' in globals()) and (globals()['_hit_ewma'] < 0.12)
         if current_ts <= _guard_until:
             lip_bias = max(1, _cap_est // 4)  # softer bias under guard
         else:
             if len(_B1_ghost) <= len(_B2_ghost):
                 lip_bias = max(1, _cap_est // 6)
+            # If locality is currently poor, bias much colder to protect working set
+            if scan_mode:
+                lip_bias = max(lip_bias, max(1, _cap_est // 2))
         _probation[k] = current_ts - lip_bias if lip_bias > 0 else current_ts
         # Seed minimal frequency for new items
         _freq[k] = _freq.get(k, 0)
 
     _ghost_trim()
 
 def update_after_evict(cache_snapshot, obj, evicted_obj):
     '''
     This function defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
     - Args:
         - `cache_snapshot`: A snapshot of the current cache state.
         - `obj`: The object to be inserted into the cache.
         - `evicted_obj`: The object that was just evicted from the cache.
     - Return: `None`
     '''
     global m_key_timestamp, _probation, _protected, _freq, _guard_until
     _ensure_capacity(cache_snapshot)
     # Remove evicted key from segments and add to appropriate ghost history.
     if evicted_obj is not None:
         k = evicted_obj.key
         was_t1 = k in _probation
         was_t2 = k in _protected
         fval = _freq.get(k, 0)
 
         _probation.pop(k, None)
         _protected.pop(k, None)
         m_key_timestamp.pop(k, None)
         _freq.pop(k, None)
 
         now = cache_snapshot.access_count
         if was_t1:
             _B1_ghost[k] = now  # record timestamp in ghost
+            try:
+                _B1_ghost.move_to_end(k, last=True)
+            except Exception:
+                pass
         elif was_t2:
             _B2_ghost[k] = now
-            # If we had to evict a strong protected item, enable a short guard window (softer).
+            try:
+                _B2_ghost.move_to_end(k, last=True)
+            except Exception:
+                pass
+            # If we had to evict a strong protected item, enable a short guard window, scaled by strength.
             if fval >= 2:
-                _guard_until = now + max(1, _cap_est // 4)
+                guard_len = min(max(1, _cap_est // 2), max(1, fval) * max(1, _cap_est // 10))
+                _guard_until = now + guard_len
         else:
             # Unknown residency; default to B1
             _B1_ghost[k] = now
+            try:
+                _B1_ghost.move_to_end(k, last=True)
+            except Exception:
+                pass
 
         _ghost_trim()
     # Do not add obj here; it will be handled in update_after_insert.
 
 # EVOLVE-BLOCK-END
 
 # This part remains fixed (not evolved)
 def run_caching(trace_path: str, copy_code_dst: str):
     """Run the caching algorithm on a trace"""
     import os
     with open(os.path.abspath(__file__), 'r', encoding="utf-8") as f:
         code_str = f.read()
     with open(os.path.join(copy_code_dst), 'w') as f:
         f.write(code_str)
     from cache_utils import Cache, CacheConfig, CacheObj, Trace
     trace = Trace(trace_path=trace_path)
     cache_capacity = max(int(trace.get_ndv() * 0.1), 1)
     cache = Cache(CacheConfig(cache_capacity))
     for entry in trace.entries:
         obj = CacheObj(key=str(entry.key))
         cache.get(obj)
     with open(copy_code_dst, 'w') as f:
         f.write("")
     hit_rate = round(cache.hit_count / cache.access_count, 6)
     return hit_rate