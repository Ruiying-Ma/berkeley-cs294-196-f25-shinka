<NAME>
implement_arc
</NAME>

<DESCRIPTION>
Replace the S3-FIFO algorithm with an Adaptive Replacement Cache (ARC). ARC balances between recency (T1) and frequency (T2) using a target parameter `p` that adapts based on "ghost" hits (hits on recently evicted items).
- Uses 4 dictionaries (T1, T2, B1, B2) to track cached items and eviction history. Python's `dict` preserves insertion order, serving as both set (O(1) access) and queue (LRU iteration).
- `evict`: Adjusts `p` if the incoming object is found in B1 or B2 (ghosts). It also protects the ghost entry from immediate eviction by moving it to MRU. Then, it selects a victim from T1 or T2 based on `p` and the ARC replacement logic.
- `update_after_hit`: Moves accessed items to the MRU position of T2 (Frequency).
- `update_after_insert`: Inserts new items into T1 (Recency) or T2 (Frequency) depending on whether they were in the ghost lists.
- `update_after_evict`: Moves the evicted item to the corresponding ghost list (B1 or B2) and ensures ghost lists do not exceed capacity.
This algorithm typically outperforms fixed-size LRU/LFU hybrids by dynamically tuning itself to the workload's characteristics.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
"""
S3-FIFO Cache Eviction Algorithm
Uses a simplified S3-FIFO approach with two queues (S and M) and lazy promotion.
- S (Small): Captures new insertions. Filters out scans and 'one-hit wonders'.
- M (Main): Holds frequently accessed items.
- Access bits: tracked via 'accessed' set.
Promotions occur lazily during eviction: if an eviction candidate in S or M has been accessed,
it is moved to M (giving it a second chance) and the access bit is cleared.
"""
from collections import deque

class S3FIFOState:
    def __init__(self, cache_id):
        self.cache_id = cache_id
        self.S = deque()
        self.M = deque()
        self.accessed = set()
        self.victim_queue = None

    def reset(self):
        self.S.clear()
        self.M.clear()
        self.accessed.clear()
        self.victim_queue = None

_state = None

def get_state(cache_snapshot):
    global _state
    # Use id of cache dict to identify the cache instance (handles multiple traces)
    current_id = id(cache_snapshot.cache)

    if _state is None or _state.cache_id != current_id:
        _state = S3FIFOState(current_id)

    # Consistency check: If state has vastly more items than cache, it's likely stale data
    # from a previous run where memory was reused (same id).
    # We allow a small slack (e.g., 5) for transient states during eviction/insertion.
    cache_len = len(cache_snapshot.cache)
    state_len = len(_state.S) + len(_state.M)
    if state_len > cache_len + 5:
        _state = S3FIFOState(current_id)

    return _state

def evict(cache_snapshot, obj):
    '''
    Determines the eviction victim using S3-FIFO logic.
    '''
    state = get_state(cache_snapshot)

    # S queue target size: 10% of total cache count
    cache_count = len(cache_snapshot.cache)
    s_capacity = max(1, int(cache_count * 0.1))

    while True:
        # Check S if it's oversized or if M is empty
        # This prioritizes cleaning up S (scan resistance)
        check_s = len(state.S) >= s_capacity or len(state.M) == 0

        queue = state.S if check_s else state.M
        q_name = 'S' if check_s else 'M'

        if not queue:
            # Fallback for safety (e.g. if state desyncs or empty cache logic)
            if cache_snapshot.cache:
                return next(iter(cache_snapshot.cache))
            return None # Should not be reached

        candidate = queue[-1] # Inspect Tail

        # Robustness: verify candidate is actually in the cache
        if candidate not in cache_snapshot.cache:
            queue.pop() # Remove phantom entry
            state.accessed.discard(candidate)
            continue

        if candidate in state.accessed:
            # Second Chance: Reinsert into M (Main) head and clear access bit
            state.accessed.remove(candidate)
            queue.pop()
            state.M.appendleft(candidate)
            # Loop continues to search for a victim
        else:
            # Found a victim (not accessed since insertion/promotion)
            state.victim_queue = q_name
            return candidate

def update_after_hit(cache_snapshot, obj):
    '''
    Mark object as accessed. Promotion is lazy (happens at eviction).
    '''
    state = get_state(cache_snapshot)
    state.accessed.add(obj.key)

def update_after_insert(cache_snapshot, obj):
    '''
    Insert new object into S (Small) queue.
    '''
    state = get_state(cache_snapshot)
    state.S.appendleft(obj.key)
    state.accessed.discard(obj.key) # Initially not accessed

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    Clean up the evicted object from the internal queues.
    '''
    state = get_state(cache_snapshot)

    # Remove from the queue we decided to evict from
    if state.victim_queue == 'S':
        # Optimistically check tail (O(1))
        if state.S and state.S[-1] == evicted_obj.key:
            state.S.pop()
        else:
            # Fallback removal (O(N))
            try: state.S.remove(evicted_obj.key)
            except ValueError: pass

    elif state.victim_queue == 'M':
        if state.M and state.M[-1] == evicted_obj.key:
            state.M.pop()
        else:
            try: state.M.remove(evicted_obj.key)
            except ValueError: pass

    # Cleanup metadata
    state.accessed.discard(evicted_obj.key)
    state.victim_queue = None
=======
"""
ARC (Adaptive Replacement Cache) Eviction Algorithm
Maintains two LRU lists: T1 (recency) and T2 (frequency), and two ghost lists B1 and B2.
Dynamically adjusts the target size `p` for T1 based on hits in the ghost lists.
"""

class ARCState:
    def __init__(self, cache_id):
        self.cache_id = cache_id
        # Use dicts as ordered sets for O(1) access and LRU preservation
        self.T1 = dict() # Recency (L1 cache)
        self.T2 = dict() # Frequency (L2 cache)
        self.B1 = dict() # Ghost Recency
        self.B2 = dict() # Ghost Frequency
        self.p = 0.0     # Target size for T1

_state = None

def get_state(cache_snapshot):
    global _state
    current_id = id(cache_snapshot.cache)
    if _state is None or _state.cache_id != current_id:
        _state = ARCState(current_id)

    # Sync check: if state deviates significantly from cache
    state_count = len(_state.T1) + len(_state.T2)
    cache_count = len(cache_snapshot.cache)

    if abs(state_count - cache_count) > 5:
        # Re-initialize from cache content
        _state = ARCState(current_id)
        for k in cache_snapshot.cache:
            # Assume recency for unknown state
            _state.T1[k] = None
        _state.p = 0.0

    return _state

def evict(cache_snapshot, obj):
    '''
    ARC eviction logic: adjusts p based on ghosts, then selects T1 or T2 victim.
    '''
    state = get_state(cache_snapshot)
    c = cache_snapshot.capacity
    key = obj.key

    # 1. Adapt p if hit in ghosts
    if key in state.B1:
        delta = 1
        if len(state.B1) >= len(state.B2) and len(state.B2) > 0:
             delta = 1
        elif len(state.B2) > len(state.B1):
             delta = len(state.B2) / len(state.B1)
        state.p = min(c, state.p + delta)
        # Move to MRU in B1 to protect from eviction in update_after_evict
        del state.B1[key]
        state.B1[key] = None

    elif key in state.B2:
        delta = 1
        if len(state.B2) >= len(state.B1) and len(state.B1) > 0:
             delta = 1
        elif len(state.B1) > len(state.B2):
             delta = len(state.B1) / len(state.B2)
        state.p = max(0, state.p - delta)
        # Move to MRU in B2
        del state.B2[key]
        state.B2[key] = None

    # 2. Determine victim
    # Replace(x) logic
    t1_excess = len(state.T1) > state.p
    in_b2_cond = (key in state.B2) and (len(state.T1) == int(state.p))

    if t1_excess or in_b2_cond:
        # Evict from T1 (LRU)
        if state.T1:
            return next(iter(state.T1))
        if state.T2: return next(iter(state.T2))
    else:
        # Evict from T2 (LRU)
        if state.T2:
            return next(iter(state.T2))
        if state.T1: return next(iter(state.T1))

    # Fallback
    if cache_snapshot.cache:
        return next(iter(cache_snapshot.cache))
    return None

def update_after_hit(cache_snapshot, obj):
    '''
    ARC: Hit in T1 -> move to T2. Hit in T2 -> MRU T2.
    '''
    state = get_state(cache_snapshot)
    key = obj.key

    if key in state.T1:
        del state.T1[key]
        state.T2[key] = None
    elif key in state.T2:
        del state.T2[key]
        state.T2[key] = None

def update_after_insert(cache_snapshot, obj):
    '''
    ARC: Insert to T1 (if new) or T2 (if in ghosts).
    '''
    state = get_state(cache_snapshot)
    key = obj.key

    is_ghost = False
    if key in state.B1:
        del state.B1[key]
        is_ghost = True
    if key in state.B2:
        del state.B2[key]
        is_ghost = True

    if is_ghost:
        state.T2[key] = None
    else:
        state.T1[key] = None

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    ARC: Move evicted to B1/B2 and trim ghosts.
    '''
    state = get_state(cache_snapshot)
    key = evicted_obj.key

    # Identify source
    if key in state.T1:
        del state.T1[key]
        state.B1[key] = None # Add to MRU B1
    elif key in state.T2:
        del state.T2[key]
        state.B2[key] = None # Add to MRU B2
    else:
        # Fallback sync
        state.B1[key] = None

    # Enforce ghost capacity (simplification: |B1| <= c, |B2| <= c)
    c = cache_snapshot.capacity
    while len(state.B1) > c:
        del state.B1[next(iter(state.B1))]
    while len(state.B2) > c:
        del state.B2[next(iter(state.B2))]
>>>>>>> REPLACE
</DIFF>