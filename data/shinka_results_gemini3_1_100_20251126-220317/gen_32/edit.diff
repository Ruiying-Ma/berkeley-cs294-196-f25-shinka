--- a/original.py
+++ b/original.py
@@ -1,180 +1,183 @@
 # EVOLVE-BLOCK-START
-"""Cache eviction algorithm for optimizing hit rates across multiple workloads"""
+"""
+WALRUS: Window-LFU with Aging and Ghost Frequencies
+Combines a FIFO Window for scan resistance with a Frequency-based Main segment.
+Uses randomized sampling for approximate LFU eviction in the Main segment.
+Maintains ghost frequencies to support loop patterns and applies periodic aging.
+"""
+import random
+from collections import deque
 
-import random
-import math
+class WalrusState:
+    def __init__(self, capacity):
+        self.capacity = capacity
+        self.window = deque()          # FIFO queue for new items
+        self.main = set()              # Set of keys in the Main segment
+        self.freq = {}                 # Global frequency counter (includes ghosts)
+        self.access_count = 0          # Total access counter
+        self.aging_interval = capacity # Age frequencies every 'capacity' accesses
+        
+        # Tuning parameters
+        self.window_ratio = 0.1
+        self.sample_size = 5
+        self.max_freq_history = capacity * 5 
 
-# ARC State
-algo_state = {
-    't1': {},            # LRU list (dict) for T1 (Recent)
-    't2': {},            # LRU list (dict) for T2 (Frequent)
-    'b1': {},            # LRU list (dict) for B1 (Ghost Recent)
-    'b2': {},            # LRU list (dict) for B2 (Ghost Frequent)
-    'p': 0,              # Target size for T1
-    'max_time': 0,       # Track time to detect trace resets
-}
+    def get_freq(self, key):
+        return self.freq.get(key, 0)
 
-def _check_reset(current_time):
-    # If time goes backwards, we are likely processing a new trace
-    if current_time < algo_state['max_time']:
-        algo_state['t1'].clear()
-        algo_state['t2'].clear()
-        algo_state['b1'].clear()
-        algo_state['b2'].clear()
-        algo_state['p'] = 0
-        algo_state['max_time'] = 0
-    algo_state['max_time'] = current_time
+    def inc_freq(self, key):
+        self.freq[key] = self.freq.get(key, 0) + 1
+
+    def age_freqs(self):
+        # Halve frequencies to bias towards recent popularity
+        keys_to_remove = []
+        for k, v in self.freq.items():
+            new_v = v >> 1 # Integer division by 2
+            if new_v == 0:
+                keys_to_remove.append(k)
+            else:
+                self.freq[k] = new_v
+        
+        for k in keys_to_remove:
+            # Don't remove if currently in cache!
+            if k not in self.main and k not in self.window:
+                del self.freq[k]
+            else:
+                self.freq[k] = 1 # Keep at least 1 if in cache
+
+_walrus_state = {}
+
+def get_state(cache_snapshot):
+    cache_id = id(cache_snapshot.cache)
+    if cache_id not in _walrus_state:
+        _walrus_state[cache_id] = WalrusState(cache_snapshot.capacity)
+    return _walrus_state[cache_id]
 
 def evict(cache_snapshot, obj):
     '''
-    ARC Eviction Policy
+    Decide eviction victim based on Window vs Main duel.
     '''
-    key = obj.key
-    t1 = algo_state['t1']
-    t2 = algo_state['t2']
-    b1 = algo_state['b1']
-    b2 = algo_state['b2']
-    p = algo_state['p']
-    capacity = cache_snapshot.capacity
+    state = get_state(cache_snapshot)
+    
+    # Clean up state if cache was reset externally
+    if not cache_snapshot.cache and (state.window or state.main):
+        state.window.clear()
+        state.main.clear()
+        state.freq.clear()
 
-    # Adaptation simulation for decision
-    p_eff = p
-    if key in b1:
-        d = 1
-        if len(b1) >= len(b2):
-            d = 1
+    # Target Window Size
+    target_window = max(1, int(cache_snapshot.capacity * state.window_ratio))
+    
+    victim = None
+    
+    # Scenario 1: Window is full (or over quota)
+    # Check if we should evict from Window or if Window victim can displace a Main item
+    if len(state.window) >= target_window:
+        # Candidate from Window (FIFO Tail)
+        w_candidate = state.window[0]
+        
+        # If Main is empty, we must evict from Window
+        if not state.main:
+            return w_candidate
+            
+        # Candidate from Main (Approximate LFU via Sampling)
+        # Random sampling is used to avoid O(N) sort/scan
+        sample_keys = random.sample(list(state.main), min(len(state.main), state.sample_size))
+        m_candidate = min(sample_keys, key=lambda k: state.get_freq(k))
+        
+        # Duel: Frequency check
+        # Strict inequality (>): New items must PROVE they are better to displace Main items.
+        # This provides scan resistance (frequency 1 items lose to frequency > 1).
+        w_freq = state.get_freq(w_candidate)
+        m_freq = state.get_freq(m_candidate)
+        
+        if w_freq > m_freq:
+            victim = m_candidate
         else:
-            d = len(b2) / len(b1)
-        p_eff = min(capacity, p + d)
-    elif key in b2:
-        d = 1
-        if len(b2) >= len(b1):
-            d = 1
+            victim = w_candidate
+            
+    # Scenario 2: Window is under quota.
+    # Ideally we make space in Main to allow Window to grow.
+    else:
+        if state.main:
+            sample_keys = random.sample(list(state.main), min(len(state.main), state.sample_size))
+            victim = min(sample_keys, key=lambda k: state.get_freq(k))
+        elif state.window:
+             victim = state.window[0]
         else:
-            d = len(b1) / len(b2)
-        p_eff = max(0, p - d)
+             victim = next(iter(cache_snapshot.cache))
 
-    # REPLACE logic
-    replace_t1 = False
-    if len(t1) > 0:
-        if len(t1) > p_eff:
-            replace_t1 = True
-        elif (key in b2) and (len(t1) == int(p_eff)):
-            replace_t1 = True
-
-    candid = None
-    if replace_t1:
-        candid = next(iter(t1))
-    elif len(t2) > 0:
-        candid = next(iter(t2))
-    elif len(t1) > 0:
-        candid = next(iter(t1))
-
-    if candid is None and cache_snapshot.cache:
-         candid = next(iter(cache_snapshot.cache))
-
-    return candid
+    return victim
 
 def update_after_hit(cache_snapshot, obj):
-    '''
-    Hit: Move to T2 MRU.
-    '''
-    _check_reset(cache_snapshot.access_count)
-    key = obj.key
-    t1 = algo_state['t1']
-    t2 = algo_state['t2']
-
-    if key in t1:
-        del t1[key]
-        t2[key] = True
-    elif key in t2:
-        del t2[key]
-        t2[key] = True
-    else:
-        # Failsafe
-        t2[key] = True
+    state = get_state(cache_snapshot)
+    state.access_count += 1
+    state.inc_freq(obj.key)
+    
+    # Aging
+    if state.access_count % state.aging_interval == 0:
+        state.age_freqs()
 
 def update_after_insert(cache_snapshot, obj):
-    '''
-    Insert: Update p and lists.
-    '''
-    _check_reset(cache_snapshot.access_count)
-
-    key = obj.key
-    t1 = algo_state['t1']
-    t2 = algo_state['t2']
-    b1 = algo_state['b1']
-    b2 = algo_state['b2']
-    p = algo_state['p']
-    capacity = cache_snapshot.capacity
-
-    # Update p (Adaptation)
-    if key in b1:
-        d = 1
-        if len(b1) >= len(b2):
-            d = 1
-        else:
-            d = len(b2) / len(b1)
-        p = min(capacity, p + d)
-        del b1[key]
-        t2[key] = True
-    elif key in b2:
-        d = 1
-        if len(b2) >= len(b1):
-            d = 1
-        else:
-            d = len(b1) / len(b2)
-        p = max(0, p - d)
-        del b2[key]
-        t2[key] = True
-    else:
-        t1[key] = True
-
-    algo_state['p'] = p
+    state = get_state(cache_snapshot)
+    state.access_count += 1
+    state.inc_freq(obj.key)
+    
+    # New items always enter Window
+    state.window.append(obj.key)
+    
+    # Clean up frequency map if growing too large (Ghost cleanup)
+    if len(state.freq) > state.max_freq_history:
+        # Simple cleanup heuristic could go here, but relying on aging is usually sufficient
+        pass
+    
+    if state.access_count % state.aging_interval == 0:
+        state.age_freqs()
 
 def update_after_evict(cache_snapshot, obj, evicted_obj):
-    '''
-    Evict: Update T1/T2 and B1/B2.
-    '''
-    ekey = evicted_obj.key
-    t1 = algo_state['t1']
-    t2 = algo_state['t2']
-    b1 = algo_state['b1']
-    b2 = algo_state['b2']
-    capacity = cache_snapshot.capacity
-
-    if ekey in t1:
-        del t1[ekey]
-        b1[ekey] = True
-    elif ekey in t2:
-        del t2[ekey]
-        b2[ekey] = True
-
-    # Trim ghosts
-    if len(b1) > capacity:
-        del b1[next(iter(b1))]
-
-    if len(b2) > capacity * 2:
-        del b2[next(iter(b2))]
-
+    state = get_state(cache_snapshot)
+    key = evicted_obj.key
+    
+    # Remove from local structures
+    if key in state.main:
+        state.main.remove(key)
+    
+    if state.window:
+        if state.window[0] == key:
+            state.window.popleft()
+        else:
+            try:
+                state.window.remove(key)
+            except ValueError:
+                pass
+                
+    # Logic Update:
+    # If we evicted a Main item to make room for a Window item (Duel won),
+    # The Window item (the duel winner) must be moved to Main to free up the Window slot.
+    # We detect this condition by checking if Window is over capacity.
+    target_window = max(1, int(cache_snapshot.capacity * state.window_ratio))
+    while len(state.window) > target_window:
+        # Promote the oldest window item to Main
+        winner = state.window.popleft()
+        state.main.add(winner)
 # EVOLVE-BLOCK-END
 
 # This part remains fixed (not evolved)
 def run_caching(trace_path: str, copy_code_dst: str):
     """Run the caching algorithm on a trace"""
     import os
     with open(os.path.abspath(__file__), 'r', encoding="utf-8") as f:
         code_str = f.read()
     with open(os.path.join(copy_code_dst), 'w') as f:
         f.write(code_str)
     from cache_utils import Cache, CacheConfig, CacheObj, Trace
     trace = Trace(trace_path=trace_path)
     cache_capacity = max(int(trace.get_ndv() * 0.1), 1)
     cache = Cache(CacheConfig(cache_capacity))
     for entry in trace.entries:
         obj = CacheObj(key=str(entry.key))
         cache.get(obj)
     with open(copy_code_dst, 'w') as f:
         f.write("")
     hit_rate = round(cache.hit_count / cache.access_count, 6)
     return hit_rate