--- a/original.py
+++ b/original.py
@@ -1,150 +1,201 @@
 # EVOLVE-BLOCK-START
 """
-S3-FIFO Eviction Algorithm
-Uses a Small (S) queue for new items and a Main (M) queue for frequent items.
-Items in S are evicted early (scan resistance) unless accessed or previously in Ghost (G).
-Items in M are given second chances upon access.
+W-TinyLFU Eviction Algorithm Implementation
+Components:
+1. Window Cache (1%): Admission buffer for new items.
+2. Main Cache (99%): Segmented LRU (SLRU) with Probation (20%) and Protected (80%).
+3. TinyLFU Admission: Frequency-based filter (Doorkeeper + Counter) to admit items from Window to Main.
 """
 
-class S3FIFOState:
-    def __init__(self, cache_id):
-        self.cache_id = cache_id
-        self.small = dict()   # Small FIFO queue (approx 10%)
-        self.main = dict()    # Main FIFO queue (approx 90%)
-        self.ghost = dict()   # Ghost FIFO queue
-        self.accessed = dict() # Track access bits
-        self.capacity = 0
+from collections import OrderedDict
+
+class WTinyLFUState:
+    def __init__(self, capacity):
+        self.capacity = capacity
+        # Cache Segments
+        self.window = OrderedDict()      # Small LRU for new items
+        self.probation = OrderedDict()   # SLRU Probation (A1)
+        self.protected = OrderedDict()   # SLRU Protected (Am)
+        
+        # Frequency Counting (Approximate)
+        self.freq = {}
+        self.doorkeeper = set()
+        self.access_counter = 0
+        
+        # Configuration
+        # Window size: small to filter scans, but large enough to capture short term locality
+        self.window_limit = max(1, int(capacity * 0.01))
+        self.main_limit = capacity - self.window_limit
+        self.protected_limit = int(self.main_limit * 0.8)
+        
+    def get_freq(self, key):
+        return self.freq.get(key, 0)
+    
+    def record_access(self, key):
+        self.access_counter += 1
+        if key not in self.doorkeeper:
+            self.doorkeeper.add(key)
+        else:
+            self.freq[key] = self.freq.get(key, 0) + 1
+            
+        # Aging process
+        if self.access_counter >= self.capacity * 10:
+            self.age_frequencies()
+            
+    def age_frequencies(self):
+        self.access_counter = 0
+        self.doorkeeper.clear()
+        # Halve frequencies
+        removals = []
+        for k, v in self.freq.items():
+            new_v = v // 2
+            if new_v == 0:
+                removals.append(k)
+            else:
+                self.freq[k] = new_v
+        for k in removals:
+            del self.freq[k]
+            
+    def maintain_slru_invariant(self):
+        # Ensure Protected doesn't exceed limit
+        while len(self.protected) > self.protected_limit:
+            # Demote from Protected LRU to Probation MRU
+            k, _ = self.protected.popitem(last=False)
+            self.probation[k] = None # Insert as MRU (default for new key in dict)
 
 _state = None
 
 def get_state(cache_snapshot):
     global _state
+    # Check if cache restarted or changed
     current_id = id(cache_snapshot.cache)
-    if _state is None or _state.cache_id != current_id:
-        _state = S3FIFOState(current_id)
-
-    # Sync check
-    state_count = len(_state.small) + len(_state.main)
-    cache_count = len(cache_snapshot.cache)
-    if abs(state_count - cache_count) > 5:
-        _state = S3FIFOState(current_id)
-        # Heuristic recovery: put all in Main
+    if _state is None or getattr(_state, 'cache_id', None) != current_id:
+        _state = WTinyLFUState(cache_snapshot.capacity)
+        _state.cache_id = current_id
+    
+    # Sync check (rare but necessary if simulator diverged)
+    total_len = len(_state.window) + len(_state.probation) + len(_state.protected)
+    # Allow small drift during transitions (evict/insert)
+    if abs(total_len - len(cache_snapshot.cache)) > 5:
+        # Rebuild state from snapshot if desync detected
+        _state = WTinyLFUState(cache_snapshot.capacity)
+        _state.cache_id = current_id
+        # Heuristic: put everything in probation to reset
         for k in cache_snapshot.cache:
-            _state.main[k] = None
-            _state.accessed[k] = False
-
-    _state.capacity = cache_snapshot.capacity
+            _state.probation[k] = None
+    
     return _state
 
 def evict(cache_snapshot, obj):
     '''
-    S3-FIFO Eviction Logic
-    '''
-    state = get_state(cache_snapshot)
-    target_small = max(1, int(state.capacity * 0.1))
-
-    # Loop to find victim, handling lazy promotions/reinsertions
-    loops = 0
-    max_loops = len(cache_snapshot.cache) * 3 + 20 # Safety limit
-
-    while loops < max_loops:
-        loops += 1
-
-        # Determine which queue to operate on
-        if len(state.small) > target_small or not state.main:
-            # Check Small queue
-            if not state.small:
-                # Fallback
-                if state.main: return next(iter(state.main))
-                return None
-
-            candidate = next(iter(state.small))
-            if state.accessed.get(candidate, False):
-                # Second chance: promote to Main
-                del state.small[candidate]
-                state.main[candidate] = None
-                state.accessed[candidate] = False
+    Decide which object to evict.
+    Policy:
+    - If Window > Limit: Duel Window LRU vs Probation LRU.
+    - Else: Evict Probation LRU (grow Window).
+    '''
+    state = get_state(cache_snapshot)
+    
+    # Candidates
+    window_candidate = next(iter(state.window)) if state.window else None
+    
+    # Find Main candidate (Probation LRU, fallback to Protected LRU)
+    probation_candidate = next(iter(state.probation)) if state.probation else None
+    
+    if probation_candidate is None and state.protected:
+        # Fallback to Protected if Probation is empty
+        probation_candidate = next(iter(state.protected))
+
+    # Decision Logic
+    if len(state.window) >= state.window_limit:
+        # Window is full, duel!
+        if window_candidate and probation_candidate:
+            freq_w = state.get_freq(window_candidate)
+            freq_p = state.get_freq(probation_candidate)
+            
+            if freq_w > freq_p:
+                return probation_candidate
             else:
-                return candidate
+                return window_candidate
+        elif window_candidate:
+            return window_candidate
         else:
-            # Check Main queue
-            if not state.main:
-                if state.small: return next(iter(state.small))
-                return None
-
-            candidate = next(iter(state.main))
-            if state.accessed.get(candidate, False):
-                # Second chance: reinsert to Main
-                del state.main[candidate]
-                state.main[candidate] = None
-                state.accessed[candidate] = False
-            else:
-                return candidate
-
-    # Emergency fallback
+            return probation_candidate 
+            
+    else:
+        # Window has space, prefer evicting from Main to let Window fill
+        if probation_candidate:
+            return probation_candidate
+        elif window_candidate:
+            return window_candidate
+            
+    # Emergency Fallback
     if cache_snapshot.cache:
         return next(iter(cache_snapshot.cache))
     return None
 
 def update_after_hit(cache_snapshot, obj):
     '''
-    Hit: Set accessed bit. Lazy promotion happens at eviction time.
-    '''
-    state = get_state(cache_snapshot)
-    state.accessed[obj.key] = True
+    Update internal state on hit.
+    '''
+    state = get_state(cache_snapshot)
+    key = obj.key
+    state.record_access(key)
+    
+    if key in state.window:
+        # Move to MRU
+        state.window.move_to_end(key)
+    elif key in state.probation:
+        # Promote to Protected
+        del state.probation[key]
+        state.protected[key] = None
+    elif key in state.protected:
+        # Move to MRU
+        state.protected.move_to_end(key)
+        
+    state.maintain_slru_invariant()
 
 def update_after_insert(cache_snapshot, obj):
     '''
-    Insert: Add to Small, or Main if in Ghost.
+    Insert new object into Window.
     '''
     state = get_state(cache_snapshot)
     key = obj.key
-    state.accessed[key] = False
-
-    if key in state.ghost:
-        state.main[key] = None
-        del state.ghost[key]
-    else:
-        state.small[key] = None
+    state.record_access(key)
+    
+    # Always insert into Window
+    state.window[key] = None
 
 def update_after_evict(cache_snapshot, obj, evicted_obj):
     '''
-    Evict: Clean up queues and update Ghost if evicted from Small.
+    Remove evicted object from internal state.
     '''
     state = get_state(cache_snapshot)
     key = evicted_obj.key
-
-    if key in state.small:
-        del state.small[key]
-        state.ghost[key] = None # Evicted from S -> G
-    elif key in state.main:
-        del state.main[key]
-        # Evicted from M -> Gone
-
-    if key in state.accessed:
-        del state.accessed[key]
-
-    # Bound Ghost size
-    while len(state.ghost) > state.capacity:
-        del state.ghost[next(iter(state.ghost))]
+    
+    if key in state.window:
+        del state.window[key]
+    elif key in state.probation:
+        del state.probation[key]
+    elif key in state.protected:
+        del state.protected[key]
 # EVOLVE-BLOCK-END
 
 # This part remains fixed (not evolved)
 def run_caching(trace_path: str, copy_code_dst: str):
     """Run the caching algorithm on a trace"""
     import os
     with open(os.path.abspath(__file__), 'r', encoding="utf-8") as f:
         code_str = f.read()
     with open(os.path.join(copy_code_dst), 'w') as f:
         f.write(code_str)
     from cache_utils import Cache, CacheConfig, CacheObj, Trace
     trace = Trace(trace_path=trace_path)
     cache_capacity = max(int(trace.get_ndv() * 0.1), 1)
     cache = Cache(CacheConfig(cache_capacity))
     for entry in trace.entries:
         obj = CacheObj(key=str(entry.key))
         cache.get(obj)
     with open(copy_code_dst, 'w') as f:
         f.write("")
     hit_rate = round(cache.hit_count / cache.access_count, 6)
     return hit_rate