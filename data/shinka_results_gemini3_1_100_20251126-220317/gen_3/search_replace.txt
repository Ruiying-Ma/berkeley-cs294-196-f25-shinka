<NAME>
slru_algorithm
</NAME>

<DESCRIPTION>
I am replacing the existing LRU implementation with a Segmented LRU (SLRU) algorithm. SLRU divides the cache into two segments: "Probationary" and "Protected".
- **Probationary Segment:** New objects are inserted here. This segment acts as a filter for objects that are accessed only once (scan resistance).
- **Protected Segment:** Objects accessed at least twice (hit while in Probationary) are promoted here. This segment protects the working set of frequently accessed items.
- **Eviction Policy:** The algorithm prioritizes evicting from the Probationary segment (LRU). If the Probationary segment is empty, it evicts from the Protected segment (LRU).
- **Size Management:** The Protected segment is limited to 80% of the cache capacity. If it exceeds this limit, the least recently used object in the Protected segment is demoted back to the Probationary segment (given a second chance).

This approach significantly improves hit rates on workloads with scans or "one-hit wonder" patterns compared to standard LRU, while maintaining O(1) complexity using `OrderedDict`.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
"""Cache eviction algorithm for optimizing hit rates across multiple workloads"""

m_key_timestamp = dict()

def evict(cache_snapshot, obj):
    '''
    This function defines how the algorithm chooses the eviction victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    candid_obj_key = None
    min_ts = min(m_key_timestamp.values())
    candid_obj_keys = list(key for key in cache_snapshot.cache if m_key_timestamp[key] == min_ts)
    candid_obj_key = candid_obj_keys[0]
    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the algorithm update the metadata it maintains immediately after a cache hit.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    global m_key_timestamp
    assert obj.key in m_key_timestamp
    m_key_timestamp[obj.key] = cache_snapshot.access_count

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    global m_key_timestamp
    assert obj.key not in m_key_timestamp
    m_key_timestamp[obj.key] = cache_snapshot.access_count

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    global m_key_timestamp
    assert obj.key not in m_key_timestamp
    assert evicted_obj.key in m_key_timestamp
    m_key_timestamp.pop(evicted_obj.key)
=======
"""Cache eviction algorithm for optimizing hit rates across multiple workloads"""

from collections import OrderedDict

m_probationary = OrderedDict()
m_protected = OrderedDict()
m_protected_size = 0

def evict(cache_snapshot, obj):
    '''
    This function defines how the algorithm chooses the eviction victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    if m_probationary:
        return next(iter(m_probationary))
    if m_protected:
        return next(iter(m_protected))
    return None

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the algorithm update the metadata it maintains immediately after a cache hit.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    global m_protected_size
    key = obj.key
    if key in m_protected:
        m_protected.move_to_end(key)
    elif key in m_probationary:
        val = m_probationary.pop(key)
        m_protected[key] = val
        m_protected_size += val

        limit = cache_snapshot.capacity * 0.8
        while m_protected_size > limit and m_protected:
            k, v = m_protected.popitem(last=False)
            m_protected_size -= v
            m_probationary[k] = v

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    m_probationary[obj.key] = obj.size

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    global m_protected_size
    key = evicted_obj.key
    if key in m_probationary:
        del m_probationary[key]
    if key in m_protected:
        val = m_protected.pop(key)
        m_protected_size -= val
>>>>>>> REPLACE

</DIFF>