<NAME>
implement_arc_algorithm
</NAME>

<DESCRIPTION>
Replace the LeCaR algorithm with the Adaptive Replacement Cache (ARC) algorithm. ARC dynamically balances between Recency (T1) and Frequency (T2) by tracking ghost hits (B1 and B2) to adjust a target parameter 'p'. This allows it to adapt to changing workloads better than static LRU or LFU, and often better than LeCaR which relies on randomized learning. The implementation uses Python's dicts as ordered access lists (LRU/MRU).
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
# LeCaR State
algo_state = {
    'freq': {},          # key -> frequency (int)
    'last_access': {},   # key -> last access timestamp (int)
    'h_lru': {},         # key -> dummy (history of keys evicted by LRU)
    'h_lfu': {},         # key -> dummy (history of keys evicted by LFU)
    'w': 0.5,            # Probability of using LRU eviction
    'learning_rate': 0.2,
    'max_time': 0,       # Track time to detect trace resets
    'last_choice': None  # 'LRU', 'LFU', or 'BOTH'
}

def _check_reset(current_time):
    # If time goes backwards, we are likely processing a new trace
    if current_time < algo_state['max_time']:
        algo_state['freq'].clear()
        algo_state['last_access'].clear()
        algo_state['h_lru'].clear()
        algo_state['h_lfu'].clear()
        algo_state['w'] = 0.5
        algo_state['max_time'] = 0
        algo_state['last_choice'] = None
    algo_state['max_time'] = current_time

def evict(cache_snapshot, obj):
    '''
    LeCaR Eviction:
    Choose the item to evict based on a weighted probability between LRU and LFU policies.
    '''
    cache_keys = list(cache_snapshot.cache.keys())
    if not cache_keys:
        return None

    # Find candidates for LRU (min last_access) and LFU (min freq)
    victim_lru = None
    min_la = float('inf')

    victim_lfu = None
    min_freq = float('inf')

    freq_map = algo_state['freq']
    la_map = algo_state['last_access']

    # Single pass to find both candidates
    for key in cache_keys:
        la = la_map.get(key, 0)
        f = freq_map.get(key, 1)

        if la < min_la:
            min_la = la
            victim_lru = key

        if f < min_freq:
            min_freq = f
            victim_lfu = key
        elif f == min_freq:
            # Tie-break LFU with LRU
            if la < la_map.get(victim_lfu, 0):
                victim_lfu = key

    # Decision
    if victim_lru == victim_lfu:
        algo_state['last_choice'] = 'BOTH'
        return victim_lru

    # Randomized choice
    if random.random() < algo_state['w']:
        algo_state['last_choice'] = 'LRU'
        return victim_lru
    else:
        algo_state['last_choice'] = 'LFU'
        return victim_lfu

def update_after_hit(cache_snapshot, obj):
    '''
    Hit: Update frequency and last access time.
    '''
    _check_reset(cache_snapshot.access_count)
    key = obj.key
    algo_state['freq'][key] = algo_state['freq'].get(key, 0) + 1
    algo_state['last_access'][key] = cache_snapshot.access_count

def update_after_insert(cache_snapshot, obj):
    '''
    Insert: Initialize metadata and update weights based on history (learning).
    '''
    _check_reset(cache_snapshot.access_count)
    key = obj.key
    curr_time = cache_snapshot.access_count

    # Initialize
    algo_state['freq'][key] = 1
    algo_state['last_access'][key] = curr_time

    # Learning
    w = algo_state['w']
    lr = algo_state['learning_rate']

    in_h_lru = key in algo_state['h_lru']
    in_h_lfu = key in algo_state['h_lfu']

    if in_h_lru:
        # Mistake by LRU -> Decrease W (prob of LRU)
        algo_state['w'] = w * math.exp(-lr)
        del algo_state['h_lru'][key]

    if in_h_lfu:
        # Mistake by LFU -> Increase W (prob of LRU)
        algo_state['w'] = 1.0 - (1.0 - w) * math.exp(-lr)
        del algo_state['h_lfu'][key]

    # Cap W to avoid getting stuck
    algo_state['w'] = max(0.001, min(0.999, algo_state['w']))

    # Manage history size (limit to capacity)
    capacity = cache_snapshot.capacity
    if len(algo_state['h_lru']) > capacity:
        # Remove oldest inserted (approx by iteration order in Python 3.7+)
        algo_state['h_lru'].pop(next(iter(algo_state['h_lru'])))

    if len(algo_state['h_lfu']) > capacity:
        algo_state['h_lfu'].pop(next(iter(algo_state['h_lfu'])))

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    Evict: Add victim to appropriate history.
    '''
    key = evicted_obj.key
    policy = algo_state.get('last_choice')

    if policy == 'LRU':
        algo_state['h_lru'][key] = True
    elif policy == 'LFU':
        algo_state['h_lfu'][key] = True
    elif policy == 'BOTH':
        algo_state['h_lru'][key] = True
        algo_state['h_lfu'][key] = True

    # Clean up
    if key in algo_state['freq']:
        del algo_state['freq'][key]
    if key in algo_state['last_access']:
        del algo_state['last_access'][key]
=======
# ARC State
algo_state = {
    't1': {},            # LRU list (dict) for T1 (Recent)
    't2': {},            # LRU list (dict) for T2 (Frequent)
    'b1': {},            # LRU list (dict) for B1 (Ghost Recent)
    'b2': {},            # LRU list (dict) for B2 (Ghost Frequent)
    'p': 0,              # Target size for T1
    'max_time': 0,       # Track time to detect trace resets
}

def _check_reset(current_time):
    # If time goes backwards, we are likely processing a new trace
    if current_time < algo_state['max_time']:
        algo_state['t1'].clear()
        algo_state['t2'].clear()
        algo_state['b1'].clear()
        algo_state['b2'].clear()
        algo_state['p'] = 0
        algo_state['max_time'] = 0
    algo_state['max_time'] = current_time

def evict(cache_snapshot, obj):
    '''
    ARC Eviction Policy
    '''
    key = obj.key
    t1 = algo_state['t1']
    t2 = algo_state['t2']
    b1 = algo_state['b1']
    b2 = algo_state['b2']
    p = algo_state['p']
    capacity = cache_snapshot.capacity

    # Adaptation simulation for decision
    p_eff = p
    if key in b1:
        d = 1
        if len(b1) >= len(b2):
            d = 1
        else:
            d = len(b2) / len(b1)
        p_eff = min(capacity, p + d)
    elif key in b2:
        d = 1
        if len(b2) >= len(b1):
            d = 1
        else:
            d = len(b1) / len(b2)
        p_eff = max(0, p - d)

    # REPLACE logic
    replace_t1 = False
    if len(t1) > 0:
        if len(t1) > p_eff:
            replace_t1 = True
        elif (key in b2) and (len(t1) == int(p_eff)):
            replace_t1 = True

    candid = None
    if replace_t1:
        candid = next(iter(t1))
    elif len(t2) > 0:
        candid = next(iter(t2))
    elif len(t1) > 0:
        candid = next(iter(t1))

    if candid is None and cache_snapshot.cache:
         candid = next(iter(cache_snapshot.cache))

    return candid

def update_after_hit(cache_snapshot, obj):
    '''
    Hit: Move to T2 MRU.
    '''
    _check_reset(cache_snapshot.access_count)
    key = obj.key
    t1 = algo_state['t1']
    t2 = algo_state['t2']

    if key in t1:
        del t1[key]
        t2[key] = True
    elif key in t2:
        del t2[key]
        t2[key] = True
    else:
        # Failsafe
        t2[key] = True

def update_after_insert(cache_snapshot, obj):
    '''
    Insert: Update p and lists.
    '''
    _check_reset(cache_snapshot.access_count)

    key = obj.key
    t1 = algo_state['t1']
    t2 = algo_state['t2']
    b1 = algo_state['b1']
    b2 = algo_state['b2']
    p = algo_state['p']
    capacity = cache_snapshot.capacity

    # Update p (Adaptation)
    if key in b1:
        d = 1
        if len(b1) >= len(b2):
            d = 1
        else:
            d = len(b2) / len(b1)
        p = min(capacity, p + d)
        del b1[key]
        t2[key] = True
    elif key in b2:
        d = 1
        if len(b2) >= len(b1):
            d = 1
        else:
            d = len(b1) / len(b2)
        p = max(0, p - d)
        del b2[key]
        t2[key] = True
    else:
        t1[key] = True

    algo_state['p'] = p

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    Evict: Update T1/T2 and B1/B2.
    '''
    ekey = evicted_obj.key
    t1 = algo_state['t1']
    t2 = algo_state['t2']
    b1 = algo_state['b1']
    b2 = algo_state['b2']
    capacity = cache_snapshot.capacity

    if ekey in t1:
        del t1[ekey]
        b1[ekey] = True
    elif ekey in t2:
        del t2[ekey]
        b2[ekey] = True

    # Trim ghosts
    if len(b1) > capacity:
        del b1[next(iter(b1))]

    if len(b2) > capacity * 2:
        del b2[next(iter(b2))]
>>>>>>> REPLACE
</DIFF>