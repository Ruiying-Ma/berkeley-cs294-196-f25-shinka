--- a/original.py
+++ b/original.py
@@ -1,155 +1,174 @@
 # EVOLVE-BLOCK-START
 """Cache eviction algorithm for optimizing hit rates across multiple workloads"""
 
 # S3-FIFO-D (Demotion) with robust frequency management
 _s3_small = {}
 _s3_main = {}
 _s3_ghost = {}
 _s3_freq = {}
 _last_ts = -1
 
 def _check_reset(snapshot):
     global _s3_small, _s3_main, _s3_ghost, _s3_freq, _last_ts
     if snapshot.access_count < _last_ts:
         _s3_small.clear()
         _s3_main.clear()
         _s3_ghost.clear()
         _s3_freq.clear()
     _last_ts = snapshot.access_count
 
 def evict(cache_snapshot, obj):
     '''
-    S3-FIFO eviction with Demotion and Ghost-triggered protection.
+    S3-FIFO with Conditional Demotion and Ghost Origin Tracking.
     '''
-    global _s3_small, _s3_main, _s3_freq
+    global _s3_small, _s3_main, _s3_freq, _s3_ghost
     _check_reset(cache_snapshot)
 
     curr_size = len(cache_snapshot.cache)
     s_target = max(1, int(curr_size * 0.1))
 
     while True:
-        # 1. Check Small (Probation)
+        # 1. Check Small (Probation) - prioritize if over target
         if len(_s3_small) > s_target:
             if not _s3_small:
                 break
 
             candidate = next(iter(_s3_small))
 
-            # Clean consistency
             if candidate not in cache_snapshot.cache:
                 _s3_small.pop(candidate, None)
                 _s3_freq.pop(candidate, None)
                 continue
 
             freq = _s3_freq.get(candidate, 0)
             if freq > 0:
                 # Promotion: Small -> Main
                 _s3_small.pop(candidate)
                 _s3_main[candidate] = None
-                # Reset frequency to 0 upon promotion (standard S3-FIFO)
                 _s3_freq[candidate] = 0
                 continue
             else:
                 # Evict from Small
                 return candidate
 
         # 2. Check Main (Protected)
         if _s3_main:
             candidate = next(iter(_s3_main))
 
             if candidate not in cache_snapshot.cache:
                 _s3_main.pop(candidate, None)
                 _s3_freq.pop(candidate, None)
                 continue
 
             freq = _s3_freq.get(candidate, 0)
             if freq > 0:
                 # Reinsert with decay
                 _s3_main.pop(candidate)
                 _s3_main[candidate] = None
                 _s3_freq[candidate] = freq - 1
                 continue
             else:
-                # Demotion: Main -> Small
-                _s3_main.pop(candidate)
-                _s3_small[candidate] = None
+                # Conditional Demotion: Main -> Small
+                # Only demote if Small is under stress limit
+                if len(_s3_small) < s_target:
+                    _s3_main.pop(candidate)
+                    _s3_small[candidate] = None
+                    _s3_freq[candidate] = 0
+                    continue
+                else:
+                    # Small is full, evict directly from Main to avoid pollution
+                    return candidate
+
+        # 3. Fallback
+        if _s3_small:
+            candidate = next(iter(_s3_small))
+            if candidate not in cache_snapshot.cache:
+                _s3_small.pop(candidate, None)
+                continue
+
+            # Use standard check even in fallback
+            freq = _s3_freq.get(candidate, 0)
+            if freq > 0:
+                _s3_small.pop(candidate)
+                _s3_main[candidate] = None
                 _s3_freq[candidate] = 0
                 continue
+            else:
+                return candidate
 
-        # 3. Fallback: Force eviction from Small if Main is empty or skipped
-        if _s3_small:
-            candidate = next(iter(_s3_small))
-            return candidate
-
-        # Final safety
         if cache_snapshot.cache:
             return next(iter(cache_snapshot.cache))
         return None
 
 def update_after_hit(cache_snapshot, obj):
     global _s3_freq
     _check_reset(cache_snapshot)
     # Cap frequency at 3
     current = _s3_freq.get(obj.key, 0)
     _s3_freq[obj.key] = min(current + 1, 3)
 
 def update_after_insert(cache_snapshot, obj):
     global _s3_small, _s3_main, _s3_ghost, _s3_freq
     _check_reset(cache_snapshot)
 
     key = obj.key
     if key in _s3_ghost:
-        # Ghost Hit: Promote to Main with protection
+        # Ghost Hit
+        origin_main = _s3_ghost.pop(key) # True if from Main, False/None if from Small
+
         if key not in _s3_main and key not in _s3_small:
-            _s3_main[key] = None
-            # Start with freq=2 to survive initial Main passes
-            # This helps loops larger than cache to persist
-            _s3_freq[key] = 2
-        _s3_ghost.pop(key)
+            if origin_main:
+                # Restore to Main (was protected)
+                _s3_main[key] = None
+                _s3_freq[key] = 1 # Moderate protection (1 reinsert)
+            else:
+                # Was in Small, give another chance in Small (Probation)
+                # This prevents scan cycling from entering Main
+                _s3_small[key] = None
+                _s3_freq[key] = 0
     else:
         # New Insert: Start in Small
         if key not in _s3_small and key not in _s3_main:
             _s3_small[key] = None
             _s3_freq[key] = 0
 
 def update_after_evict(cache_snapshot, obj, evicted_obj):
     global _s3_small, _s3_main, _s3_ghost, _s3_freq
     _check_reset(cache_snapshot)
 
     key = evicted_obj.key
-    # Track in Ghost
+    # Track in Ghost with Origin
     if key in _s3_small:
         _s3_small.pop(key)
-        _s3_ghost[key] = None
+        _s3_ghost[key] = False # From Small
     elif key in _s3_main:
         _s3_main.pop(key)
-        # Also track Main evictions in Ghost for robustness
-        _s3_ghost[key] = None
+        _s3_ghost[key] = True  # From Main
 
     _s3_freq.pop(key, None)
 
     # Cap Ghost Size
     if len(_s3_ghost) > cache_snapshot.capacity:
         _s3_ghost.pop(next(iter(_s3_ghost)), None)
 
 # EVOLVE-BLOCK-END
 
 # This part remains fixed (not evolved)
 def run_caching(trace_path: str, copy_code_dst: str):
     """Run the caching algorithm on a trace"""
     import os
     with open(os.path.abspath(__file__), 'r', encoding="utf-8") as f:
         code_str = f.read()
     with open(os.path.join(copy_code_dst), 'w') as f:
         f.write(code_str)
     from cache_utils import Cache, CacheConfig, CacheObj, Trace
     trace = Trace(trace_path=trace_path)
     cache_capacity = max(int(trace.get_ndv() * 0.1), 1)
     cache = Cache(CacheConfig(cache_capacity))
     for entry in trace.entries:
         obj = CacheObj(key=str(entry.key))
         cache.get(obj)
     with open(copy_code_dst, 'w') as f:
         f.write("")
     hit_rate = round(cache.hit_count / cache.access_count, 6)
     return hit_rate