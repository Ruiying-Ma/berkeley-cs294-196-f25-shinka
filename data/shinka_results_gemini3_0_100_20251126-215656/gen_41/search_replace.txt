<NAME>
conditional_demotion_ghost_origin
</NAME>

<DESCRIPTION>
1.  **Conditional Demotion**: In `evict`, when evicting from Main, only demote to Small if Small is not full (below target size). If Small is full, evict directly to Ghost. This prevents Main victims from polluting Small during scan/churn phases.
2.  **Ghost Origin Tracking**: In `update_after_evict`, record whether the victim came from Main (`True`) or Small (`False`) in the ghost map.
3.  **Origin-Aware Insertion**: In `update_after_insert`, use the ghost origin. If from Main, promote to Main (restore protection). If from Small, reinsert into Small (probation). This separates high-value recurrences from scan loops, preventing scans from entering Main via ghost hits.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
def evict(cache_snapshot, obj):
    '''
    S3-FIFO eviction with Demotion and Ghost-triggered protection.
    '''
    global _s3_small, _s3_main, _s3_freq
    _check_reset(cache_snapshot)

    curr_size = len(cache_snapshot.cache)
    s_target = max(1, int(curr_size * 0.1))

    while True:
        # 1. Check Small (Probation)
        if len(_s3_small) > s_target:
            if not _s3_small:
                break

            candidate = next(iter(_s3_small))

            # Clean consistency
            if candidate not in cache_snapshot.cache:
                _s3_small.pop(candidate, None)
                _s3_freq.pop(candidate, None)
                continue

            freq = _s3_freq.get(candidate, 0)
            if freq > 0:
                # Promotion: Small -> Main
                _s3_small.pop(candidate)
                _s3_main[candidate] = None
                # Reset frequency to 0 upon promotion (standard S3-FIFO)
                _s3_freq[candidate] = 0
                continue
            else:
                # Evict from Small
                return candidate

        # 2. Check Main (Protected)
        if _s3_main:
            candidate = next(iter(_s3_main))

            if candidate not in cache_snapshot.cache:
                _s3_main.pop(candidate, None)
                _s3_freq.pop(candidate, None)
                continue

            freq = _s3_freq.get(candidate, 0)
            if freq > 0:
                # Reinsert with decay
                _s3_main.pop(candidate)
                _s3_main[candidate] = None
                _s3_freq[candidate] = freq - 1
                continue
            else:
                # Demotion: Main -> Small
                _s3_main.pop(candidate)
                _s3_small[candidate] = None
                _s3_freq[candidate] = 0
                continue

        # 3. Fallback: Force eviction from Small if Main is empty or skipped
        if _s3_small:
            candidate = next(iter(_s3_small))
            return candidate

        # Final safety
        if cache_snapshot.cache:
            return next(iter(cache_snapshot.cache))
        return None
=======
def evict(cache_snapshot, obj):
    '''
    S3-FIFO with Conditional Demotion and Ghost Origin Tracking.
    '''
    global _s3_small, _s3_main, _s3_freq, _s3_ghost
    _check_reset(cache_snapshot)

    curr_size = len(cache_snapshot.cache)
    s_target = max(1, int(curr_size * 0.1))

    while True:
        # 1. Check Small (Probation) - prioritize if over target
        if len(_s3_small) > s_target:
            if not _s3_small:
                break

            candidate = next(iter(_s3_small))

            if candidate not in cache_snapshot.cache:
                _s3_small.pop(candidate, None)
                _s3_freq.pop(candidate, None)
                continue

            freq = _s3_freq.get(candidate, 0)
            if freq > 0:
                # Promotion: Small -> Main
                _s3_small.pop(candidate)
                _s3_main[candidate] = None
                _s3_freq[candidate] = 0
                continue
            else:
                # Evict from Small
                return candidate

        # 2. Check Main (Protected)
        if _s3_main:
            candidate = next(iter(_s3_main))

            if candidate not in cache_snapshot.cache:
                _s3_main.pop(candidate, None)
                _s3_freq.pop(candidate, None)
                continue

            freq = _s3_freq.get(candidate, 0)
            if freq > 0:
                # Reinsert with decay
                _s3_main.pop(candidate)
                _s3_main[candidate] = None
                _s3_freq[candidate] = freq - 1
                continue
            else:
                # Conditional Demotion: Main -> Small
                # Only demote if Small is under stress limit
                if len(_s3_small) < s_target:
                    _s3_main.pop(candidate)
                    _s3_small[candidate] = None
                    _s3_freq[candidate] = 0
                    continue
                else:
                    # Small is full, evict directly from Main to avoid pollution
                    return candidate

        # 3. Fallback
        if _s3_small:
            candidate = next(iter(_s3_small))
            if candidate not in cache_snapshot.cache:
                _s3_small.pop(candidate, None)
                continue

            # Use standard check even in fallback
            freq = _s3_freq.get(candidate, 0)
            if freq > 0:
                _s3_small.pop(candidate)
                _s3_main[candidate] = None
                _s3_freq[candidate] = 0
                continue
            else:
                return candidate

        if cache_snapshot.cache:
            return next(iter(cache_snapshot.cache))
        return None
>>>>>>> REPLACE
<<<<<<< SEARCH
def update_after_insert(cache_snapshot, obj):
    global _s3_small, _s3_main, _s3_ghost, _s3_freq
    _check_reset(cache_snapshot)

    key = obj.key
    if key in _s3_ghost:
        # Ghost Hit: Promote to Main with protection
        if key not in _s3_main and key not in _s3_small:
            _s3_main[key] = None
            # Start with freq=2 to survive initial Main passes
            # This helps loops larger than cache to persist
            _s3_freq[key] = 2
        _s3_ghost.pop(key)
    else:
        # New Insert: Start in Small
        if key not in _s3_small and key not in _s3_main:
            _s3_small[key] = None
            _s3_freq[key] = 0
=======
def update_after_insert(cache_snapshot, obj):
    global _s3_small, _s3_main, _s3_ghost, _s3_freq
    _check_reset(cache_snapshot)

    key = obj.key
    if key in _s3_ghost:
        # Ghost Hit
        origin_main = _s3_ghost.pop(key) # True if from Main, False/None if from Small

        if key not in _s3_main and key not in _s3_small:
            if origin_main:
                # Restore to Main (was protected)
                _s3_main[key] = None
                _s3_freq[key] = 1 # Moderate protection (1 reinsert)
            else:
                # Was in Small, give another chance in Small (Probation)
                # This prevents scan cycling from entering Main
                _s3_small[key] = None
                _s3_freq[key] = 0
    else:
        # New Insert: Start in Small
        if key not in _s3_small and key not in _s3_main:
            _s3_small[key] = None
            _s3_freq[key] = 0
>>>>>>> REPLACE
<<<<<<< SEARCH
def update_after_evict(cache_snapshot, obj, evicted_obj):
    global _s3_small, _s3_main, _s3_ghost, _s3_freq
    _check_reset(cache_snapshot)

    key = evicted_obj.key
    # Track in Ghost
    if key in _s3_small:
        _s3_small.pop(key)
        _s3_ghost[key] = None
    elif key in _s3_main:
        _s3_main.pop(key)
        # Also track Main evictions in Ghost for robustness
        _s3_ghost[key] = None

    _s3_freq.pop(key, None)

    # Cap Ghost Size
    if len(_s3_ghost) > cache_snapshot.capacity:
        _s3_ghost.pop(next(iter(_s3_ghost)), None)
=======
def update_after_evict(cache_snapshot, obj, evicted_obj):
    global _s3_small, _s3_main, _s3_ghost, _s3_freq
    _check_reset(cache_snapshot)

    key = evicted_obj.key
    # Track in Ghost with Origin
    if key in _s3_small:
        _s3_small.pop(key)
        _s3_ghost[key] = False # From Small
    elif key in _s3_main:
        _s3_main.pop(key)
        _s3_ghost[key] = True  # From Main

    _s3_freq.pop(key, None)

    # Cap Ghost Size
    if len(_s3_ghost) > cache_snapshot.capacity:
        _s3_ghost.pop(next(iter(_s3_ghost)), None)
>>>>>>> REPLACE
</DIFF>