--- a/original.py
+++ b/original.py
@@ -1,119 +1,180 @@
 # EVOLVE-BLOCK-START
-"""
-S3-FIFO Cache Eviction Algorithm Implementation.
-Inspired by S3-FIFO (Simple, Scalable, Static) which uses a small FIFO queue (S)
-and a main FIFO queue (M) with re-insertion to approximate LRU with scan resistance
-and frequency awareness.
-"""
-
 from collections import OrderedDict
 
-# Global metadata structures
-# s_queue: Small FIFO queue (probationary)
-# m_queue: Main FIFO queue (protected)
-# ghost_registry: Ghost FIFO queue (history of evicted probationary items)
-# accessed_bits: Set of keys accessed while in cache (simulating reference bits)
+# S3-FIFO-D-G (Dynamic Demotion + Ghost Origins)
+# - q_small: FIFO queue for new/probationary items
+# - q_main: FIFO queue for protected items
+# - q_ghost: FIFO queue mapping key -> origin_was_main (bool)
+# - meta_freq: Frequency counter (0-3)
 
-s_queue = OrderedDict()
-m_queue = OrderedDict()
-ghost_registry = OrderedDict()
-accessed_bits = set()
+q_small = OrderedDict()
+q_main = OrderedDict()
+q_ghost = OrderedDict()
+meta_freq = {}
+last_chk_time = -1
+
+def _maintain_consistency(snapshot):
+    global last_chk_time, q_small, q_main, q_ghost, meta_freq
+    # Reset if time moves backward or cache is empty but state exists
+    if snapshot.access_count < last_chk_time or (not snapshot.cache and (q_small or q_main)):
+        q_small.clear()
+        q_main.clear()
+        q_ghost.clear()
+        meta_freq.clear()
+    last_chk_time = snapshot.access_count
 
 def evict(cache_snapshot, obj):
     '''
-    Selects a victim using S3-FIFO policy.
-    Iterates through S and M queues to find a candidate without an active access bit.
-    Promotes/Re-inserts items with access bits.
+    S3-FIFO eviction with:
+    - Conditional M->S demotion (only if S has space)
+    - Origin-aware Ghost management
     '''
-    # Target size for the small queue (10% of capacity)
-    s_capacity = max(int(cache_snapshot.capacity * 0.1), 1)
+    global q_small, q_main, q_ghost, meta_freq
+    _maintain_consistency(cache_snapshot)
     
-    while True:
-        # Check S queue first if it exceeds capacity or if M is empty
-        if len(s_queue) > s_capacity or (len(s_queue) > 0 and len(m_queue) == 0):
-            candidate_key, _ = s_queue.popitem(last=False) # Pop from head (FIFO)
+    capacity = cache_snapshot.capacity
+    # Target Small queue size (10% of capacity)
+    target_s = max(1, int(capacity * 0.1))
+    
+    # Operations limit to prevent infinite loops in extreme cases
+    ops = 0
+    limit = len(cache_snapshot.cache) * 4
+    
+    while ops < limit:
+        ops += 1
+        
+        # S3-FIFO Policy: 
+        # Scan Small if it's large or Main is empty. Otherwise scan Main.
+        check_small = False
+        if len(q_small) > target_s or not q_main:
+            check_small = True
             
-            if candidate_key in accessed_bits:
-                # Second chance: Move to M
-                accessed_bits.discard(candidate_key)
-                m_queue[candidate_key] = None
+        if check_small:
+            if not q_small:
+                # If S is empty, try M (unless M is also empty)
+                if q_main:
+                    check_small = False
+                else:
+                    break # Cache is empty
+            
+            if check_small:
+                # Process Small Queue
+                cand, _ = q_small.popitem(last=False)
+                
+                # Cleanup if inconsistent
+                if cand not in cache_snapshot.cache:
+                    meta_freq.pop(cand, None)
+                    continue
+                
+                freq = meta_freq.get(cand, 0)
+                if freq > 0:
+                    # Promote to Main
+                    q_main[cand] = None
+                    meta_freq[cand] = 0 # Reset frequency
+                    continue
+                else:
+                    # Evict from Small
+                    # Record origin as Small (False)
+                    q_ghost[cand] = False
+                    if len(q_ghost) > capacity * 3:
+                        q_ghost.popitem(last=False)
+                    
+                    meta_freq.pop(cand, None)
+                    return cand
+        else:
+            # Process Main Queue
+            cand, _ = q_main.popitem(last=False)
+            
+            if cand not in cache_snapshot.cache:
+                meta_freq.pop(cand, None)
+                continue
+                
+            freq = meta_freq.get(cand, 0)
+            if freq > 0:
+                # Reinsert to Main with decay
+                q_main[cand] = None
+                meta_freq[cand] = freq - 1
+                continue
             else:
-                # Victim found in S
-                # Add to ghost registry
-                ghost_registry[candidate_key] = None
-                # Cap ghost size to cache capacity
-                if len(ghost_registry) > cache_snapshot.capacity:
-                    ghost_registry.popitem(last=False)
-                return candidate_key
-        
-        else:
-            # Check M queue
-            if not m_queue:
-                # Should not be reached if cache is not empty
-                # Fallback to S if M is empty
-                if s_queue:
-                        k, _ = s_queue.popitem(last=False)
-                        return k
-                # Extreme fallback
-                return next(iter(cache_snapshot.cache))
-                
-            candidate_key, _ = m_queue.popitem(last=False) # Pop from head
-            
-            if candidate_key in accessed_bits:
-                # Second chance: Re-insert at tail of M
-                accessed_bits.discard(candidate_key)
-                m_queue[candidate_key] = None
-            else:
-                # Victim found in M
-                # Do not add to ghost (only S evictions go to ghost)
-                return candidate_key
+                # Conditional Demotion
+                # Only demote to S if S is not full.
+                # This prevents cold M items from trashing S during scans.
+                if len(q_small) < target_s:
+                    q_small[cand] = None
+                    meta_freq[cand] = 0
+                    continue
+                else:
+                    # Direct Eviction from Main (bypass S)
+                    # Record origin as Main (True)
+                    q_ghost[cand] = True
+                    if len(q_ghost) > capacity * 3:
+                        q_ghost.popitem(last=False)
+                    
+                    meta_freq.pop(cand, None)
+                    return cand
+
+    # Fallback
+    if cache_snapshot.cache:
+        return next(iter(cache_snapshot.cache))
+    return None
 
 def update_after_hit(cache_snapshot, obj):
-    '''
-    Mark the object as accessed.
-    '''
-    accessed_bits.add(obj.key)
+    '''Increment frequency on hit, capped at 3.'''
+    global meta_freq
+    _maintain_consistency(cache_snapshot)
+    k = obj.key
+    meta_freq[k] = min(meta_freq.get(k, 0) + 1, 3)
 
 def update_after_insert(cache_snapshot, obj):
-    '''
-    Insert new object into S or M based on ghost history.
-    '''
-    if obj.key in ghost_registry:
-        # Promote directly to Main queue
-        m_queue[obj.key] = None
-        del ghost_registry[obj.key]
+    '''Handle new insertions and ghost hits.'''
+    global q_small, q_main, q_ghost, meta_freq
+    _maintain_consistency(cache_snapshot)
+    
+    k = obj.key
+    
+    if k in q_ghost:
+        origin_main = q_ghost.pop(k)
+        if origin_main:
+            # Ghost from Main: Restore directly to Main
+            q_main[k] = None
+            meta_freq[k] = 0
+        else:
+            # Ghost from Small: Restore to Small
+            # Initialize with freq=1 to ensure promotion on next scan
+            q_small[k] = None
+            meta_freq[k] = 1
     else:
-        # Insert into Small queue
-        s_queue[obj.key] = None
-        
-    # Reset access bit on insert (usually assumed 0 freq initially)
-    accessed_bits.discard(obj.key)
+        # New Insert: Start in Small with 0 frequency
+        q_small[k] = None
+        meta_freq[k] = 0
 
 def update_after_evict(cache_snapshot, obj, evicted_obj):
-    '''
-    Cleanup. Most logic handled in evict, but ensure consistency.
-    '''
-    # The evicted object was already removed from our queues in `evict`.
-    # Just ensure it's cleared from accessed bits if it lingered.
-    accessed_bits.discard(evicted_obj.key)
+    '''Cleanup metadata.'''
+    global q_small, q_main, meta_freq
+    _maintain_consistency(cache_snapshot)
+    
+    k = evicted_obj.key
+    q_small.pop(k, None)
+    q_main.pop(k, None)
+    meta_freq.pop(k, None)
 # EVOLVE-BLOCK-END
 
 # This part remains fixed (not evolved)
 def run_caching(trace_path: str, copy_code_dst: str):
     """Run the caching algorithm on a trace"""
     import os
     with open(os.path.abspath(__file__), 'r', encoding="utf-8") as f:
         code_str = f.read()
     with open(os.path.join(copy_code_dst), 'w') as f:
         f.write(code_str)
     from cache_utils import Cache, CacheConfig, CacheObj, Trace
     trace = Trace(trace_path=trace_path)
     cache_capacity = max(int(trace.get_ndv() * 0.1), 1)
     cache = Cache(CacheConfig(cache_capacity))
     for entry in trace.entries:
         obj = CacheObj(key=str(entry.key))
         cache.get(obj)
     with open(copy_code_dst, 'w') as f:
         f.write("")
     hit_rate = round(cache.hit_count / cache.access_count, 6)
     return hit_rate