--- a/original.py
+++ b/original.py
@@ -1,79 +1,119 @@
 # EVOLVE-BLOCK-START
-"""Cache eviction algorithm for optimizing hit rates across multiple workloads"""
+"""
+S3-FIFO Cache Eviction Algorithm Implementation.
+Inspired by S3-FIFO (Simple, Scalable, Static) which uses a small FIFO queue (S)
+and a main FIFO queue (M) with re-insertion to approximate LRU with scan resistance
+and frequency awareness.
+"""
 
-m_key_timestamp = dict()
+from collections import OrderedDict
+
+# Global metadata structures
+# s_queue: Small FIFO queue (probationary)
+# m_queue: Main FIFO queue (protected)
+# ghost_registry: Ghost FIFO queue (history of evicted probationary items)
+# accessed_bits: Set of keys accessed while in cache (simulating reference bits)
+
+s_queue = OrderedDict()
+m_queue = OrderedDict()
+ghost_registry = OrderedDict()
+accessed_bits = set()
 
 def evict(cache_snapshot, obj):
     '''
-    This function defines how the algorithm chooses the eviction victim.
-    - Args:
-        - `cache_snapshot`: A snapshot of the current cache state.
-        - `obj`: The new object that needs to be inserted into the cache.
-    - Return:
-        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
+    Selects a victim using S3-FIFO policy.
+    Iterates through S and M queues to find a candidate without an active access bit.
+    Promotes/Re-inserts items with access bits.
     '''
-    candid_obj_key = None
-    min_ts = min(m_key_timestamp.values())
-    candid_obj_keys = list(key for key in cache_snapshot.cache if m_key_timestamp[key] == min_ts)
-    candid_obj_key = candid_obj_keys[0]
-    return candid_obj_key
+    # Target size for the small queue (10% of capacity)
+    s_capacity = max(int(cache_snapshot.capacity * 0.1), 1)
+    
+    while True:
+        # Check S queue first if it exceeds capacity or if M is empty
+        if len(s_queue) > s_capacity or (len(s_queue) > 0 and len(m_queue) == 0):
+            candidate_key, _ = s_queue.popitem(last=False) # Pop from head (FIFO)
+            
+            if candidate_key in accessed_bits:
+                # Second chance: Move to M
+                accessed_bits.discard(candidate_key)
+                m_queue[candidate_key] = None
+            else:
+                # Victim found in S
+                # Add to ghost registry
+                ghost_registry[candidate_key] = None
+                # Cap ghost size to cache capacity
+                if len(ghost_registry) > cache_snapshot.capacity:
+                    ghost_registry.popitem(last=False)
+                return candidate_key
+        
+        else:
+            # Check M queue
+            if not m_queue:
+                # Should not be reached if cache is not empty
+                # Fallback to S if M is empty
+                if s_queue:
+                        k, _ = s_queue.popitem(last=False)
+                        return k
+                # Extreme fallback
+                return next(iter(cache_snapshot.cache))
+                
+            candidate_key, _ = m_queue.popitem(last=False) # Pop from head
+            
+            if candidate_key in accessed_bits:
+                # Second chance: Re-insert at tail of M
+                accessed_bits.discard(candidate_key)
+                m_queue[candidate_key] = None
+            else:
+                # Victim found in M
+                # Do not add to ghost (only S evictions go to ghost)
+                return candidate_key
 
 def update_after_hit(cache_snapshot, obj):
     '''
-    This function defines how the algorithm update the metadata it maintains immediately after a cache hit.
-    - Args:
-        - `cache_snapshot`: A snapshot of the current cache state.
-        - `obj`: The object accessed during the cache hit.
-    - Return: `None`
+    Mark the object as accessed.
     '''
-    global m_key_timestamp
-    assert obj.key in m_key_timestamp
-    m_key_timestamp[obj.key] = cache_snapshot.access_count
+    accessed_bits.add(obj.key)
 
 def update_after_insert(cache_snapshot, obj):
     '''
-    This function defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
-    - Args:
-        - `cache_snapshot`: A snapshot of the current cache state.
-        - `obj`: The object that was just inserted into the cache.
-    - Return: `None`
+    Insert new object into S or M based on ghost history.
     '''
-    global m_key_timestamp
-    assert obj.key not in m_key_timestamp
-    m_key_timestamp[obj.key] = cache_snapshot.access_count
+    if obj.key in ghost_registry:
+        # Promote directly to Main queue
+        m_queue[obj.key] = None
+        del ghost_registry[obj.key]
+    else:
+        # Insert into Small queue
+        s_queue[obj.key] = None
+        
+    # Reset access bit on insert (usually assumed 0 freq initially)
+    accessed_bits.discard(obj.key)
 
 def update_after_evict(cache_snapshot, obj, evicted_obj):
     '''
-    This function defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
-    - Args:
-        - `cache_snapshot`: A snapshot of the current cache state.
-        - `obj`: The object to be inserted into the cache.
-        - `evicted_obj`: The object that was just evicted from the cache.
-    - Return: `None`
+    Cleanup. Most logic handled in evict, but ensure consistency.
     '''
-    global m_key_timestamp
-    assert obj.key not in m_key_timestamp
-    assert evicted_obj.key in m_key_timestamp
-    m_key_timestamp.pop(evicted_obj.key)
-
+    # The evicted object was already removed from our queues in `evict`.
+    # Just ensure it's cleared from accessed bits if it lingered.
+    accessed_bits.discard(evicted_obj.key)
 # EVOLVE-BLOCK-END
 
 # This part remains fixed (not evolved)
 def run_caching(trace_path: str, copy_code_dst: str):
     """Run the caching algorithm on a trace"""
     import os
     with open(os.path.abspath(__file__), 'r', encoding="utf-8") as f:
         code_str = f.read()
     with open(os.path.join(copy_code_dst), 'w') as f:
         f.write(code_str)
     from cache_utils import Cache, CacheConfig, CacheObj, Trace
     trace = Trace(trace_path=trace_path)
     cache_capacity = max(int(trace.get_ndv() * 0.1), 1)
     cache = Cache(CacheConfig(cache_capacity))
     for entry in trace.entries:
         obj = CacheObj(key=str(entry.key))
         cache.get(obj)
     with open(copy_code_dst, 'w') as f:
         f.write("")
     hit_rate = round(cache.hit_count / cache.access_count, 6)
     return hit_rate