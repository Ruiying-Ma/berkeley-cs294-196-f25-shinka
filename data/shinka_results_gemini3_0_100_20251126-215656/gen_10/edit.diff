--- a/original.py
+++ b/original.py
@@ -1,119 +1,149 @@
 # EVOLVE-BLOCK-START
 """
-S3-FIFO Cache Eviction Algorithm Implementation.
-Inspired by S3-FIFO (Simple, Scalable, Static) which uses a small FIFO queue (S)
-and a main FIFO queue (M) with re-insertion to approximate LRU with scan resistance
-and frequency awareness.
+Adaptive S3-FIFO (A-S3-FIFO)
+Combines S3-FIFO with Adaptive Replacement Cache (ARC) principles.
+Dynamically adjusts the size of the small/probationary queue (S) based on hits in ghost registries.
+Uses two ghost queues:
+- Ghost S: Tracks items evicted from S. Hits here imply S is too small.
+- Ghost M: Tracks items evicted from M. Hits here imply M is too small (S is too big).
 """
 
 from collections import OrderedDict
 
-# Global metadata structures
-# s_queue: Small FIFO queue (probationary)
-# m_queue: Main FIFO queue (protected)
-# ghost_registry: Ghost FIFO queue (history of evicted probationary items)
-# accessed_bits: Set of keys accessed while in cache (simulating reference bits)
+# Global state
+s_queue = OrderedDict()    # Small/Probationary FIFO
+m_queue = OrderedDict()    # Main/Protected FIFO
+ghost_s = OrderedDict()    # Ghost registry for S
+ghost_m = OrderedDict()    # Ghost registry for M
+accessed_bits = set()      # Tracks access status
+s_dist = 0.1               # Target fraction for S queue (0.0 to 1.0)
 
-s_queue = OrderedDict()
-m_queue = OrderedDict()
-ghost_registry = OrderedDict()
-accessed_bits = set()
+def reset_globals_if_new_trace(cache_snapshot):
+    """
+    Heuristic to reset globals if a new trace has started.
+    Checks if cache is nearly empty but internal state is large.
+    """
+    global s_queue, m_queue, ghost_s, ghost_m, accessed_bits, s_dist
+    # If cache has <= 1 items (start of trace) but we have history, reset.
+    if len(cache_snapshot.cache) <= 1 and (len(s_queue) > 1 or len(m_queue) > 1):
+        s_queue.clear()
+        m_queue.clear()
+        ghost_s.clear()
+        ghost_m.clear()
+        accessed_bits.clear()
+        s_dist = 0.1
 
 def evict(cache_snapshot, obj):
     '''
-    Selects a victim using S3-FIFO policy.
-    Iterates through S and M queues to find a candidate without an active access bit.
-    Promotes/Re-inserts items with access bits.
+    Selects a victim using Adaptive S3-FIFO logic.
+    Adjusts eviction source based on s_dist target.
     '''
-    # Target size for the small queue (10% of capacity)
-    s_capacity = max(int(cache_snapshot.capacity * 0.1), 1)
+    global s_dist
+    
+    capacity = cache_snapshot.capacity
+    # Target size for S based on adaptive distribution
+    s_target = max(1, int(capacity * s_dist))
     
     while True:
-        # Check S queue first if it exceeds capacity or if M is empty
-        if len(s_queue) > s_capacity or (len(s_queue) > 0 and len(m_queue) == 0):
-            candidate_key, _ = s_queue.popitem(last=False) # Pop from head (FIFO)
+        # Determine if we should evict from S or M
+        # Evict from S if it exceeds its target share, or if M is empty
+        evict_s = (len(s_queue) > s_target) or (len(m_queue) == 0)
+        
+        if evict_s:
+            if not s_queue:
+                 # Should not happen if cache is full
+                 return next(iter(cache_snapshot.cache))
             
-            if candidate_key in accessed_bits:
-                # Second chance: Move to M
-                accessed_bits.discard(candidate_key)
-                m_queue[candidate_key] = None
+            key, _ = s_queue.popitem(last=False) # FIFO head
+            
+            if key in accessed_bits:
+                # Second chance: promote to M
+                accessed_bits.discard(key)
+                m_queue[key] = None
             else:
-                # Victim found in S
-                # Add to ghost registry
-                ghost_registry[candidate_key] = None
-                # Cap ghost size to cache capacity
-                if len(ghost_registry) > cache_snapshot.capacity:
-                    ghost_registry.popitem(last=False)
-                return candidate_key
-        
+                # Evict from S -> Ghost S
+                ghost_s[key] = None
+                # Cap ghost size
+                if len(ghost_s) > capacity:
+                    ghost_s.popitem(last=False)
+                return key
         else:
-            # Check M queue
-            if not m_queue:
-                # Should not be reached if cache is not empty
-                # Fallback to S if M is empty
-                if s_queue:
-                        k, _ = s_queue.popitem(last=False)
-                        return k
-                # Extreme fallback
-                return next(iter(cache_snapshot.cache))
-                
-            candidate_key, _ = m_queue.popitem(last=False) # Pop from head
+            # Evict from M
+            key, _ = m_queue.popitem(last=False) # FIFO head
             
-            if candidate_key in accessed_bits:
-                # Second chance: Re-insert at tail of M
-                accessed_bits.discard(candidate_key)
-                m_queue[candidate_key] = None
+            if key in accessed_bits:
+                # Second chance: reinsert to M tail
+                accessed_bits.discard(key)
+                m_queue[key] = None
             else:
-                # Victim found in M
-                # Do not add to ghost (only S evictions go to ghost)
-                return candidate_key
+                # Evict from M -> Ghost M
+                ghost_m[key] = None
+                # Cap ghost size
+                if len(ghost_m) > capacity:
+                    ghost_m.popitem(last=False)
+                return key
 
 def update_after_hit(cache_snapshot, obj):
-    '''
-    Mark the object as accessed.
-    '''
     accessed_bits.add(obj.key)
 
 def update_after_insert(cache_snapshot, obj):
-    '''
-    Insert new object into S or M based on ghost history.
-    '''
-    if obj.key in ghost_registry:
-        # Promote directly to Main queue
-        m_queue[obj.key] = None
-        del ghost_registry[obj.key]
+    reset_globals_if_new_trace(cache_snapshot)
+    
+    global s_dist
+    key = obj.key
+    capacity = cache_snapshot.capacity
+    
+    # Calculate adaptation step size (1 slot equivalent)
+    delta = 1.0 / capacity if capacity > 0 else 0.01
+    
+    if key in ghost_s:
+        # Was in S, evicted, now back. S was too small.
+        # Increase S target
+        s_dist = min(0.9, s_dist + delta)
+        # Promote to M (rescue)
+        m_queue[key] = None
+        del ghost_s[key]
+        
+    elif key in ghost_m:
+        # Was in M, evicted, now back. M was too small.
+        # Decrease S target (grow M)
+        s_dist = max(0.01, s_dist - delta)
+        # Promote to M (rescue)
+        m_queue[key] = None
+        del ghost_m[key]
+        
     else:
-        # Insert into Small queue
-        s_queue[obj.key] = None
-        
-    # Reset access bit on insert (usually assumed 0 freq initially)
-    accessed_bits.discard(obj.key)
+        # New item -> S
+        s_queue[key] = None
+    
+    # Reset access bit for new/promoted item
+    accessed_bits.discard(key)
 
 def update_after_evict(cache_snapshot, obj, evicted_obj):
-    '''
-    Cleanup. Most logic handled in evict, but ensure consistency.
-    '''
-    # The evicted object was already removed from our queues in `evict`.
-    # Just ensure it's cleared from accessed bits if it lingered.
     accessed_bits.discard(evicted_obj.key)
+    # Ensure consistency (cleanup if needed)
+    if evicted_obj.key in s_queue:
+        del s_queue[evicted_obj.key]
+    if evicted_obj.key in m_queue:
+        del m_queue[evicted_obj.key]
 # EVOLVE-BLOCK-END
 
 # This part remains fixed (not evolved)
 def run_caching(trace_path: str, copy_code_dst: str):
     """Run the caching algorithm on a trace"""
     import os
     with open(os.path.abspath(__file__), 'r', encoding="utf-8") as f:
         code_str = f.read()
     with open(os.path.join(copy_code_dst), 'w') as f:
         f.write(code_str)
     from cache_utils import Cache, CacheConfig, CacheObj, Trace
     trace = Trace(trace_path=trace_path)
     cache_capacity = max(int(trace.get_ndv() * 0.1), 1)
     cache = Cache(CacheConfig(cache_capacity))
     for entry in trace.entries:
         obj = CacheObj(key=str(entry.key))
         cache.get(obj)
     with open(copy_code_dst, 'w') as f:
         f.write("")
     hit_rate = round(cache.hit_count / cache.access_count, 6)
     return hit_rate