--- a/original.py
+++ b/original.py
@@ -1,121 +1,140 @@
 # EVOLVE-BLOCK-START
 """
-S3-FIFO Cache Eviction Algorithm Implementation.
-Inspired by S3-FIFO (Simple, Scalable, Static) which uses a small FIFO queue (S)
-and a main FIFO queue (M) with re-insertion to approximate LRU with scan resistance
-and frequency awareness.
+Smart S3-FIFO (SmartS3FIFO)
+Enhancements:
+- Conditional Demotion: M->S demotion only when S is under capacity.
+- Strict Eviction: Direct M eviction when S is full.
+- Ghost Registry: Tracks S evictions to rescue false negatives.
+- Frequency Map: Uses integer counters instead of bits for future extensibility.
 """
 
 from collections import OrderedDict
 
-# Global metadata structures
-# s_queue: Small FIFO queue (probationary)
-# m_queue: Main FIFO queue (protected)
-# ghost_registry: Ghost FIFO queue (history of evicted probationary items)
-# accessed_bits: Set of keys accessed while in cache (simulating reference bits)
-
-s_queue = OrderedDict()
-m_queue = OrderedDict()
-ghost_registry = OrderedDict()
-accessed_bits = set()
+# Global State
+s_queue = OrderedDict()       # Small/Probationary Queue
+m_queue = OrderedDict()       # Main/Protected Queue
+ghost_registry = OrderedDict() # History of S evictions
+freq_map = {}                 # Frequency counter (0-3)
 
 def evict(cache_snapshot, obj):
     '''
-    Selects a victim using S3-FIFO policy.
-    Iterates through S and M queues to find a candidate without an active access bit.
-    Promotes/Re-inserts items with access bits.
+    Selects a victim.
+    Policy:
+    - If S is above target size (10%) or M is empty: Clean S.
+      - S-Victim accessed? -> Promote to M.
+      - Else -> Evict & Ghost.
+    - Else (S is small enough, M has data): Clean M.
+      - M-Victim accessed? -> Reinsert M.
+      - Else ->
+         - If S has room? -> Demote to S.
+         - Else -> Evict directly.
     '''
-    # Target size for the small queue (10% of capacity)
-    s_capacity = max(int(cache_snapshot.capacity * 0.1), 1)
+    # 10% capacity target for S
+    capacity = cache_snapshot.capacity
+    s_target = max(int(capacity * 0.1), 1)
+    
+    # Cap ghost to N (e.g., 2x capacity)
+    ghost_limit = capacity * 2
 
     while True:
-        # Check S queue first if it exceeds capacity or if M is empty
-        if len(s_queue) > s_capacity or (len(s_queue) > 0 and len(m_queue) == 0):
-            candidate_key, _ = s_queue.popitem(last=False) # Pop from head (FIFO)
+        # Check if we need to prioritize S eviction
+        # We process S if it's over budget, OR if M is empty (must keep cache full)
+        force_s = len(s_queue) > s_target or len(m_queue) == 0
+        
+        if force_s:
+            if not s_queue:
+                # Fallback if M is empty and S is empty (should not happen in full cache)
+                # But if we just demoted everything?
+                if m_queue:
+                    force_s = False # Go to M logic
+                else:
+                    return next(iter(cache_snapshot.cache)) # Failsafe
 
-            if candidate_key in accessed_bits:
-                # Second chance: Move to M
-                accessed_bits.discard(candidate_key)
-                m_queue[candidate_key] = None
+            if force_s:
+                candidate, _ = s_queue.popitem(last=False)
+                cnt = freq_map.get(candidate, 0)
+                
+                if cnt > 0:
+                    # Accessed in S -> Promote to M
+                    m_queue[candidate] = None
+                    freq_map[candidate] = 0 # Reset frequency on move
+                else:
+                    # Not accessed -> Evict
+                    # Record in ghost
+                    ghost_registry[candidate] = None
+                    if len(ghost_registry) > ghost_limit:
+                        ghost_registry.popitem(last=False)
+                    return candidate
+        
+        if not force_s:
+            # Process M
+            if not m_queue:
+                # M empty, go back to S (loop will handle)
+                continue
+                
+            candidate, _ = m_queue.popitem(last=False)
+            cnt = freq_map.get(candidate, 0)
+            
+            if cnt > 0:
+                # Accessed in M -> Reinsert M (Second Chance)
+                m_queue[candidate] = None
+                freq_map[candidate] = 0
             else:
-                # Victim found in S
-                # Add to ghost registry
-                ghost_registry[candidate_key] = None
-                # Cap ghost size to 2x cache capacity for better history coverage
-                if len(ghost_registry) > cache_snapshot.capacity * 2:
-                    ghost_registry.popitem(last=False)
-                return candidate_key
-
-        else:
-            # Check M queue
-            if not m_queue:
-                # Should not be reached if cache is not empty
-                # Fallback to S if M is empty
-                if s_queue:
-                        k, _ = s_queue.popitem(last=False)
-                        return k
-                # Extreme fallback
-                return next(iter(cache_snapshot.cache))
-
-            candidate_key, _ = m_queue.popitem(last=False) # Pop from head
-
-            if candidate_key in accessed_bits:
-                # Second chance: Re-insert at tail of M
-                accessed_bits.discard(candidate_key)
-                m_queue[candidate_key] = None
-            else:
-                # Victim found in M
-                # Demote to S queue (tail) to give one final chance
-                s_queue[candidate_key] = None
-                # We haven't found a victim yet, so continue the loop
-                continue
+                # Cold in M
+                # Conditional Demotion: Only if S has space
+                if len(s_queue) < s_target:
+                    s_queue[candidate] = None
+                    # frequency remains 0
+                else:
+                    # S is full, don't pollute it. Evict M-victim directly.
+                    return candidate
 
 def update_after_hit(cache_snapshot, obj):
-    '''
-    Mark the object as accessed.
-    '''
-    accessed_bits.add(obj.key)
+    '''Increment frequency, cap at 3.'''
+    curr = freq_map.get(obj.key, 0)
+    freq_map[obj.key] = min(curr + 1, 3)
 
 def update_after_insert(cache_snapshot, obj):
-    '''
-    Insert new object into S or M based on ghost history.
-    '''
-    if obj.key in ghost_registry:
-        # Promote directly to Main queue
-        m_queue[obj.key] = None
-        del ghost_registry[obj.key]
+    '''Insert based on Ghost history.'''
+    key = obj.key
+    freq_map[key] = 0 # Reset frequency on new insert
+    
+    if key in ghost_registry:
+        # Ghost hit -> Insert to M (skip probation)
+        m_queue[key] = None
+        del ghost_registry[key]
     else:
-        # Insert into Small queue
-        s_queue[obj.key] = None
-
-    # Reset access bit on insert (usually assumed 0 freq initially)
-    accessed_bits.discard(obj.key)
+        # New -> Insert to S
+        s_queue[key] = None
 
 def update_after_evict(cache_snapshot, obj, evicted_obj):
-    '''
-    Cleanup. Most logic handled in evict, but ensure consistency.
-    '''
-    # The evicted object was already removed from our queues in `evict`.
-    # Just ensure it's cleared from accessed bits if it lingered.
-    accessed_bits.discard(evicted_obj.key)
+    '''Cleanup metadata.'''
+    key = evicted_obj.key
+    if key in freq_map:
+        del freq_map[key]
+    # Queues are handled in evict, but safety check
+    if key in s_queue:
+        del s_queue[key]
+    if key in m_queue:
+        del m_queue[key]
 # EVOLVE-BLOCK-END
 
 # This part remains fixed (not evolved)
 def run_caching(trace_path: str, copy_code_dst: str):
     """Run the caching algorithm on a trace"""
     import os
     with open(os.path.abspath(__file__), 'r', encoding="utf-8") as f:
         code_str = f.read()
     with open(os.path.join(copy_code_dst), 'w') as f:
         f.write(code_str)
     from cache_utils import Cache, CacheConfig, CacheObj, Trace
     trace = Trace(trace_path=trace_path)
     cache_capacity = max(int(trace.get_ndv() * 0.1), 1)
     cache = Cache(CacheConfig(cache_capacity))
     for entry in trace.entries:
         obj = CacheObj(key=str(entry.key))
         cache.get(obj)
     with open(copy_code_dst, 'w') as f:
         f.write("")
     hit_rate = round(cache.hit_count / cache.access_count, 6)
     return hit_rate