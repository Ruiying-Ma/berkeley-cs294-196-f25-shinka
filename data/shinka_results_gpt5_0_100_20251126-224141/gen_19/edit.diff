--- a/original.py
+++ b/original.py
@@ -1,297 +1,264 @@
 # EVOLVE-BLOCK-START
 """Cache eviction algorithm for optimizing hit rates across multiple workloads"""
 
 from collections import OrderedDict
 from itertools import islice
 
-# LRU timestamp map for fallback/tie-breaking
-m_key_timestamp = dict()
-
-# ARC-style metadata
-arc_T1 = OrderedDict()  # recent, resident
-arc_T2 = OrderedDict()  # frequent, resident
-arc_B1 = OrderedDict()  # ghost of T1
-arc_B2 = OrderedDict()  # ghost of T2
-arc_p = 0               # target size of T1
-arc_capacity = None     # will be initialized from cache_snapshot
-
-# Delayed-promotion state: first-hit time in T1
-t1_pending = dict()     # key -> access_count of first hit
-
-# Control state
-last_ghost_hit_access = -1
-cold_streak = 0
-
-
-def _ensure_capacity(cache_snapshot):
-    global arc_capacity
-    if arc_capacity is None:
-        arc_capacity = max(int(cache_snapshot.capacity), 1)
-
-
-def _move_to_mru(od, key):
-    if key in od:
-        od.pop(key, None)
-    od[key] = True
-
-
-def _pop_lru(od):
-    if od:
-        k, _ = od.popitem(last=False)
-        return k
-    return None
-
-
-def _trim_ghosts():
-    # Keep ghosts total size within 2×capacity; evict from the larger first
-    total = len(arc_B1) + len(arc_B2)
-    cap = arc_capacity if arc_capacity is not None else 1
-    limit = 2 * cap
-    while total > limit:
-        if len(arc_B1) >= len(arc_B2):
-            _pop_lru(arc_B1)
+
+class ARCPlus:
+    # Core ARC state
+    T1 = OrderedDict()   # recent, resident
+    T2 = OrderedDict()   # frequent, resident
+    B1 = OrderedDict()   # ghost of T1 (recent history)
+    B2 = OrderedDict()   # ghost of T2 (frequent history)
+    p = 0                # target size of T1 (in items)
+    capacity = None      # cache capacity (items)
+
+    # Aux state
+    ts = dict()          # key -> last access_count (for LRU tie-breaking/fallback)
+    last_ghost_hit_access = -1  # last access_count when B1/B2 was hit
+    cold_streak = 0               # count of consecutive brand-new inserts (no ghost)
+
+    @classmethod
+    def ensure_capacity(cls, cache_snapshot):
+        if cls.capacity is None:
+            cls.capacity = max(int(cache_snapshot.capacity), 1)
+
+    @classmethod
+    def move_to_mru(cls, od, key):
+        if key in od:
+            od.pop(key, None)
+        od[key] = True
+
+    @classmethod
+    def pop_lru(cls, od):
+        if od:
+            k, _ = od.popitem(last=False)
+            return k
+        return None
+
+    @classmethod
+    def trim_ghosts(cls):
+        # Keep total ghosts ≤ 2×capacity; evict from the larger first
+        total = len(cls.B1) + len(cls.B2)
+        limit = 2 * (cls.capacity if cls.capacity is not None else 1)
+        while total > limit:
+            if len(cls.B1) >= len(cls.B2):
+                cls.pop_lru(cls.B1)
+            else:
+                cls.pop_lru(cls.B2)
+            total = len(cls.B1) + len(cls.B2)
+
+    @classmethod
+    def resync(cls, cache_snapshot):
+        # Ensure resident metadata tracks actual cache content
+        cache_keys = set(cache_snapshot.cache.keys())
+        for k in list(cls.T1.keys()):
+            if k not in cache_keys:
+                cls.T1.pop(k, None)
+        for k in list(cls.T2.keys()):
+            if k not in cache_keys:
+                cls.T2.pop(k, None)
+        # Any cached keys not tracked: assume recent (T1)
+        for k in cache_keys:
+            if k not in cls.T1 and k not in cls.T2:
+                cls.T1[k] = True
+        cls.trim_ghosts()
+
+    @classmethod
+    def decay_p_if_idle(cls, cache_snapshot):
+        # If no ghost hits for a while, gently decay p toward 0 to recover from scans
+        if cls.last_ghost_hit_access >= 0:
+            idle = cache_snapshot.access_count - cls.last_ghost_hit_access
+            if idle > cls.capacity and cls.p > 0:
+                cls.p = max(0, cls.p - 1)
+
+    @classmethod
+    def choose_victim(cls, incoming_key):
+        # ARC replacement preference
+        x_in_B2 = incoming_key in cls.B2
+        t1_sz = len(cls.T1)
+        from_t1 = (t1_sz >= 1 and (t1_sz > cls.p or (x_in_B2 and t1_sz == cls.p)))
+
+        if from_t1 and cls.T1:
+            return next(iter(cls.T1))  # LRU from T1
+        if (not from_t1) and cls.T2:
+            return next(iter(cls.T2))  # LRU from T2
+
+        # If preferred list empty, try the other
+        if cls.T1:
+            return next(iter(cls.T1))
+        if cls.T2:
+            return next(iter(cls.T2))
+        return None
+
+    @classmethod
+    def fallback_victim(cls, cache_snapshot):
+        # Ghost-informed fallback: prefer evicting something present in B1 (recency-only)
+        for k in cache_snapshot.cache.keys():
+            if k in cls.B1:
+                return k
+        # Otherwise, prefer any key not in B2
+        for k in cache_snapshot.cache.keys():
+            if k not in cls.B2:
+                return k
+        # Timestamp tie-breaker
+        if cls.ts:
+            min_ts = min(cls.ts.get(k, float('inf')) for k in cache_snapshot.cache.keys())
+            for k in cache_snapshot.cache.keys():
+                if cls.ts.get(k, float('inf')) == min_ts:
+                    return k
+        # Last resort: arbitrary
+        if cache_snapshot.cache:
+            return next(iter(cache_snapshot.cache.keys()))
+        return None
+
+    @classmethod
+    def on_hit(cls, cache_snapshot, key):
+        # Immediate promotion to T2 (standard ARC)
+        if key in cls.T1:
+            cls.T1.pop(key, None)
+            cls.move_to_mru(cls.T2, key)
+        elif key in cls.T2:
+            cls.move_to_mru(cls.T2, key)
         else:
-            _pop_lru(arc_B2)
-        total = len(arc_B1) + len(arc_B2)
-
-
-def _resync(cache_snapshot):
-    # Ensure resident metadata tracks actual cache content
-    cache_keys = set(cache_snapshot.cache.keys())
-    for k in list(arc_T1.keys()):
-        if k not in cache_keys:
-            arc_T1.pop(k, None)
-            t1_pending.pop(k, None)
-    for k in list(arc_T2.keys()):
-        if k not in cache_keys:
-            arc_T2.pop(k, None)
-    # Add any cached keys we missed to T1 as recent
-    for k in cache_keys:
-        if k not in arc_T1 and k not in arc_T2:
-            arc_T1[k] = True
-    _trim_ghosts()
-
-
-def _decay_p_if_idle(cache_snapshot):
-    # If no ghost hits for a while, slowly decay p toward 0
-    global arc_p
-    if last_ghost_hit_access >= 0:
-        idle = cache_snapshot.access_count - last_ghost_hit_access
-        if idle > arc_capacity and arc_p > 0:
-            arc_p = max(0, arc_p - 1)
-
-
-def _pick_lru_non_pending_from_t1():
-    # Prefer evicting a non-pending key from T1 if possible (scan up to a few)
-    if not arc_T1:
-        return None
-    limit = min(8, len(arc_T1))  # small scan budget
-    keys = list(islice(arc_T1.keys(), 0, limit))
-    for k in keys:
-        if k not in t1_pending:
-            return k
-    # If all scanned are pending, fall back to true LRU
-    return next(iter(arc_T1))
+            # Drift: still a hit; place in T2 to reflect reuse
+            cls.move_to_mru(cls.T2, key)
+        # Update timestamp
+        cls.ts[key] = cache_snapshot.access_count
+
+    @classmethod
+    def on_insert(cls, cache_snapshot, key):
+        # Adjust ARC target p using ghost hints (damped), then admit
+        step_cap = max(1, cls.capacity // 8)  # cap adjustment magnitude
+        if key in cls.B1:
+            # Favor recency: increase p
+            inc = max(1, len(cls.B2) // max(1, len(cls.B1)))
+            cls.p = min(cls.capacity, cls.p + min(inc, step_cap))
+            cls.last_ghost_hit_access = cache_snapshot.access_count
+            cls.cold_streak = 0
+            cls.B1.pop(key, None)
+            # On return, insert to T2 (has shown reuse)
+            cls.move_to_mru(cls.T2, key)
+        elif key in cls.B2:
+            # Favor frequency: decrease p
+            dec = max(1, len(cls.B1) // max(1, len(cls.B2)))
+            cls.p = max(0, cls.p - min(dec, step_cap))
+            cls.last_ghost_hit_access = cache_snapshot.access_count
+            cls.cold_streak = 0
+            cls.B2.pop(key, None)
+            cls.move_to_mru(cls.T2, key)
+        else:
+            # Brand-new: insert into T1 (probationary)
+            cls.move_to_mru(cls.T1, key)
+            cls.cold_streak += 1
+            # Scan clamp: prolonged cold stream -> push p down
+            if cls.cold_streak > cls.capacity:
+                cls.p = max(0, cls.p - max(1, cls.capacity // 4))
+
+        cls.ts[key] = cache_snapshot.access_count
+        cls.trim_ghosts()
+        # Light consistency guard
+        if (len(cls.T1) + len(cls.T2)) != len(cache_snapshot.cache):
+            cls.resync(cache_snapshot)
+
+    @classmethod
+    def on_evict(cls, cache_snapshot, evicted_key):
+        # Move evicted resident to corresponding ghost list
+        if evicted_key in cls.T1:
+            cls.T1.pop(evicted_key, None)
+            cls.move_to_mru(cls.B1, evicted_key)
+        elif evicted_key in cls.T2:
+            cls.T2.pop(evicted_key, None)
+            cls.move_to_mru(cls.B2, evicted_key)
+        else:
+            # Unknown membership: default to B1
+            cls.move_to_mru(cls.B1, evicted_key)
+        cls.ts.pop(evicted_key, None)
+        cls.trim_ghosts()
 
 
 def evict(cache_snapshot, obj):
     '''
     This function defines how the algorithm chooses the eviction victim.
     - Args:
         - `cache_snapshot`: A snapshot of the current cache state.
         - `obj`: The new object that needs to be inserted into the cache.
     - Return:
         - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
     '''
-    _ensure_capacity(cache_snapshot)
-    # Keep metadata consistent
-    if (len(arc_T1) + len(arc_T2)) != len(cache_snapshot.cache):
-        _resync(cache_snapshot)
-    _decay_p_if_idle(cache_snapshot)
-
-    # ARC replacement preference
-    x_in_B2 = obj.key in arc_B2
-    t1_sz = len(arc_T1)
-    from_t1 = (t1_sz >= 1 and (t1_sz > arc_p or (x_in_B2 and t1_sz == arc_p)))
-
-    if from_t1 and arc_T1:
-        candidate = _pick_lru_non_pending_from_t1()
-        if candidate is not None:
-            return candidate
-    if (not from_t1) and arc_T2:
-        return next(iter(arc_T2))  # LRU from T2
-
-    # If preferred list empty, try the other
-    if arc_T1:
-        cand = _pick_lru_non_pending_from_t1()
-        if cand is not None:
-            return cand
-    if arc_T2:
-        return next(iter(arc_T2))
-
-    # Fallback: metadata drift; choose based on ghost hints, then timestamp
-    candidate = None
-    # Prefer evicting a key present in B1 (recency-only) over B2 (likely frequent)
-    for k in cache_snapshot.cache.keys():
-        if k in arc_B1:
-            candidate = k
-            break
-    if candidate is None:
-        # Next prefer a key not in B2
-        for k in cache_snapshot.cache.keys():
-            if k not in arc_B2:
-                candidate = k
-                break
-    if candidate is None and m_key_timestamp:
-        min_ts = min(m_key_timestamp.get(k, float('inf')) for k in cache_snapshot.cache.keys())
-        for k in cache_snapshot.cache.keys():
-            if m_key_timestamp.get(k, float('inf')) == min_ts:
-                candidate = k
-                break
-    if candidate is None and cache_snapshot.cache:
-        candidate = next(iter(cache_snapshot.cache.keys()))
-    return candidate
+    ARCPlus.ensure_capacity(cache_snapshot)
+    # Keep metadata consistent and apply p-decay
+    if (len(ARCPlus.T1) + len(ARCPlus.T2)) != len(cache_snapshot.cache):
+        ARCPlus.resync(cache_snapshot)
+    ARCPlus.decay_p_if_idle(cache_snapshot)
+
+    candidate = ARCPlus.choose_victim(obj.key)
+    if candidate is not None:
+        return candidate
+    # Fallback path
+    return ARCPlus.fallback_victim(cache_snapshot)
 
 
 def update_after_hit(cache_snapshot, obj):
     '''
     This function defines how the algorithm update the metadata it maintains immediately after a cache hit.
     - Args:
         - `cache_snapshot`: A snapshot of the current cache state.
         - `obj`: The object accessed during the cache hit.
     - Return: `None`
     '''
-    global m_key_timestamp
-    _ensure_capacity(cache_snapshot)
-    _decay_p_if_idle(cache_snapshot)
-
-    key = obj.key
-    W = max(1, arc_capacity // 4)  # promotion window
-
-    if key in arc_T2:
-        # Frequent: refresh MRU
-        _move_to_mru(arc_T2, key)
-    elif key in arc_T1:
-        # Delayed promotion: first hit marks pending, second hit within W promotes
-        first = t1_pending.get(key)
-        if first is None:
-            # First hit: keep in T1, mark pending, refresh MRU
-            t1_pending[key] = cache_snapshot.access_count
-            _move_to_mru(arc_T1, key)
-        else:
-            if cache_snapshot.access_count - first <= W:
-                # Second hit within window: promote to T2
-                arc_T1.pop(key, None)
-                t1_pending.pop(key, None)
-                _move_to_mru(arc_T2, key)
-            else:
-                # Window expired: treat as new first-hit
-                t1_pending[key] = cache_snapshot.access_count
-                _move_to_mru(arc_T1, key)
-    else:
-        # Drift: place into T2 (it's a hit in cache anyway)
-        _move_to_mru(arc_T2, key)
-        t1_pending.pop(key, None)
-
-    # Update timestamp and consistency guard
-    m_key_timestamp[key] = cache_snapshot.access_count
-    if (len(arc_T1) + len(arc_T2)) != len(cache_snapshot.cache):
-        _resync(cache_snapshot)
+    ARCPlus.ensure_capacity(cache_snapshot)
+    ARCPlus.decay_p_if_idle(cache_snapshot)
+    ARCPlus.on_hit(cache_snapshot, obj.key)
+    # Post-condition consistency (rare)
+    if (len(ARCPlus.T1) + len(ARCPlus.T2)) != len(cache_snapshot.cache):
+        ARCPlus.resync(cache_snapshot)
 
 
 def update_after_insert(cache_snapshot, obj):
     '''
     This function defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
     - Args:
         - `cache_snapshot`: A snapshot of the current cache state.
         - `obj`: The object that was just inserted into the cache.
     - Return: `None`
     '''
-    global m_key_timestamp, arc_p, last_ghost_hit_access, cold_streak
-    _ensure_capacity(cache_snapshot)
-    _decay_p_if_idle(cache_snapshot)
-
-    key = obj.key
-    step_cap = max(1, arc_capacity // 8)
-
-    if key in arc_B1:
-        # Ghost hit in B1: increase p (favor recency), damped
-        inc = max(1, len(arc_B2) // max(1, len(arc_B1)))
-        arc_p = min(arc_capacity, arc_p + min(inc, step_cap))
-        last_ghost_hit_access = cache_snapshot.access_count
-        cold_streak = 0
-        arc_B1.pop(key, None)
-        _move_to_mru(arc_T2, key)  # admit to frequent on return
-    elif key in arc_B2:
-        # Ghost hit in B2: decrease p (favor frequency), damped
-        dec = max(1, len(arc_B1) // max(1, len(arc_B2)))
-        arc_p = max(0, arc_p - min(dec, step_cap))
-        last_ghost_hit_access = cache_snapshot.access_count
-        cold_streak = 0
-        arc_B2.pop(key, None)
-        _move_to_mru(arc_T2, key)
-    else:
-        # Brand-new miss: insert into T1
-        _move_to_mru(arc_T1, key)
-        cold_streak += 1
-        # Scan clamp: prolonged cold stream -> push p down quickly
-        if cold_streak > arc_capacity:
-            arc_p = max(0, arc_p - max(1, arc_capacity // 4))
-
-    # Timestamp and consistency
-    m_key_timestamp[key] = cache_snapshot.access_count
-    _trim_ghosts()
-    if (len(arc_T1) + len(arc_T2)) != len(cache_snapshot.cache):
-        _resync(cache_snapshot)
+    ARCPlus.ensure_capacity(cache_snapshot)
+    ARCPlus.decay_p_if_idle(cache_snapshot)
+    ARCPlus.on_insert(cache_snapshot, obj.key)
 
 
 def update_after_evict(cache_snapshot, obj, evicted_obj):
     '''
     This function defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
     - Args:
         - `cache_snapshot`: A snapshot of the current cache state.
         - `obj`: The object to be inserted into the cache.
         - `evicted_obj`: The object that was just evicted from the cache.
     - Return: `None`
     '''
-    global m_key_timestamp
-    _ensure_capacity(cache_snapshot)
-    k = evicted_obj.key
-    # Move evicted resident to corresponding ghost list
-    if k in arc_T1:
-        arc_T1.pop(k, None)
-        t1_pending.pop(k, None)
-        _move_to_mru(arc_B1, k)
-    elif k in arc_T2:
-        arc_T2.pop(k, None)
-        _move_to_mru(arc_B2, k)
-    else:
-        # Unknown membership: default to B1
-        _move_to_mru(arc_B1, k)
-        t1_pending.pop(k, None)
-    # Remove timestamp entry for evicted item to avoid growth
-    m_key_timestamp.pop(k, None)
-    _trim_ghosts()
-    # Reset cold streak on eviction of keys that had ghost hints? conservative: no-op here.
+    ARCPlus.ensure_capacity(cache_snapshot)
+    ARCPlus.on_evict(cache_snapshot, evicted_obj.key)
 
 # EVOLVE-BLOCK-END
 
 # This part remains fixed (not evolved)
 def run_caching(trace_path: str, copy_code_dst: str):
     """Run the caching algorithm on a trace"""
     import os
     with open(os.path.abspath(__file__), 'r', encoding="utf-8") as f:
         code_str = f.read()
     with open(os.path.join(copy_code_dst), 'w') as f:
         f.write(code_str)
     from cache_utils import Cache, CacheConfig, CacheObj, Trace
     trace = Trace(trace_path=trace_path)
     cache_capacity = max(int(trace.get_ndv() * 0.1), 1)
     cache = Cache(CacheConfig(cache_capacity))
     for entry in trace.entries:
         obj = CacheObj(key=str(entry.key))
         cache.get(obj)
     with open(copy_code_dst, 'w') as f:
         f.write("")
     hit_rate = round(cache.hit_count / cache.access_count, 6)
     return hit_rate