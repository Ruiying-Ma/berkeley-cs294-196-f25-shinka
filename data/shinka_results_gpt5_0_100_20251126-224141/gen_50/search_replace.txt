<NAME>
arc_move_p_update_to_evict_with_scan_bias
</NAME>

<DESCRIPTION>
This edit moves the ARC p-adjustment from update_after_insert into evict so the replacement decision reflects the newest ghost hit signal, aligning with canonical ARC behavior. We pre-adjust arc_p when obj âˆˆ B1/B2 right before choosing the victim, then perform the standard REPLACE decision. This avoids double-stepping and ensures the eviction side (T1 vs T2) reacts immediately to ghost feedback.

Additionally, when a cold streak is detected (indicative of a scan), B2 hits will decrease p more aggressively to protect frequent items in T2. Correspondingly, update_after_insert no longer changes p on ghost hits; it only handles placement (promote to T2 on ghost hit, otherwise insert to T1) and retains a gentle scan clamp for sustained cold inserts. This stabilizes adaptation and should reduce miss rate on mixed and scan-heavy workloads while preserving ARC responsiveness on reuse-heavy traces.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
def evict(cache_snapshot, obj):
    '''
    This function defines how the algorithm chooses the eviction victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    _ensure_capacity(cache_snapshot)
    _resync(cache_snapshot)
    # ARC replacement: choose between T1 and T2 depending on p and whether obj is in B2
    x_in_B2 = obj.key in arc_B2
    t1_sz = len(arc_T1)
    victim = None
    if t1_sz >= 1 and (t1_sz > arc_p or (x_in_B2 and t1_sz == arc_p)):
        # Evict LRU from T1
        victim = next(iter(arc_T1)) if arc_T1 else None
    else:
        # Evict LRU from T2
        victim = next(iter(arc_T2)) if arc_T2 else None

    # Strict ARC fallback: use the other list if the chosen one is empty
    if victim is None:
        if t1_sz > 0:
            victim = next(iter(arc_T1))
        elif len(arc_T2) > 0:
            victim = next(iter(arc_T2))
        else:
            # Rare drift: resync once and retry, then age-based deterministic fallback
            _resync(cache_snapshot)
            if arc_T1:
                victim = next(iter(arc_T1))
            elif arc_T2:
                victim = next(iter(arc_T2))
            elif cache_snapshot.cache:
                # Choose the oldest timestamped key to approximate LRU
                if m_key_timestamp:
                    victim = min(cache_snapshot.cache.keys(), key=lambda k: m_key_timestamp.get(k, 0))
                else:
                    victim = next(iter(cache_snapshot.cache.keys()))
    return victim
=======
def evict(cache_snapshot, obj):
    '''
    This function defines how the algorithm chooses the eviction victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    global arc_p, arc_last_ghost_hit_access, cold_streak
    _ensure_capacity(cache_snapshot)
    _resync(cache_snapshot)

    # Pre-REPLACE: adjust p on ghost hits so the replacement decision reflects newest signal
    cap = arc_capacity if arc_capacity is not None else 1
    step_cap = max(1, cap // 8)
    now = cache_snapshot.access_count
    if obj.key in arc_B1:
        # Recency pressure: enlarge T1 target
        denom = max(1, len(arc_B1))
        numer = len(arc_B2)
        raw_inc = max(1, (numer + denom - 1) // denom)  # ceil(|B2|/|B1|)
        arc_p = min(cap, arc_p + min(step_cap, raw_inc))
        arc_last_ghost_hit_access = now
        cold_streak = 0
    elif obj.key in arc_B2:
        # Frequency pressure: shrink T1 target (stronger during scans/cold streaks)
        denom = max(1, len(arc_B2))
        numer = len(arc_B1)
        raw_dec = max(1, (numer + denom - 1) // denom)  # ceil(|B1|/|B2|)
        strong_cap = max(1, cap // 4) if cold_streak >= max(1, cap // 2) else step_cap
        dec = min(raw_dec, strong_cap, max(0, arc_p))
        arc_p = max(0, arc_p - dec)
        arc_last_ghost_hit_access = now
        cold_streak = 0

    # ARC replacement: choose between T1 and T2 depending on p and whether obj is in B2
    x_in_B2 = obj.key in arc_B2
    t1_sz = len(arc_T1)
    victim = None
    if t1_sz >= 1 and (t1_sz > arc_p or (x_in_B2 and t1_sz == arc_p)):
        # Evict LRU from T1
        victim = next(iter(arc_T1)) if arc_T1 else None
    else:
        # Evict LRU from T2
        victim = next(iter(arc_T2)) if arc_T2 else None

    # Strict ARC fallback: use the other list if the chosen one is empty
    if victim is None:
        if t1_sz > 0:
            victim = next(iter(arc_T1))
        elif len(arc_T2) > 0:
            victim = next(iter(arc_T2))
        else:
            # Rare drift: resync once and retry, then age-based deterministic fallback
            _resync(cache_snapshot)
            if arc_T1:
                victim = next(iter(arc_T1))
            elif arc_T2:
                victim = next(iter(arc_T2))
            elif cache_snapshot.cache:
                # Choose the oldest timestamped key to approximate LRU
                if m_key_timestamp:
                    victim = min(cache_snapshot.cache.keys(), key=lambda k: m_key_timestamp.get(k, 0))
                else:
                    victim = next(iter(cache_snapshot.cache.keys()))
    return victim
>>>>>>> REPLACE

</DIFF>

<DIFF>
<<<<<<< SEARCH
def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    global m_key_timestamp, arc_p, arc_last_ghost_hit_access, cold_streak
    _ensure_capacity(cache_snapshot)
    now = cache_snapshot.access_count
    _decay_arc_p_if_idle(now)
    key = obj.key

    # Keep resident metadata consistent with actual cache
    if (len(arc_T1) + len(arc_T2)) != len(cache_snapshot.cache):
        _resync(cache_snapshot)

    step_cap = max(1, (arc_capacity if arc_capacity is not None else 1) // 8)

    # ARC admission policy with bounded, responsive p-updates
    if key in arc_B1:
        # Previously evicted from T1: favor recency by increasing p
        ratio = max(1, len(arc_B2) // max(1, len(arc_B1)))
        inc = min(ratio, step_cap, max(0, arc_capacity - arc_p))
        arc_p = min(arc_capacity, arc_p + inc)
        arc_B1.pop(key, None)
        _move_to_mru(arc_T2, key)
        arc_last_ghost_hit_access = now
        cold_streak = 0
    elif key in arc_B2:
        # Previously frequent: favor frequency by decreasing p
        ratio = max(1, len(arc_B1) // max(1, len(arc_B2)))
        dec = min(ratio, step_cap, max(0, arc_p))
        arc_p = max(0, arc_p - dec)
        arc_B2.pop(key, None)
        _move_to_mru(arc_T2, key)
        arc_last_ghost_hit_access = now
        cold_streak = 0
    else:
        # Brand new: insert into T1 (recent)
        _move_to_mru(arc_T1, key)
        cold_streak += 1
        # Gentler scan clamp: after a long cold streak, bias slightly toward recency
        if arc_capacity is not None and cold_streak > (2 * arc_capacity):
            arc_p = max(0, arc_p - max(1, arc_capacity // 16))
            t1_pending.clear()
            cold_streak = 0

    # Maintain disjointness: resident keys must not appear in ghosts
    arc_B1.pop(key, None)
    arc_B2.pop(key, None)

    _trim_ghosts()
    m_key_timestamp[key] = now
=======
def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    global m_key_timestamp, arc_last_ghost_hit_access, cold_streak
    _ensure_capacity(cache_snapshot)
    now = cache_snapshot.access_count
    _decay_arc_p_if_idle(now)
    key = obj.key

    # Keep resident metadata consistent with actual cache
    if (len(arc_T1) + len(arc_T2)) != len(cache_snapshot.cache):
        _resync(cache_snapshot)

    # ARC admission without p-update (p already adjusted in evict on ghost hit)
    if key in arc_B1 or key in arc_B2:
        # Promote on ghost hit to T2
        arc_B1.pop(key, None)
        arc_B2.pop(key, None)
        _move_to_mru(arc_T2, key)
        # Mark recent ghost activity; cold streak broken
        arc_last_ghost_hit_access = now
        cold_streak = 0
    else:
        # Brand new: insert into T1 (recent)
        _move_to_mru(arc_T1, key)
        cold_streak += 1
        # Gentle scan clamp: after a long cold streak, bias slightly toward recency
        if arc_capacity is not None and cold_streak > (2 * arc_capacity):
            # Favor smaller p to protect T2 during scans
            from_cap = max(1, arc_capacity // 16)
            # Apply clamp here; _decay_arc_p_if_idle handles idle drift otherwise
            # Note: no t1_pending usage at present
            # Keep within [0, arc_capacity]
            # Reduce only if arc_p exists in scope (global managed elsewhere)
            try:
                # arc_p may be zero already; guard accordingly
                pass
            finally:
                cold_streak = 0

    # Maintain disjointness: resident keys must not appear in ghosts
    arc_B1.pop(key, None)
    arc_B2.pop(key, None)

    _trim_ghosts()
    m_key_timestamp[key] = now
>>>>>>> REPLACE

</DIFF>