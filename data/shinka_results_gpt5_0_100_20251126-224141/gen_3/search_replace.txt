<NAME>
segmented_lru_2q_promotion
</NAME>

<DESCRIPTION>
I replaced the pure LRU policy with a segmented LRU (2Q-style) algorithm to better handle mixed workloads and scans. In the original code, eviction always selected the globally oldest entry (LRU) using timestamps. This performs poorly on scan-heavy traces because one-time accesses flush out reusable items, leading to very low hit rates (many near-zero traces in the report).

The improved approach maintains two segments:
- A1 (probation): newly inserted objects (seen once).
- Am (protected): objects promoted upon their first hit (seen at least twice).

Eviction prefers removing older items from A1, thus shielding frequently reused items in Am from scans. We also include a simple split target (~25% of current cache size) to keep A1 from growing too large; if A1 exceeds its target, we evict from A1; otherwise, we evict from Am. Within a segment, we still use LRU (via last-access timestamp), and as a secondary tiebreaker we evict the lowest-frequency among the oldest to be robust when timestamps tie.

Metadata updates:
- On insert: place item in A1 with initial timestamp and frequency.
- On hit: increment frequency, update timestamp; if in A1, promote to Am.
- On evict: remove all metadata of the evicted key.

This segmented design reduces cache pollution from one-hit wonders and preserves valuable items, which should increase hit rates across a broader range of workloads compared to pure LRU, especially on traces exhibiting scans or bursty reuse.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
"""Cache eviction algorithm for optimizing hit rates across multiple workloads"""

m_key_timestamp = dict()

def evict(cache_snapshot, obj):
    '''
    This function defines how the algorithm chooses the eviction victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    candid_obj_key = None
    min_ts = min(m_key_timestamp.values())
    candid_obj_keys = list(key for key in cache_snapshot.cache if m_key_timestamp[key] == min_ts)
    candid_obj_key = candid_obj_keys[0]
    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the algorithm update the metadata it maintains immediately after a cache hit.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    global m_key_timestamp
    assert obj.key in m_key_timestamp
    m_key_timestamp[obj.key] = cache_snapshot.access_count

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    global m_key_timestamp
    assert obj.key not in m_key_timestamp
    m_key_timestamp[obj.key] = cache_snapshot.access_count

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    global m_key_timestamp
    assert obj.key not in m_key_timestamp
    assert evicted_obj.key in m_key_timestamp
    m_key_timestamp.pop(evicted_obj.key)
=======
"""Cache eviction algorithm for optimizing hit rates across multiple workloads"""

# Segmented LRU (2Q-style) metadata:
# - m_key_timestamp: last access time for LRU within segments
# - m_tier: 'A1' (probation; seen once) or 'Am' (protected; seen >=2 times)
# - m_freq: hit count (used for tie-breaking on eviction)
m_key_timestamp = dict()
m_tier = dict()
m_freq = dict()

def evict(cache_snapshot, obj):
    '''
    This function defines how the algorithm chooses the eviction victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    global m_key_timestamp, m_tier, m_freq
    keys = list(cache_snapshot.cache.keys())
    if not keys:
        return None

    # Segment the current cache keys
    a1_keys = [k for k in keys if m_tier.get(k, 'A1') == 'A1']
    am_keys = [k for k in keys if m_tier.get(k) == 'Am']

    total = len(keys)
    target_a1 = max(1, total // 4)  # keep ~25% in probation

    # Decide which segment to evict from
    if not a1_keys and not am_keys:
        pick_from = keys
    elif not a1_keys:
        pick_from = am_keys
    elif not am_keys:
        pick_from = a1_keys
    elif len(a1_keys) > target_a1:
        pick_from = a1_keys
    else:
        # Prefer evicting from A1 to protect reusable items;
        # if A1 is small, evict from Am.
        pick_from = a1_keys if a1_keys else am_keys

    # Choose LRU within the chosen segment; tie-break by lowest frequency
    def ts(k): return m_key_timestamp.get(k, -1)
    if not pick_from:
        pick_from = keys
    min_ts = min(ts(k) for k in pick_from)
    ts_candidates = [k for k in pick_from if ts(k) == min_ts]
    if len(ts_candidates) > 1:
        min_f = min(m_freq.get(k, 1) for k in ts_candidates)
        freq_candidates = [k for k in ts_candidates if m_freq.get(k, 1) == min_f]
        candid_obj_key = freq_candidates[0]
    else:
        candid_obj_key = ts_candidates[0]
    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the algorithm update the metadata it maintains immediately after a cache hit.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    global m_key_timestamp, m_tier, m_freq
    # Update recency and frequency
    m_key_timestamp[obj.key] = cache_snapshot.access_count
    m_freq[obj.key] = m_freq.get(obj.key, 0) + 1

    # Promote to protected segment on first hit (or if metadata missing)
    if m_tier.get(obj.key) != 'Am':
        m_tier[obj.key] = 'Am'

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    global m_key_timestamp, m_tier, m_freq
    # New items start in probation (A1)
    m_key_timestamp[obj.key] = cache_snapshot.access_count
    m_tier[obj.key] = 'A1'
    # Initialize frequency to 1 on insertion
    m_freq[obj.key] = m_freq.get(obj.key, 0) + 1 if obj.key in m_freq else 1

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    global m_key_timestamp, m_tier, m_freq
    # Clean up all metadata for the evicted key
    m_key_timestamp.pop(evicted_obj.key, None)
    m_tier.pop(evicted_obj.key, None)
    m_freq.pop(evicted_obj.key, None)
>>>>>>> REPLACE

</DIFF>