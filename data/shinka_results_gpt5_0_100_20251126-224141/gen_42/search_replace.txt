<NAME>
arc_two_hit_promotion_and_scan_demote
</NAME>

<DESCRIPTION>
I introduce three coordinated improvements inspired by ARC and scan-resilient caching:

1) Two-hit promotion from T1 to T2 to reduce over-protection of transient items. Instead of immediately promoting on the first hit in T1, we require two hits within a short window (≈ C/2 accesses). This dampens premature promotion during scans and bursty noise, while still moving genuinely reused items to T2 quickly.

2) Scan-aware temporary demotion: during sustained cold streaks (≥ C/2 cold misses), we demote a small number of the weakest T2 items back to T1 (up to min(2, C//16)). This shifts eviction pressure toward T1 under scans, protecting truly frequent items that remain in T2 and improving robustness across mixed workloads.

3) Tighten the ARC REPLACE condition and add a scan bias in eviction. We align the REPLACE condition with ARC by evicting from T1 when |T1| > p or (key ∈ B2 and |T1| == p), and we force T1 eviction during sustained cold streaks to reduce damage to T2 under scans.

These changes keep the ghost-driven adaptation and hybrid LFU-LRU victim selection, while addressing identified weaknesses on streaming and scan-heavy traces. The frequency sketch is kept but made more effective through differential hit weighting and controlled promotions.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
def evict(cache_snapshot, obj):
    '''
    This function defines how the algorithm chooses the eviction victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    _ensure_init(cache_snapshot)
    t1_keys, t2_keys = _resident_sets(cache_snapshot)

    # Keep ghosts disjoint from current residents to ensure consistent ARC signals
    for k in cache_snapshot.cache.keys():
        m_ghost_b1_ts.pop(k, None)
        m_ghost_b2_ts.pop(k, None)

    # Strict ARC REPLACE decision with hybrid LFU-LRU victim choice within a segment:
    cap = _cap(cache_snapshot)
    p = min(max(0, m_target_p), cap)
    t1_len = len(t1_keys)
    now = cache_snapshot.access_count

    evict_from_t1 = (t1_len > p) or (obj.key in m_ghost_b2_ts and t1_len >= max(1, p))

    if evict_from_t1:
        victim = _choose_victim(t1_keys, now)
        if victim is not None:
            return victim
        # If T1 is empty, fall back to T2 with hybrid choice
        victim = _choose_victim(t2_keys, now)
        if victim is not None:
            return victim
    else:
        victim = _choose_victim(t2_keys, now)
        if victim is not None:
            return victim
        # If T2 is empty, fall back to T1
        victim = _choose_victim(t1_keys, now)
        if victim is not None:
            return victim

    # Last resort: global lowest-frequency then oldest
    all_keys = list(cache_snapshot.cache.keys())
    if not all_keys:
        return None
    return _choose_victim(all_keys, now)
=======
def evict(cache_snapshot, obj):
    '''
    This function defines how the algorithm chooses the eviction victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    _ensure_init(cache_snapshot)
    t1_keys, t2_keys = _resident_sets(cache_snapshot)

    # Keep ghosts disjoint from current residents to ensure consistent ARC signals
    for k in cache_snapshot.cache.keys():
        m_ghost_b1_ts.pop(k, None)
        m_ghost_b2_ts.pop(k, None)

    # ARC REPLACE decision with scan-aware bias and hybrid LFU-LRU within a segment
    cap = _cap(cache_snapshot)
    p = min(max(0, m_target_p), cap)
    t1_len = len(t1_keys)
    now = cache_snapshot.access_count

    # Force T1 eviction under sustained cold streaks to protect T2 during scans
    force_t1 = m_cold_streak >= max(1, cap // 2)

    # ARC: evict from T1 if |T1| > p or (key in B2 and |T1| == p)
    evict_from_t1 = False
    if t1_len >= 1:
        if (t1_len > p) or (obj.key in m_ghost_b2_ts and t1_len == p):
            evict_from_t1 = True

    if force_t1:
        evict_from_t1 = True

    if evict_from_t1:
        victim = _choose_victim(t1_keys, now)
        if victim is not None:
            return victim
        # If T1 is empty, fall back to T2 with hybrid choice
        victim = _choose_victim(t2_keys, now)
        if victim is not None:
            return victim
    else:
        victim = _choose_victim(t2_keys, now)
        if victim is not None:
            return victim
        # If T2 is empty, fall back to T1
        victim = _choose_victim(t1_keys, now)
        if victim is not None:
            return victim

    # Last resort: global lowest-frequency then oldest
    all_keys = list(cache_snapshot.cache.keys())
    if not all_keys:
        return None
    return _choose_victim(all_keys, now)
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the algorithm update the metadata it maintains immediately after a cache hit.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    global m_key_timestamp, m_key_segment, m_t1_pending_hits, m_cold_streak, m_target_p, m_last_ghost_hit_access, m_freq, m_next_decay_access
    _ensure_init(cache_snapshot)

    # Periodic decay to keep frequency sketch recent
    _maybe_decay_freq(cache_snapshot)

    # Refresh recency
    m_key_timestamp[obj.key] = cache_snapshot.access_count

    # Reset cold streak on any hit and bump frequency
    m_cold_streak = 0
    _bump_freq(obj.key, 1)

    # Slow decay of p if no ghost hits for a while (scan recovery)
    cap = _cap(cache_snapshot)
    if cache_snapshot.access_count - m_last_ghost_hit_access > cap:
        m_target_p = max(0, m_target_p - 1)

    # ARC-style immediate promotion: on a hit in T1, move to T2
    seg = m_key_segment.get(obj.key, 't1')
    if seg != 't2':
        m_key_segment[obj.key] = 't2'
    # Clear any pending two-hit state (no longer used)
    m_t1_pending_hits.pop(obj.key, None)

    # Ensure ghosts remain disjoint from residents
    m_ghost_b1_ts.pop(obj.key, None)
    m_ghost_b2_ts.pop(obj.key, None)
=======
def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the algorithm update the metadata it maintains immediately after a cache hit.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    global m_key_timestamp, m_key_segment, m_t1_pending_hits, m_cold_streak, m_target_p, m_last_ghost_hit_access, m_freq, m_next_decay_access
    _ensure_init(cache_snapshot)

    # Periodic decay to keep frequency sketch recent
    _maybe_decay_freq(cache_snapshot)

    # Refresh recency
    now = cache_snapshot.access_count
    m_key_timestamp[obj.key] = now

    # Reset cold streak on any hit and bump frequency (heavier for T2)
    seg = m_key_segment.get(obj.key, 't1')
    m_cold_streak = 0
    _bump_freq(obj.key, 2 if seg == 't2' else 1)

    # Slow decay of p if no ghost hits for a while (scan recovery)
    cap = _cap(cache_snapshot)
    if now - m_last_ghost_hit_access > cap:
        m_target_p = max(0, m_target_p - 1)

    # Two-hit promotion policy for T1 to reduce over-protection:
    # - First hit in T1 sets a pending marker
    # - Second hit within a short window promotes to T2
    if seg != 't2':
        last = m_t1_pending_hits.get(obj.key)
        window = max(1, cap // 2)
        if last is None:
            m_t1_pending_hits[obj.key] = now
        else:
            if now - last <= window:
                m_key_segment[obj.key] = 't2'
                m_t1_pending_hits.pop(obj.key, None)
            else:
                # Reset the window if too old
                m_t1_pending_hits[obj.key] = now
    else:
        # Already in T2; clear any stale pending state
        m_t1_pending_hits.pop(obj.key, None)

    # Ensure ghosts remain disjoint from residents
    m_ghost_b1_ts.pop(obj.key, None)
    m_ghost_b2_ts.pop(obj.key, None)
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    global m_key_timestamp, m_key_segment, m_target_p, m_last_ghost_hit_access, m_cold_streak, m_t1_pending_hits, m_freq, m_next_decay_access
    _ensure_init(cache_snapshot)

    # Periodic decay to keep frequency sketch recent
    _maybe_decay_freq(cache_snapshot)

    cap = _cap(cache_snapshot)
    in_b1 = obj.key in m_ghost_b1_ts
    in_b2 = obj.key in m_ghost_b2_ts

    # Adaptive step caps with asymmetric responsiveness (scan-aware)
    inc_cap = max(1, cap // 8)
    dec_cap = max(1, (cap // 4) if m_cold_streak >= max(1, cap // 2) else (cap // 8))

    seg = 't1'
    if in_b1:
        # Increase p (give more room to recency), with ceiling ratio and cap
        denom = max(1, len(m_ghost_b1_ts))
        numer = len(m_ghost_b2_ts)
        raw_inc = max(1, (numer + denom - 1) // denom)  # ceil(|B2|/|B1|)
        inc = min(inc_cap, raw_inc)
        m_target_p = min(cap, m_target_p + inc)
        # Ghost bookkeeping
        m_ghost_b1_ts.pop(obj.key, None)
        m_ghost_b2_ts.pop(obj.key, None)
        # Promote on ghost hit
        seg = 't2'
        m_last_ghost_hit_access = cache_snapshot.access_count
        m_cold_streak = 0
        _bump_freq(obj.key, 2)
    elif in_b2:
        # Decrease p (favor frequency), with ceiling ratio and stronger cap during cold streaks
        denom = max(1, len(m_ghost_b2_ts))
        numer = len(m_ghost_b1_ts)
        raw_dec = max(1, (numer + denom - 1) // denom)  # ceil(|B1|/|B2|)
        dec = min(dec_cap, raw_dec)
        m_target_p = max(0, m_target_p - dec)
        # Ghost bookkeeping
        m_ghost_b2_ts.pop(obj.key, None)
        m_ghost_b1_ts.pop(obj.key, None)
        # Promote on ghost hit
        seg = 't2'
        m_last_ghost_hit_access = cache_snapshot.access_count
        m_cold_streak = 0
        _bump_freq(obj.key, 3)
    else:
        # Cold miss - track streak and apply gentle scan clamp to reduce T1 pressure
        m_cold_streak += 1
        # Gradual clamp during sustained cold streaks
        if m_cold_streak % max(1, cap // 2) == 0:
            m_target_p = max(0, m_target_p - max(1, cap // 16))
        if m_cold_streak >= cap:
            m_target_p = max(0, m_target_p - max(1, cap // 8))
            m_cold_streak = 0
        # Ensure no stale ghost entries remain for this resident
        m_ghost_b1_ts.pop(obj.key, None)
        m_ghost_b2_ts.pop(obj.key, None)
        _bump_freq(obj.key, 1)

    # Insert into resident set
    m_key_segment[obj.key] = seg
    m_key_timestamp[obj.key] = cache_snapshot.access_count
    # Clear any stale pending state for this key
    m_t1_pending_hits.pop(obj.key, None)

    # Control ghost size (expanded history)
    _prune_ghosts(cache_snapshot)
=======
def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    global m_key_timestamp, m_key_segment, m_target_p, m_last_ghost_hit_access, m_cold_streak, m_t1_pending_hits, m_freq, m_next_decay_access
    _ensure_init(cache_snapshot)

    # Periodic decay to keep frequency sketch recent
    _maybe_decay_freq(cache_snapshot)

    cap = _cap(cache_snapshot)
    in_b1 = obj.key in m_ghost_b1_ts
    in_b2 = obj.key in m_ghost_b2_ts

    # Adaptive step caps with asymmetric responsiveness (scan-aware)
    inc_cap = max(1, cap // 8)
    dec_cap = max(1, (cap // 4) if m_cold_streak >= max(1, cap // 2) else (cap // 8))

    seg = 't1'
    if in_b1:
        # Increase p (give more room to recency), with ceiling ratio and cap
        denom = max(1, len(m_ghost_b1_ts))
        numer = len(m_ghost_b2_ts)
        raw_inc = max(1, (numer + denom - 1) // denom)  # ceil(|B2|/|B1|)
        inc = min(inc_cap, raw_inc)
        m_target_p = min(cap, m_target_p + inc)
        # Ghost bookkeeping
        m_ghost_b1_ts.pop(obj.key, None)
        m_ghost_b2_ts.pop(obj.key, None)
        # Promote on ghost hit
        seg = 't2'
        m_last_ghost_hit_access = cache_snapshot.access_count
        m_cold_streak = 0
        _bump_freq(obj.key, 2)
    elif in_b2:
        # Decrease p (favor frequency), with ceiling ratio and stronger cap during cold streaks
        denom = max(1, len(m_ghost_b2_ts))
        numer = len(m_ghost_b1_ts)
        raw_dec = max(1, (numer + denom - 1) // denom)  # ceil(|B1|/|B2|)
        dec = min(dec_cap, raw_dec)
        m_target_p = max(0, m_target_p - dec)
        # Ghost bookkeeping
        m_ghost_b2_ts.pop(obj.key, None)
        m_ghost_b1_ts.pop(obj.key, None)
        # Promote on ghost hit
        seg = 't2'
        m_last_ghost_hit_access = cache_snapshot.access_count
        m_cold_streak = 0
        _bump_freq(obj.key, 3)
    else:
        # Cold miss - track streak and apply gentle scan clamp to reduce T1 pressure
        m_cold_streak += 1
        # Gradual clamp during sustained cold streaks
        if m_cold_streak % max(1, cap // 2) == 0:
            m_target_p = max(0, m_target_p - max(1, cap // 16))
        if m_cold_streak >= cap:
            m_target_p = max(0, m_target_p - max(1, cap // 8))
            m_cold_streak = 0
        # Ensure no stale ghost entries remain for this resident
        m_ghost_b1_ts.pop(obj.key, None)
        m_ghost_b2_ts.pop(obj.key, None)
        _bump_freq(obj.key, 1)

        # Scan-aware probation path: temporarily demote a few weakest T2 items to T1
        if m_cold_streak >= max(1, cap // 2):
            t1_keys, t2_keys = _resident_sets(cache_snapshot)
            if t2_keys:
                k = min(2, max(0, cap // 16))
                if k > 0:
                    # Demote the weakest T2 entries (low freq, old recency)
                    cand_sorted = sorted(t2_keys, key=lambda k_: (m_freq.get(k_, 0), m_key_timestamp.get(k_, float('inf'))))
                    for demote_key in cand_sorted[:k]:
                        m_key_segment[demote_key] = 't1'

    # Insert into resident set
    m_key_segment[obj.key] = seg
    m_key_timestamp[obj.key] = cache_snapshot.access_count
    # Clear any stale pending state for this key
    m_t1_pending_hits.pop(obj.key, None)

    # Control ghost size (expanded history)
    _prune_ghosts(cache_snapshot)
>>>>>>> REPLACE

</DIFF>