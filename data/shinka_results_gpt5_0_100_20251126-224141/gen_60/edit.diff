--- a/original.py
+++ b/original.py
@@ -1,378 +1,320 @@
 # EVOLVE-BLOCK-START
 """Cache eviction algorithm for optimizing hit rates across multiple workloads"""
 
 from collections import OrderedDict
 
-# LRU timestamp map kept for compatibility and as a tie-breaker
+# Global timestamps for fallback/tie-breaks
 m_key_timestamp = dict()
 
-# Lightweight LFU counter with periodic aging
-m_freq = dict()
-last_age_access = 0
-AGE_INTERVAL_FACTOR = 4  # age every ~4×capacity accesses (at least 500)
-
-
-# Adaptive Replacement Cache (ARC) metadata
+# ARC state
 arc_T1 = OrderedDict()  # recent, resident
 arc_T2 = OrderedDict()  # frequent, resident
 arc_B1 = OrderedDict()  # ghost of T1
 arc_B2 = OrderedDict()  # ghost of T2
 arc_p = 0               # target size of T1
 arc_capacity = None     # will be initialized from cache_snapshot
 
+# Adaptation control
+last_ghost_hit_access = 0   # last time we saw a ghost hit
+cold_streak = 0             # consecutive evictions/admissions without ghost/hit signal
+scan_guard_until = 0        # temporarily bias REPLACE toward T1 during scans
+
 
 def _ensure_capacity(cache_snapshot):
     global arc_capacity, arc_p
     if arc_capacity is None:
         arc_capacity = max(int(cache_snapshot.capacity), 1)
-    # Bound p within [0, C]
-    if arc_capacity is not None:
-        arc_p = min(max(arc_p, 0), arc_capacity)
-
-
-def _maybe_age(cache_snapshot):
-    global last_age_access, m_freq
-    if arc_capacity is None:
-        return
-    interval = max(500, arc_capacity * AGE_INTERVAL_FACTOR)
-    now = cache_snapshot.access_count
-    if now - last_age_access >= interval:
-        # Halve all frequencies to age out stale popularity
-        for k in list(m_freq.keys()):
-            newv = m_freq.get(k, 0) >> 1
-            if newv <= 0:
-                m_freq.pop(k, None)
-            else:
-                m_freq[k] = newv
-        last_age_access = now
+    # Keep p within [0, C]
+    arc_p = min(max(arc_p, 0), arc_capacity)
 
 
 def _move_to_mru(od, key):
-    # Push key to MRU position of an OrderedDict
     if key in od:
         od.pop(key, None)
     od[key] = True
 
 
 def _pop_lru(od):
     if od:
         k, _ = od.popitem(last=False)
         return k
     return None
 
 
 def _trim_ghosts():
-    # Keep ghosts within 2x capacity and bias trimming to track p split:
-    # target |B1| ≈ p, |B2| ≈ C - p
+    # Keep ghosts total length within 2*C, and bias trimming according to p split
     cap = arc_capacity if arc_capacity is not None else 1
-    # Bound p
     global arc_p
     arc_p = min(max(arc_p, 0), cap)
     total_cap = 2 * cap
     while (len(arc_B1) + len(arc_B2)) > total_cap:
-        target_B1 = min(cap, max(0, arc_p))
+        target_B1 = min(cap, arc_p)
         target_B2 = max(0, cap - target_B1)
         excess_B1 = max(0, len(arc_B1) - target_B1)
         excess_B2 = max(0, len(arc_B2) - target_B2)
         if excess_B1 >= excess_B2 and arc_B1:
             _pop_lru(arc_B1)
         elif arc_B2:
             _pop_lru(arc_B2)
         else:
-            # If both within target but total still exceeds (due to rounding), trim larger
+            # If both within targets but overall still exceeds (rounding), trim larger
             if len(arc_B1) >= len(arc_B2) and arc_B1:
                 _pop_lru(arc_B1)
             elif arc_B2:
                 _pop_lru(arc_B2)
             else:
                 break
 
 
 def _resync(cache_snapshot):
-    # Ensure resident metadata tracks actual cache content and ghosts remain disjoint
+    # Ensure residents track actual cache and ghosts are disjoint
     cache_keys = set(cache_snapshot.cache.keys())
     for k in list(arc_T1.keys()):
         if k not in cache_keys:
             arc_T1.pop(k, None)
     for k in list(arc_T2.keys()):
         if k not in cache_keys:
             arc_T2.pop(k, None)
-    # Add any cached keys we missed to T1 as recent
+    # Any resident keys not tracked go to T1 (recent)
     for k in cache_keys:
         if k not in arc_T1 and k not in arc_T2:
-            arc_T1[k] = True
+            _move_to_mru(arc_T1, k)
     # Ghosts must not contain residents
     for k in list(arc_B1.keys()):
         if k in arc_T1 or k in arc_T2:
             arc_B1.pop(k, None)
     for k in list(arc_B2.keys()):
         if k in arc_T1 or k in arc_T2:
             arc_B2.pop(k, None)
     _trim_ghosts()
 
 
-def _pick_lfu_among_lru_with_score(od, sample_k):
-    # Among the k oldest in od, pick the key with the lowest frequency.
-    # Tie-break by oldest timestamp to better approximate true LRU for equals.
-    # Return a tuple (key, freq, ts). If od empty, return (None, None, None).
-    if not od:
-        return (None, None, None)
-    k = max(1, sample_k)
-    best_key = None
-    best_freq = None
-    best_ts = None
-    count = 0
-    for key in od.keys():
-        f = m_freq.get(key, 0)
-        ts = m_key_timestamp.get(key, float('inf'))
-        if (best_freq is None or
-            f < best_freq or
-            (f == best_freq and ts < best_ts)):
-            best_freq = f
-            best_ts = ts
-            best_key = key
-        count += 1
-        if count >= k:
-            break
-    if best_key is None:
-        # Fallback to LRU if somehow not set
-        try:
-            best_key = next(iter(od))
-        except StopIteration:
-            return (None, None, None)
-        best_freq = m_freq.get(best_key, 0)
-        best_ts = m_key_timestamp.get(best_key, float('inf'))
-    return (best_key, best_freq, best_ts)
-
-
-def _pick_lfu_among_lru(od, sample_k):
-    # Backward-compatible wrapper that returns only the key
-    key, _, _ = _pick_lfu_among_lru_with_score(od, sample_k)
-    return key
+def _decay_p_if_idle(now):
+    # Decay p slowly when there has been no ghost signal for a while
+    global arc_p
+    if arc_capacity is None:
+        return
+    idle = now - last_ghost_hit_access
+    if idle <= 0:
+        return
+    # Base decay proportional to idle, bounded
+    base_step = max(1, idle // max(1, arc_capacity // 4))
+    arc_p = max(0, arc_p - min(base_step, max(1, arc_capacity // 8)))
+
+
+def _adapt_p_on_ghost(now, obj_key):
+    # Adjust p when we see a ghost hit, clamp, and reset cold streak/guard
+    global arc_p, last_ghost_hit_access, cold_streak, scan_guard_until
+    if arc_capacity is None:
+        return
+    cap = arc_capacity
+    if obj_key in arc_B1:
+        # Favor recency: grow T1 target
+        step = max(1, len(arc_B2) // max(1, len(arc_B1)))
+        arc_p = min(cap, arc_p + min(step, max(1, cap // 8)))
+        last_ghost_hit_access = now
+        cold_streak = 0
+        scan_guard_until = 0
+    elif obj_key in arc_B2:
+        # Favor frequency: shrink T1 target, more aggressively if prolonged cold streak
+        step = max(1, len(arc_B1) // max(1, len(arc_B2)))
+        maxstep = max(1, (cap // 4) if cold_streak >= max(1, cap // 2) else (cap // 8))
+        arc_p = max(0, arc_p - min(step, maxstep))
+        last_ghost_hit_access = now
+        cold_streak = 0
+        scan_guard_until = 0
+
+
+def _maybe_enable_scan_guard(now, is_ghost):
+    # On sustained cold streaks, bias REPLACE toward evicting from T1
+    global scan_guard_until
+    if arc_capacity is None:
+        return
+    cap = arc_capacity
+    if is_ghost:
+        return
+    if cold_streak >= max(1, cap // 2):
+        # Guard window for a short period
+        scan_guard_until = max(scan_guard_until, now + max(1, cap // 8))
+
+
+def _replace_choose_from(which):
+    # Peek LRU key from a chosen list without mutating
+    if which == 'T1':
+        return next(iter(arc_T1)) if arc_T1 else None
+    else:
+        return next(iter(arc_T2)) if arc_T2 else None
 
 
 def evict(cache_snapshot, obj):
     '''
     This function defines how the algorithm chooses the eviction victim.
     - Args:
         - `cache_snapshot`: A snapshot of the current cache state.
         - `obj`: The new object that needs to be inserted into the cache.
     - Return:
         - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
     '''
     _ensure_capacity(cache_snapshot)
-    _maybe_age(cache_snapshot)
-    # Keep metadata consistent
-    if (len(arc_T1) + len(arc_T2)) != len(cache_snapshot.cache):
-        _resync(cache_snapshot)
-
-    # ARC replacement: choose between T1 and T2 depending on arc_p and ghost hit type
-    x_in_B2 = obj.key in arc_B2
+    _resync(cache_snapshot)
+
+    now = cache_snapshot.access_count
+    # Adjust p if this is a ghost hit, and track cold/guard
+    is_ghost = (obj.key in arc_B1) or (obj.key in arc_B2)
+    _adapt_p_on_ghost(now, obj.key)
+    if not is_ghost:
+        # cold admission; increment cold streak and maybe enable guard
+        # This runs per miss leading to eviction
+        # Note: hits reset cold_streak elsewhere
+        globals()['cold_streak'] = globals()['cold_streak'] + 1
+        _maybe_enable_scan_guard(now, is_ghost)
+    else:
+        # Ensure cold streak stays reset on ghost signal
+        globals()['cold_streak'] = 0
+
+    # Idle decay of p to recover faster after long idle/no-ghost periods
+    _decay_p_if_idle(now)
+
+    # Canonical ARC REPLACE decision with optional scan guard bias
     t1_sz = len(arc_T1)
-    choose_T1 = (t1_sz >= 1 and (t1_sz > arc_p or (x_in_B2 and t1_sz == arc_p)))
-
-    # Frequency-aware sampling among the k oldest of both lists
-    cap = arc_capacity if arc_capacity else 1
-    sample_k = min(16, max(2, cap // 8))
-
-    k1, f1, ts1 = _pick_lfu_among_lru_with_score(arc_T1, sample_k)
-    k2, f2, ts2 = _pick_lfu_among_lru_with_score(arc_T2, sample_k)
-
-    # Start with canonical ARC decision
+    choose_T1 = (t1_sz >= 1 and (t1_sz > arc_p or (obj.key in arc_B2 and t1_sz == arc_p)))
+
+    # If scan guard active, bias toward T1 unless T1 empty
+    if scan_guard_until > now:
+        if arc_T1:
+            choose_T1 = True
+        elif arc_T2:
+            choose_T1 = False
+
     candidate = None
-    cand_freq = None
-    cand_ts = None
     if choose_T1:
-        if k1 is not None:
-            candidate, cand_freq, cand_ts = k1, f1, ts1
-        elif k2 is not None:
-            candidate, cand_freq, cand_ts = k2, f2, ts2
-    else:
-        if k2 is not None:
-            candidate, cand_freq, cand_ts = k2, f2, ts2
-        elif k1 is not None:
-            candidate, cand_freq, cand_ts = k1, f1, ts1
-
-    # Cross-list override: if the opposite list has a much colder candidate, pick it
-    MARGIN = 1  # require at least 1 lower frequency to override
-    if k1 is not None and k2 is not None:
-        if choose_T1:
-            # Opposite (T2) is much colder
-            if f2 is not None and cand_freq is not None and (f2 + MARGIN) < cand_freq:
-                candidate, cand_freq, cand_ts = k2, f2, ts2
-            elif f2 == cand_freq and ts2 is not None and cand_ts is not None and ts2 < cand_ts:
-                # Tie-break by older timestamp if frequencies equal
-                candidate, cand_freq, cand_ts = k2, f2, ts2
-        else:
-            # Opposite (T1) is much colder
-            if f1 is not None and cand_freq is not None and (f1 + MARGIN) < cand_freq:
-                candidate, cand_freq, cand_ts = k1, f1, ts1
-            elif f1 == cand_freq and ts1 is not None and cand_ts is not None and ts1 < cand_ts:
-                candidate, cand_freq, cand_ts = k1, f1, ts1
-
-    # If still no candidate, try any resident list deterministically
+        candidate = _replace_choose_from('T1')
+        if candidate is None:
+            candidate = _replace_choose_from('T2')
+    else:
+        candidate = _replace_choose_from('T2')
+        if candidate is None:
+            candidate = _replace_choose_from('T1')
+
     if candidate is None:
-        if arc_T1:
-            candidate = _pick_lfu_among_lru(arc_T1, sample_k)
-        elif arc_T2:
-            candidate = _pick_lfu_among_lru(arc_T2, sample_k)
-
-    if candidate is None:
-        # Fallback: choose the oldest by timestamp if available, else any key
+        # Fallback: oldest by timestamp; else any key
         if m_key_timestamp and cache_snapshot.cache:
             min_ts = float('inf')
             best = None
             for k in cache_snapshot.cache.keys():
                 ts = m_key_timestamp.get(k, float('inf'))
                 if ts < min_ts:
                     min_ts = ts
                     best = k
             candidate = best
         if candidate is None and cache_snapshot.cache:
             candidate = next(iter(cache_snapshot.cache.keys()))
     return candidate
 
 
 def update_after_hit(cache_snapshot, obj):
     '''
-    This function defines how the algorithm update the metadata it maintains immediately after a cache hit.
-    - Args:
-        - `cache_snapshot`: A snapshot of the current cache state.
-        - `obj`: The object accessed during the cache hit.
-    - Return: `None`
-    '''
-    global m_key_timestamp
+    Update metadata after a cache hit.
+    '''
     _ensure_capacity(cache_snapshot)
-    _maybe_age(cache_snapshot)
-
-    # ARC: on hit, move to T2 MRU
+    now = cache_snapshot.access_count
     key = obj.key
+
+    # ARC hit handling: promote/refresh to T2
     if key in arc_T1:
         arc_T1.pop(key, None)
         _move_to_mru(arc_T2, key)
-    else:
-        # If already in T2, refresh; if not present due to drift, place in T2
-        if key in arc_T2:
-            _move_to_mru(arc_T2, key)
-        else:
-            _move_to_mru(arc_T2, key)
-    # Keep ghosts disjoint with residents
+    elif key in arc_T2:
+        _move_to_mru(arc_T2, key)
+    else:
+        # Untracked but hit: place into T2 to protect
+        _move_to_mru(arc_T2, key)
+
+    # Ghosts must be disjoint with residents
     arc_B1.pop(key, None)
     arc_B2.pop(key, None)
-    # Update timestamp for tie-breaking/fallback and bump frequency
-    m_key_timestamp[key] = cache_snapshot.access_count
-    m_freq[key] = m_freq.get(key, 0) + 1
-
-    # Defensive: repair metadata drift if any
-    if (len(arc_T1) + len(arc_T2)) != len(cache_snapshot.cache):
-        _resync(cache_snapshot)
+
+    # Timestamps used for fallback victim selection
+    m_key_timestamp[key] = now
+
+    # Any hit indicates locality; reset cold streak and guard
+    global cold_streak, scan_guard_until
+    cold_streak = 0
+    scan_guard_until = 0
 
 
 def update_after_insert(cache_snapshot, obj):
     '''
-    This function defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
-    - Args:
-        - `cache_snapshot`: A snapshot of the current cache state.
-        - `obj`: The object that was just inserted into the cache.
-    - Return: `None`
-    '''
-    global m_key_timestamp, arc_p, m_freq
+    Update metadata after inserting a new object into the cache.
+    '''
     _ensure_capacity(cache_snapshot)
-    _maybe_age(cache_snapshot)
+    now = cache_snapshot.access_count
     key = obj.key
-    # Use boundary-aware step to prevent p overshoot
-    cap = arc_capacity if arc_capacity is not None else 1
-    step_cap = max(1, cap // 8)
-
-    was_ghost = False
-    # ARC admission policy
+
+    # ARC admission: ghost re-references go directly to T2; brand new to T1
     if key in arc_B1:
-        # Previously evicted from T1: favor recency by increasing p
-        ratio = max(1, len(arc_B2) // max(1, len(arc_B1)))
-        inc = min(ratio, step_cap, max(0, cap - arc_p))
-        arc_p = min(cap, arc_p + inc)
         arc_B1.pop(key, None)
         _move_to_mru(arc_T2, key)
-        was_ghost = True
+        # Ghost hit confirmation
+        global last_ghost_hit_access, cold_streak, scan_guard_until
+        last_ghost_hit_access = now
+        cold_streak = 0
+        scan_guard_until = 0
     elif key in arc_B2:
-        # Previously frequent: favor frequency by decreasing p
-        ratio = max(1, len(arc_B1) // max(1, len(arc_B2)))
-        dec = min(ratio, step_cap, arc_p)
-        arc_p = max(0, arc_p - dec)
         arc_B2.pop(key, None)
         _move_to_mru(arc_T2, key)
-        was_ghost = True
-    else:
-        # Brand new: insert into T1 (recent)
+        global last_ghost_hit_access, cold_streak, scan_guard_until
+        last_ghost_hit_access = now
+        cold_streak = 0
+        scan_guard_until = 0
+    else:
         _move_to_mru(arc_T1, key)
 
-    # Bound p and keep ghosts disjoint with residents and trimmed
-    arc_p = min(max(arc_p, 0), cap)
-    arc_B1.pop(key, None)
-    arc_B2.pop(key, None)
+    # Keep ghosts tidy and timestamps fresh
     _trim_ghosts()
-    # Track access time; bump frequency only for ghost re-admissions (reuse signal)
-    m_key_timestamp[key] = cache_snapshot.access_count
-    if was_ghost:
-        m_freq[key] = m_freq.get(key, 0) + 1
-
-    # Defensive: repair metadata drift if any
-    if (len(arc_T1) + len(arc_T2)) != len(cache_snapshot.cache):
-        _resync(cache_snapshot)
+    m_key_timestamp[key] = now
 
 
 def update_after_evict(cache_snapshot, obj, evicted_obj):
     '''
-    This function defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
-    - Args:
-        - `cache_snapshot`: A snapshot of the current cache state.
-        - `obj`: The object to be inserted into the cache.
-        - `evicted_obj`: The object that was just evicted from the cache.
-    - Return: `None`
-    '''
-    global m_key_timestamp
+    Update metadata after evicting the victim.
+    '''
     _ensure_capacity(cache_snapshot)
-    _maybe_age(cache_snapshot)
     k = evicted_obj.key
-    # Move evicted resident to corresponding ghost list and keep ghosts disjoint
+
+    # Move evicted resident to corresponding ghost list
     if k in arc_T1:
         arc_T1.pop(k, None)
-        arc_B2.pop(k, None)
         _move_to_mru(arc_B1, k)
     elif k in arc_T2:
         arc_T2.pop(k, None)
-        arc_B1.pop(k, None)
         _move_to_mru(arc_B2, k)
     else:
-        # Unknown membership: prefer consistency with existing ghost presence
-        if k in arc_B2:
-            arc_B1.pop(k, None)
-            _move_to_mru(arc_B2, k)
-        else:
-            arc_B2.pop(k, None)
-            _move_to_mru(arc_B1, k)
-    # Remove timestamp entry for evicted item to avoid growth (keep freq as history)
+        # Unknown membership: default to B1
+        _move_to_mru(arc_B1, k)
+
+    # Shrink ghosts if needed and drop timestamp
+    _trim_ghosts()
     m_key_timestamp.pop(k, None)
-    _trim_ghosts()
 
 # EVOLVE-BLOCK-END
 
 # This part remains fixed (not evolved)
 def run_caching(trace_path: str, copy_code_dst: str):
     """Run the caching algorithm on a trace"""
     import os
     with open(os.path.abspath(__file__), 'r', encoding="utf-8") as f:
         code_str = f.read()
     with open(os.path.join(copy_code_dst), 'w') as f:
         f.write(code_str)
     from cache_utils import Cache, CacheConfig, CacheObj, Trace
     trace = Trace(trace_path=trace_path)
     cache_capacity = max(int(trace.get_ndv() * 0.1), 1)
     cache = Cache(CacheConfig(cache_capacity))
     for entry in trace.entries:
         obj = CacheObj(key=str(entry.key))
         cache.get(obj)
     with open(copy_code_dst, 'w') as f:
         f.write("")
     hit_rate = round(cache.hit_count / cache.access_count, 6)
     return hit_rate