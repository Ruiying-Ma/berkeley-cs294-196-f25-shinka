<NAME>
arc_promotion_and_strict_replace
</NAME>

<DESCRIPTION>
I convert the hit path to immediate promotion (ARCâ€™s standard) instead of requiring two quick hits. The previous delayed promotion was over-aggressive and led to frequent thrashing on workloads where items are reused once per cycle. I also tighten the eviction decision to the canonical ARC REPLACE rule: evict from T1 if |T1| > p or (x in B2 and |T1| >= p), otherwise from T2, and if the chosen list is empty, take from the other. Additionally, I enforce ghost/resident disjointness by removing resident keys from the ghost lists on hit/insert and always removing a key from the opposite ghost on evict/ghost-hit insert. This keeps ghost signals accurate for p steering and improves stability across workloads.

Together, these changes make the policy closer to ARC while maintaining the existing adaptive p logic (with capped step sizes and mild decay), improving hit rates, especially on mixed and looping workloads where the previous delayed promotion harmed performance.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
def evict(cache_snapshot, obj):
    '''
    This function defines how the algorithm chooses the eviction victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    _ensure_init(cache_snapshot)
    t1_keys, t2_keys = _resident_sets(cache_snapshot)

    # ARC-like replace() rule:
    # Prefer evicting from T1 when:
    # - T1 is larger than target p, or
    # - The incoming key is in B2 and T1 is at target (to reduce T1), or
    # - T2 is empty (nothing protected yet).
    evict_from_t1 = False
    if len(t1_keys) > m_target_p:
        evict_from_t1 = True
    elif obj.key in m_ghost_b2_ts and len(t1_keys) >= max(1, m_target_p):
        evict_from_t1 = True
    elif not t2_keys and t1_keys:
        evict_from_t1 = True

    if evict_from_t1 and t1_keys:
        victim = _lru_key(t1_keys)
        if victim is not None:
            return victim

    # Otherwise evict LRU from T2 if available
    if t2_keys:
        victim = _lru_key(t2_keys)
        if victim is not None:
            return victim

    # Fallback: global LRU
    all_keys = list(cache_snapshot.cache.keys())
    if not all_keys:
        return None
    return _lru_key(all_keys)
=======
def evict(cache_snapshot, obj):
    '''
    This function defines how the algorithm chooses the eviction victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    _ensure_init(cache_snapshot)
    t1_keys, t2_keys = _resident_sets(cache_snapshot)

    # Keep ghosts disjoint from current residents to ensure consistent ARC signals
    for k in cache_snapshot.cache.keys():
        m_ghost_b1_ts.pop(k, None)
        m_ghost_b2_ts.pop(k, None)

    # Strict ARC REPLACE decision:
    # Evict from T1 if |T1| > p, or (incoming in B2 and |T1| >= max(1, p)), else from T2.
    cap = _cap(cache_snapshot)
    p = min(max(0, m_target_p), cap)
    t1_len = len(t1_keys)

    evict_from_t1 = (t1_len > p) or (obj.key in m_ghost_b2_ts and t1_len >= max(1, p))

    if evict_from_t1:
        victim = _lru_key(t1_keys)
        if victim is not None:
            return victim
        # If T1 is empty, fall back to T2
        victim = _lru_key(t2_keys)
        if victim is not None:
            return victim
    else:
        victim = _lru_key(t2_keys)
        if victim is not None:
            return victim
        # If T2 is empty, fall back to T1
        victim = _lru_key(t1_keys)
        if victim is not None:
            return victim

    # Last resort: global LRU
    all_keys = list(cache_snapshot.cache.keys())
    if not all_keys:
        return None
    return _lru_key(all_keys)
>>>>>>> REPLACE

</DIFF>

<DIFF>
<<<<<<< SEARCH
def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the algorithm update the metadata it maintains immediately after a cache hit.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    global m_key_timestamp, m_key_segment, m_t1_pending_hits, m_cold_streak, m_target_p, m_last_ghost_hit_access
    _ensure_init(cache_snapshot)

    # Refresh recency
    m_key_timestamp[obj.key] = cache_snapshot.access_count

    # Reset cold streak on any hit
    m_cold_streak = 0

    # Slow decay of p if no ghost hits for a while (scan recovery)
    cap = _cap(cache_snapshot)
    if cache_snapshot.access_count - m_last_ghost_hit_access > cap:
        m_target_p = max(0, m_target_p - 1)

    # Delayed promotion: require two hits within a short window while in T1
    seg = m_key_segment.get(obj.key, 't1')
    if seg == 't2':
        return
    # In T1
    W = max(1, cap // 4)
    last = m_t1_pending_hits.get(obj.key)
    if last is not None and cache_snapshot.access_count - last <= W:
        m_key_segment[obj.key] = 't2'
        m_t1_pending_hits.pop(obj.key, None)
    else:
        m_t1_pending_hits[obj.key] = cache_snapshot.access_count
=======
def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the algorithm update the metadata it maintains immediately after a cache hit.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    global m_key_timestamp, m_key_segment, m_t1_pending_hits, m_cold_streak, m_target_p, m_last_ghost_hit_access
    _ensure_init(cache_snapshot)

    # Refresh recency
    m_key_timestamp[obj.key] = cache_snapshot.access_count

    # Reset cold streak on any hit
    m_cold_streak = 0

    # Slow decay of p if no ghost hits for a while (scan recovery)
    cap = _cap(cache_snapshot)
    if cache_snapshot.access_count - m_last_ghost_hit_access > cap:
        m_target_p = max(0, m_target_p - 1)

    # ARC-style immediate promotion: on a hit in T1, move to T2
    seg = m_key_segment.get(obj.key, 't1')
    if seg != 't2':
        m_key_segment[obj.key] = 't2'
    # Clear any pending two-hit state (no longer used)
    m_t1_pending_hits.pop(obj.key, None)

    # Ensure ghosts remain disjoint from residents
    m_ghost_b1_ts.pop(obj.key, None)
    m_ghost_b2_ts.pop(obj.key, None)
>>>>>>> REPLACE

</DIFF>

<DIFF>
<<<<<<< SEARCH
def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    global m_key_timestamp, m_key_segment, m_target_p, m_last_ghost_hit_access, m_cold_streak, m_t1_pending_hits
    _ensure_init(cache_snapshot)

    cap = _cap(cache_snapshot)
    step_cap = max(1, cap // 8)

    in_b1 = obj.key in m_ghost_b1_ts
    in_b2 = obj.key in m_ghost_b2_ts

    seg = 't1'
    if in_b1:
        # Increase p (give more room to recency), damped
        raw = max(1, len(m_ghost_b2_ts) // max(1, len(m_ghost_b1_ts)))
        inc = min(step_cap, raw)
        m_target_p = min(cap, m_target_p + inc)
        m_ghost_b1_ts.pop(obj.key, None)
        seg = 't2'
        m_last_ghost_hit_access = cache_snapshot.access_count
        m_cold_streak = 0
    elif in_b2:
        # Decrease p (favor frequency), damped
        raw = max(1, len(m_ghost_b1_ts) // max(1, len(m_ghost_b2_ts)))
        dec = min(step_cap, raw)
        m_target_p = max(0, m_target_p - dec)
        m_ghost_b2_ts.pop(obj.key, None)
        seg = 't2'
        m_last_ghost_hit_access = cache_snapshot.access_count
        m_cold_streak = 0
    else:
        # Cold miss - track streak and apply scan clamp if needed
        m_cold_streak += 1
        if m_cold_streak > cap:
            m_target_p = max(0, m_target_p - max(1, cap // 4))
            m_cold_streak = 0

    # Insert into resident set
    m_key_segment[obj.key] = seg
    m_key_timestamp[obj.key] = cache_snapshot.access_count
    # Clear any stale pending state for this key
    m_t1_pending_hits.pop(obj.key, None)

    # Control ghost size (expanded history)
    _prune_ghosts(cache_snapshot)
=======
def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    global m_key_timestamp, m_key_segment, m_target_p, m_last_ghost_hit_access, m_cold_streak, m_t1_pending_hits
    _ensure_init(cache_snapshot)

    cap = _cap(cache_snapshot)
    step_cap = max(1, cap // 8)

    in_b1 = obj.key in m_ghost_b1_ts
    in_b2 = obj.key in m_ghost_b2_ts

    seg = 't1'
    if in_b1:
        # Increase p (give more room to recency), damped
        raw = max(1, len(m_ghost_b2_ts) // max(1, len(m_ghost_b1_ts)))
        inc = min(step_cap, raw)
        m_target_p = min(cap, m_target_p + inc)
        # Ghost bookkeeping
        m_ghost_b1_ts.pop(obj.key, None)
        m_ghost_b2_ts.pop(obj.key, None)
        # Promote on ghost hit
        seg = 't2'
        m_last_ghost_hit_access = cache_snapshot.access_count
        m_cold_streak = 0
    elif in_b2:
        # Decrease p (favor frequency), damped
        raw = max(1, len(m_ghost_b1_ts) // max(1, len(m_ghost_b2_ts)))
        dec = min(step_cap, raw)
        m_target_p = max(0, m_target_p - dec)
        # Ghost bookkeeping
        m_ghost_b2_ts.pop(obj.key, None)
        m_ghost_b1_ts.pop(obj.key, None)
        # Promote on ghost hit
        seg = 't2'
        m_last_ghost_hit_access = cache_snapshot.access_count
        m_cold_streak = 0
    else:
        # Cold miss - track streak and apply scan clamp if needed
        m_cold_streak += 1
        if m_cold_streak > cap:
            m_target_p = max(0, m_target_p - max(1, cap // 4))
            m_cold_streak = 0
        # Ensure no stale ghost entries remain for this resident
        m_ghost_b1_ts.pop(obj.key, None)
        m_ghost_b2_ts.pop(obj.key, None)

    # Insert into resident set
    m_key_segment[obj.key] = seg
    m_key_timestamp[obj.key] = cache_snapshot.access_count
    # Clear any stale pending state for this key
    m_t1_pending_hits.pop(obj.key, None)

    # Control ghost size (expanded history)
    _prune_ghosts(cache_snapshot)
>>>>>>> REPLACE

</DIFF>

<DIFF>
<<<<<<< SEARCH
def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    global m_key_timestamp, m_key_segment, m_ghost_b1_ts, m_ghost_b2_ts, m_t1_pending_hits
    _ensure_init(cache_snapshot)

    # Remove resident metadata for evicted key
    seg = m_key_segment.pop(evicted_obj.key, 't1')
    m_key_timestamp.pop(evicted_obj.key, None)
    m_t1_pending_hits.pop(evicted_obj.key, None)

    # Add to corresponding ghost list with current time to maintain LRU
    ts = cache_snapshot.access_count
    if seg == 't2':
        m_ghost_b2_ts[evicted_obj.key] = ts
    else:
        m_ghost_b1_ts[evicted_obj.key] = ts

    # Control ghost size (expanded history)
    _prune_ghosts(cache_snapshot)
=======
def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    global m_key_timestamp, m_key_segment, m_ghost_b1_ts, m_ghost_b2_ts, m_t1_pending_hits
    _ensure_init(cache_snapshot)

    # Remove resident metadata for evicted key
    seg = m_key_segment.pop(evicted_obj.key, 't1')
    m_key_timestamp.pop(evicted_obj.key, None)
    m_t1_pending_hits.pop(evicted_obj.key, None)

    # Add to corresponding ghost list with current time to maintain LRU.
    # Ensure ghosts remain disjoint.
    ts = cache_snapshot.access_count
    if seg == 't2':
        m_ghost_b2_ts[evicted_obj.key] = ts
        m_ghost_b1_ts.pop(evicted_obj.key, None)
    else:
        m_ghost_b1_ts[evicted_obj.key] = ts
        m_ghost_b2_ts.pop(evicted_obj.key, None)

    # Control ghost size (expanded history)
    _prune_ghosts(cache_snapshot)
>>>>>>> REPLACE

</DIFF>