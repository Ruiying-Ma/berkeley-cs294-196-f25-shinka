<NAME>
arc_p_in_evict_2C_ghosts_scan_decay
</NAME>

<DESCRIPTION>
I move the ghost-driven p adaptation into evict so the ARC REPLACE decision uses the freshest signal (canonical ARC flow), and remove the duplicate p updates from update_after_insert to avoid double-stepping. I also expand the ghost history budget to 2×capacity with proportional trimming toward p, which preserves more predictive history and stabilizes adaptation. Finally, I strengthen idle/scan recovery by making p decay proportional and bounded, enabling quicker recovery from scans without oscillation. These changes improve eviction choices under mixed workloads and streaming patterns, lowering miss rates while keeping metadata robust.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
def _trim_ghosts():
    # Keep ghosts total size within capacity (matches best baseline)
    total = len(arc_B1) + len(arc_B2)
    cap = arc_capacity if arc_capacity is not None else 1
    while total > cap:
        # Evict from the larger ghost list first
        if len(arc_B1) >= len(arc_B2):
            _pop_lru(arc_B1)
        else:
            _pop_lru(arc_B2)
        total = len(arc_B1) + len(arc_B2)
=======
def _trim_ghosts():
    # Keep ghosts total size within 2x capacity with a p-biased trimming.
    cap = arc_capacity if arc_capacity is not None else 1
    total_cap = 2 * cap
    while (len(arc_B1) + len(arc_B2)) > total_cap:
        # Bias trimming toward exceeding side relative to target split (|B1|≈p, |B2|≈C-p)
        target_B1 = min(cap, max(0, arc_p))
        target_B2 = max(0, cap - target_B1)
        excess_B1 = max(0, len(arc_B1) - target_B1)
        excess_B2 = max(0, len(arc_B2) - target_B2)
        if excess_B1 >= excess_B2 and arc_B1:
            _pop_lru(arc_B1)
        elif arc_B2:
            _pop_lru(arc_B2)
        else:
            # Fallback: trim larger side
            if len(arc_B1) >= len(arc_B2) and arc_B1:
                _pop_lru(arc_B1)
            elif arc_B2:
                _pop_lru(arc_B2)
            else:
                break
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
def _decay_p_if_idle(cache_snapshot):
    # If no ghost hits for a while, gently decay p toward 0 to recover from scans
    global arc_p
    if last_ghost_hit_access >= 0:
        idle = cache_snapshot.access_count - last_ghost_hit_access
        if idle > (arc_capacity if arc_capacity else 1) and arc_p > 0:
            arc_p = max(0, arc_p - 1)
=======
def _decay_p_if_idle(cache_snapshot):
    # If no ghost hits for a while, decay p proportionally to recover from scans
    global arc_p
    cap = arc_capacity if arc_capacity else 1
    if last_ghost_hit_access >= 0:
        idle = cache_snapshot.access_count - last_ghost_hit_access
        if idle > 0 and arc_p > 0:
            step = min(max(1, idle // max(1, cap // 4)), max(1, cap // 8))
            arc_p = max(0, arc_p - step)
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
def evict(cache_snapshot, obj):
    '''
    This function defines how the algorithm chooses the eviction victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    _ensure_capacity(cache_snapshot)
    # Keep metadata consistent first and decay p if idle
    if (len(arc_T1) + len(arc_T2)) != len(cache_snapshot.cache):
        _resync(cache_snapshot)
    _decay_p_if_idle(cache_snapshot)

    # ARC replacement: choose between T1 and T2 depending on arc_p and ghost hit type
    x_in_B2 = obj.key in arc_B2
    t1_sz = len(arc_T1)
    from_t1 = (t1_sz >= 1 and (t1_sz > arc_p or (x_in_B2 and t1_sz == arc_p)))

    # Primary choice
    if from_t1 and arc_T1:
        return next(iter(arc_T1))
    if (not from_t1) and arc_T2:
        return next(iter(arc_T2))
    # If preferred list empty, try the other
    if arc_T1:
        return next(iter(arc_T1))
    if arc_T2:
        return next(iter(arc_T2))

    # Try to repair metadata and retry ARC replacement before falling back
    _resync(cache_snapshot)
    t1_sz = len(arc_T1)
    from_t1 = (t1_sz >= 1 and (t1_sz > arc_p or (x_in_B2 and t1_sz == arc_p)))
    if from_t1 and arc_T1:
        return next(iter(arc_T1))
    if (not from_t1) and arc_T2:
        return next(iter(arc_T2))
    if arc_T1:
        return next(iter(arc_T1))
    if arc_T2:
        return next(iter(arc_T2))

    # Ghost-informed fallback: prefer evicting something present in B1 (recency-only)
    for k in cache_snapshot.cache.keys():
        if k in arc_B1:
            return k
    # Next: prefer any key not in B2 (avoid evicting likely frequent)
    for k in cache_snapshot.cache.keys():
        if k not in arc_B2:
            return k
    # Otherwise, timestamp tie-breaker
    if m_key_timestamp:
        min_ts = min(m_key_timestamp.get(k, float('inf')) for k in cache_snapshot.cache.keys())
        for k in cache_snapshot.cache.keys():
            if m_key_timestamp.get(k, float('inf')) == min_ts:
                return k
    # Last resort: arbitrary
    if cache_snapshot.cache:
        return next(iter(cache_snapshot.cache.keys()))
    return None
=======
def evict(cache_snapshot, obj):
    '''
    This function defines how the algorithm chooses the eviction victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    global arc_p, last_ghost_hit_access
    _ensure_capacity(cache_snapshot)
    # Keep metadata consistent first and decay p if idle
    if (len(arc_T1) + len(arc_T2)) != len(cache_snapshot.cache):
        _resync(cache_snapshot)
    _decay_p_if_idle(cache_snapshot)

    # Apply ghost-driven p adjustment before REPLACE (canonical ARC)
    cap = arc_capacity if arc_capacity is not None else 1
    step_cap = max(1, cap // 8)
    if obj.key in arc_B1:
        b1 = max(1, len(arc_B1))
        delta = (len(arc_B2) + b1 - 1) // b1  # ceil(|B2|/|B1|)
        inc = min(delta, step_cap, max(0, cap - arc_p))
        if inc > 0:
            arc_p = min(cap, arc_p + inc)
        last_ghost_hit_access = cache_snapshot.access_count
    elif obj.key in arc_B2:
        b2 = max(1, len(arc_B2))
        delta = (len(arc_B1) + b2 - 1) // b2  # ceil(|B1|/|B2|)
        dec = min(delta, step_cap, arc_p)
        if dec > 0:
            arc_p = max(0, arc_p - dec)
        last_ghost_hit_access = cache_snapshot.access_count

    # ARC replacement: choose between T1 and T2 depending on arc_p and ghost hit type
    x_in_B2 = obj.key in arc_B2
    t1_sz = len(arc_T1)
    from_t1 = (t1_sz >= 1 and (t1_sz > arc_p or (x_in_B2 and t1_sz == arc_p)))

    # Primary choice
    if from_t1 and arc_T1:
        return next(iter(arc_T1))
    if (not from_t1) and arc_T2:
        return next(iter(arc_T2))
    # If preferred list empty, try the other
    if arc_T1:
        return next(iter(arc_T1))
    if arc_T2:
        return next(iter(arc_T2))

    # Try to repair metadata and retry ARC replacement before falling back
    _resync(cache_snapshot)
    t1_sz = len(arc_T1)
    from_t1 = (t1_sz >= 1 and (t1_sz > arc_p or (x_in_B2 and t1_sz == arc_p)))
    if from_t1 and arc_T1:
        return next(iter(arc_T1))
    if (not from_t1) and arc_T2:
        return next(iter(arc_T2))
    if arc_T1:
        return next(iter(arc_T1))
    if arc_T2:
        return next(iter(arc_T2))

    # Ghost-informed fallback: prefer evicting something present in B1 (recency-only)
    for k in cache_snapshot.cache.keys():
        if k in arc_B1:
            return k
    # Next: prefer any key not in B2 (avoid evicting likely frequent)
    for k in cache_snapshot.cache.keys():
        if k not in arc_B2:
            return k
    # Otherwise, timestamp tie-breaker
    if m_key_timestamp:
        min_ts = min(m_key_timestamp.get(k, float('inf')) for k in cache_snapshot.cache.keys())
        for k in cache_snapshot.cache.keys():
            if m_key_timestamp.get(k, float('inf')) == min_ts:
                return k
    # Last resort: arbitrary
    if cache_snapshot.cache:
        return next(iter(cache_snapshot.cache.keys()))
    return None
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    global m_key_timestamp, arc_p, last_ghost_hit_access
    _ensure_capacity(cache_snapshot)
    _decay_p_if_idle(cache_snapshot)

    key = obj.key
    # ARC admission policy with bounded p updates
    step_cap = max(1, arc_capacity // 8)
    if key in arc_B1:
        # Previously evicted from T1: favor recency by increasing p
        inc = max(1, len(arc_B2) // max(1, len(arc_B1)))
        inc = min(inc, step_cap, max(0, arc_capacity - arc_p))
        arc_p = min(arc_capacity, arc_p + inc)
        last_ghost_hit_access = cache_snapshot.access_count
        arc_B1.pop(key, None)
        arc_B2.pop(key, None)  # keep ghosts disjoint
        _move_to_mru(arc_T2, key)
    elif key in arc_B2:
        # Previously frequent: favor frequency by decreasing p
        dec = max(1, len(arc_B1) // max(1, len(arc_B2)))
        dec = min(dec, step_cap, arc_p)
        arc_p = max(0, arc_p - dec)
        last_ghost_hit_access = cache_snapshot.access_count
        arc_B2.pop(key, None)
        arc_B1.pop(key, None)
        _move_to_mru(arc_T2, key)
    else:
        # Brand new: insert into T1 (recent)
        _move_to_mru(arc_T1, key)
        # Ensure ghosts are disjoint from residents
        arc_B1.pop(key, None)
        arc_B2.pop(key, None)

    _trim_ghosts()
    m_key_timestamp[key] = cache_snapshot.access_count

    # Post-condition: keep metadata consistent
    if (len(arc_T1) + len(arc_T2)) != len(cache_snapshot.cache):
        _resync(cache_snapshot)
=======
def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    global m_key_timestamp
    _ensure_capacity(cache_snapshot)
    _decay_p_if_idle(cache_snapshot)

    key = obj.key
    # ARC admission policy: placement only; p was already adjusted (in evict) on ghost hits
    if key in arc_B1 or key in arc_B2:
        arc_B1.pop(key, None)
        arc_B2.pop(key, None)  # keep ghosts disjoint
        _move_to_mru(arc_T2, key)
    else:
        # Brand new: insert into T1 (recent)
        _move_to_mru(arc_T1, key)
        # Ensure ghosts are disjoint from residents
        arc_B1.pop(key, None)
        arc_B2.pop(key, None)

    _trim_ghosts()
    m_key_timestamp[key] = cache_snapshot.access_count

    # Post-condition: keep metadata consistent
    if (len(arc_T1) + len(arc_T2)) != len(cache_snapshot.cache):
        _resync(cache_snapshot)
>>>>>>> REPLACE

</DIFF>