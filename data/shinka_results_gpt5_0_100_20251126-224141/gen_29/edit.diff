--- a/original.py
+++ b/original.py
@@ -1,254 +1,162 @@
 # EVOLVE-BLOCK-START
-"""Cache eviction algorithm for optimizing hit rates across multiple workloads"""
+"""Cache eviction algorithm for optimizing hit rates across multiple workloads
+LRU-K (K=2) with Correlated Reference Period (CRP)
+- Maintain the last two distinct reference times per key across evictions.
+- Evict the item with the largest backward K-distance (or cold items with no 2nd ref).
+- CRP avoids counting rapid, correlated hits as separate references.
+This filters one-hit wonders and favors items with proven reuse.
+"""
 
-from collections import OrderedDict
-
-# LRU timestamp map kept for compatibility and as a tie-breaker
-m_key_timestamp = dict()
-
-# Adaptive Replacement Cache (ARC) metadata
-arc_T1 = OrderedDict()  # recent, resident
-arc_T2 = OrderedDict()  # frequent, resident
-arc_B1 = OrderedDict()  # ghost of T1
-arc_B2 = OrderedDict()  # ghost of T2
-arc_p = 0               # target size of T1
-arc_capacity = None     # will be initialized from cache_snapshot
-
-# Delayed promotion and adaptation state
-t1_pending = dict()             # key -> last hit access_count while in T1
-arc_last_ghost_hit_access = 0   # last access_count when a ghost hit occurred
-arc_last_decay_access = 0       # throttle decay operations
-cold_streak = 0                 # consecutive cold admissions without ghost/hit signal
-
-def _pending_window():
-    cap = arc_capacity if arc_capacity is not None else 1
-    return max(1, cap // 4)
+# Per-key compact history: key -> (last_ts, prev_ts)
+# last_ts: timestamp of most recent reference
+# prev_ts: timestamp of the second most recent (distinct) reference, or None if not available
+m_history = dict()
 
 
-def _ensure_capacity(cache_snapshot):
-    global arc_capacity
-    if arc_capacity is None:
-        arc_capacity = max(int(cache_snapshot.capacity), 1)
+def _cap(cache_snapshot):
+    try:
+        return max(1, int(cache_snapshot.capacity))
+    except Exception:
+        # Fallback to count-based capacity
+        return max(1, len(cache_snapshot.cache))
 
 
-def _move_to_mru(od, key):
-    # Push key to MRU position of an OrderedDict
-    if key in od:
-        od.pop(key, None)
-    od[key] = True
+def _crp_window(cache_snapshot):
+    # Correlated reference period window. Hits closer than this window are not counted as distinct.
+    cap = _cap(cache_snapshot)
+    return max(1, cap // 16)
 
 
-def _pop_lru(od):
-    if od:
-        k, _ = od.popitem(last=False)
-        return k
-    return None
+def _update_history_for_ref(now, key, crp):
+    """Record a reference to key at time 'now', honoring CRP."""
+    last, prev = m_history.get(key, (None, None))
+    if last is None:
+        # First-ever reference
+        m_history[key] = (now, None)
+        return
+
+    # If the last reference is within CRP, treat this as the same burst: refresh last only.
+    if now - last < crp:
+        m_history[key] = (now, prev)
+    else:
+        # Distinct reference: shift last to prev and set new last
+        m_history[key] = (now, last)
 
 
-def _trim_ghosts():
-    # Keep ghosts total size within 2x capacity (more history for adaptation)
-    total = len(arc_B1) + len(arc_B2)
-    cap = (arc_capacity if arc_capacity is not None else 1) * 2
-    while total > cap:
-        # Evict from the larger ghost list first
-        if len(arc_B1) >= len(arc_B2):
-            _pop_lru(arc_B1)
-        else:
-            _pop_lru(arc_B2)
-        total = len(arc_B1) + len(arc_B2)
-
-# Decay controller: if no ghost hits for a while, slowly bias toward recency (smaller p)
-def _decay_arc_p_if_idle(now):
-    global arc_p, arc_last_decay_access
-    if arc_capacity is None:
+def _prune_history(cache_snapshot):
+    """Bound history size by trimming oldest non-resident entries."""
+    cap = _cap(cache_snapshot)
+    # Allow history up to 16x capacity; prune conservatively beyond that.
+    limit = max(16 * cap, 64)
+    if len(m_history) <= limit:
         return
-    # Only decay if we've had no ghost hits for at least one cache of accesses
-    idle = now - arc_last_ghost_hit_access
-    step_interval = max(1, arc_capacity // 8)
-    if idle >= arc_capacity and (now - arc_last_decay_access) >= step_interval:
-        arc_p = max(0, arc_p - 1)
-        arc_last_decay_access = now
-
-
-def _resync(cache_snapshot):
-    # Ensure resident metadata tracks actual cache content
-    cache_keys = set(cache_snapshot.cache.keys())
-    for k in list(arc_T1.keys()):
-        if k not in cache_keys:
-            arc_T1.pop(k, None)
-    for k in list(arc_T2.keys()):
-        if k not in cache_keys:
-            arc_T2.pop(k, None)
-    # Add any cached keys we missed to T1 as recent
-    for k in cache_keys:
-        if k not in arc_T1 and k not in arc_T2:
-            arc_T1[k] = True
-    _trim_ghosts()
+    resident = set(cache_snapshot.cache.keys())
+    # Build a list of non-resident entries with their last_ts (older first)
+    victims = []
+    for k, (last, prev) in m_history.items():
+        if k not in resident:
+            # Treat missing timestamps as very old
+            victims.append((last if last is not None else -1, k))
+    # Remove up to the overflow amount from the oldest non-resident histories
+    overflow = len(m_history) - limit
+    if overflow <= 0 or not victims:
+        return
+    victims.sort(key=lambda x: x[0])  # oldest first
+    for i in range(min(overflow, len(victims))):
+        _, k = victims[i]
+        m_history.pop(k, None)
 
 
 def evict(cache_snapshot, obj):
     '''
-    This function defines how the algorithm chooses the eviction victim.
-    - Args:
-        - `cache_snapshot`: A snapshot of the current cache state.
-        - `obj`: The new object that needs to be inserted into the cache.
-    - Return:
-        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
+    Choose eviction victim using LRU-2 with CRP:
+    - Prefer keys without a second distinct reference (cold).
+    - Otherwise, pick the one with the largest backward 2nd-reference distance.
+    - Tie-break by older last reference.
     '''
-    _ensure_capacity(cache_snapshot)
-    _resync(cache_snapshot)
-    # ARC replacement: choose between T1 and T2 depending on arc_p and ghost hit type
-    x_in_B2 = obj.key in arc_B2
-    t1_sz = len(arc_T1)
-    candidate = None
-    if t1_sz >= 1 and (t1_sz > arc_p or (x_in_B2 and t1_sz == arc_p)):
-        # Evict LRU from T1
-        candidate = next(iter(arc_T1)) if arc_T1 else None
-    else:
-        # Evict LRU from T2
-        candidate = next(iter(arc_T2)) if arc_T2 else None
-    if candidate is None:
-        # Fallback: choose the oldest by timestamp if available, else any key
-        if m_key_timestamp:
-            min_ts = min(m_key_timestamp.get(k, float('inf')) for k in cache_snapshot.cache.keys())
-            for k in cache_snapshot.cache.keys():
-                if m_key_timestamp.get(k, float('inf')) == min_ts:
-                    candidate = k
-                    break
-        if candidate is None and cache_snapshot.cache:
-            candidate = next(iter(cache_snapshot.cache.keys()))
-    return candidate
+    now = cache_snapshot.access_count
+    cache_keys = cache_snapshot.cache.keys()
+    if not cache_keys:
+        return None
+
+    # Select victim by maximizing the tuple: (is_cold, k_distance, last_age)
+    # where:
+    #   is_cold = 1 if prev_ts is None else 0
+    #   k_distance = inf if prev_ts is None else now - prev_ts
+    #   last_age = now - last_ts
+    best_key = None
+    best_tuple = (float('-inf'), float('-inf'), float('-inf'))
+
+    for k in cache_keys:
+        last, prev = m_history.get(k, (None, None))
+        # Compute components
+        is_cold = 1 if prev is None else 0
+        if prev is None:
+            k_distance = float('inf')
+        else:
+            k_distance = now - prev
+        if last is None:
+            last_age = float('inf')
+        else:
+            last_age = now - last
+
+        candidate = (is_cold, k_distance, last_age)
+        if candidate > best_tuple:
+            best_tuple = candidate
+            best_key = k
+
+    # Fallback (should not trigger, but keep for robustness)
+    if best_key is None:
+        best_key = next(iter(cache_snapshot.cache.keys()))
+    return best_key
 
 
 def update_after_hit(cache_snapshot, obj):
     '''
-    This function defines how the algorithm update the metadata it maintains immediately after a cache hit.
-    - Args:
-        - `cache_snapshot`: A snapshot of the current cache state.
-        - `obj`: The object accessed during the cache hit.
-    - Return: `None`
+    On hit, record a reference with CRP handling.
     '''
-    global m_key_timestamp, cold_streak
-    _ensure_capacity(cache_snapshot)
     now = cache_snapshot.access_count
-    _decay_arc_p_if_idle(now)
-    # Any hit breaks cold streaks
-    cold_streak = 0
-
-    key = obj.key
-    if key in arc_T1:
-        # Delayed promotion: require a second hit within a short window
-        last = t1_pending.get(key)
-        if last is not None and now - last <= _pending_window():
-            arc_T1.pop(key, None)
-            t1_pending.pop(key, None)
-            _move_to_mru(arc_T2, key)
-        else:
-            _move_to_mru(arc_T1, key)
-            t1_pending[key] = now
-    elif key in arc_T2:
-        _move_to_mru(arc_T2, key)
-    else:
-        # Metadata drift: protect a hit by placing into T2
-        _move_to_mru(arc_T2, key)
-    # Update timestamp for tie-breaking/fallback
-    m_key_timestamp[key] = now
+    crp = _crp_window(cache_snapshot)
+    _update_history_for_ref(now, obj.key, crp)
+    _prune_history(cache_snapshot)
 
 
 def update_after_insert(cache_snapshot, obj):
     '''
-    This function defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
-    - Args:
-        - `cache_snapshot`: A snapshot of the current cache state.
-        - `obj`: The object that was just inserted into the cache.
-    - Return: `None`
+    After insert (which follows a miss), count it as a reference.
+    This links consecutive misses to a key into the LRU-2 history across evictions.
     '''
-    global m_key_timestamp, arc_p, arc_last_ghost_hit_access, cold_streak
-    _ensure_capacity(cache_snapshot)
     now = cache_snapshot.access_count
-    _decay_arc_p_if_idle(now)
-    key = obj.key
-    step_cap = max(1, (arc_capacity if arc_capacity is not None else 1) // 8)
-
-    # ARC admission policy
-    if key in arc_B1:
-        # Previously evicted from T1: favor recency by increasing p
-        raw = max(1, len(arc_B2) // max(1, len(arc_B1)))
-        inc = min(step_cap, raw)
-        arc_p = min(arc_capacity, arc_p + inc)
-        arc_B1.pop(key, None)
-        _move_to_mru(arc_T2, key)
-        arc_last_ghost_hit_access = now
-        cold_streak = 0
-    elif key in arc_B2:
-        # Previously frequent: favor frequency by decreasing p
-        raw = max(1, len(arc_B1) // max(1, len(arc_B2)))
-        dec = min(step_cap, raw)
-        arc_p = max(0, arc_p - dec)
-        arc_B2.pop(key, None)
-        _move_to_mru(arc_T2, key)
-        arc_last_ghost_hit_access = now
-        cold_streak = 0
-    else:
-        # Brand new: insert into T1 (recent)
-        _move_to_mru(arc_T1, key)
-        cold_streak += 1
-        # Scan clamp: on long cold streaks, bias toward recency by reducing p
-        if arc_capacity is not None and cold_streak > arc_capacity:
-            arc_p = max(0, arc_p - max(1, arc_capacity // 4))
-            # Keep pending hints conservative after clamp
-            t1_pending.clear()
-            cold_streak = 0
-
-    _trim_ghosts()
-    m_key_timestamp[key] = now
+    crp = _crp_window(cache_snapshot)
+    _update_history_for_ref(now, obj.key, crp)
+    _prune_history(cache_snapshot)
 
 
 def update_after_evict(cache_snapshot, obj, evicted_obj):
     '''
-    This function defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
-    - Args:
-        - `cache_snapshot`: A snapshot of the current cache state.
-        - `obj`: The object to be inserted into the cache.
-        - `evicted_obj`: The object that was just evicted from the cache.
-    - Return: `None`
+    We keep histories across evictions to recognize returning items.
+    Only prune history opportunistically to bound memory.
     '''
-    global m_key_timestamp
-    _ensure_capacity(cache_snapshot)
-    k = evicted_obj.key
-    # Move evicted resident to corresponding ghost list
-    if k in arc_T1:
-        arc_T1.pop(k, None)
-        _move_to_mru(arc_B1, k)
-    elif k in arc_T2:
-        arc_T2.pop(k, None)
-        _move_to_mru(arc_B2, k)
-    else:
-        # Unknown membership: default to B1
-        _move_to_mru(arc_B1, k)
-    # Clean up metadata for evicted item
-    m_key_timestamp.pop(k, None)
-    t1_pending.pop(k, None)
-    _trim_ghosts()
+    _prune_history(cache_snapshot)
 
 # EVOLVE-BLOCK-END
 
 # This part remains fixed (not evolved)
 def run_caching(trace_path: str, copy_code_dst: str):
     """Run the caching algorithm on a trace"""
     import os
     with open(os.path.abspath(__file__), 'r', encoding="utf-8") as f:
         code_str = f.read()
     with open(os.path.join(copy_code_dst), 'w') as f:
         f.write(code_str)
     from cache_utils import Cache, CacheConfig, CacheObj, Trace
     trace = Trace(trace_path=trace_path)
     cache_capacity = max(int(trace.get_ndv() * 0.1), 1)
     cache = Cache(CacheConfig(cache_capacity))
     for entry in trace.entries:
         obj = CacheObj(key=str(entry.key))
         cache.get(obj)
     with open(copy_code_dst, 'w') as f:
         f.write("")
     hit_rate = round(cache.hit_count / cache.access_count, 6)
     return hit_rate