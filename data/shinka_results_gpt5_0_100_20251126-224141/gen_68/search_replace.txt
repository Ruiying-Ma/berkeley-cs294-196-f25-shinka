<NAME>
arc_replace_ghost_adjust_scan_bias
</NAME>

<DESCRIPTION>
I move the ARC target parameter p adaptation (on B1/B2 ghost hits) from update_after_insert into evict before running the REPLACE decision, which aligns with canonical ARC and prevents double-stepping. I also add scan-aware bias directly in evict: during sustained cold streaks of brand-new keys, gently reduce p and prefer evicting from T1 to protect T2, improving resilience to scans. Finally, I strengthen fallback victim selection to probe resident T1/T2 lists with ghost hints instead of scanning arbitrary cache dict order, reducing the chance of evicting frequently reused items. The insert path is simplified to only handle placement (T1 for brand new, T2 for ghost hits) without altering p, avoiding conflicting updates. This should lower miss rate across mixed workloads by making adaptation faster, more stable, and less prone to T2 pollution under scans, while keeping the benefits observed in the current code (ghost budget and scan-aware insertion behavior).
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
def evict(cache_snapshot, obj):
    '''
    This function defines how the algorithm chooses the eviction victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    _ensure_capacity(cache_snapshot)
    _resync(cache_snapshot)
    _decay_p_if_idle(cache_snapshot)

    # ARC replacement: choose between T1 and T2 depending on arc_p and ghost hit type
    x_in_B2 = obj.key in arc_B2
    t1_sz = len(arc_T1)
    candidate = None
    if t1_sz >= 1 and (t1_sz > arc_p or (x_in_B2 and t1_sz == arc_p)):
        # Evict LRU from T1
        candidate = next(iter(arc_T1)) if arc_T1 else None
    else:
        # Evict LRU from T2
        candidate = next(iter(arc_T2)) if arc_T2 else None

    if candidate is None:
        # Ghost-informed fallback:
        # 1) Prefer evicting a cached key present in B1 (recency-only history)
        for k in cache_snapshot.cache.keys():
            if k in arc_B1:
                candidate = k
                break
        # 2) Otherwise prefer any key not hinted as frequent (not in B2)
        if candidate is None:
            for k in cache_snapshot.cache.keys():
                if k not in arc_B2:
                    candidate = k
                    break
        # 3) Timestamp tie-breaker
        if candidate is None and m_key_timestamp:
            min_ts = min(m_key_timestamp.get(k, float('inf')) for k in cache_snapshot.cache.keys())
            for k in cache_snapshot.cache.keys():
                if m_key_timestamp.get(k, float('inf')) == min_ts:
                    candidate = k
                    break
        # 4) Last resort: arbitrary
        if candidate is None and cache_snapshot.cache:
            candidate = next(iter(cache_snapshot.cache.keys()))
    return candidate
=======
def evict(cache_snapshot, obj):
    '''
    This function defines how the algorithm chooses the eviction victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    global arc_p, last_ghost_hit_access, cold_streak
    _ensure_capacity(cache_snapshot)
    _resync(cache_snapshot)
    _decay_p_if_idle(cache_snapshot)

    # Ghost-driven p updates BEFORE REPLACE (canonical ARC)
    key = obj.key
    C = arc_capacity if arc_capacity else 1
    in_B1 = key in arc_B1
    in_B2 = key in arc_B2
    if in_B1:
        step = max(1, len(arc_B2) // max(1, len(arc_B1)))
        arc_p = min(C, arc_p + min(step, max(1, C // 8)))
        last_ghost_hit_access = cache_snapshot.access_count
        cold_streak = 0
    elif in_B2:
        step = max(1, len(arc_B1) // max(1, len(arc_B2)))
        dec_cap = max(1, (C // 4) if cold_streak >= max(1, C // 2) else (C // 8))
        arc_p = max(0, arc_p - min(step, dec_cap))
        last_ghost_hit_access = cache_snapshot.access_count
        cold_streak = 0
    else:
        # Brand-new key: during scan streaks, gently bias toward smaller p
        if cold_streak >= max(1, C // 2):
            arc_p = max(0, arc_p - max(1, C // 8))

    # ARC REPLACE with scan bias: prefer T1 when we are in a scan streak
    t1_sz = len(arc_T1)
    candidate = None
    if cold_streak >= max(1, C // 2) and t1_sz > 0:
        candidate = next(iter(arc_T1))
    else:
        if t1_sz >= 1 and (t1_sz > arc_p or (in_B2 and t1_sz == arc_p)):
            # Evict LRU from T1
            candidate = next(iter(arc_T1)) if arc_T1 else None
        else:
            # Evict LRU from T2
            candidate = next(iter(arc_T2)) if arc_T2 else None

    # Strengthened, ghost-informed fallback selection when chosen list is empty
    if candidate is None:
        # 1) Prefer T1 LRU not hinted as frequent (not in B2)
        for k in list(arc_T1.keys()):
            if k not in arc_B2:
                candidate = k
                break
    if candidate is None:
        # 2) Prefer T2 LRU that shows up in B1 (recency-only hint)
        for k in list(arc_T2.keys()):
            if k in arc_B1:
                candidate = k
                break
    if candidate is None:
        # 3) Scan a small budget from T1 then T2 to avoid B2-hinted keys
        budget = max(1, C // 16)
        cnt = 0
        for k in arc_T1.keys():
            if k not in arc_B2:
                candidate = k
                break
            cnt += 1
            if cnt >= budget:
                break
        if candidate is None:
            cnt = 0
            for k in arc_T2.keys():
                if k in arc_B1:
                    candidate = k
                    break
                cnt += 1
                if cnt >= budget:
                    break
    if candidate is None and m_key_timestamp:
        # 4) Timestamp tie-breaker
        min_ts = float('inf')
        min_k = None
        for k in cache_snapshot.cache.keys():
            ts = m_key_timestamp.get(k, float('inf'))
            if ts < min_ts:
                min_ts = ts
                min_k = k
        candidate = min_k
    if candidate is None and cache_snapshot.cache:
        # 5) Last resort: arbitrary
        candidate = next(iter(cache_snapshot.cache.keys()))
    return candidate
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    global m_key_timestamp, arc_p, last_ghost_hit_access, cold_streak
    _ensure_capacity(cache_snapshot)
    _decay_p_if_idle(cache_snapshot)

    key = obj.key
    # ARC admission policy with capped p updates and scan-aware handling
    if key in arc_B1:
        # Previously evicted from T1: favor recency by increasing p (capped)
        inc_ratio = max(1, len(arc_B2) // max(1, len(arc_B1)))
        inc_cap = max(1, arc_capacity // 8)
        arc_p = min(arc_capacity, arc_p + min(inc_ratio, inc_cap))
        last_ghost_hit_access = cache_snapshot.access_count
        cold_streak = 0
        arc_B1.pop(key, None)
        arc_B2.pop(key, None)  # keep ghosts disjoint
        _move_to_mru(arc_T2, key)
    elif key in arc_B2:
        # Previously frequent: favor frequency by decreasing p (asymmetric cap under scans)
        dec_ratio = max(1, len(arc_B1) // max(1, len(arc_B2)))
        scan_threshold = max(1, arc_capacity // 2)
        dec_cap = max(1, (arc_capacity // 4) if cold_streak >= scan_threshold else (arc_capacity // 8))
        arc_p = max(0, arc_p - min(dec_ratio, dec_cap))
        last_ghost_hit_access = cache_snapshot.access_count
        cold_streak = 0
        arc_B2.pop(key, None)
        arc_B1.pop(key, None)
        _move_to_mru(arc_T2, key)
    else:
        # Brand new: insert into T1; during scans, insert at LRU to reduce pollution and push p down
        cold_streak += 1
        if cold_streak >= max(1, arc_capacity // 2):
            _insert_at_lru(arc_T1, key)
            # Accelerate recovery from frequency bias during scans
            arc_p = max(0, arc_p - max(1, arc_capacity // 8))
        else:
            _move_to_mru(arc_T1, key)
        # Ensure ghosts are disjoint from residents
        arc_B1.pop(key, None)
        arc_B2.pop(key, None)

    _trim_ghosts()
    m_key_timestamp[key] = cache_snapshot.access_count
=======
def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    global m_key_timestamp, cold_streak
    _ensure_capacity(cache_snapshot)
    _decay_p_if_idle(cache_snapshot)

    key = obj.key
    # ARC admission policy: ghost hits go to T2 (p already adjusted in evict)
    if key in arc_B1 or key in arc_B2:
        cold_streak = 0
        arc_B1.pop(key, None)
        arc_B2.pop(key, None)  # keep ghosts disjoint
        _move_to_mru(arc_T2, key)
    else:
        # Brand new: insert into T1; during scans, insert at LRU to reduce pollution
        cold_streak += 1
        if cold_streak >= max(1, arc_capacity // 2):
            _insert_at_lru(arc_T1, key)
        else:
            _move_to_mru(arc_T1, key)
        # Ensure ghosts are disjoint from residents
        arc_B1.pop(key, None)
        arc_B2.pop(key, None)

    _trim_ghosts()
    m_key_timestamp[key] = cache_snapshot.access_count
>>>>>>> REPLACE

</DIFF>