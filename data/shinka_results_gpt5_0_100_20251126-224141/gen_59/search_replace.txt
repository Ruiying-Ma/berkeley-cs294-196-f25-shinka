<NAME>
arc_p_in_evict_scan_guard
</NAME>

<DESCRIPTION>
I move the adaptive parameter updates (p) for ARC into evict so the REPLACE decision reflects the latest ghost signals, preventing double-stepping that previously happened in update_after_insert. I also add a lightweight, time-bounded scan guard that biases eviction toward T1 during detected cold streaks while gently nudging p downward to protect T2 from scan pollution. To strengthen robustness across workloads, I expand the ghost history budget to 2Ã—capacity (canonical ARC) and improve fallback victim selection to prefer recency-only items and avoid evicting keys hinted as frequent in B2.

Additionally, I reset the scan guard on any hit (reuse signal), keep ghost lists disjoint, and simplify update_after_insert so that ghost hits are inserted into T2 without modifying p there. These changes stabilize adaptation, reduce misses in scan-heavy traces, and preserve strong performance on reuse-heavy traces.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
# Idle tracking for gentle scan recovery
last_ghost_hit_access = -1  # last access_count when B1/B2 was hit
# Scan detection counter: consecutive brand-new inserts (no ghost)
cold_streak = 0
=======
# Idle tracking for gentle scan recovery
last_ghost_hit_access = -1  # last access_count when B1/B2 was hit
# Scan detection counter: consecutive brand-new inserts (no ghost)
cold_streak = 0
# Short window to bias REPLACE during detected scans
scan_guard_until = -1
>>>>>>> REPLACE

</DIFF>

<DIFF>
<<<<<<< SEARCH
def _trim_ghosts():
    # Keep ghosts total size within capacity (matches best baseline)
    total = len(arc_B1) + len(arc_B2)
    cap = arc_capacity if arc_capacity is not None else 1
    while total > cap:
        # Evict from the larger ghost list first
        if len(arc_B1) >= len(arc_B2):
            _pop_lru(arc_B1)
        else:
            _pop_lru(arc_B2)
        total = len(arc_B1) + len(arc_B2)
=======
def _trim_ghosts():
    # Keep ghosts total size within 2x capacity (canonical ARC budget)
    total = len(arc_B1) + len(arc_B2)
    cap = (arc_capacity if arc_capacity is not None else 1) * 2
    while total > cap:
        # Evict from the larger ghost list first
        if len(arc_B1) >= len(arc_B2):
            _pop_lru(arc_B1)
        else:
            _pop_lru(arc_B2)
        total = len(arc_B1) + len(arc_B2)
>>>>>>> REPLACE

</DIFF>

<DIFF>
<<<<<<< SEARCH
def evict(cache_snapshot, obj):
    '''
    This function defines how the algorithm chooses the eviction victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    _ensure_capacity(cache_snapshot)
    _resync(cache_snapshot)
    _decay_p_if_idle(cache_snapshot)

    # ARC replacement: choose between T1 and T2 depending on arc_p and ghost hit type
    x_in_B2 = obj.key in arc_B2
    t1_sz = len(arc_T1)
    candidate = None
    if t1_sz >= 1 and (t1_sz > arc_p or (x_in_B2 and t1_sz == arc_p)):
        # Evict LRU from T1
        candidate = next(iter(arc_T1)) if arc_T1 else None
    else:
        # Evict LRU from T2
        candidate = next(iter(arc_T2)) if arc_T2 else None

    if candidate is None:
        # Ghost-informed fallback:
        # 1) Prefer evicting a cached key present in B1 (recency-only history)
        for k in cache_snapshot.cache.keys():
            if k in arc_B1:
                candidate = k
                break
        # 2) Otherwise prefer any key not hinted as frequent (not in B2)
        if candidate is None:
            for k in cache_snapshot.cache.keys():
                if k not in arc_B2:
                    candidate = k
                    break
        # 3) Timestamp tie-breaker
        if candidate is None and m_key_timestamp:
            min_ts = min(m_key_timestamp.get(k, float('inf')) for k in cache_snapshot.cache.keys())
            for k in cache_snapshot.cache.keys():
                if m_key_timestamp.get(k, float('inf')) == min_ts:
                    candidate = k
                    break
        # 4) Last resort: arbitrary
        if candidate is None and cache_snapshot.cache:
            candidate = next(iter(cache_snapshot.cache.keys()))
    return candidate
=======
def evict(cache_snapshot, obj):
    '''
    This function defines how the algorithm chooses the eviction victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    global arc_p, last_ghost_hit_access, scan_guard_until
    _ensure_capacity(cache_snapshot)
    _resync(cache_snapshot)
    _decay_p_if_idle(cache_snapshot)

    # Adjust ARC p based on ghost hits BEFORE replacement (canonical ARC behavior)
    key = obj.key
    in_B1 = key in arc_B1
    in_B2 = key in arc_B2
    C = arc_capacity if arc_capacity else 1
    if in_B1:
        step = max(1, len(arc_B2) // max(1, len(arc_B1)))
        arc_p = min(C, arc_p + min(step, max(1, C // 8)))
        last_ghost_hit_access = cache_snapshot.access_count
        # reuse signal: cancel any scan guard
        scan_guard_until = -1
    elif in_B2:
        step = max(1, len(arc_B1) // max(1, len(arc_B2)))
        dec_cap = max(1, (C // 4) if cold_streak >= max(1, C // 2) else (C // 8))
        arc_p = max(0, arc_p - min(step, dec_cap))
        last_ghost_hit_access = cache_snapshot.access_count
        scan_guard_until = -1
    else:
        # Scan-aware protection for bursts of brand-new keys
        if cold_streak >= max(1, C // 2):
            scan_guard_until = max(scan_guard_until, cache_snapshot.access_count + max(1, C // 8))
            # Gently bias toward smaller p to protect T2
            arc_p = max(0, arc_p - max(1, C // 8))

    # ARC REPLACE with scan guard
    t1_sz = len(arc_T1)
    candidate = None
    if scan_guard_until != -1 and cache_snapshot.access_count < scan_guard_until and t1_sz > 0:
        # During scan guard window: prefer evicting from T1
        candidate = next(iter(arc_T1))
    else:
        if t1_sz >= 1 and (t1_sz > arc_p or (in_B2 and t1_sz == arc_p)):
            candidate = next(iter(arc_T1)) if arc_T1 else None
        else:
            candidate = next(iter(arc_T2)) if arc_T2 else None

    # Strengthened fallback selection when chosen list is empty
    if candidate is None:
        # 1) Prefer T1 LRU not hinted as frequent (not in B2)
        for k in list(arc_T1.keys()):
            if k not in arc_B2:
                candidate = k
                break
    if candidate is None:
        # 2) Prefer T2 LRU that shows up in B1 (recency-only hint)
        for k in list(arc_T2.keys()):
            if k in arc_B1:
                candidate = k
                break
    if candidate is None:
        # 3) Scan a small budget from T1 then T2 to avoid B2-hinted keys
        budget = max(1, C // 16)
        cnt = 0
        for k in arc_T1.keys():
            if k not in arc_B2:
                candidate = k
                break
            cnt += 1
            if cnt >= budget:
                break
        if candidate is None:
            cnt = 0
            for k in arc_T2.keys():
                if k in arc_B1:
                    candidate = k
                    break
                cnt += 1
                if cnt >= budget:
                    break
    if candidate is None:
        # 4) Timestamp tie-breaker
        if m_key_timestamp:
            min_ts = float('inf')
            min_k = None
            for k in cache_snapshot.cache.keys():
                ts = m_key_timestamp.get(k, float('inf'))
                if ts < min_ts:
                    min_ts = ts
                    min_k = k
            candidate = min_k
    if candidate is None and cache_snapshot.cache:
        # 5) Last resort: arbitrary
        candidate = next(iter(cache_snapshot.cache.keys()))
    return candidate
>>>>>>> REPLACE

</DIFF>

<DIFF>
<<<<<<< SEARCH
def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the algorithm update the metadata it maintains immediately after a cache hit.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    global m_key_timestamp, cold_streak
    _ensure_capacity(cache_snapshot)
    _decay_p_if_idle(cache_snapshot)

    # ARC: on hit, move to T2 MRU
    key = obj.key
    if key in arc_T1:
        arc_T1.pop(key, None)
        _move_to_mru(arc_T2, key)
    else:
        # If already in T2, refresh; if not present due to drift, place in T2
        if key in arc_T2:
            _move_to_mru(arc_T2, key)
        else:
            _move_to_mru(arc_T2, key)
    # Resident keys must not exist in ghosts
    arc_B1.pop(key, None)
    arc_B2.pop(key, None)
    # Any hit breaks a cold streak
    cold_streak = 0
    # Update timestamp for tie-breaking/fallback
    m_key_timestamp[key] = cache_snapshot.access_count
=======
def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the algorithm update the metadata it maintains immediately after a cache hit.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    global m_key_timestamp, cold_streak, scan_guard_until
    _ensure_capacity(cache_snapshot)
    _decay_p_if_idle(cache_snapshot)

    # ARC: on hit, move to T2 MRU
    key = obj.key
    if key in arc_T1:
        arc_T1.pop(key, None)
        _move_to_mru(arc_T2, key)
    else:
        # If already in T2, refresh; if not present due to drift, place in T2
        if key in arc_T2:
            _move_to_mru(arc_T2, key)
        else:
            _move_to_mru(arc_T2, key)
    # Resident keys must not exist in ghosts
    arc_B1.pop(key, None)
    arc_B2.pop(key, None)
    # Any hit breaks a cold streak and cancels scan guard
    cold_streak = 0
    scan_guard_until = -1
    # Update timestamp for tie-breaking/fallback
    m_key_timestamp[key] = cache_snapshot.access_count
>>>>>>> REPLACE

</DIFF>

<DIFF>
<<<<<<< SEARCH
def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    global m_key_timestamp, arc_p, last_ghost_hit_access, cold_streak
    _ensure_capacity(cache_snapshot)
    _decay_p_if_idle(cache_snapshot)

    key = obj.key
    # ARC admission policy with capped p updates and scan-aware handling
    if key in arc_B1:
        # Previously evicted from T1: favor recency by increasing p (capped)
        inc_ratio = max(1, len(arc_B2) // max(1, len(arc_B1)))
        inc_cap = max(1, arc_capacity // 8)
        arc_p = min(arc_capacity, arc_p + min(inc_ratio, inc_cap))
        last_ghost_hit_access = cache_snapshot.access_count
        cold_streak = 0
        arc_B1.pop(key, None)
        arc_B2.pop(key, None)  # keep ghosts disjoint
        _move_to_mru(arc_T2, key)
    elif key in arc_B2:
        # Previously frequent: favor frequency by decreasing p (asymmetric cap under scans)
        dec_ratio = max(1, len(arc_B1) // max(1, len(arc_B2)))
        scan_threshold = max(1, arc_capacity // 2)
        dec_cap = max(1, (arc_capacity // 4) if cold_streak >= scan_threshold else (arc_capacity // 8))
        arc_p = max(0, arc_p - min(dec_ratio, dec_cap))
        last_ghost_hit_access = cache_snapshot.access_count
        cold_streak = 0
        arc_B2.pop(key, None)
        arc_B1.pop(key, None)
        _move_to_mru(arc_T2, key)
    else:
        # Brand new: insert into T1; during scans, insert at LRU to reduce pollution and push p down
        cold_streak += 1
        if cold_streak >= max(1, arc_capacity // 2):
            _insert_at_lru(arc_T1, key)
            # Accelerate recovery from frequency bias during scans
            arc_p = max(0, arc_p - max(1, arc_capacity // 8))
        else:
            _move_to_mru(arc_T1, key)
        # Ensure ghosts are disjoint from residents
        arc_B1.pop(key, None)
        arc_B2.pop(key, None)

    _trim_ghosts()
    m_key_timestamp[key] = cache_snapshot.access_count
=======
def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    global m_key_timestamp, cold_streak
    _ensure_capacity(cache_snapshot)
    _decay_p_if_idle(cache_snapshot)

    key = obj.key
    # ARC admission policy: on ghost hit, insert into T2 (p already adjusted in evict)
    if key in arc_B1 or key in arc_B2:
        cold_streak = 0
        arc_B1.pop(key, None)
        arc_B2.pop(key, None)  # keep ghosts disjoint
        _move_to_mru(arc_T2, key)
    else:
        # Brand new: insert into T1; during scans, insert at LRU to reduce pollution
        cold_streak += 1
        if cold_streak >= max(1, arc_capacity // 2):
            _insert_at_lru(arc_T1, key)
        else:
            _move_to_mru(arc_T1, key)
        # Ensure ghosts are disjoint from residents
        arc_B1.pop(key, None)
        arc_B2.pop(key, None)

    _trim_ghosts()
    m_key_timestamp[key] = cache_snapshot.access_count
>>>>>>> REPLACE

</DIFF>