<NAME>
arc_p_decay_and_scan_clamp
</NAME>

<DESCRIPTION>
I strengthen the ARC-based policy by adding three targeted improvements:

1) Reintroduce and use p-decay and scan clamp: If there are long periods without ghost hits (a sign of streaming), decay p gently; and if there is a long streak of brand-new misses, push p down faster. This reduces cache pollution on scans and improves adaptability.

2) Make p adjustments more responsive but stable: Increase the step cap for p updates from capacity//16 to capacity//8 to react faster to workload shifts without overshooting.

3) Consistency and responsiveness on fast paths: Call decay_p_if_idle in evict and update_after_{hit,insert}; reset cold_streak on hits and ghost-informed inserts. This keeps the policy stable and prevents stale state from biasing decisions.

These changes improve miss rates in mixed and scan-heavy workloads while preserving standard ARC behavior, ghost-driven adaptation, and robustness.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    @classmethod
    def on_insert(cls, cache_snapshot, key):
        # Adjust ARC target p using ghost hints (damped), then admit
        step_cap = max(1, cls.capacity // 16)  # gentler cap to avoid overshoot
        if key in cls.B1:
            # Favor recency: increase p
            inc = max(1, len(cls.B2) // max(1, len(cls.B1)))
            cls.p = min(cls.capacity, cls.p + min(inc, step_cap))
            cls.last_ghost_hit_access = cache_snapshot.access_count
            cls.B1.pop(key, None)
            cls.B2.pop(key, None)  # keep ghosts disjoint
            # On return, insert to T2 (has shown reuse)
            cls.move_to_mru(cls.T2, key)
        elif key in cls.B2:
            # Favor frequency: decrease p
            dec = max(1, len(cls.B1) // max(1, len(cls.B2)))
            cls.p = max(0, cls.p - min(dec, step_cap))
            cls.last_ghost_hit_access = cache_snapshot.access_count
            cls.B2.pop(key, None)
            cls.B1.pop(key, None)  # keep ghosts disjoint
            cls.move_to_mru(cls.T2, key)
        else:
            # Brand-new: insert into T1 (probationary)
            cls.move_to_mru(cls.T1, key)
            # Ensure ghosts are disjoint from residents
            cls.B1.pop(key, None)
            cls.B2.pop(key, None)

        cls.ts[key] = cache_snapshot.access_count
        cls.trim_ghosts()
        # Light consistency guard
        if (len(cls.T1) + len(cls.T2)) != len(cache_snapshot.cache):
            cls.resync(cache_snapshot)
=======
    @classmethod
    def on_insert(cls, cache_snapshot, key):
        # Adjust ARC target p using ghost hints (damped), then admit
        step_cap = max(1, cls.capacity // 8)  # slightly faster adaptation without overshoot
        if key in cls.B1:
            # Favor recency: increase p
            inc = max(1, len(cls.B2) // max(1, len(cls.B1)))
            cls.p = min(cls.capacity, cls.p + min(inc, step_cap))
            cls.last_ghost_hit_access = cache_snapshot.access_count
            cls.cold_streak = 0
            cls.B1.pop(key, None)
            cls.B2.pop(key, None)  # keep ghosts disjoint
            # On return, insert to T2 (has shown reuse)
            cls.move_to_mru(cls.T2, key)
        elif key in cls.B2:
            # Favor frequency: decrease p
            dec = max(1, len(cls.B1) // max(1, len(cls.B2)))
            cls.p = max(0, cls.p - min(dec, step_cap))
            cls.last_ghost_hit_access = cache_snapshot.access_count
            cls.cold_streak = 0
            cls.B2.pop(key, None)
            cls.B1.pop(key, None)  # keep ghosts disjoint
            cls.move_to_mru(cls.T2, key)
        else:
            # Brand-new: insert into T1 (probationary)
            cls.move_to_mru(cls.T1, key)
            # Scan clamp: prolonged cold stream -> push p down
            cls.cold_streak += 1
            if cls.cold_streak > cls.capacity:
                cls.p = max(0, cls.p - max(1, cls.capacity // 4))
            # Ensure ghosts are disjoint from residents
            cls.B1.pop(key, None)
            cls.B2.pop(key, None)

        cls.ts[key] = cache_snapshot.access_count
        cls.trim_ghosts()
        # Light consistency guard
        if (len(cls.T1) + len(cls.T2)) != len(cache_snapshot.cache):
            cls.resync(cache_snapshot)
>>>>>>> REPLACE

</DIFF>

<DIFF>
<<<<<<< SEARCH
    @classmethod
    def on_hit(cls, cache_snapshot, key):
        # Immediate promotion to T2 (standard ARC)
        if key in cls.T1:
            cls.T1.pop(key, None)
            cls.move_to_mru(cls.T2, key)
        elif key in cls.T2:
            cls.move_to_mru(cls.T2, key)
        else:
            # Drift: still a hit; place in T2 to reflect reuse
            cls.move_to_mru(cls.T2, key)
        # Resident keys must not exist in ghosts
        cls.B1.pop(key, None)
        cls.B2.pop(key, None)
        # Update timestamp
        cls.ts[key] = cache_snapshot.access_count
=======
    @classmethod
    def on_hit(cls, cache_snapshot, key):
        # Immediate promotion to T2 (standard ARC)
        if key in cls.T1:
            cls.T1.pop(key, None)
            cls.move_to_mru(cls.T2, key)
        elif key in cls.T2:
            cls.move_to_mru(cls.T2, key)
        else:
            # Drift: still a hit; place in T2 to reflect reuse
            cls.move_to_mru(cls.T2, key)
        # Resident keys must not exist in ghosts
        cls.B1.pop(key, None)
        cls.B2.pop(key, None)
        # Reset cold streak on any hit
        cls.cold_streak = 0
        # Update timestamp
        cls.ts[key] = cache_snapshot.access_count
>>>>>>> REPLACE

</DIFF>

<DIFF>
<<<<<<< SEARCH
def evict(cache_snapshot, obj):
    '''
    This function defines how the algorithm chooses the eviction victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    ARCPlus.ensure_capacity(cache_snapshot)
    # Keep metadata consistent
    if (len(ARCPlus.T1) + len(ARCPlus.T2)) != len(cache_snapshot.cache):
        ARCPlus.resync(cache_snapshot)

    candidate = ARCPlus.choose_victim(obj.key)
    if candidate is not None:
        return candidate
    # Try to repair metadata and retry ARC replacement before falling back
    ARCPlus.resync(cache_snapshot)
    candidate = ARCPlus.choose_victim(obj.key)
    if candidate is not None:
        return candidate
    # Fallback path
    return ARCPlus.fallback_victim(cache_snapshot)
=======
def evict(cache_snapshot, obj):
    '''
    This function defines how the algorithm chooses the eviction victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    ARCPlus.ensure_capacity(cache_snapshot)
    # Keep metadata consistent
    if (len(ARCPlus.T1) + len(ARCPlus.T2)) != len(cache_snapshot.cache):
        ARCPlus.resync(cache_snapshot)
    # Recover from scan-like phases by decaying p if no ghost hits
    ARCPlus.decay_p_if_idle(cache_snapshot)

    candidate = ARCPlus.choose_victim(obj.key)
    if candidate is not None:
        return candidate
    # Try to repair metadata and retry ARC replacement before falling back
    ARCPlus.resync(cache_snapshot)
    candidate = ARCPlus.choose_victim(obj.key)
    if candidate is not None:
        return candidate
    # Fallback path
    return ARCPlus.fallback_victim(cache_snapshot)
>>>>>>> REPLACE

</DIFF>

<DIFF>
<<<<<<< SEARCH
def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the algorithm update the metadata it maintains immediately after a cache hit.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    ARCPlus.ensure_capacity(cache_snapshot)
    ARCPlus.on_hit(cache_snapshot, obj.key)
    # Post-condition consistency (rare)
    if (len(ARCPlus.T1) + len(ARCPlus.T2)) != len(cache_snapshot.cache):
        ARCPlus.resync(cache_snapshot)
=======
def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the algorithm update the metadata it maintains immediately after a cache hit.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    ARCPlus.ensure_capacity(cache_snapshot)
    ARCPlus.decay_p_if_idle(cache_snapshot)
    ARCPlus.on_hit(cache_snapshot, obj.key)
    # Post-condition consistency (rare)
    if (len(ARCPlus.T1) + len(ARCPlus.T2)) != len(cache_snapshot.cache):
        ARCPlus.resync(cache_snapshot)
>>>>>>> REPLACE

</DIFF>

<DIFF>
<<<<<<< SEARCH
def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    ARCPlus.ensure_capacity(cache_snapshot)
    ARCPlus.on_insert(cache_snapshot, obj.key)
=======
def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    ARCPlus.ensure_capacity(cache_snapshot)
    ARCPlus.decay_p_if_idle(cache_snapshot)
    ARCPlus.on_insert(cache_snapshot, obj.key)
>>>>>>> REPLACE

</DIFF>