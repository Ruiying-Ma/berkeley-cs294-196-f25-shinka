--- a/original.py
+++ b/original.py
@@ -1,319 +1,384 @@
 # EVOLVE-BLOCK-START
 """Cache eviction algorithm for optimizing hit rates across multiple workloads"""
 
 from collections import OrderedDict
 
 # LRU timestamp map kept for tie-breaking and fallback
 m_key_timestamp = dict()
 
 # Adaptive Replacement Cache (ARC) metadata
 arc_T1 = OrderedDict()  # recent, resident
 arc_T2 = OrderedDict()  # frequent, resident
 arc_B1 = OrderedDict()  # ghost of T1 (recent history)
 arc_B2 = OrderedDict()  # ghost of T2 (frequent history)
 arc_p = 0               # target size of T1
 arc_capacity = None     # initialized from cache_snapshot
 
 # Idle tracking for gentle scan recovery
 last_ghost_hit_access = -1  # last access_count when B1/B2 was hit
 # Scan detection counter: consecutive brand-new inserts (no ghost)
 cold_streak = 0
+# Scan guard and replacement source tracking
+scan_guard_until = -1       # short bias window for scans
+force_from_T2_once = False  # one-shot demotion bias
+last_replaced_from = None   # 'T1' or 'T2' for ghost routing
 
 
 def _ensure_capacity(cache_snapshot):
     global arc_capacity
     if arc_capacity is None:
         arc_capacity = max(int(cache_snapshot.capacity), 1)
 
 
 def _move_to_mru(od, key):
     # Push key to MRU position of an OrderedDict
     if key in od:
         od.pop(key, None)
     od[key] = True
 
 def _insert_at_lru(od, key):
     # Insert key at LRU position (probation)
     if key in od:
         od.pop(key, None)
     od[key] = True
     try:
         # Move to beginning (LRU side)
         od.move_to_end(key, last=False)
     except Exception:
         # Fallback: ignore if move_to_end isn't available
         pass
 
 
 def _pop_lru(od):
     if od:
         k, _ = od.popitem(last=False)
         return k
     return None
 
 
 def _trim_ghosts():
-    # Keep ghosts total size within capacity (matches best baseline)
+    # Keep ghosts total size within capacity; trim toward split given by arc_p with hysteresis
+    cap = arc_capacity if arc_capacity is not None else 1
+    target_B1 = max(0, min(cap, arc_p))
+    target_B2 = max(0, cap - target_B1)
+    h = max(1, cap // 32)
     total = len(arc_B1) + len(arc_B2)
-    cap = arc_capacity if arc_capacity is not None else 1
     while total > cap:
-        # Evict from the larger ghost list first
-        if len(arc_B1) >= len(arc_B2):
+        excess_B1 = len(arc_B1) - (target_B1 + h)
+        excess_B2 = len(arc_B2) - (target_B2 + h)
+        if excess_B1 > excess_B2 and len(arc_B1) > 0:
             _pop_lru(arc_B1)
+        elif len(arc_B2) > 0 and excess_B2 >= excess_B1:
+            _pop_lru(arc_B2)
         else:
-            _pop_lru(arc_B2)
+            # Otherwise trim the larger side
+            if len(arc_B1) >= len(arc_B2) and arc_B1:
+                _pop_lru(arc_B1)
+            elif arc_B2:
+                _pop_lru(arc_B2)
+            else:
+                break
         total = len(arc_B1) + len(arc_B2)
 
 
 def _resync(cache_snapshot):
     # Ensure resident metadata tracks actual cache content
     cache_keys = set(cache_snapshot.cache.keys())
     for k in list(arc_T1.keys()):
         if k not in cache_keys:
             arc_T1.pop(k, None)
     for k in list(arc_T2.keys()):
         if k not in cache_keys:
             arc_T2.pop(k, None)
     # Any cached keys not tracked: seed using ghost hints for better accuracy
     for k in cache_keys:
         if k not in arc_T1 and k not in arc_T2:
             if k in arc_B2:
                 _move_to_mru(arc_T2, k)
                 arc_B2.pop(k, None)
             elif k in arc_B1:
                 _move_to_mru(arc_T1, k)
                 arc_B1.pop(k, None)
             else:
                 _move_to_mru(arc_T1, k)
     # Keep ghosts disjoint from residents (robustness)
     for k in list(arc_B1.keys()):
         if k in arc_T1 or k in arc_T2:
             arc_B1.pop(k, None)
     for k in list(arc_B2.keys()):
         if k in arc_T1 or k in arc_T2:
             arc_B2.pop(k, None)
     _trim_ghosts()
 
 
 def _decay_p_if_idle(cache_snapshot):
     # If no ghost hits for a while, gently decay p toward 0 to recover from scans
     global arc_p
     if last_ghost_hit_access >= 0:
         idle = cache_snapshot.access_count - last_ghost_hit_access
         if idle > (arc_capacity if arc_capacity else 1) and arc_p > 0:
             arc_p = max(0, arc_p - 1)
 
 
+def _arm_scan_guard_if_needed(now, C):
+    # Short, gentle guard window for suspected scans; avoid rapid oscillation
+    global scan_guard_until
+    window = min(8, max(1, C // 16))
+    if scan_guard_until < now:
+        scan_guard_until = now + window
+
+
+def _effective_p(now, C):
+    # During an active guard window, use a slightly reduced p
+    if scan_guard_until >= now:
+        base_drop = max(1, C // 16)
+        extra = 0
+        half = max(1, C // 2)
+        if cold_streak > half:
+            extra = min(base_drop, 1 + (cold_streak - half) // max(1, C // 16))
+        return max(0, arc_p - max(base_drop, extra))
+    return arc_p
+
+
 def evict(cache_snapshot, obj):
     '''
     This function defines how the algorithm chooses the eviction victim.
     - Args:
         - `cache_snapshot`: A snapshot of the current cache state.
         - `obj`: The new object that needs to be inserted into the cache.
     - Return:
         - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
     '''
-    global arc_p, last_ghost_hit_access, cold_streak
+    global arc_p, last_ghost_hit_access, cold_streak, scan_guard_until
+    global force_from_T2_once, last_replaced_from
     _ensure_capacity(cache_snapshot)
     _resync(cache_snapshot)
     _decay_p_if_idle(cache_snapshot)
 
-    # Ghost-driven p updates BEFORE REPLACE (canonical ARC)
     key = obj.key
     C = arc_capacity if arc_capacity else 1
+    now = cache_snapshot.access_count
     in_B1 = key in arc_B1
     in_B2 = key in arc_B2
+
+    # Canonical ARC p-updates on ghost hits only (no brand-new decrements)
     if in_B1:
-        step = max(1, len(arc_B2) // max(1, len(arc_B1)))
-        arc_p = min(C, arc_p + min(step, max(1, C // 8)))
-        last_ghost_hit_access = cache_snapshot.access_count
+        step_up = (len(arc_B2) + max(1, len(arc_B1)) - 1) // max(1, len(arc_B1))  # ceil(|B2|/|B1|)
+        step_up = min(step_up, max(1, C // 8))
+        arc_p = min(C, arc_p + step_up)
+        last_ghost_hit_access = now
         cold_streak = 0
+        scan_guard_until = -1
+        force_from_T2_once = False
     elif in_B2:
-        step = max(1, len(arc_B1) // max(1, len(arc_B2)))
-        dec_cap = max(1, (C // 4) if cold_streak >= max(1, C // 2) else (C // 8))
-        arc_p = max(0, arc_p - min(step, dec_cap))
-        last_ghost_hit_access = cache_snapshot.access_count
+        step_down = (len(arc_B1) + max(1, len(arc_B2)) - 1) // max(1, len(arc_B2))  # ceil(|B1|/|B2|)
+        step_down = min(step_down, max(1, C // 8))
+        arc_p = max(0, arc_p - step_down)
+        last_ghost_hit_access = now
         cold_streak = 0
-    else:
-        # Brand-new key: during scan streaks, gently bias toward smaller p
-        if cold_streak >= max(1, C // 2):
-            arc_p = max(0, arc_p - max(1, C // 8))
-
-    # ARC REPLACE with scan bias: prefer T1 when we are in a scan streak
+        scan_guard_until = -1
+        force_from_T2_once = False
+    else:
+        # Brand-new: scan guard and one-shot demotion bias
+        cold_streak += 1
+        if cold_streak >= max(1, C // 8):
+            _arm_scan_guard_if_needed(now, C)
+        if scan_guard_until >= now and len(arc_B2) == 0 and len(arc_T2) > len(arc_T1):
+            force_from_T2_once = True
+
+    # Replacement with guard and optional one-shot demotion from T2
+    if force_from_T2_once and arc_T2:
+        cand = next(iter(arc_T2))
+        last_replaced_from = 'T2'
+        force_from_T2_once = False
+        return cand
+
     t1_sz = len(arc_T1)
+    eff_p = _effective_p(now, C)
+    pick_T1 = t1_sz >= 1 and (t1_sz > eff_p or (in_B2 and t1_sz == eff_p))
+
     candidate = None
-    if cold_streak >= max(1, C // 2) and t1_sz > 0:
-        candidate = next(iter(arc_T1))
-    else:
-        if t1_sz >= 1 and (t1_sz > arc_p or (in_B2 and t1_sz == arc_p)):
-            # Evict LRU from T1
-            candidate = next(iter(arc_T1)) if arc_T1 else None
-        else:
-            # Evict LRU from T2
-            candidate = next(iter(arc_T2)) if arc_T2 else None
-
-    # Strengthened, ghost-informed fallback selection when chosen list is empty
+    if pick_T1:
+        candidate = next(iter(arc_T1)) if arc_T1 else None
+    else:
+        candidate = next(iter(arc_T2)) if arc_T2 else None
+
+    # Strengthened fallback probing with bounded scans
     if candidate is None:
-        # 1) Prefer T1 LRU not hinted as frequent (not in B2)
-        for k in list(arc_T1.keys()):
-            if k not in arc_B2:
-                candidate = k
-                break
-    if candidate is None:
-        # 2) Prefer T2 LRU that shows up in B1 (recency-only hint)
-        for k in list(arc_T2.keys()):
-            if k in arc_B1:
-                candidate = k
-                break
-    if candidate is None:
-        # 3) Scan a small budget from T1 then T2 to avoid B2-hinted keys
-        budget = max(1, C // 16)
+        d = min(8, max(1, C // 16))
         cnt = 0
         for k in arc_T1.keys():
             if k not in arc_B2:
                 candidate = k
+                pick_T1 = True
                 break
             cnt += 1
-            if cnt >= budget:
-                break
-        if candidate is None:
-            cnt = 0
-            for k in arc_T2.keys():
-                if k in arc_B1:
-                    candidate = k
-                    break
-                cnt += 1
-                if cnt >= budget:
-                    break
+            if cnt >= d:
+                break
+    if candidate is None:
+        d = min(8, max(1, C // 16))
+        cnt = 0
+        for k in arc_T2.keys():
+            if k in arc_B1:
+                candidate = k
+                pick_T1 = False
+                break
+            cnt += 1
+            if cnt >= d:
+                break
     if candidate is None and m_key_timestamp:
-        # 4) Timestamp tie-breaker
         min_ts = float('inf')
         min_k = None
         for k in cache_snapshot.cache.keys():
             ts = m_key_timestamp.get(k, float('inf'))
             if ts < min_ts:
                 min_ts = ts
                 min_k = k
         candidate = min_k
     if candidate is None and cache_snapshot.cache:
-        # 5) Last resort: arbitrary
         candidate = next(iter(cache_snapshot.cache.keys()))
+
+    # Record source side for ghost routing
+    if candidate in arc_T1:
+        last_replaced_from = 'T1'
+    elif candidate in arc_T2:
+        last_replaced_from = 'T2'
+    else:
+        last_replaced_from = 'T1' if pick_T1 else 'T2'
+
     return candidate
 
 
 def update_after_hit(cache_snapshot, obj):
     '''
     This function defines how the algorithm update the metadata it maintains immediately after a cache hit.
     - Args:
         - `cache_snapshot`: A snapshot of the current cache state.
         - `obj`: The object accessed during the cache hit.
     - Return: `None`
     '''
-    global m_key_timestamp, cold_streak
+    global m_key_timestamp, cold_streak, scan_guard_until, force_from_T2_once
     _ensure_capacity(cache_snapshot)
     _decay_p_if_idle(cache_snapshot)
 
     # ARC: on hit, move to T2 MRU
     key = obj.key
     if key in arc_T1:
         arc_T1.pop(key, None)
         _move_to_mru(arc_T2, key)
     else:
-        # If already in T2, refresh; if not present due to drift, place in T2
-        if key in arc_T2:
-            _move_to_mru(arc_T2, key)
-        else:
-            _move_to_mru(arc_T2, key)
+        _move_to_mru(arc_T2, key)
+
     # Resident keys must not exist in ghosts
     arc_B1.pop(key, None)
     arc_B2.pop(key, None)
-    # Any hit breaks a cold streak
+    # Any hit breaks a cold streak and cancels guard/demotion bias
     cold_streak = 0
+    scan_guard_until = -1
+    force_from_T2_once = False
     # Update timestamp for tie-breaking/fallback
     m_key_timestamp[key] = cache_snapshot.access_count
 
 
 def update_after_insert(cache_snapshot, obj):
     '''
     This function defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
     - Args:
         - `cache_snapshot`: A snapshot of the current cache state.
         - `obj`: The object that was just inserted into the cache.
     - Return: `None`
     '''
-    global m_key_timestamp, cold_streak
+    global m_key_timestamp, cold_streak, scan_guard_until, force_from_T2_once, last_ghost_hit_access
     _ensure_capacity(cache_snapshot)
     _decay_p_if_idle(cache_snapshot)
 
     key = obj.key
+    now = cache_snapshot.access_count
+    C = arc_capacity if arc_capacity else 1
+
     # ARC admission policy: ghost hits go to T2 (p already adjusted in evict)
     if key in arc_B1 or key in arc_B2:
         cold_streak = 0
+        scan_guard_until = -1
+        force_from_T2_once = False
+        last_ghost_hit_access = now
         arc_B1.pop(key, None)
         arc_B2.pop(key, None)  # keep ghosts disjoint
         _move_to_mru(arc_T2, key)
     else:
-        # Brand new: insert into T1; during scans, insert at LRU to reduce pollution
+        # Brand new: insert into T1; during guard, insert at LRU to reduce pollution
         cold_streak += 1
-        if cold_streak >= max(1, arc_capacity // 2):
+        if cold_streak >= max(1, C // 8):
+            _arm_scan_guard_if_needed(now, C)
+        if scan_guard_until >= now:
             _insert_at_lru(arc_T1, key)
         else:
             _move_to_mru(arc_T1, key)
         # Ensure ghosts are disjoint from residents
         arc_B1.pop(key, None)
         arc_B2.pop(key, None)
 
     _trim_ghosts()
-    m_key_timestamp[key] = cache_snapshot.access_count
+    m_key_timestamp[key] = now
 
 
 def update_after_evict(cache_snapshot, obj, evicted_obj):
     '''
     This function defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
     - Args:
         - `cache_snapshot`: A snapshot of the current cache state.
         - `obj`: The object to be inserted into the cache.
         - `evicted_obj`: The object that was just evicted from the cache.
     - Return: `None`
     '''
-    global m_key_timestamp
+    global m_key_timestamp, last_replaced_from
     _ensure_capacity(cache_snapshot)
     k = evicted_obj.key
-    # Move evicted resident to corresponding ghost list
-    if k in arc_T1:
-        arc_T1.pop(k, None)
+
+    # Remove from resident lists if present
+    arc_T1.pop(k, None)
+    arc_T2.pop(k, None)
+
+    # Route to ghost using last_replaced_from for reliability
+    if last_replaced_from == 'T2':
+        arc_B1.pop(k, None)
+        _move_to_mru(arc_B2, k)
+    elif last_replaced_from == 'T1':
+        arc_B2.pop(k, None)
         _move_to_mru(arc_B1, k)
-        arc_B2.pop(k, None)
-    elif k in arc_T2:
-        arc_T2.pop(k, None)
-        _move_to_mru(arc_B2, k)
-        arc_B1.pop(k, None)
-    else:
-        # Unknown membership: default to B1
-        _move_to_mru(arc_B1, k)
-        arc_B2.pop(k, None)
+    else:
+        # Fallback to membership-based default (T1â†’B1, else B2)
+        if k in arc_T2:
+            arc_T2.pop(k, None)
+            arc_B1.pop(k, None)
+            _move_to_mru(arc_B2, k)
+        else:
+            arc_T1.pop(k, None)
+            arc_B2.pop(k, None)
+            _move_to_mru(arc_B1, k)
+
     # Remove timestamp entry for evicted item to avoid growth
     m_key_timestamp.pop(k, None)
     _trim_ghosts()
 
 # EVOLVE-BLOCK-END
 
 # This part remains fixed (not evolved)
 def run_caching(trace_path: str, copy_code_dst: str):
     """Run the caching algorithm on a trace"""
     import os
     with open(os.path.abspath(__file__), 'r', encoding="utf-8") as f:
         code_str = f.read()
     with open(os.path.join(copy_code_dst), 'w') as f:
         f.write(code_str)
     from cache_utils import Cache, CacheConfig, CacheObj, Trace
     trace = Trace(trace_path=trace_path)
     cache_capacity = max(int(trace.get_ndv() * 0.1), 1)
     cache = Cache(CacheConfig(cache_capacity))
     for entry in trace.entries:
         obj = CacheObj(key=str(entry.key))
         cache.get(obj)
     with open(copy_code_dst, 'w') as f:
         f.write("")
     hit_rate = round(cache.hit_count / cache.access_count, 6)
     return hit_rate