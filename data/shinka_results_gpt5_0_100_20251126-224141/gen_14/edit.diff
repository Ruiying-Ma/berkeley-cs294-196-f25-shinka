--- a/original.py
+++ b/original.py
@@ -1,203 +1,297 @@
 # EVOLVE-BLOCK-START
 """Cache eviction algorithm for optimizing hit rates across multiple workloads"""
 
 from collections import OrderedDict
-
-# LRU timestamp map kept for compatibility and as a tie-breaker
+from itertools import islice
+
+# LRU timestamp map for fallback/tie-breaking
 m_key_timestamp = dict()
 
-# Adaptive Replacement Cache (ARC) metadata
+# ARC-style metadata
 arc_T1 = OrderedDict()  # recent, resident
 arc_T2 = OrderedDict()  # frequent, resident
 arc_B1 = OrderedDict()  # ghost of T1
 arc_B2 = OrderedDict()  # ghost of T2
 arc_p = 0               # target size of T1
 arc_capacity = None     # will be initialized from cache_snapshot
 
+# Delayed-promotion state: first-hit time in T1
+t1_pending = dict()     # key -> access_count of first hit
+
+# Control state
+last_ghost_hit_access = -1
+cold_streak = 0
+
 
 def _ensure_capacity(cache_snapshot):
     global arc_capacity
     if arc_capacity is None:
         arc_capacity = max(int(cache_snapshot.capacity), 1)
 
 
 def _move_to_mru(od, key):
-    # Push key to MRU position of an OrderedDict
     if key in od:
         od.pop(key, None)
     od[key] = True
 
 
 def _pop_lru(od):
     if od:
         k, _ = od.popitem(last=False)
         return k
     return None
 
 
 def _trim_ghosts():
-    # Keep ghosts total size within capacity
+    # Keep ghosts total size within 2Ã—capacity; evict from the larger first
     total = len(arc_B1) + len(arc_B2)
     cap = arc_capacity if arc_capacity is not None else 1
-    while total > cap:
-        # Evict from the larger ghost list first
+    limit = 2 * cap
+    while total > limit:
         if len(arc_B1) >= len(arc_B2):
             _pop_lru(arc_B1)
         else:
             _pop_lru(arc_B2)
         total = len(arc_B1) + len(arc_B2)
 
 
 def _resync(cache_snapshot):
     # Ensure resident metadata tracks actual cache content
     cache_keys = set(cache_snapshot.cache.keys())
     for k in list(arc_T1.keys()):
         if k not in cache_keys:
             arc_T1.pop(k, None)
+            t1_pending.pop(k, None)
     for k in list(arc_T2.keys()):
         if k not in cache_keys:
             arc_T2.pop(k, None)
     # Add any cached keys we missed to T1 as recent
     for k in cache_keys:
         if k not in arc_T1 and k not in arc_T2:
             arc_T1[k] = True
     _trim_ghosts()
 
 
+def _decay_p_if_idle(cache_snapshot):
+    # If no ghost hits for a while, slowly decay p toward 0
+    global arc_p
+    if last_ghost_hit_access >= 0:
+        idle = cache_snapshot.access_count - last_ghost_hit_access
+        if idle > arc_capacity and arc_p > 0:
+            arc_p = max(0, arc_p - 1)
+
+
+def _pick_lru_non_pending_from_t1():
+    # Prefer evicting a non-pending key from T1 if possible (scan up to a few)
+    if not arc_T1:
+        return None
+    limit = min(8, len(arc_T1))  # small scan budget
+    keys = list(islice(arc_T1.keys(), 0, limit))
+    for k in keys:
+        if k not in t1_pending:
+            return k
+    # If all scanned are pending, fall back to true LRU
+    return next(iter(arc_T1))
+
+
 def evict(cache_snapshot, obj):
     '''
     This function defines how the algorithm chooses the eviction victim.
     - Args:
         - `cache_snapshot`: A snapshot of the current cache state.
         - `obj`: The new object that needs to be inserted into the cache.
     - Return:
         - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
     '''
     _ensure_capacity(cache_snapshot)
-    _resync(cache_snapshot)
-    # ARC replacement: choose between T1 and T2 depending on arc_p and ghost hit type
+    # Keep metadata consistent
+    if (len(arc_T1) + len(arc_T2)) != len(cache_snapshot.cache):
+        _resync(cache_snapshot)
+    _decay_p_if_idle(cache_snapshot)
+
+    # ARC replacement preference
     x_in_B2 = obj.key in arc_B2
     t1_sz = len(arc_T1)
+    from_t1 = (t1_sz >= 1 and (t1_sz > arc_p or (x_in_B2 and t1_sz == arc_p)))
+
+    if from_t1 and arc_T1:
+        candidate = _pick_lru_non_pending_from_t1()
+        if candidate is not None:
+            return candidate
+    if (not from_t1) and arc_T2:
+        return next(iter(arc_T2))  # LRU from T2
+
+    # If preferred list empty, try the other
+    if arc_T1:
+        cand = _pick_lru_non_pending_from_t1()
+        if cand is not None:
+            return cand
+    if arc_T2:
+        return next(iter(arc_T2))
+
+    # Fallback: metadata drift; choose based on ghost hints, then timestamp
     candidate = None
-    if t1_sz >= 1 and (t1_sz > arc_p or (x_in_B2 and t1_sz == arc_p)):
-        # Evict LRU from T1
-        candidate = next(iter(arc_T1)) if arc_T1 else None
-    else:
-        # Evict LRU from T2
-        candidate = next(iter(arc_T2)) if arc_T2 else None
+    # Prefer evicting a key present in B1 (recency-only) over B2 (likely frequent)
+    for k in cache_snapshot.cache.keys():
+        if k in arc_B1:
+            candidate = k
+            break
     if candidate is None:
-        # Fallback: choose the oldest by timestamp if available, else any key
-        if m_key_timestamp:
-            min_ts = min(m_key_timestamp.get(k, float('inf')) for k in cache_snapshot.cache.keys())
-            for k in cache_snapshot.cache.keys():
-                if m_key_timestamp.get(k, float('inf')) == min_ts:
-                    candidate = k
-                    break
-        if candidate is None and cache_snapshot.cache:
-            candidate = next(iter(cache_snapshot.cache.keys()))
+        # Next prefer a key not in B2
+        for k in cache_snapshot.cache.keys():
+            if k not in arc_B2:
+                candidate = k
+                break
+    if candidate is None and m_key_timestamp:
+        min_ts = min(m_key_timestamp.get(k, float('inf')) for k in cache_snapshot.cache.keys())
+        for k in cache_snapshot.cache.keys():
+            if m_key_timestamp.get(k, float('inf')) == min_ts:
+                candidate = k
+                break
+    if candidate is None and cache_snapshot.cache:
+        candidate = next(iter(cache_snapshot.cache.keys()))
     return candidate
 
 
 def update_after_hit(cache_snapshot, obj):
     '''
     This function defines how the algorithm update the metadata it maintains immediately after a cache hit.
     - Args:
         - `cache_snapshot`: A snapshot of the current cache state.
         - `obj`: The object accessed during the cache hit.
     - Return: `None`
     '''
     global m_key_timestamp
     _ensure_capacity(cache_snapshot)
-    # ARC: on hit, move to T2 MRU
+    _decay_p_if_idle(cache_snapshot)
+
     key = obj.key
-    if key in arc_T1:
-        arc_T1.pop(key, None)
+    W = max(1, arc_capacity // 4)  # promotion window
+
+    if key in arc_T2:
+        # Frequent: refresh MRU
         _move_to_mru(arc_T2, key)
+    elif key in arc_T1:
+        # Delayed promotion: first hit marks pending, second hit within W promotes
+        first = t1_pending.get(key)
+        if first is None:
+            # First hit: keep in T1, mark pending, refresh MRU
+            t1_pending[key] = cache_snapshot.access_count
+            _move_to_mru(arc_T1, key)
+        else:
+            if cache_snapshot.access_count - first <= W:
+                # Second hit within window: promote to T2
+                arc_T1.pop(key, None)
+                t1_pending.pop(key, None)
+                _move_to_mru(arc_T2, key)
+            else:
+                # Window expired: treat as new first-hit
+                t1_pending[key] = cache_snapshot.access_count
+                _move_to_mru(arc_T1, key)
     else:
-        # If already in T2, refresh; if not present due to drift, place in T2
-        if key in arc_T2:
-            _move_to_mru(arc_T2, key)
-        else:
-            _move_to_mru(arc_T2, key)
-    # Update timestamp for tie-breaking/fallback
+        # Drift: place into T2 (it's a hit in cache anyway)
+        _move_to_mru(arc_T2, key)
+        t1_pending.pop(key, None)
+
+    # Update timestamp and consistency guard
     m_key_timestamp[key] = cache_snapshot.access_count
+    if (len(arc_T1) + len(arc_T2)) != len(cache_snapshot.cache):
+        _resync(cache_snapshot)
 
 
 def update_after_insert(cache_snapshot, obj):
     '''
     This function defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
     - Args:
         - `cache_snapshot`: A snapshot of the current cache state.
         - `obj`: The object that was just inserted into the cache.
     - Return: `None`
     '''
-    global m_key_timestamp, arc_p
-    _ensure_capacity(cache_snapshot)
+    global m_key_timestamp, arc_p, last_ghost_hit_access, cold_streak
+    _ensure_capacity(cache_snapshot)
+    _decay_p_if_idle(cache_snapshot)
+
     key = obj.key
-    # ARC admission policy
+    step_cap = max(1, arc_capacity // 8)
+
     if key in arc_B1:
-        # Previously evicted from T1: favor recency by increasing p
+        # Ghost hit in B1: increase p (favor recency), damped
         inc = max(1, len(arc_B2) // max(1, len(arc_B1)))
-        arc_p = min(arc_capacity, arc_p + inc)
+        arc_p = min(arc_capacity, arc_p + min(inc, step_cap))
+        last_ghost_hit_access = cache_snapshot.access_count
+        cold_streak = 0
         arc_B1.pop(key, None)
-        _move_to_mru(arc_T2, key)
+        _move_to_mru(arc_T2, key)  # admit to frequent on return
     elif key in arc_B2:
-        # Previously frequent: favor frequency by decreasing p
+        # Ghost hit in B2: decrease p (favor frequency), damped
         dec = max(1, len(arc_B1) // max(1, len(arc_B2)))
-        arc_p = max(0, arc_p - dec)
+        arc_p = max(0, arc_p - min(dec, step_cap))
+        last_ghost_hit_access = cache_snapshot.access_count
+        cold_streak = 0
         arc_B2.pop(key, None)
         _move_to_mru(arc_T2, key)
     else:
-        # Brand new: insert into T1 (recent)
+        # Brand-new miss: insert into T1
         _move_to_mru(arc_T1, key)
+        cold_streak += 1
+        # Scan clamp: prolonged cold stream -> push p down quickly
+        if cold_streak > arc_capacity:
+            arc_p = max(0, arc_p - max(1, arc_capacity // 4))
+
+    # Timestamp and consistency
+    m_key_timestamp[key] = cache_snapshot.access_count
     _trim_ghosts()
-    m_key_timestamp[key] = cache_snapshot.access_count
+    if (len(arc_T1) + len(arc_T2)) != len(cache_snapshot.cache):
+        _resync(cache_snapshot)
 
 
 def update_after_evict(cache_snapshot, obj, evicted_obj):
     '''
     This function defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
     - Args:
         - `cache_snapshot`: A snapshot of the current cache state.
         - `obj`: The object to be inserted into the cache.
         - `evicted_obj`: The object that was just evicted from the cache.
     - Return: `None`
     '''
     global m_key_timestamp
     _ensure_capacity(cache_snapshot)
     k = evicted_obj.key
     # Move evicted resident to corresponding ghost list
     if k in arc_T1:
         arc_T1.pop(k, None)
+        t1_pending.pop(k, None)
         _move_to_mru(arc_B1, k)
     elif k in arc_T2:
         arc_T2.pop(k, None)
         _move_to_mru(arc_B2, k)
     else:
         # Unknown membership: default to B1
         _move_to_mru(arc_B1, k)
+        t1_pending.pop(k, None)
     # Remove timestamp entry for evicted item to avoid growth
     m_key_timestamp.pop(k, None)
     _trim_ghosts()
+    # Reset cold streak on eviction of keys that had ghost hints? conservative: no-op here.
 
 # EVOLVE-BLOCK-END
 
 # This part remains fixed (not evolved)
 def run_caching(trace_path: str, copy_code_dst: str):
     """Run the caching algorithm on a trace"""
     import os
     with open(os.path.abspath(__file__), 'r', encoding="utf-8") as f:
         code_str = f.read()
     with open(os.path.join(copy_code_dst), 'w') as f:
         f.write(code_str)
     from cache_utils import Cache, CacheConfig, CacheObj, Trace
     trace = Trace(trace_path=trace_path)
     cache_capacity = max(int(trace.get_ndv() * 0.1), 1)
     cache = Cache(CacheConfig(cache_capacity))
     for entry in trace.entries:
         obj = CacheObj(key=str(entry.key))
         cache.get(obj)
     with open(copy_code_dst, 'w') as f:
         f.write("")
     hit_rate = round(cache.hit_count / cache.access_count, 6)
     return hit_rate