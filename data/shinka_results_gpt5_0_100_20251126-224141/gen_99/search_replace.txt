<NAME>
arc_tinylfu_t2_bias_and_scan_one_shot
</NAME>

<DESCRIPTION>
I propose three coordinated improvements to lower miss rates:
1) Make evictions from T2 frequency-aware within an LRU-side window. ARC is great at recency/frequency balancing via T1/T2, but within T2 a pure LRU can evict moderately hot objects too eagerly. Using a Tiny-LFU signal on a small window near the LRU end helps retain stronger hotsets while still respecting recency for probationary entries.
2) Introduce a one-shot demotion bias under scan suspicion. When a scan-like cold streak is detected and there is no frequent history (B2 empty), force just one eviction from T2. This prevents T2 from being monopolized by noise during bursts, yet avoids continuous over-demotion by clearing the flag after one use or on any hit/ghost hit.
3) Improve frequency aging to exponential halving at a sensible interval, and reward hits in T2 more than hits elsewhere. This keeps the LFU signal fresh and bounded, penalizes staleness quickly, and differentiates strong hot items (T2) from transient ones.

Together, these changes stabilize ARCâ€™s adaptation (p) while leveraging a lightweight LFU to improve victim choice, especially on mixed workloads and traces with transient scans. The modifications are focused, consistent, and maintain compatibility with the existing metadata and flow.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
# One-time extra clamp flag during cold scan phases
cold_extra_applied = False
# Remember which list REPLACE selected from in evict (for accurate ghosting)
last_replaced_from = None
=======
# One-time extra clamp flag during cold scan phases
cold_extra_applied = False
# Remember which list REPLACE selected from in evict (for accurate ghosting)
last_replaced_from = None
# One-shot demotion bias during scan guard
guard_demote_next = False
>>>>>>> REPLACE

</DIFF>

<DIFF>
<<<<<<< SEARCH
def _maybe_decay_freq(cache_snapshot):
    # Periodically decay resident frequencies to keep LFU signal fresh and bounded
    global last_freq_decay_access
    _ensure_capacity(cache_snapshot)
    C = arc_capacity if arc_capacity else 1
    interval = max(64, C)
    if cache_snapshot.access_count - last_freq_decay_access >= interval:
        for k in list(m_key_freq.keys()):
            v = m_key_freq.get(k, 0)
            if v <= 1:
                m_key_freq.pop(k, None)
            else:
                m_key_freq[k] = v - 1
        last_freq_decay_access = cache_snapshot.access_count
=======
def _maybe_decay_freq(cache_snapshot):
    # Periodically decay resident frequencies using exponential aging for freshness
    global last_freq_decay_access
    _ensure_capacity(cache_snapshot)
    C = arc_capacity if arc_capacity else 1
    # Decay less frequently to preserve strong frequency signals; halve counts to age quickly
    interval = max(64, C)
    if cache_snapshot.access_count - last_freq_decay_access >= interval:
        for k in list(m_key_freq.keys()):
            v = m_key_freq.get(k, 0)
            nv = (v + 1) // 2  # halve (round up)
            if nv <= 0:
                m_key_freq.pop(k, None)
            else:
                m_key_freq[k] = nv
        last_freq_decay_access = cache_snapshot.access_count
>>>>>>> REPLACE

</DIFF>

<DIFF>
<<<<<<< SEARCH
def evict(cache_snapshot, obj):
    '''
    This function defines how the algorithm chooses the eviction victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    global arc_p, last_ghost_hit_access, cold_streak, scan_guard_until, cold_extra_applied, last_replaced_from
    _ensure_capacity(cache_snapshot)
    _resync(cache_snapshot)
    _decay_p_if_idle(cache_snapshot)
    _maybe_decay_freq(cache_snapshot)

    # Ghost-driven p updates BEFORE REPLACE (canonical ARC with ceil step and clamp)
    key = obj.key
    C = arc_capacity if arc_capacity else 1
    in_B1 = key in arc_B1
    in_B2 = key in arc_B2
    if in_B1:
        step_up = (len(arc_B2) + max(1, len(arc_B1)) - 1) // max(1, len(arc_B1))
        arc_p = min(C, arc_p + min(step_up, max(1, C // 8)))
        last_ghost_hit_access = cache_snapshot.access_count
        cold_streak = 0
        scan_guard_until = -1  # ghost hit: cancel scan guard
        cold_extra_applied = False
    elif in_B2:
        step_down = (len(arc_B1) + max(1, len(arc_B2)) - 1) // max(1, len(arc_B2))
        arc_p = max(0, arc_p - min(step_down, max(1, C // 8)))
        last_ghost_hit_access = cache_snapshot.access_count
        cold_streak = 0
        scan_guard_until = -1
        cold_extra_applied = False
    # No p change on brand-new here; scan mitigation handled via guard during insert

    # ARC REPLACE with guard-adjusted effective p (short, gentle guard)
    t1_sz = len(arc_T1)
    guard_active = (scan_guard_until != -1 and cache_snapshot.access_count < scan_guard_until)
    drop_unit = max(1, C // 16)
    # gentle drop grows with cold_streak beyond ~C/2, bounded by drop_unit
    drop = min(drop_unit, max(0, 1 + (cold_streak - max(1, C // 2)) // drop_unit))
    p_eff = max(0, arc_p - (drop if guard_active else 0))

    # Choose which list to evict from
    candidate = None
    last_replaced_from = None
    if t1_sz >= 1 and (t1_sz > p_eff or (in_B2 and t1_sz == p_eff)):
        # Evict from T1: use Tiny-LFU-biased pick in a small LRU-side window
        window = min(8, max(1, C // 8))
        candidate = _pick_freq_aware_lru(arc_T1, window)
        if candidate is not None:
            last_replaced_from = 'T1'
    else:
        # Evict from T2: stick to pure LRU to avoid over-bias
        candidate = next(iter(arc_T2)) if arc_T2 else None
        if candidate is not None:
            last_replaced_from = 'T2'

    # Strengthened, ghost-informed deterministic fallback selection
    if candidate is None:
        # 1) Prefer T1 LRU not hinted as frequent (not in B2)
        for k in list(arc_T1.keys()):
            if k not in arc_B2:
                candidate = k
                last_replaced_from = 'T1'
                break
    if candidate is None:
        # 2) Prefer T2 LRU that shows up in B1 (recency-only hint)
        for k in list(arc_T2.keys()):
            if k in arc_B1:
                candidate = k
                last_replaced_from = 'T2'
                break
    if candidate is None:
        # 3) Depth-limited peek to avoid B2-hinted keys and prefer B1-hinted in T2
        budget = min(8, max(1, C // 16))
        cnt = 0
        for k in arc_T1.keys():
            if k not in arc_B2:
                candidate = k
                last_replaced_from = 'T1'
                break
            cnt += 1
            if cnt >= budget:
                break
        if candidate is None:
            cnt = 0
            for k in arc_T2.keys():
                if k in arc_B1:
                    candidate = k
                    last_replaced_from = 'T2'
                    break
                cnt += 1
                if cnt >= budget:
                    break
    if candidate is None:
        # 4) Timestamp tie-breaker, prefer T1 side if possible
        min_ts = float('inf')
        min_k = None
        for k in arc_T1.keys():
            ts = m_key_timestamp.get(k, float('inf'))
            if ts < min_ts:
                min_ts = ts
                min_k = k
        if min_k is not None:
            candidate = min_k
            last_replaced_from = 'T1'
    if candidate is None and m_key_timestamp:
        # 5) Fallback timestamp across all cached keys
        min_ts = float('inf')
        min_k = None
        for k in cache_snapshot.cache.keys():
            ts = m_key_timestamp.get(k, float('inf'))
            if ts < min_ts:
                min_ts = ts
                min_k = k
        candidate = min_k
        if candidate is not None:
            last_replaced_from = 'T1' if candidate in arc_T1 else ('T2' if candidate in arc_T2 else None)
    if candidate is None and cache_snapshot.cache:
        # 6) Last resort: arbitrary
        candidate = next(iter(cache_snapshot.cache.keys()))
        if candidate is not None:
            last_replaced_from = 'T1' if candidate in arc_T1 else ('T2' if candidate in arc_T2 else None)
    return candidate
=======
def evict(cache_snapshot, obj):
    '''
    This function defines how the algorithm chooses the eviction victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    global arc_p, last_ghost_hit_access, cold_streak, scan_guard_until, cold_extra_applied, last_replaced_from, guard_demote_next
    _ensure_capacity(cache_snapshot)
    _resync(cache_snapshot)
    _decay_p_if_idle(cache_snapshot)
    _maybe_decay_freq(cache_snapshot)

    # Ghost-driven p updates BEFORE REPLACE (canonical ARC with ceil step and clamp)
    key = obj.key
    C = arc_capacity if arc_capacity else 1
    in_B1 = key in arc_B1
    in_B2 = key in arc_B2
    if in_B1:
        step_up = (len(arc_B2) + max(1, len(arc_B1)) - 1) // max(1, len(arc_B1))
        arc_p = min(C, arc_p + min(step_up, max(1, C // 8)))
        last_ghost_hit_access = cache_snapshot.access_count
        cold_streak = 0
        scan_guard_until = -1  # ghost hit: cancel scan guard
        cold_extra_applied = False
        guard_demote_next = False
    elif in_B2:
        step_down = (len(arc_B1) + max(1, len(arc_B2)) - 1) // max(1, len(arc_B2))
        arc_p = max(0, arc_p - min(step_down, max(1, C // 8)))
        last_ghost_hit_access = cache_snapshot.access_count
        cold_streak = 0
        scan_guard_until = -1
        cold_extra_applied = False
        guard_demote_next = False
    # No p change on brand-new here; scan mitigation handled via guard during insert

    # ARC REPLACE with guard-adjusted effective p (short, gentle guard)
    t1_sz = len(arc_T1)
    guard_active = (scan_guard_until != -1 and cache_snapshot.access_count < scan_guard_until)
    drop_unit = max(1, C // 16)
    # gentle drop grows with cold_streak beyond ~C/2, bounded by drop_unit
    drop = min(drop_unit, max(0, 1 + (cold_streak - max(1, C // 2)) // drop_unit))
    p_eff = max(0, arc_p - (drop if guard_active else 0))

    # If scan guard is active with no frequent history and T2 dominates, force a one-shot T2 eviction
    if guard_active and len(arc_B2) == 0 and len(arc_T2) > len(arc_T1):
        guard_demote_next = True

    # Choose which list to evict from
    candidate = None
    last_replaced_from = None
    if guard_demote_next and arc_T2:
        # One-shot demotion from T2 to curb scan pollution; then clear the flag
        candidate = next(iter(arc_T2))
        last_replaced_from = 'T2'
        guard_demote_next = False
    elif t1_sz >= 1 and (t1_sz > p_eff or (in_B2 and t1_sz == p_eff)):
        # Evict from T1: use Tiny-LFU-biased pick in a small LRU-side window
        window_T1 = min(8, max(1, C // 16))
        candidate = _pick_freq_aware_lru(arc_T1, window_T1)
        if candidate is not None:
            last_replaced_from = 'T1'
    else:
        # Evict from T2: prefer the lowest-frequency item within a slightly larger LRU window
        window_T2 = min(16, max(2, C // 8))
        candidate = _pick_freq_aware_lru(arc_T2, window_T2) if arc_T2 else None
        if candidate is not None:
            last_replaced_from = 'T2'

    # Strengthened, ghost-informed deterministic fallback selection
    if candidate is None:
        # 1) Prefer T1 LRU not hinted as frequent (not in B2)
        for k in list(arc_T1.keys()):
            if k not in arc_B2:
                candidate = k
                last_replaced_from = 'T1'
                break
    if candidate is None:
        # 2) Prefer T2 LRU that shows up in B1 (recency-only hint)
        for k in list(arc_T2.keys()):
            if k in arc_B1:
                candidate = k
                last_replaced_from = 'T2'
                break
    if candidate is None:
        # 3) Depth-limited peek to avoid B2-hinted keys and prefer B1-hinted in T2
        budget = min(8, max(1, C // 16))
        cnt = 0
        for k in arc_T1.keys():
            if k not in arc_B2:
                candidate = k
                last_replaced_from = 'T1'
                break
            cnt += 1
            if cnt >= budget:
                break
        if candidate is None:
            cnt = 0
            for k in arc_T2.keys():
                if k in arc_B1:
                    candidate = k
                    last_replaced_from = 'T2'
                    break
                cnt += 1
                if cnt >= budget:
                    break
    if candidate is None:
        # 4) Timestamp tie-breaker, prefer T1 side if possible
        min_ts = float('inf')
        min_k = None
        for k in arc_T1.keys():
            ts = m_key_timestamp.get(k, float('inf'))
            if ts < min_ts:
                min_ts = ts
                min_k = k
        if min_k is not None:
            candidate = min_k
            last_replaced_from = 'T1'
    if candidate is None and m_key_timestamp:
        # 5) Fallback timestamp across all cached keys
        min_ts = float('inf')
        min_k = None
        for k in cache_snapshot.cache.keys():
            ts = m_key_timestamp.get(k, float('inf'))
            if ts < min_ts:
                min_ts = ts
                min_k = k
        candidate = min_k
        if candidate is not None:
            last_replaced_from = 'T1' if candidate in arc_T1 else ('T2' if candidate in arc_T2 else None)
    if candidate is None and cache_snapshot.cache:
        # 6) Last resort: arbitrary
        candidate = next(iter(cache_snapshot.cache.keys()))
        if candidate is not None:
            last_replaced_from = 'T1' if candidate in arc_T1 else ('T2' if candidate in arc_T2 else None)
    return candidate
>>>>>>> REPLACE

</DIFF>

<DIFF>
<<<<<<< SEARCH
def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the algorithm update the metadata it maintains immediately after a cache hit.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    global m_key_timestamp, cold_streak, scan_guard_until
    _ensure_capacity(cache_snapshot)
    _decay_p_if_idle(cache_snapshot)
    _maybe_decay_freq(cache_snapshot)

    # ARC: on hit, move to T2 MRU
    key = obj.key
    if key in arc_T1:
        arc_T1.pop(key, None)
        _move_to_mru(arc_T2, key)
    else:
        # If already in T2, refresh; if not present due to drift, place in T2
        if key in arc_T2:
            _move_to_mru(arc_T2, key)
        else:
            _move_to_mru(arc_T2, key)
    # Resident keys must not exist in ghosts
    arc_B1.pop(key, None)
    arc_B2.pop(key, None)
    # Any hit breaks a cold streak and cancels scan guard
    cold_streak = 0
    scan_guard_until = -1
    # Update timestamp and frequency for tie-breaking/fallback
    m_key_timestamp[key] = cache_snapshot.access_count
    m_key_freq[key] = m_key_freq.get(key, 0) + 1
=======
def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the algorithm update the metadata it maintains immediately after a cache hit.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    global m_key_timestamp, cold_streak, scan_guard_until, guard_demote_next
    _ensure_capacity(cache_snapshot)
    _decay_p_if_idle(cache_snapshot)
    _maybe_decay_freq(cache_snapshot)

    # ARC: on hit, move to T2 MRU
    key = obj.key
    if key in arc_T1:
        arc_T1.pop(key, None)
        _move_to_mru(arc_T2, key)
    else:
        # If already in T2, refresh; if not present due to drift, place in T2
        if key in arc_T2:
            _move_to_mru(arc_T2, key)
        else:
            _move_to_mru(arc_T2, key)
    # Resident keys must not exist in ghosts
    arc_B1.pop(key, None)
    arc_B2.pop(key, None)
    # Any hit breaks a cold streak and cancels scan guard and one-shot demotion bias
    cold_streak = 0
    scan_guard_until = -1
    guard_demote_next = False
    # Update timestamp and frequency for tie-breaking/fallback
    m_key_timestamp[key] = cache_snapshot.access_count
    in_T2_after = key in arc_T2
    m_key_freq[key] = m_key_freq.get(key, 0) + (2 if in_T2_after else 1)
>>>>>>> REPLACE

</DIFF>

<DIFF>
<<<<<<< SEARCH
def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    global m_key_timestamp, cold_streak, scan_guard_until
    _ensure_capacity(cache_snapshot)
    _decay_p_if_idle(cache_snapshot)
    _maybe_decay_freq(cache_snapshot)

    key = obj.key
    # ARC admission policy: ghost hits go to T2 (p already adjusted in evict)
    if key in arc_B1 or key in arc_B2:
        cold_streak = 0
        scan_guard_until = -1
        arc_B1.pop(key, None)
        arc_B2.pop(key, None)  # keep ghosts disjoint
        _move_to_mru(arc_T2, key)
        # Ghost hits imply history: modest frequency bump
        m_key_freq[key] = m_key_freq.get(key, 0) + 1
    else:
        # Brand new: insert into T1; during scans, insert at LRU and open a short guard
        cold_streak += 1
        if cold_streak >= max(1, arc_capacity // 2):
            _insert_at_lru(arc_T1, key)
            guard = min(8, max(1, arc_capacity // 16))
            scan_guard_until = max(scan_guard_until, cache_snapshot.access_count + guard)
        else:
            _move_to_mru(arc_T1, key)
        # Ensure ghosts are disjoint from residents
        arc_B1.pop(key, None)
        arc_B2.pop(key, None)
        # Seed minimal frequency
        m_key_freq[key] = m_key_freq.get(key, 0) + 1

    _trim_ghosts()
    m_key_timestamp[key] = cache_snapshot.access_count
=======
def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    global m_key_timestamp, cold_streak, scan_guard_until, guard_demote_next
    _ensure_capacity(cache_snapshot)
    _decay_p_if_idle(cache_snapshot)
    _maybe_decay_freq(cache_snapshot)

    key = obj.key
    # ARC admission policy: ghost hits go to T2 (p already adjusted in evict)
    if key in arc_B1 or key in arc_B2:
        cold_streak = 0
        scan_guard_until = -1
        guard_demote_next = False
        arc_B1.pop(key, None)
        arc_B2.pop(key, None)  # keep ghosts disjoint
        _move_to_mru(arc_T2, key)
        # Ghost hits imply history: ensure at least moderate frequency
        cur = m_key_freq.get(key, 0)
        m_key_freq[key] = max(cur + 1, 2)
    else:
        # Brand new: insert into T1; during scans, insert at LRU and open a short guard
        cold_streak += 1
        if cold_streak >= max(1, arc_capacity // 2):
            _insert_at_lru(arc_T1, key)
            guard = min(8, max(1, arc_capacity // 16))
            scan_guard_until = max(scan_guard_until, cache_snapshot.access_count + guard)
        else:
            _move_to_mru(arc_T1, key)
        # Ensure ghosts are disjoint from residents
        arc_B1.pop(key, None)
        arc_B2.pop(key, None)
        # Seed minimal frequency for new admissions
        m_key_freq[key] = m_key_freq.get(key, 0) + 1

    _trim_ghosts()
    m_key_timestamp[key] = cache_snapshot.access_count
>>>>>>> REPLACE

</DIFF>