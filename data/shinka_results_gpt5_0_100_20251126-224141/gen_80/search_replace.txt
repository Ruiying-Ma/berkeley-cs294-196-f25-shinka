<NAME>
arc_plus_tiny_freq_hysteresis
</NAME>

<DESCRIPTION>
I introduce three focused improvements grounded in ARC best practices and lightweight frequency-aware refinement:

1) Stabilized ARC adaptation with ceiling ratios, bounded steps, and mild scan bias: In evict, ghost-driven p updates now use ceil(len(B2)/len(B1)) and ceil(len(B1)/len(B2)) as in canonical ARC, clamped by C//8. I also add a time-bounded demotion bias that, when the scan guard is active but there are no B2 signals and T2 dominates T1, evicts from T2 once. This reduces over-eviction of recency-friendly items during scans.

2) Frequency-aware sampling and initialization tweaks: I increase the sampling depth slightly and initialize brand-new items’ frequency at 0 (instead of 1), while keeping ghost re-admissions boosted. This makes the victim selector more resilient to scans by preferring eviction of cold newcomers without hurting frequently reused items.

3) Ghost-list hysteresis and better metadata stability: I add a small hysteresis margin to ghost trimming to reduce oscillations and use a new last_replaced_from signal to reliably send evicted residents to the correct ghost list, even under metadata drift. The scan guard window is shortened to a small, dynamic duration and is reset on hits to prevent overreaction.

Together, these changes keep ARC’s strengths while damping oscillation and improving behavior on mixed and scan-heavy traces. The changes are confined to evict, update_after_hit, update_after_insert, update_after_evict, and auxiliary helpers, preserving compatibility.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
arc_B2 = OrderedDict()  # ghost of T2
arc_p = 0               # target size of T1
arc_capacity = None     # will be initialized from cache_snapshot
=======
arc_B2 = OrderedDict()  # ghost of T2
arc_p = 0               # target size of T1
arc_capacity = None     # will be initialized from cache_snapshot
last_replaced_from = None  # 'T1' or 'T2' for accurate ghost placement
>>>>>>> REPLACE

</DIFF>

<DIFF>
<<<<<<< SEARCH
def _trim_ghosts():
    # Keep ghosts total size within 2x capacity with proportional trimming to p
    cap_base = (arc_capacity if arc_capacity is not None else 1)
    total_cap = cap_base * 2
    # Targets proportional to current p (approximately 2*p and 2C-2*p)
    target_B1 = min(total_cap, max(0, int(total_cap * (float(arc_p) / max(1, cap_base)))))
    target_B2 = max(0, total_cap - target_B1)

    def _over_target():
        return (len(arc_B1) + len(arc_B2)) - total_cap

    # Trim until under the total budget, favoring lists above their targets
    while (len(arc_B1) + len(arc_B2)) > total_cap:
        if len(arc_B1) > target_B1:
            _pop_lru(arc_B1)
        elif len(arc_B2) > target_B2:
            _pop_lru(arc_B2)
        else:
            # If neither is over its proportional target, drop from the larger one
            if len(arc_B1) >= len(arc_B2):
                _pop_lru(arc_B1)
            else:
                _pop_lru(arc_B2)
=======
def _trim_ghosts():
    # Keep ghosts total size within 2x capacity with proportional trimming to p and hysteresis
    cap_base = (arc_capacity if arc_capacity is not None else 1)
    total_cap = cap_base * 2
    # Proportional targets to current p (approximately 2*p and 2C-2*p)
    target_B1 = min(total_cap, max(0, int(total_cap * (float(arc_p) / max(1, cap_base)))))
    target_B2 = max(0, total_cap - target_B1)
    # Add small hysteresis band to reduce oscillation
    h = max(1, cap_base // 32)

    # Trim until under the total budget, favoring lists above their targets plus hysteresis
    while (len(arc_B1) + len(arc_B2)) > total_cap:
        if len(arc_B1) > target_B1 + h:
            _pop_lru(arc_B1)
        elif len(arc_B2) > target_B2 + h:
            _pop_lru(arc_B2)
        else:
            # If neither exceeds target+h, drop from the larger one
            if len(arc_B1) >= len(arc_B2):
                _pop_lru(arc_B1)
            else:
                _pop_lru(arc_B2)
>>>>>>> REPLACE

</DIFF>

<DIFF>
<<<<<<< SEARCH
def evict(cache_snapshot, obj):
    '''
    This function defines how the algorithm chooses the eviction victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    _ensure_capacity(cache_snapshot)
    _resync(cache_snapshot)
    # Apply ghost-driven adaptation before replacement (canonical ARC behavior)
    global arc_p, arc_last_ghost_hit_access, cold_streak, scan_guard_until
    now = cache_snapshot.access_count
    step_cap = max(1, (arc_capacity if arc_capacity is not None else 1) // 8)
    if obj.key in arc_B1:
        # Favor recency: increase p
        ratio = max(1, len(arc_B2) // max(1, len(arc_B1)))
        inc = min(ratio, step_cap, max(0, (arc_capacity if arc_capacity is not None else 0) - arc_p))
        arc_p = min((arc_capacity if arc_capacity is not None else arc_p), arc_p + inc)
        arc_last_ghost_hit_access = now
        cold_streak = 0
    elif obj.key in arc_B2:
        # Favor frequency: decrease p
        ratio = max(1, len(arc_B1) // max(1, len(arc_B2)))
        dec = min(ratio, step_cap, arc_p)
        arc_p = max(0, arc_p - dec)
        arc_last_ghost_hit_access = now
        cold_streak = 0

    # ARC replacement: choose between T1 and T2 depending on p and whether obj is in B2
    x_in_B2 = obj.key in arc_B2
    t1_sz = len(arc_T1)
    choose_from_T1 = False
    if t1_sz >= 1 and (t1_sz > arc_p or (x_in_B2 and t1_sz == arc_p)):
        choose_from_T1 = True

    # Scan-guard bias: during suspected scans, prefer evicting from T1 if possible
    if now <= scan_guard_until and t1_sz > 0:
        choose_from_T1 = True

    # Depth-limited, frequency- and age-informed victim selection within chosen list
    victim = None
    depth = min(8, max(1, (arc_capacity if arc_capacity is not None else 1) // 16))
    if choose_from_T1:
        if arc_T1:
            victim = _pick_victim_from_od(arc_T1, now, depth)
    else:
        if arc_T2:
            victim = _pick_victim_from_od(arc_T2, now, depth)

    # Try the other list with sampling if the chosen one is empty
    if victim is None:
        if choose_from_T1 and arc_T2:
            victim = _pick_victim_from_od(arc_T2, now, depth)
        elif (not choose_from_T1) and arc_T1:
            victim = _pick_victim_from_od(arc_T1, now, depth)

    # Fallbacks: if still none, use classic ARC fallbacks
    if victim is None:
        if t1_sz > 0 and arc_T1:
            victim = next(iter(arc_T1))
        elif len(arc_T2) > 0 and arc_T2:
            victim = next(iter(arc_T2))
        else:
            # Rare drift: resync once and retry small bounded scan, then deterministic fallback
            _resync(cache_snapshot)
            scan_lim = max(1, (arc_capacity if arc_capacity is not None else 1) // 16)
            if arc_T1:
                i = 0
                for k in arc_T1.keys():
                    victim = k
                    i += 1
                    if i >= scan_lim:
                        break
            elif arc_T2:
                i = 0
                for k in arc_T2.keys():
                    victim = k
                    i += 1
                    if i >= scan_lim:
                        break
            elif cache_snapshot.cache:
                # Deterministic final fallback: first key iteration
                victim = next(iter(cache_snapshot.cache.keys()))
    return victim
=======
def evict(cache_snapshot, obj):
    '''
    This function defines how the algorithm chooses the eviction victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    _ensure_capacity(cache_snapshot)
    _resync(cache_snapshot)
    # Apply ghost-driven adaptation before replacement (canonical ARC behavior)
    global arc_p, arc_last_ghost_hit_access, cold_streak, scan_guard_until, last_replaced_from
    now = cache_snapshot.access_count
    step_cap = max(1, (arc_capacity if arc_capacity is not None else 1) // 8)
    b1 = len(arc_B1)
    b2 = len(arc_B2)
    if obj.key in arc_B1:
        # Favor recency: increase p (ceil ratio)
        ratio_up = (b2 + max(1, b1) - 1) // max(1, b1)
        inc = min(ratio_up, step_cap, max(0, (arc_capacity if arc_capacity is not None else 0) - arc_p))
        arc_p = min((arc_capacity if arc_capacity is not None else arc_p), arc_p + inc)
        arc_last_ghost_hit_access = now
        cold_streak = 0
    elif obj.key in arc_B2:
        # Favor frequency: decrease p (ceil ratio)
        ratio_down = (b1 + max(1, b2) - 1) // max(1, b2)
        dec = min(ratio_down, step_cap, arc_p)
        arc_p = max(0, arc_p - dec)
        arc_last_ghost_hit_access = now
        cold_streak = 0

    # ARC replacement: choose between T1 and T2 depending on p and whether obj is in B2
    x_in_B2 = obj.key in arc_B2
    t1_sz = len(arc_T1)
    choose_from_T1 = False
    if t1_sz >= 1 and (t1_sz > arc_p or (x_in_B2 and t1_sz == arc_p)):
        choose_from_T1 = True

    # Scan-guard bias: during suspected scans, prefer evicting from T1 if possible,
    # but if there is no frequency signal (B2 empty) and T2 dominates, evict from T2 once.
    if now <= scan_guard_until and t1_sz > 0:
        choose_from_T1 = True
        if b2 == 0 and len(arc_T2) > len(arc_T1):
            choose_from_T1 = False

    # Depth-limited, frequency- and age-informed victim selection within chosen list
    victim = None
    depth = min(12, max(2, (arc_capacity if arc_capacity is not None else 1) // 16))
    if choose_from_T1:
        if arc_T1:
            victim = _pick_victim_from_od(arc_T1, now, depth)
            if victim is not None:
                last_replaced_from = 'T1'
    else:
        if arc_T2:
            victim = _pick_victim_from_od(arc_T2, now, depth)
            if victim is not None:
                last_replaced_from = 'T2'

    # Try the other list with sampling if the chosen one is empty
    if victim is None:
        if choose_from_T1 and arc_T2:
            victim = _pick_victim_from_od(arc_T2, now, depth)
            if victim is not None:
                last_replaced_from = 'T2'
        elif (not choose_from_T1) and arc_T1:
            victim = _pick_victim_from_od(arc_T1, now, depth)
            if victim is not None:
                last_replaced_from = 'T1'

    # Fallbacks: if still none, use classic ARC fallbacks
    if victim is None:
        if t1_sz > 0 and arc_T1:
            victim = next(iter(arc_T1))
            last_replaced_from = 'T1'
        elif len(arc_T2) > 0 and arc_T2:
            victim = next(iter(arc_T2))
            last_replaced_from = 'T2'
        else:
            # Rare drift: resync once and retry small bounded scan, then deterministic fallback
            _resync(cache_snapshot)
            scan_lim = max(1, (arc_capacity if arc_capacity is not None else 1) // 16)
            if arc_T1:
                i = 0
                for k in arc_T1.keys():
                    victim = k
                    last_replaced_from = 'T1'
                    i += 1
                    if i >= scan_lim:
                        break
            elif arc_T2:
                i = 0
                for k in arc_T2.keys():
                    victim = k
                    last_replaced_from = 'T2'
                    i += 1
                    if i >= scan_lim:
                        break
            elif cache_snapshot.cache:
                # Deterministic final fallback: first key iteration
                victim = next(iter(cache_snapshot.cache.keys()))
                last_replaced_from = None
    return victim
>>>>>>> REPLACE

</DIFF>

<DIFF>
<<<<<<< SEARCH
def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the algorithm update the metadata it maintains immediately after a cache hit.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    global m_key_timestamp, cold_streak, m_key_freq
    _ensure_capacity(cache_snapshot)
    now = cache_snapshot.access_count
    _decay_arc_p_if_idle(now)
    # Any hit breaks cold streaks
    cold_streak = 0

    # Keep resident metadata consistent with actual cache
    if (len(arc_T1) + len(arc_T2)) != len(cache_snapshot.cache):
        _resync(cache_snapshot)

    key = obj.key
    if key in arc_T1:
        # Canonical ARC: on a hit in T1, move to T2 (become frequent)
        arc_T1.pop(key, None)
        _move_to_mru(arc_T2, key)
        t1_pending.pop(key, None)
    elif key in arc_T2:
        # Refresh recency within T2
        _move_to_mru(arc_T2, key)
    else:
        # Metadata drift: conservatively place into T1 as recent
        _move_to_mru(arc_T1, key)

    # Increment lightweight frequency counter (saturate)
    m_key_freq[key] = min(7, m_key_freq.get(key, 0) + 1)

    # Maintain disjointness: resident keys must not appear in ghosts
    arc_B1.pop(key, None)
    arc_B2.pop(key, None)

    _trim_ghosts()
    # Update timestamp for tie-breaking/fallback
    m_key_timestamp[key] = now
=======
def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the algorithm update the metadata it maintains immediately after a cache hit.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    global m_key_timestamp, cold_streak, m_key_freq, scan_guard_until
    _ensure_capacity(cache_snapshot)
    now = cache_snapshot.access_count
    _decay_arc_p_if_idle(now)
    # Any hit breaks cold streaks and cancels scan guard quickly
    cold_streak = 0
    scan_guard_until = 0

    # Keep resident metadata consistent with actual cache
    if (len(arc_T1) + len(arc_T2)) != len(cache_snapshot.cache):
        _resync(cache_snapshot)

    key = obj.key
    if key in arc_T1:
        # Canonical ARC: on a hit in T1, move to T2 (become frequent)
        arc_T1.pop(key, None)
        _move_to_mru(arc_T2, key)
        t1_pending.pop(key, None)
    elif key in arc_T2:
        # Refresh recency within T2
        _move_to_mru(arc_T2, key)
    else:
        # Metadata drift: conservatively place into T1 as recent
        _move_to_mru(arc_T1, key)

    # Increment lightweight frequency counter (saturate)
    m_key_freq[key] = min(7, m_key_freq.get(key, 0) + 1)

    # Maintain disjointness: resident keys must not appear in ghosts
    arc_B1.pop(key, None)
    arc_B2.pop(key, None)

    _trim_ghosts()
    # Update timestamp for tie-breaking/fallback
    m_key_timestamp[key] = now
>>>>>>> REPLACE

</DIFF>

<DIFF>
<<<<<<< SEARCH
def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    global m_key_timestamp, arc_p, arc_last_ghost_hit_access, cold_streak, scan_guard_until, m_key_freq
    _ensure_capacity(cache_snapshot)
    now = cache_snapshot.access_count
    _decay_arc_p_if_idle(now)
    key = obj.key

    # Keep resident metadata consistent with actual cache
    if (len(arc_T1) + len(arc_T2)) != len(cache_snapshot.cache):
        _resync(cache_snapshot)

    # ARC admission: p was already adapted in evict on ghost hits. Place accordingly.
    if key in arc_B1 or key in arc_B2:
        # On a ghost hit, item becomes frequent
        _move_to_mru(arc_T2, key)
        arc_last_ghost_hit_access = now
        cold_streak = 0
        # Initialize/boost frequency on ghost re-admission
        m_key_freq[key] = max(m_key_freq.get(key, 0), 2)
    else:
        # Brand new: insert into T1 (recent)
        _move_to_mru(arc_T1, key)
        cold_streak += 1
        # Initialize frequency low for brand new items
        m_key_freq[key] = max(m_key_freq.get(key, 0), 1)
        # Streaming-aware behavior: early guard and progressive clamp
        if arc_capacity is not None:
            cap = arc_capacity
            # Bias REPLACE to draw from T1 for a short window during scans
            if cold_streak >= max(1, cap // 2):
                scan_guard_until = now + max(1, cap // 8)
            if cold_streak >= cap:
                dec = max(1, cap // 8)
                arc_p = max(0, arc_p - dec)
                # Keep pending hints conservative after clamp
                t1_pending.clear()
                # Prevent unbounded growth of the streak counter to keep adaptation responsive
                if cold_streak >= 2 * cap:
                    arc_p = max(0, arc_p - dec)
                    cold_streak = cap

    # Maintain disjointness: resident keys must not appear in ghosts
    arc_B1.pop(key, None)
    arc_B2.pop(key, None)

    _trim_ghosts()
    m_key_timestamp[key] = now
=======
def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    global m_key_timestamp, arc_p, arc_last_ghost_hit_access, cold_streak, scan_guard_until, m_key_freq
    _ensure_capacity(cache_snapshot)
    now = cache_snapshot.access_count
    _decay_arc_p_if_idle(now)
    key = obj.key

    # Keep resident metadata consistent with actual cache
    if (len(arc_T1) + len(arc_T2)) != len(cache_snapshot.cache):
        _resync(cache_snapshot)

    # ARC admission: p was already adapted in evict on ghost hits. Place accordingly.
    if key in arc_B1 or key in arc_B2:
        # On a ghost hit, item becomes frequent
        _move_to_mru(arc_T2, key)
        arc_last_ghost_hit_access = now
        cold_streak = 0
        # Initialize/boost frequency on ghost re-admission
        m_key_freq[key] = max(m_key_freq.get(key, 0), 2)
    else:
        # Brand new: insert into T1 (recent)
        _move_to_mru(arc_T1, key)
        cold_streak += 1
        # Initialize frequency very low for brand new items
        m_key_freq[key] = 0
        # Streaming-aware behavior: early guard and progressive clamp
        if arc_capacity is not None:
            cap = arc_capacity
            # Bias REPLACE to draw from T1 for a short window during scans
            if cold_streak >= max(1, cap // 2):
                scan_guard_until = now + min(8, max(1, cap // 16))
            if cold_streak >= cap:
                dec = max(1, cap // 16)
                arc_p = max(0, arc_p - dec)
                # Keep pending hints conservative after clamp
                t1_pending.clear()
                # Prevent unbounded growth of the streak counter to keep adaptation responsive
                if cold_streak >= 2 * cap:
                    arc_p = max(0, arc_p - dec)
                    cold_streak = cap

    # Maintain disjointness: resident keys must not appear in ghosts
    arc_B1.pop(key, None)
    arc_B2.pop(key, None)

    _trim_ghosts()
    m_key_timestamp[key] = now
>>>>>>> REPLACE

</DIFF>

<DIFF>
<<<<<<< SEARCH
def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    global m_key_timestamp, m_key_freq
    _ensure_capacity(cache_snapshot)
    k = evicted_obj.key
    # Move evicted resident to corresponding ghost list, keeping ghosts disjoint
    if k in arc_T1:
        arc_T1.pop(k, None)
        _move_to_mru(arc_B1, k)
        arc_B2.pop(k, None)
    elif k in arc_T2:
        arc_T2.pop(k, None)
        _move_to_mru(arc_B2, k)
        arc_B1.pop(k, None)
    else:
        # Unknown membership: prefer B2 if it already exists there, otherwise B1
        if k in arc_B2:
            _move_to_mru(arc_B2, k)
            arc_B1.pop(k, None)
        else:
            _move_to_mru(arc_B1, k)
            arc_B2.pop(k, None)
    # Clean up metadata for evicted item
    m_key_timestamp.pop(k, None)
    m_key_freq.pop(k, None)
    t1_pending.pop(k, None)
    _trim_ghosts()
=======
def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    global m_key_timestamp, m_key_freq, last_replaced_from
    _ensure_capacity(cache_snapshot)
    k = evicted_obj.key
    # Move evicted resident to corresponding ghost list, keeping ghosts disjoint
    if k in arc_T1:
        arc_T1.pop(k, None)
        _move_to_mru(arc_B1, k)
        arc_B2.pop(k, None)
    elif k in arc_T2:
        arc_T2.pop(k, None)
        _move_to_mru(arc_B2, k)
        arc_B1.pop(k, None)
    else:
        # Unknown membership: use the recorded source if available for correct ghost placement
        if last_replaced_from == 'T2':
            _move_to_mru(arc_B2, k)
            arc_B1.pop(k, None)
        elif last_replaced_from == 'T1':
            _move_to_mru(arc_B1, k)
            arc_B2.pop(k, None)
        else:
            # Fallback: prefer B2 if it already exists there, otherwise B1
            if k in arc_B2:
                _move_to_mru(arc_B2, k)
                arc_B1.pop(k, None)
            else:
                _move_to_mru(arc_B1, k)
                arc_B2.pop(k, None)
    # Clean up metadata for evicted item
    m_key_timestamp.pop(k, None)
    m_key_freq.pop(k, None)
    t1_pending.pop(k, None)
    last_replaced_from = None
    _trim_ghosts()
>>>>>>> REPLACE

</DIFF>