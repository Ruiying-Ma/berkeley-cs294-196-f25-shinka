--- a/original.py
+++ b/original.py
@@ -1,255 +1,315 @@
 # EVOLVE-BLOCK-START
-"""Cache eviction algorithm for optimizing hit rates across multiple workloads"""
+"""ARC+LFU(aged) eviction with proportional ghost control and strict invariants.
+
+Architecture:
+- Central policy state encapsulated in module-level dicts, managed via helpers.
+- ARC resident sets: T1 (recent), T2 (frequent).
+- Ghost sets: B1 (evicted from T1), B2 (evicted from T2), sized to 2×capacity with
+  p-aware proportional trimming for sharper steering.
+- p is target size for T1 (0..capacity). On B1/B2 hits, adjust p asymmetrically with
+  bounded steps to avoid overshoot.
+- T2 victim selection uses effective frequency with time-decay, LRU tiebreak.
+
+Invariants enforced:
+- |T1| + |T2| == resident cache size (resync on drift).
+- T-sets and B-sets are disjoint (remove from ghosts on admission/promotion).
+- Ghosts bounded and trimmed after updates.
+"""
 
 from collections import OrderedDict
 
-# LRU timestamp map used as a tie-breaker and fallback
-m_key_timestamp = dict()
-
-# Adaptive Replacement Cache (ARC) metadata
-arc_T1 = OrderedDict()  # recent, resident
-arc_T2 = OrderedDict()  # frequent, resident
-arc_B1 = OrderedDict()  # ghost of T1
-arc_B2 = OrderedDict()  # ghost of T2
-arc_p = 0               # target size of T1
-arc_capacity = None     # will be initialized from cache_snapshot
-
-# Delayed promotion and adaptation state
-t1_pending = dict()             # key -> last hit access_count while in T1
-arc_last_ghost_hit_access = 0   # last access_count when a ghost hit occurred
-arc_last_decay_access = 0       # throttle decay operations
-cold_streak = 0                 # consecutive cold admissions without ghost/hit signal
-
-def _pending_window():
-    cap = arc_capacity if arc_capacity is not None else 1
-    return max(1, cap // 4)
-
-
-def _ensure_capacity(cache_snapshot):
-    global arc_capacity
-    if arc_capacity is None:
-        arc_capacity = max(int(cache_snapshot.capacity), 1)
-
-
-def _move_to_mru(od, key):
-    # Push key to MRU position of an OrderedDict
+# Policy state
+PS = {
+    "cap": None,             # capacity (items)
+    "p": 0,                  # ARC target size for T1
+    "T1": OrderedDict(),     # resident recent
+    "T2": OrderedDict(),     # resident frequent
+    "B1": OrderedDict(),     # ghost of T1 (key -> True)
+    "B2": OrderedDict(),     # ghost of T2 (key -> True)
+    "ts": dict(),            # key -> last access timestamp (for recency/age)
+    "f2": dict(),            # T2 frequency counters
+}
+
+# ------------- Helpers and invariants ------------- #
+
+def _ensure_cap(cache_snapshot):
+    if PS["cap"] is None:
+        PS["cap"] = max(int(cache_snapshot.capacity), 1)
+        # Start p in the middle for faster stabilization
+        PS["p"] = PS["cap"] // 2
+
+def _move_mru(od: OrderedDict, key: str):
     if key in od:
         od.pop(key, None)
     od[key] = True
 
-
-def _pop_lru(od):
-    if od:
-        k, _ = od.popitem(last=False)
-        return k
-    return None
-
+def _pop_lru(od: OrderedDict):
+    if not od:
+        return None
+    k, _ = od.popitem(last=False)
+    return k
+
+def _resync(cache_snapshot):
+    """Align resident metadata with actual cache contents and enforce disjointness."""
+    cache_keys = set(cache_snapshot.cache.keys())
+    # Remove non-resident from T1/T2
+    for k in list(PS["T1"].keys()):
+        if k not in cache_keys:
+            PS["T1"].pop(k, None)
+            PS["ts"].pop(k, None)
+    for k in list(PS["T2"].keys()):
+        if k not in cache_keys:
+            PS["T2"].pop(k, None)
+            PS["ts"].pop(k, None)
+            PS["f2"].pop(k, None)
+    # Add any resident keys missing in metadata into T1
+    for k in cache_keys:
+        if k not in PS["T1"] and k not in PS["T2"]:
+            _move_mru(PS["T1"], k)
+    # Ensure disjointness with ghosts: remove any resident from B1/B2
+    for k in list(PS["B1"].keys()):
+        if k in PS["T1"] or k in PS["T2"]:
+            PS["B1"].pop(k, None)
+    for k in list(PS["B2"].keys()):
+        if k in PS["T1"] or k in PS["T2"]:
+            PS["B2"].pop(k, None)
+    _trim_ghosts()
+
+def _ghost_targets():
+    """Compute proportional ghost targets based on current p: |B1| target = 2p, |B2| = 2C-2p."""
+    C = PS["cap"] if PS["cap"] is not None else 1
+    p = max(0, min(C, PS["p"]))
+    total_ghost_cap = 2 * C
+    target_B1 = min(total_ghost_cap, 2 * p)
+    target_B2 = total_ghost_cap - target_B1
+    return target_B1, target_B2, total_ghost_cap
 
 def _trim_ghosts():
-    # Keep ghosts total size within 2x capacity (more history for adaptation)
-    total = len(arc_B1) + len(arc_B2)
-    cap = (arc_capacity if arc_capacity is not None else 1) * 2
-    while total > cap:
-        # Evict from the larger ghost list first
-        if len(arc_B1) >= len(arc_B2):
-            _pop_lru(arc_B1)
+    """Keep |B1|+|B2| ≤ 2C with proportional trimming around p."""
+    C = PS["cap"] if PS["cap"] is not None else 1
+    target_B1, target_B2, total_cap = _ghost_targets()
+    # Trim until within total cap
+    while len(PS["B1"]) + len(PS["B2"]) > total_cap:
+        # Prefer trimming the list exceeding its proportional target
+        if len(PS["B1"]) > target_B1:
+            _pop_lru(PS["B1"])
+        elif len(PS["B2"]) > target_B2:
+            _pop_lru(PS["B2"])
         else:
-            _pop_lru(arc_B2)
-        total = len(arc_B1) + len(arc_B2)
-
-# Decay controller: if no ghost hits for a while, slowly bias toward recency (smaller p)
-def _decay_arc_p_if_idle(now):
-    global arc_p, arc_last_decay_access
-    if arc_capacity is None:
+            # Otherwise trim the larger ghost
+            if len(PS["B1"]) >= len(PS["B2"]):
+                _pop_lru(PS["B1"])
+            else:
+                _pop_lru(PS["B2"])
+
+def _bounded_inc_dec(x, delta, lo, hi):
+    return max(lo, min(hi, x + delta))
+
+def _adjust_p_on_ghost_hit(in_B1: bool, in_B2: bool):
+    """Adjust p asymmetrically, bounded to avoid runaway."""
+    C = PS["cap"] if PS["cap"] is not None else 1
+    p = PS["p"]
+    if in_B1:
+        # Increase p, favor recency; step bounded by both ratio and C/8 and remaining headroom
+        ratio_step = max(1, len(PS["B2"]) // max(1, len(PS["B1"])))
+        step_cap = max(1, C // 8)
+        inc = min(step_cap, ratio_step, C - p)
+        PS["p"] = _bounded_inc_dec(p, inc, 0, C)
+    elif in_B2:
+        # Decrease p, favor frequency
+        ratio_step = max(1, len(PS["B1"]) // max(1, len(PS["B2"])))
+        step_cap = max(1, C // 8)
+        dec = min(step_cap, ratio_step, p)
+        PS["p"] = _bounded_inc_dec(p, -dec, 0, C)
+
+def _eff_freq(cache_snapshot, k: str):
+    """Aged frequency used for T2 victim selection."""
+    now = cache_snapshot.access_count
+    freq = PS["f2"].get(k, 1)
+    last = PS["ts"].get(k, now)
+    staleness = max(0, now - last)
+    # Window scales with capacity; larger windows reduce over-aging
+    window = max(1, (PS["cap"] if PS["cap"] is not None else 1) // 2)
+    aged = max(1, freq - (staleness // window))
+    return aged, last  # return tuple for tiebreaking
+
+def _choose_t2_victim(cache_snapshot):
+    """Select T2 victim with lowest aged frequency; break ties by oldest last access."""
+    if not PS["T2"]:
+        return None
+    best_k = None
+    best_tuple = None
+    for k in PS["T2"].keys():
+        tup = _eff_freq(cache_snapshot, k)
+        # Compare on (eff_freq, last_ts) — smaller is worse
+        if best_tuple is None or tup < best_tuple:
+            best_tuple = tup
+            best_k = k
+    return best_k
+
+def _replace_should_evict_T1(obj_key: str):
+    """ARC REPLACE decision; returns True to evict from T1, else T2."""
+    t1_sz = len(PS["T1"])
+    # Strict ARC rule
+    if t1_sz and (t1_sz > PS["p"] or (obj_key in PS["B2"] and t1_sz == PS["p"])):
+        return True
+    return False
+
+# ------------- Required API ------------- #
+
+def evict(cache_snapshot, obj):
+    '''
+    Decide eviction victim key using strict ARC REPLACE with LFU-aged T2.
+    '''
+    _ensure_cap(cache_snapshot)
+    _resync(cache_snapshot)
+
+    # Primary ARC choice
+    evict_T1 = _replace_should_evict_T1(obj.key)
+
+    victim = None
+    if evict_T1:
+        # Evict LRU from T1
+        victim = next(iter(PS["T1"])) if PS["T1"] else None
+        if victim is None and PS["T2"]:
+            # Fallback to T2 if T1 empty
+            victim = _choose_t2_victim(cache_snapshot)
+    else:
+        # Evict from T2 with LFU-aged selection
+        victim = _choose_t2_victim(cache_snapshot)
+        if victim is None and PS["T1"]:
+            victim = next(iter(PS["T1"]))
+    # Last resort: if both empty (drift), resync one more time and pick any
+    if victim is None:
+        _resync(cache_snapshot)
+        if PS["T1"]:
+            victim = next(iter(PS["T1"]))
+        elif PS["T2"]:
+            victim = _choose_t2_victim(cache_snapshot)
+        elif cache_snapshot.cache:
+            victim = next(iter(cache_snapshot.cache.keys()))
+    return victim
+
+
+def update_after_hit(cache_snapshot, obj):
+    '''
+    Update metadata on cache hit: promote T1→T2, refresh recency, bump T2 freq.
+    '''
+    _ensure_cap(cache_snapshot)
+    _resync(cache_snapshot)
+    key = obj.key
+    now = cache_snapshot.access_count
+
+    # Refresh timestamp
+    PS["ts"][key] = now
+
+    if key in PS["T1"]:
+        # Promote to T2 on first hit (canonical ARC)
+        PS["T1"].pop(key, None)
+        _move_mru(PS["T2"], key)
+        PS["f2"][key] = PS["f2"].get(key, 1) + 1
+    elif key in PS["T2"]:
+        _move_mru(PS["T2"], key)
+        PS["f2"][key] = PS["f2"].get(key, 1) + 1
+    else:
+        # Drift: if a resident but not tracked, treat as T2 to protect
+        if key in cache_snapshot.cache:
+            _move_mru(PS["T2"], key)
+            PS["f2"][key] = PS["f2"].get(key, 1) + 1
+
+    # Remove from ghosts if present (disjointness)
+    PS["B1"].pop(key, None)
+    PS["B2"].pop(key, None)
+    _trim_ghosts()
+
+
+def update_after_insert(cache_snapshot, obj):
+    '''
+    Update metadata on new insertion (after optional eviction).
+    Handles B1/B2 ghost hits with bounded p-updates and disjointness.
+    '''
+    _ensure_cap(cache_snapshot)
+    _resync(cache_snapshot)
+    key = obj.key
+    now = cache_snapshot.access_count
+
+    in_B1 = key in PS["B1"]
+    in_B2 = key in PS["B2"]
+
+    if in_B1 or in_B2:
+        # Adjust p according to ghost hit type
+        _adjust_p_on_ghost_hit(in_B1, in_B2)
+        # On ghost hit, admit to T2
+        PS["B1"].pop(key, None)
+        PS["B2"].pop(key, None)
+        _move_mru(PS["T2"], key)
+        PS["f2"][key] = PS["f2"].get(key, 1) + 1
+    else:
+        # Cold admission goes to T1
+        _move_mru(PS["T1"], key)
+        # Remove any lingering ghost entry
+        PS["B1"].pop(key, None)
+        PS["B2"].pop(key, None)
+
+    PS["ts"][key] = now
+    _trim_ghosts()
+
+
+def update_after_evict(cache_snapshot, obj, evicted_obj):
+    '''
+    After evicting a resident, move it to the appropriate ghost list and clean state.
+    Maintain ghost disjointness and proportional bounds.
+    '''
+    _ensure_cap(cache_snapshot)
+    if evicted_obj is None:
         return
-    # Only decay if we've had no ghost hits for at least one cache of accesses
-    idle = now - arc_last_ghost_hit_access
-    step_interval = max(1, arc_capacity // 8)
-    if idle >= arc_capacity and (now - arc_last_decay_access) >= step_interval:
-        arc_p = max(0, arc_p - 1)
-        arc_last_decay_access = now
-
-
-def _resync(cache_snapshot):
-    # Ensure resident metadata tracks actual cache content
-    cache_keys = set(cache_snapshot.cache.keys())
-    for k in list(arc_T1.keys()):
-        if k not in cache_keys:
-            arc_T1.pop(k, None)
-    for k in list(arc_T2.keys()):
-        if k not in cache_keys:
-            arc_T2.pop(k, None)
-    # Add any cached keys we missed to T1 as recent
-    for k in cache_keys:
-        if k not in arc_T1 and k not in arc_T2:
-            arc_T1[k] = True
+    k = evicted_obj.key
+
+    # Identify residency and move to proper ghost
+    moved = False
+    if k in PS["T1"]:
+        PS["T1"].pop(k, None)
+        # keep ghosts disjoint
+        PS["B2"].pop(k, None)
+        _move_mru(PS["B1"], k)
+        moved = True
+    elif k in PS["T2"]:
+        PS["T2"].pop(k, None)
+        PS["f2"].pop(k, None)
+        PS["B1"].pop(k, None)
+        _move_mru(PS["B2"], k)
+        moved = True
+    else:
+        # Unknown membership: prefer B2 if it already exists, else B1
+        if k in PS["B2"]:
+            _move_mru(PS["B2"], k)
+        else:
+            PS["B2"].pop(k, None)
+            _move_mru(PS["B1"], k)
+
+    # Remove transient metadata
+    PS["ts"].pop(k, None)
+
+    # Enforce ghost bounds
     _trim_ghosts()
-
-
-def evict(cache_snapshot, obj):
-    '''
-    This function defines how the algorithm chooses the eviction victim.
-    - Args:
-        - `cache_snapshot`: A snapshot of the current cache state.
-        - `obj`: The new object that needs to be inserted into the cache.
-    - Return:
-        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
-    '''
-    _ensure_capacity(cache_snapshot)
-    _resync(cache_snapshot)
-    # ARC replacement: choose between T1 and T2 depending on arc_p and ghost hit type
-    x_in_B2 = obj.key in arc_B2
-    t1_sz = len(arc_T1)
-    candidate = None
-    if t1_sz >= 1 and (t1_sz > arc_p or (x_in_B2 and t1_sz == arc_p)):
-        # Evict LRU from T1
-        candidate = next(iter(arc_T1)) if arc_T1 else None
-    else:
-        # Evict LRU from T2
-        candidate = next(iter(arc_T2)) if arc_T2 else None
-    if candidate is None:
-        # Fallback: choose the oldest by timestamp if available, else any key
-        if m_key_timestamp and cache_snapshot.cache:
-            # LRU among resident keys by timestamp
-            min_ts = min(m_key_timestamp.get(k, float('inf')) for k in cache_snapshot.cache.keys())
-            for k in cache_snapshot.cache.keys():
-                if m_key_timestamp.get(k, float('inf')) == min_ts:
-                    candidate = k
-                    break
-        if candidate is None and cache_snapshot.cache:
-            candidate = next(iter(cache_snapshot.cache.keys()))
-    return candidate
-
-
-def update_after_hit(cache_snapshot, obj):
-    '''
-    This function defines how the algorithm update the metadata it maintains immediately after a cache hit.
-    - Args:
-        - `cache_snapshot`: A snapshot of the current cache state.
-        - `obj`: The object accessed during the cache hit.
-    - Return: `None`
-    '''
-    global m_key_timestamp, cold_streak
-    _ensure_capacity(cache_snapshot)
-    now = cache_snapshot.access_count
-    _decay_arc_p_if_idle(now)
-    # Any hit breaks cold streaks
-    cold_streak = 0
-
-    key = obj.key
-    if key in arc_T1:
-        # Delayed promotion: require a second hit within a short window
-        last = t1_pending.get(key)
-        if last is not None and now - last <= _pending_window():
-            arc_T1.pop(key, None)
-            t1_pending.pop(key, None)
-            _move_to_mru(arc_T2, key)
-        else:
-            _move_to_mru(arc_T1, key)
-            t1_pending[key] = now
-    elif key in arc_T2:
-        _move_to_mru(arc_T2, key)
-    else:
-        # Metadata drift: protect a hit by placing into T2
-        _move_to_mru(arc_T2, key)
-    # Update timestamp for tie-breaking/fallback
-    m_key_timestamp[key] = now
-
-
-def update_after_insert(cache_snapshot, obj):
-    '''
-    This function defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
-    - Args:
-        - `cache_snapshot`: A snapshot of the current cache state.
-        - `obj`: The object that was just inserted into the cache.
-    - Return: `None`
-    '''
-    global m_key_timestamp, arc_p, arc_last_ghost_hit_access, cold_streak
-    _ensure_capacity(cache_snapshot)
-    now = cache_snapshot.access_count
-    _decay_arc_p_if_idle(now)
-    key = obj.key
-    step_cap = max(1, (arc_capacity if arc_capacity is not None else 1) // 8)
-
-    # ARC admission policy
-    if key in arc_B1:
-        # Previously evicted from T1: favor recency by increasing p (bounded)
-        raw = max(1, len(arc_B2) // max(1, len(arc_B1)))
-        inc = min(step_cap, raw)
-        arc_p = min(arc_capacity, arc_p + inc)
-        arc_B1.pop(key, None)
-        _move_to_mru(arc_T2, key)
-        arc_last_ghost_hit_access = now
-        cold_streak = 0
-    elif key in arc_B2:
-        # Previously frequent: favor frequency by decreasing p (bounded)
-        raw = max(1, len(arc_B1) // max(1, len(arc_B2)))
-        dec = min(step_cap, raw)
-        arc_p = max(0, arc_p - dec)
-        arc_B2.pop(key, None)
-        _move_to_mru(arc_T2, key)
-        arc_last_ghost_hit_access = now
-        cold_streak = 0
-    else:
-        # Brand new: insert into T1 (recent)
-        _move_to_mru(arc_T1, key)
-        cold_streak += 1
-        # Scan clamp: on long cold streaks, bias toward recency by reducing p
-        if arc_capacity is not None and cold_streak > arc_capacity:
-            arc_p = max(0, arc_p - max(1, arc_capacity // 4))
-            # Keep pending hints conservative after clamp
-            t1_pending.clear()
-            cold_streak = 0
-
-    _trim_ghosts()
-    m_key_timestamp[key] = now
-
-
-def update_after_evict(cache_snapshot, obj, evicted_obj):
-    '''
-    This function defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
-    - Args:
-        - `cache_snapshot`: A snapshot of the current cache state.
-        - `obj`: The object to be inserted into the cache.
-        - `evicted_obj`: The object that was just evicted from the cache.
-    - Return: `None`
-    '''
-    global m_key_timestamp
-    _ensure_capacity(cache_snapshot)
-    k = evicted_obj.key
-    # Move evicted resident to corresponding ghost list
-    if k in arc_T1:
-        arc_T1.pop(k, None)
-        _move_to_mru(arc_B1, k)
-    elif k in arc_T2:
-        arc_T2.pop(k, None)
-        _move_to_mru(arc_B2, k)
-    else:
-        # Unknown membership: default to B1
-        _move_to_mru(arc_B1, k)
-    # Clean up metadata for evicted item
-    m_key_timestamp.pop(k, None)
-    t1_pending.pop(k, None)
-    _trim_ghosts()
-
 # EVOLVE-BLOCK-END
 
 # This part remains fixed (not evolved)
 def run_caching(trace_path: str, copy_code_dst: str):
     """Run the caching algorithm on a trace"""
     import os
     with open(os.path.abspath(__file__), 'r', encoding="utf-8") as f:
         code_str = f.read()
     with open(os.path.join(copy_code_dst), 'w') as f:
         f.write(code_str)
     from cache_utils import Cache, CacheConfig, CacheObj, Trace
     trace = Trace(trace_path=trace_path)
     cache_capacity = max(int(trace.get_ndv() * 0.1), 1)
     cache = Cache(CacheConfig(cache_capacity))
     for entry in trace.entries:
         obj = CacheObj(key=str(entry.key))
         cache.get(obj)
     with open(copy_code_dst, 'w') as f:
         f.write("")
     hit_rate = round(cache.hit_count / cache.access_count, 6)
     return hit_rate