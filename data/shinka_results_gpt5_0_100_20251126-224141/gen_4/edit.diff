--- a/original.py
+++ b/original.py
@@ -1,113 +1,221 @@
 # EVOLVE-BLOCK-START
-"""Cache eviction algorithm for optimizing hit rates across multiple workloads"""
-
-# Metadata
-# - m_key_timestamp: last access time for each cached key
-# - m_key_segment: 'p' = protected (frequent), 'b' = probation (recent/unproven)
+"""Cache eviction algorithm for optimizing hit rates across multiple workloads
+Simplified ARC:
+- Resident sets: T1 (recent), T2 (frequent).
+- Ghost sets: B1 (recently evicted from T1), B2 (recently evicted from T2).
+- Adaptive target p controls desired size of T1.
+"""
+
+# Resident metadata
+# - m_key_timestamp: last access time for each resident key
+# - m_key_segment: 't1' (recent) or 't2' (frequent) for resident keys
 m_key_timestamp = dict()
 m_key_segment = dict()
 
-def _protected_limit(cache_snapshot):
-    """Target size for the protected segment (80% of capacity, at least 1)."""
+# Ghost metadata (key -> last timestamp when it entered ghost)
+m_ghost_b1_ts = dict()
+m_ghost_b2_ts = dict()
+
+# Adaptive target for T1 size
+m_target_p = None
+
+
+def _cap(cache_snapshot):
     try:
-        cap = int(cache_snapshot.capacity)
+        return int(cache_snapshot.capacity)
     except Exception:
-        cap = max(1, len(cache_snapshot.cache))
-    return max(1, int(0.8 * cap))
-
-def _demote_if_needed(cache_snapshot):
-    """Ensure protected segment does not exceed its quota by demoting its LRU."""
-    prot_limit = _protected_limit(cache_snapshot)
-    prot_keys = [k for k in cache_snapshot.cache if m_key_segment.get(k) == 'p']
-    if len(prot_keys) <= prot_limit:
-        return
-    # Demote LRU from protected to probation
-    lru_key = min(prot_keys, key=lambda k: m_key_timestamp.get(k, float('inf')))
-    m_key_segment[lru_key] = 'b'
+        return max(1, len(cache_snapshot.cache))
+
+
+def _ensure_init(cache_snapshot):
+    global m_target_p
+    if m_target_p is None:
+        m_target_p = max(1, _cap(cache_snapshot) // 2)
+
+
+def _resident_sets(cache_snapshot):
+    """Return (t1_keys, t2_keys) among current cache keys, using metadata."""
+    cache_keys = set(cache_snapshot.cache.keys())
+    t1_keys = []
+    t2_keys = []
+    for k in cache_keys:
+        seg = m_key_segment.get(k, 't1')
+        if seg == 't2':
+            t2_keys.append(k)
+        else:
+            # default everything unknown to t1
+            if seg not in ('t1', 't2'):
+                m_key_segment[k] = 't1'
+            t1_keys.append(k)
+    return t1_keys, t2_keys
+
+
+def _lru_key(keys):
+    """Return LRU key among `keys` using m_key_timestamp; None if empty."""
+    if not keys:
+        return None
+    return min(keys, key=lambda k: m_key_timestamp.get(k, float('inf')))
+
+
+def _prune_ghosts(cache_snapshot):
+    """Keep total ghost size <= capacity by discarding oldest ghosts."""
+    total = len(m_ghost_b1_ts) + len(m_ghost_b2_ts)
+    cap = _cap(cache_snapshot)
+    while total > cap:
+        # Evict the oldest across both ghosts
+        b1_old_key = min(m_ghost_b1_ts, key=m_ghost_b1_ts.get) if m_ghost_b1_ts else None
+        b2_old_key = min(m_ghost_b2_ts, key=m_ghost_b2_ts.get) if m_ghost_b2_ts else None
+        if b1_old_key is None and b2_old_key is None:
+            break
+        if b2_old_key is None or (b1_old_key is not None and m_ghost_b1_ts[b1_old_key] <= m_ghost_b2_ts.get(b2_old_key, float('inf'))):
+            m_ghost_b1_ts.pop(b1_old_key, None)
+        else:
+            m_ghost_b2_ts.pop(b2_old_key, None)
+        total = len(m_ghost_b1_ts) + len(m_ghost_b2_ts)
+
 
 def evict(cache_snapshot, obj):
     '''
     This function defines how the algorithm chooses the eviction victim.
     - Args:
         - `cache_snapshot`: A snapshot of the current cache state.
         - `obj`: The new object that needs to be inserted into the cache.
     - Return:
         - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
     '''
-    # Prefer evicting from probation (items not yet proven frequent)
-    probation_keys = [k for k in cache_snapshot.cache if m_key_segment.get(k, 'b') == 'b']
-    if probation_keys:
-        victim = min(probation_keys, key=lambda k: m_key_timestamp.get(k, float('inf')))
-        return victim
-    # Fallback: evict global LRU
+    _ensure_init(cache_snapshot)
+    t1_keys, t2_keys = _resident_sets(cache_snapshot)
+
+    # ARC-like replace() rule:
+    # Prefer evicting from T1 when:
+    # - T1 is larger than target p, or
+    # - The incoming key is in B2 and T1 is at target (to reduce T1), or
+    # - T2 is empty (nothing protected yet).
+    evict_from_t1 = False
+    if len(t1_keys) > m_target_p:
+        evict_from_t1 = True
+    elif obj.key in m_ghost_b2_ts and len(t1_keys) >= max(1, m_target_p):
+        evict_from_t1 = True
+    elif not t2_keys and t1_keys:
+        evict_from_t1 = True
+
+    if evict_from_t1 and t1_keys:
+        victim = _lru_key(t1_keys)
+        if victim is not None:
+            return victim
+
+    # Otherwise evict LRU from T2 if available
+    if t2_keys:
+        victim = _lru_key(t2_keys)
+        if victim is not None:
+            return victim
+
+    # Fallback: global LRU
     all_keys = list(cache_snapshot.cache.keys())
-    victim = min(all_keys, key=lambda k: m_key_timestamp.get(k, float('inf')))
-    return victim
+    if not all_keys:
+        return None
+    return _lru_key(all_keys)
+
 
 def update_after_hit(cache_snapshot, obj):
     '''
     This function defines how the algorithm update the metadata it maintains immediately after a cache hit.
     - Args:
         - `cache_snapshot`: A snapshot of the current cache state.
         - `obj`: The object accessed during the cache hit.
     - Return: `None`
     '''
     global m_key_timestamp, m_key_segment
+    _ensure_init(cache_snapshot)
+
     # Refresh recency
     m_key_timestamp[obj.key] = cache_snapshot.access_count
-    # Promote to protected on first post-admission hit
-    if m_key_segment.get(obj.key, 'b') == 'b':
-        m_key_segment[obj.key] = 'p'
-    # Enforce protected quota
-    _demote_if_needed(cache_snapshot)
+
+    # Promote from T1 to T2 on a hit (frequency signal)
+    seg = m_key_segment.get(obj.key, 't1')
+    if seg != 't2':
+        m_key_segment[obj.key] = 't2'
+
 
 def update_after_insert(cache_snapshot, obj):
     '''
     This function defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
     - Args:
         - `cache_snapshot`: A snapshot of the current cache state.
         - `obj`: The object that was just inserted into the cache.
     - Return: `None`
     '''
-    global m_key_timestamp, m_key_segment
-    # New entries start in probation
+    global m_key_timestamp, m_key_segment, m_target_p
+    _ensure_init(cache_snapshot)
+
+    # ARC adaptation: if we see a miss on a key present in a ghost list,
+    # adjust target p and insert into T2.
+    seg = 't1'
+    if obj.key in m_ghost_b1_ts:
+        # Increase p (give more room to recency) proportional to |B2|/|B1|
+        inc = max(1, len(m_ghost_b2_ts) // max(1, len(m_ghost_b1_ts)))
+        m_target_p = min(_cap(cache_snapshot), m_target_p + inc)
+        m_ghost_b1_ts.pop(obj.key, None)
+        seg = 't2'
+    elif obj.key in m_ghost_b2_ts:
+        # Decrease p (favor frequency) proportional to |B1|/|B2|
+        dec = max(1, len(m_ghost_b1_ts) // max(1, len(m_ghost_b2_ts)))
+        m_target_p = max(0, m_target_p - dec)
+        m_ghost_b2_ts.pop(obj.key, None)
+        seg = 't2'
+
+    # Insert into resident set
+    m_key_segment[obj.key] = seg
     m_key_timestamp[obj.key] = cache_snapshot.access_count
-    m_key_segment[obj.key] = 'b'
-    # Keep protected within quota as cache grows
-    _demote_if_needed(cache_snapshot)
+
+    # Control ghost size
+    _prune_ghosts(cache_snapshot)
+
 
 def update_after_evict(cache_snapshot, obj, evicted_obj):
     '''
     This function defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
     - Args:
         - `cache_snapshot`: A snapshot of the current cache state.
         - `obj`: The object to be inserted into the cache.
         - `evicted_obj`: The object that was just evicted from the cache.
     - Return: `None`
     '''
-    global m_key_timestamp, m_key_segment
-    # Clean up all metadata for the evicted object
+    global m_key_timestamp, m_key_segment, m_ghost_b1_ts, m_ghost_b2_ts
+    _ensure_init(cache_snapshot)
+
+    # Remove resident metadata for evicted key
+    seg = m_key_segment.pop(evicted_obj.key, 't1')
     m_key_timestamp.pop(evicted_obj.key, None)
-    m_key_segment.pop(evicted_obj.key, None)
+
+    # Add to corresponding ghost list with current time to maintain LRU
+    ts = cache_snapshot.access_count
+    if seg == 't2':
+        m_ghost_b2_ts[evicted_obj.key] = ts
+    else:
+        m_ghost_b1_ts[evicted_obj.key] = ts
+
+    # Control ghost size
+    _prune_ghosts(cache_snapshot)
 
 # EVOLVE-BLOCK-END
 
 # This part remains fixed (not evolved)
 def run_caching(trace_path: str, copy_code_dst: str):
     """Run the caching algorithm on a trace"""
     import os
     with open(os.path.abspath(__file__), 'r', encoding="utf-8") as f:
         code_str = f.read()
     with open(os.path.join(copy_code_dst), 'w') as f:
         f.write(code_str)
     from cache_utils import Cache, CacheConfig, CacheObj, Trace
     trace = Trace(trace_path=trace_path)
     cache_capacity = max(int(trace.get_ndv() * 0.1), 1)
     cache = Cache(CacheConfig(cache_capacity))
     for entry in trace.entries:
         obj = CacheObj(key=str(entry.key))
         cache.get(obj)
     with open(copy_code_dst, 'w') as f:
         f.write("")
     hit_rate = round(cache.hit_count / cache.access_count, 6)
     return hit_rate