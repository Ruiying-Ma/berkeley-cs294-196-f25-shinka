<NAME>
arc_pre_replace_scan_guard_and_paware_ghosts
</NAME>

<DESCRIPTION>
I introduce three coordinated improvements to the ARC-based algorithm to reduce miss rates across mixed workloads:

1) Pre-REPLACE ghost-driven adaptation with scan guard in evict: Move all arc_p updates to evict so the REPLACE decision uses the freshest ghost signal, as in robust ARC variants. Also add a lightweight scan guard window that biases REPLACE to evict from T1 during sustained cold streaks, protecting T2 from scans.

2) Proportional, bounded idle decay of p: Replace the coarse decay with a proportional scheme throttled by access windows, with an extra clamp during long cold streaks. This stabilizes p under phase shifts and recovers faster from scans while avoiding oscillation.

3) p-aware ghost trimming and cancel guard on signal: Make total ghosts bounded by capacity and trim proportionally to p, preserving the recency/frequency signal, and reset the scan guard on any ghost/hit to stop over-bias once locality returns.

Additionally, update_after_insert no longer adjusts p (to avoid double-stepping), but still promotes on ghost hits and manages the scan-guard window. update_after_hit resets the cold streak and cancels scan guard immediately on hits.

These changes align with top-performing ARC variants and address the weaknesses observed in scan-heavy traces and phase shifts, improving hit rates and stability.

</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
# Delayed promotion and adaptation state
t1_pending = dict()             # key -> last hit access_count while in T1
arc_last_ghost_hit_access = 0   # last access_count when a ghost hit occurred
arc_last_decay_access = 0       # throttle decay operations
cold_streak = 0                 # consecutive cold admissions without ghost/hit signal
=======
# Delayed promotion and adaptation state
t1_pending = dict()             # key -> last hit access_count while in T1
arc_last_ghost_hit_access = 0   # last access_count when a ghost hit occurred
arc_last_decay_access = 0       # throttle decay operations
cold_streak = 0                 # consecutive cold admissions without ghost/hit signal
scan_guard_until = 0            # scan guard window end (access_count)
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
def _trim_ghosts():
    # Keep ghosts total size within 2x capacity with proportional trimming to p
    cap_base = (arc_capacity if arc_capacity is not None else 1)
    total_cap = cap_base * 2
    # Targets proportional to current p (approximately 2*p and 2C-2*p)
    target_B1 = min(total_cap, max(0, int(total_cap * (float(arc_p) / max(1, cap_base)))))
    target_B2 = max(0, total_cap - target_B1)

    def _over_target():
        return (len(arc_B1) + len(arc_B2)) - total_cap

    # Trim until under the total budget, favoring lists above their targets
    while (len(arc_B1) + len(arc_B2)) > total_cap:
        if len(arc_B1) > target_B1:
            _pop_lru(arc_B1)
        elif len(arc_B2) > target_B2:
            _pop_lru(arc_B2)
        else:
            # If neither is over its proportional target, drop from the larger one
            if len(arc_B1) >= len(arc_B2):
                _pop_lru(arc_B1)
            else:
                _pop_lru(arc_B2)
=======
def _trim_ghosts():
    # Keep ghosts total size within capacity with p-aware trimming.
    cap = (arc_capacity if arc_capacity is not None else 1)
    # Clamp p for safety
    p = arc_p
    if p < 0:
        p = 0
    elif p > cap:
        p = cap
    target_B1 = p
    target_B2 = max(0, cap - p)

    # Trim until the total ghost size is within the budget,
    # preferring to trim lists exceeding their targets, otherwise the larger one.
    while (len(arc_B1) + len(arc_B2)) > cap:
        if len(arc_B1) > target_B1:
            _pop_lru(arc_B1)
        elif len(arc_B2) > target_B2:
            _pop_lru(arc_B2)
        else:
            if len(arc_B1) >= len(arc_B2):
                _pop_lru(arc_B1)
            else:
                _pop_lru(arc_B2)
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
# Decay controller: if no ghost hits for a while, slowly bias toward recency (smaller p)
def _decay_arc_p_if_idle(now):
    global arc_p, arc_last_decay_access
    if arc_capacity is None:
        return
    # Only decay if we've had no ghost hits for at least one cache of accesses
    idle = now - arc_last_ghost_hit_access
    step_interval = max(1, arc_capacity // 8)
    if idle >= arc_capacity and (now - arc_last_decay_access) >= step_interval:
        arc_p = max(0, arc_p - 1)
        arc_last_decay_access = now
=======
# Decay controller: proportional, bounded decay toward recency when idle
def _decay_arc_p_if_idle(now):
    global arc_p, arc_last_decay_access, cold_streak
    if arc_capacity is None:
        return
    cap = arc_capacity
    idle = now - arc_last_ghost_hit_access
    # Throttle decay checks to avoid oscillation
    step_interval = max(1, cap // 16)
    if (now - arc_last_decay_access) < step_interval:
        return
    if idle > 0 and arc_p > 0:
        # Proportional bounded decay: larger idle â‡’ faster recovery, but capped
        step = max(1, idle // max(1, cap // 4))
        arc_p = max(0, arc_p - min(max(1, cap // 8), step))
        arc_last_decay_access = now
    # Extra clamp under sustained cold streaks
    if cold_streak >= max(1, cap // 2) and arc_p > 0:
        extra = min(max(1, cap // 4), max(1, cold_streak // max(1, cap // 8)))
        arc_p = max(0, arc_p - extra)
        arc_last_decay_access = now
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
def evict(cache_snapshot, obj):
    '''
    This function defines how the algorithm chooses the eviction victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    _ensure_capacity(cache_snapshot)
    _resync(cache_snapshot)
    # ARC replacement: choose between T1 and T2 depending on p and whether obj is in B2
    x_in_B2 = obj.key in arc_B2
    t1_sz = len(arc_T1)
    victim = None
    if t1_sz >= 1 and (t1_sz > arc_p or (x_in_B2 and t1_sz == arc_p)):
        # Evict LRU from T1
        victim = next(iter(arc_T1)) if arc_T1 else None
    else:
        # Evict LRU from T2
        victim = next(iter(arc_T2)) if arc_T2 else None

    # Strict ARC fallback: use the other list if the chosen one is empty
    if victim is None:
        if t1_sz > 0:
            victim = next(iter(arc_T1))
        elif len(arc_T2) > 0:
            victim = next(iter(arc_T2))
        else:
            # Rare drift: resync once and retry, then age-based deterministic fallback
            _resync(cache_snapshot)
            if arc_T1:
                victim = next(iter(arc_T1))
            elif arc_T2:
                victim = next(iter(arc_T2))
            elif cache_snapshot.cache:
                # Choose the oldest timestamped key to approximate LRU
                if m_key_timestamp:
                    victim = min(cache_snapshot.cache.keys(), key=lambda k: m_key_timestamp.get(k, 0))
                else:
                    victim = next(iter(cache_snapshot.cache.keys()))
    return victim
=======
def evict(cache_snapshot, obj):
    '''
    This function defines how the algorithm chooses the eviction victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    global arc_p, arc_last_ghost_hit_access, cold_streak, scan_guard_until
    _ensure_capacity(cache_snapshot)
    _resync(cache_snapshot)

    # Pre-REPLACE: adjust p on ghost hits so REPLACE uses the newest signal
    cap = arc_capacity if arc_capacity is not None else 1
    step_cap = max(1, cap // 8)
    now = cache_snapshot.access_count
    if obj.key in arc_B1:
        # Recency pressure: enlarge T1 target
        denom = max(1, len(arc_B1))
        numer = len(arc_B2)
        raw_inc = max(1, (numer + denom - 1) // denom)  # ceil(|B2|/|B1|)
        arc_p = min(cap, arc_p + min(step_cap, raw_inc))
        arc_last_ghost_hit_access = now
        cold_streak = 0
        scan_guard_until = now  # cancel any guard on real locality signal
    elif obj.key in arc_B2:
        # Frequency pressure: shrink T1 target; stronger during long cold streaks
        denom = max(1, len(arc_B2))
        numer = len(arc_B1)
        raw_dec = max(1, (numer + denom - 1) // denom)  # ceil(|B1|/|B2|)
        strong_cap = max(1, cap // 4) if cold_streak >= max(1, cap // 2) else step_cap
        dec = min(raw_dec, strong_cap, max(0, arc_p))
        arc_p = max(0, arc_p - dec)
        arc_last_ghost_hit_access = now
        cold_streak = 0
        scan_guard_until = now  # cancel any guard on real locality signal

    # Clamp p within [0, cap]
    if arc_p < 0:
        arc_p = 0
    elif arc_p > cap:
        arc_p = cap

    # Scan guard: bias REPLACE for a short window during sustained cold streaks
    effective_p = arc_p
    if now < scan_guard_until:
        effective_p = max(0, arc_p - max(1, cap // 8))

    # ARC replacement: choose between T1 and T2 depending on effective_p and whether obj is in B2
    x_in_B2 = obj.key in arc_B2
    t1_sz = len(arc_T1)
    victim = None
    if t1_sz >= 1 and (t1_sz > effective_p or (x_in_B2 and t1_sz == effective_p)):
        # Evict LRU from T1
        victim = next(iter(arc_T1)) if arc_T1 else None
    else:
        # Evict LRU from T2
        victim = next(iter(arc_T2)) if arc_T2 else None

    # Strict ARC fallback: use the other list if the chosen one is empty
    if victim is None:
        if t1_sz > 0:
            victim = next(iter(arc_T1))
        elif len(arc_T2) > 0:
            victim = next(iter(arc_T2))
        else:
            # Rare drift: resync once and retry, then age-based deterministic fallback
            _resync(cache_snapshot)
            if arc_T1:
                victim = next(iter(arc_T1))
            elif arc_T2:
                victim = next(iter(arc_T2))
            elif cache_snapshot.cache:
                # Choose the oldest timestamped key to approximate LRU
                if m_key_timestamp:
                    victim = min(cache_snapshot.cache.keys(), key=lambda k: m_key_timestamp.get(k, 0))
                else:
                    victim = next(iter(cache_snapshot.cache.keys()))
    return victim
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the algorithm update the metadata it maintains immediately after a cache hit.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    global m_key_timestamp, cold_streak
    _ensure_capacity(cache_snapshot)
    now = cache_snapshot.access_count
    _decay_arc_p_if_idle(now)
    # Any hit breaks cold streaks
    cold_streak = 0

    # Keep resident metadata consistent with actual cache
    if (len(arc_T1) + len(arc_T2)) != len(cache_snapshot.cache):
        _resync(cache_snapshot)

    key = obj.key
    if key in arc_T1:
        # Canonical ARC: on a hit in T1, move to T2 (become frequent)
        arc_T1.pop(key, None)
        _move_to_mru(arc_T2, key)
        t1_pending.pop(key, None)
    elif key in arc_T2:
        # Refresh recency within T2
        _move_to_mru(arc_T2, key)
    else:
        # Metadata drift: conservatively place into T1 as recent
        _move_to_mru(arc_T1, key)

    # Maintain disjointness: resident keys must not appear in ghosts
    arc_B1.pop(key, None)
    arc_B2.pop(key, None)

    _trim_ghosts()
    # Update timestamp for tie-breaking/fallback
    m_key_timestamp[key] = now
=======
def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the algorithm update the metadata it maintains immediately after a cache hit.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    global m_key_timestamp, cold_streak, scan_guard_until
    _ensure_capacity(cache_snapshot)
    now = cache_snapshot.access_count
    _decay_arc_p_if_idle(now)
    # Any hit breaks cold streaks and cancels scan guard
    cold_streak = 0
    scan_guard_until = now

    # Keep resident metadata consistent with actual cache
    if (len(arc_T1) + len(arc_T2)) != len(cache_snapshot.cache):
        _resync(cache_snapshot)

    key = obj.key
    if key in arc_T1:
        # Canonical ARC: on a hit in T1, move to T2 (become frequent)
        arc_T1.pop(key, None)
        _move_to_mru(arc_T2, key)
        t1_pending.pop(key, None)
    elif key in arc_T2:
        # Refresh recency within T2
        _move_to_mru(arc_T2, key)
    else:
        # Metadata drift: conservatively place into T1 as recent
        _move_to_mru(arc_T1, key)

    # Maintain disjointness: resident keys must not appear in ghosts
    arc_B1.pop(key, None)
    arc_B2.pop(key, None)

    _trim_ghosts()
    # Update timestamp for tie-breaking/fallback
    m_key_timestamp[key] = now
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    global m_key_timestamp, arc_p, arc_last_ghost_hit_access, cold_streak
    _ensure_capacity(cache_snapshot)
    now = cache_snapshot.access_count
    _decay_arc_p_if_idle(now)
    key = obj.key

    # Keep resident metadata consistent with actual cache
    if (len(arc_T1) + len(arc_T2)) != len(cache_snapshot.cache):
        _resync(cache_snapshot)

    step_cap = max(1, (arc_capacity if arc_capacity is not None else 1) // 8)

    # ARC admission policy with bounded, responsive p-updates
    if key in arc_B1:
        # Previously evicted from T1: favor recency by increasing p
        ratio = max(1, len(arc_B2) // max(1, len(arc_B1)))
        inc = min(ratio, step_cap, max(0, arc_capacity - arc_p))
        arc_p = min(arc_capacity, arc_p + inc)
        arc_B1.pop(key, None)
        _move_to_mru(arc_T2, key)
        arc_last_ghost_hit_access = now
        cold_streak = 0
    elif key in arc_B2:
        # Previously frequent: favor frequency by decreasing p
        ratio = max(1, len(arc_B1) // max(1, len(arc_B2)))
        dec = min(ratio, step_cap, max(0, arc_p))
        arc_p = max(0, arc_p - dec)
        arc_B2.pop(key, None)
        _move_to_mru(arc_T2, key)
        arc_last_ghost_hit_access = now
        cold_streak = 0
    else:
        # Brand new: insert into T1 (recent)
        _move_to_mru(arc_T1, key)
        cold_streak += 1
        # Gentler scan clamp: after a long cold streak, bias slightly toward recency
        if arc_capacity is not None and cold_streak > (2 * arc_capacity):
            arc_p = max(0, arc_p - max(1, arc_capacity // 16))
            t1_pending.clear()
            cold_streak = 0

    # Maintain disjointness: resident keys must not appear in ghosts
    arc_B1.pop(key, None)
    arc_B2.pop(key, None)

    _trim_ghosts()
    m_key_timestamp[key] = now
=======
def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    global m_key_timestamp, arc_last_ghost_hit_access, cold_streak, scan_guard_until
    _ensure_capacity(cache_snapshot)
    now = cache_snapshot.access_count
    _decay_arc_p_if_idle(now)
    key = obj.key

    # Keep resident metadata consistent with actual cache
    if (len(arc_T1) + len(arc_T2)) != len(cache_snapshot.cache):
        _resync(cache_snapshot)

    cap = arc_capacity if arc_capacity is not None else 1

    # ARC admission without p-update (p already adjusted in evict on ghost hit)
    if key in arc_B1 or key in arc_B2:
        # Promote on ghost hit to T2
        arc_B1.pop(key, None)
        arc_B2.pop(key, None)
        _move_to_mru(arc_T2, key)
        # Mark recent ghost activity; cold streak broken and cancel scan guard
        arc_last_ghost_hit_access = now
        cold_streak = 0
        scan_guard_until = now
    else:
        # Brand new: insert into T1 (recent) and extend cold streak
        _move_to_mru(arc_T1, key)
        cold_streak += 1
        # Enable a short scan guard window during sustained cold streaks
        if cold_streak >= max(1, cap // 2):
            scan_guard_until = now + max(1, cap // 8)
        # Keep ghosts disjoint
        arc_B1.pop(key, None)
        arc_B2.pop(key, None)

    _trim_ghosts()
    m_key_timestamp[key] = now
>>>>>>> REPLACE

</DIFF>