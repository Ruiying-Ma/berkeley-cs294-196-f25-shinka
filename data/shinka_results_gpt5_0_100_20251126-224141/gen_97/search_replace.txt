<NAME>
freq_aware_t2_and_faster_decay
</NAME>

<DESCRIPTION>
I introduce two synergistic improvements:
1) Frequency-aware eviction from T2: Rather than evicting pure LRU from T2, the algorithm now selects the lowest-frequency item within a small LRU-side window of T2. This preserves highly frequent items longer and reduces misses on multi-modal and Zipfian workloads, while still keeping the decision mostly local and stable.
2) Stronger, more responsive Tiny-LFU signal: I accelerate the frequency decay to occur more often and use halving (exponential aging) instead of linear decrement. This keeps the frequency map fresh and bounded, preventing older popularity from dominating long after a phase shift.

Additionally, I align frequency increments with promotion events:
- Hits in T2 increment frequency by 2, reflecting stronger evidence of usefulness.
- Ghost hits (B1/B2 promotions to T2) set at least a frequency of 2.
These changes help the algorithm more effectively distinguish hot items and avoid evicting them, improving hit rates across diverse traces.

The rest of ARC mechanics, scan guard, ghost trimming, and p-adaptation remain intact and consistent with previous logic.

</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
def _maybe_decay_freq(cache_snapshot):
    # Periodically decay resident frequencies to keep LFU signal fresh and bounded
    global last_freq_decay_access
    _ensure_capacity(cache_snapshot)
    C = arc_capacity if arc_capacity else 1
    interval = max(64, C)
    if cache_snapshot.access_count - last_freq_decay_access >= interval:
        for k in list(m_key_freq.keys()):
            v = m_key_freq.get(k, 0)
            if v <= 1:
                m_key_freq.pop(k, None)
            else:
                m_key_freq[k] = v - 1
        last_freq_decay_access = cache_snapshot.access_count
=======
def _maybe_decay_freq(cache_snapshot):
    # Periodically decay resident frequencies using exponential aging for freshness
    global last_freq_decay_access
    _ensure_capacity(cache_snapshot)
    C = arc_capacity if arc_capacity else 1
    # Decay a bit more frequently and halve counts to forget stale popularity faster
    interval = max(32, C // 2)
    if cache_snapshot.access_count - last_freq_decay_access >= interval:
        for k in list(m_key_freq.keys()):
            v = m_key_freq.get(k, 0)
            nv = (v + 1) // 2  # halve (round up); quickly suppresses stale heavy hitters
            if nv <= 0:
                m_key_freq.pop(k, None)
            else:
                m_key_freq[k] = nv
        last_freq_decay_access = cache_snapshot.access_count
>>>>>>> REPLACE
</DIFF>

<DIFF>
<<<<<<< SEARCH
    if t1_sz >= 1 and (t1_sz > p_eff or (in_B2 and t1_sz == p_eff)):
        # Evict from T1: use Tiny-LFU-biased pick in a small LRU-side window
        window = min(8, max(1, C // 8))
        candidate = _pick_freq_aware_lru(arc_T1, window)
        if candidate is not None:
            last_replaced_from = 'T1'
    else:
        # Evict from T2: stick to pure LRU to avoid over-bias
        candidate = next(iter(arc_T2)) if arc_T2 else None
        if candidate is not None:
            last_replaced_from = 'T2'
=======
    if t1_sz >= 1 and (t1_sz > p_eff or (in_B2 and t1_sz == p_eff)):
        # Evict from T1: use Tiny-LFU-biased pick in a small LRU-side window
        window_T1 = min(8, max(1, C // 16))
        candidate = _pick_freq_aware_lru(arc_T1, window_T1)
        if candidate is not None:
            last_replaced_from = 'T1'
    else:
        # Evict from T2: prefer the lowest-frequency item within a slightly larger LRU window
        window_T2 = min(16, max(2, C // 8))
        candidate = _pick_freq_aware_lru(arc_T2, window_T2) if arc_T2 else None
        if candidate is not None:
            last_replaced_from = 'T2'
>>>>>>> REPLACE
</DIFF>

<DIFF>
<<<<<<< SEARCH
    # Update timestamp and frequency for tie-breaking/fallback
    m_key_timestamp[key] = cache_snapshot.access_count
    m_key_freq[key] = m_key_freq.get(key, 0) + 1
=======
    # Update timestamp and frequency for tie-breaking/fallback
    m_key_timestamp[key] = cache_snapshot.access_count
    # Hits in T2 are stronger evidence; reward with a larger increment
    in_T2_after = key in arc_T2
    m_key_freq[key] = m_key_freq.get(key, 0) + (2 if in_T2_after else 1)
>>>>>>> REPLACE
</DIFF>

<DIFF>
<<<<<<< SEARCH
    if key in arc_B1 or key in arc_B2:
        cold_streak = 0
        scan_guard_until = -1
        arc_B1.pop(key, None)
        arc_B2.pop(key, None)  # keep ghosts disjoint
        _move_to_mru(arc_T2, key)
        # Ghost hits imply history: modest frequency bump
        m_key_freq[key] = m_key_freq.get(key, 0) + 1
    else:
        # Brand new: insert into T1; during scans, insert at LRU and open a short guard
        cold_streak += 1
        if cold_streak >= max(1, arc_capacity // 2):
            _insert_at_lru(arc_T1, key)
            guard = min(8, max(1, arc_capacity // 16))
            scan_guard_until = max(scan_guard_until, cache_snapshot.access_count + guard)
        else:
            _move_to_mru(arc_T1, key)
        # Ensure ghosts are disjoint from residents
        arc_B1.pop(key, None)
        arc_B2.pop(key, None)
        # Seed minimal frequency
        m_key_freq[key] = m_key_freq.get(key, 0) + 1
=======
    if key in arc_B1 or key in arc_B2:
        cold_streak = 0
        scan_guard_until = -1
        arc_B1.pop(key, None)
        arc_B2.pop(key, None)  # keep ghosts disjoint
        _move_to_mru(arc_T2, key)
        # Ghost hits imply history: ensure at least moderate frequency
        cur = m_key_freq.get(key, 0)
        m_key_freq[key] = max(cur + 1, 2)
    else:
        # Brand new: insert into T1; during scans, insert at LRU and open a short guard
        cold_streak += 1
        if cold_streak >= max(1, arc_capacity // 2):
            _insert_at_lru(arc_T1, key)
            guard = min(8, max(1, arc_capacity // 16))
            scan_guard_until = max(scan_guard_until, cache_snapshot.access_count + guard)
        else:
            _move_to_mru(arc_T1, key)
        # Ensure ghosts are disjoint from residents
        arc_B1.pop(key, None)
        arc_B2.pop(key, None)
        # Seed minimal frequency for new admissions
        m_key_freq[key] = m_key_freq.get(key, 0) + 1
>>>>>>> REPLACE
</DIFF>