--- a/original.py
+++ b/original.py
@@ -1,461 +1,401 @@
 # EVOLVE-BLOCK-START
-"""Hybrid W-TinyLFU + LRFU-decayed scoring with SLRU main segments.
+"""Hybrid ARC + TinyLFU with LRFU-decayed sampling.
 
 Public API:
 - evict(cache_snapshot, obj) -> key
 - update_after_hit(cache_snapshot, obj)
 - update_after_insert(cache_snapshot, obj)
 - update_after_evict(cache_snapshot, obj, evicted_obj)
 """
 
 from collections import OrderedDict
 
 
-class _CmSketch:
+class _ArcTinyLfuLrfu:
     """
-    Count-Min Sketch with conservative aging (TinyLFU).
-    - d hash functions, width w (power-of-two).
-    - Periodic right-shift halves counters to forget stale history.
+    ARC resident sets with ghosts + TinyLFU for admission + LRFU decayed scores
+    for fine-grained victim selection within segments.
+    - T1: probationary (recency)
+    - T2: protected (frequency)
+    - B1, B2: ghosts to adapt ARC target p
     """
-    __slots__ = ("d", "w", "tables", "mask", "ops", "age_period", "seeds")
-
-    def __init__(self, width_power=12, d=3):
-        self.d = int(max(1, d))
-        w = 1 << int(max(8, width_power))  # min 256
-        self.w = w
-        self.mask = w - 1
-        self.tables = [[0] * w for _ in range(self.d)]
-        self.ops = 0
-        self.age_period = max(1024, w)
-        self.seeds = (0x9e3779b1, 0x85ebca77, 0xc2b2ae3d, 0x27d4eb2f)
-
-    def _hash(self, key_hash: int, i: int) -> int:
-        h = key_hash ^ self.seeds[i % len(self.seeds)]
-        h ^= (h >> 33) & 0xFFFFFFFFFFFFFFFF
-        h *= 0xff51afd7ed558ccd
-        h &= 0xFFFFFFFFFFFFFFFF
-        h ^= (h >> 33)
-        h *= 0xc4ceb9fe1a85ec53
-        h &= 0xFFFFFFFFFFFFFFFF
-        h ^= (h >> 33)
-        return h & self.mask
-
-    def _maybe_age(self):
-        self.ops += 1
-        if self.ops % self.age_period == 0:
-            for t in self.tables:
-                for i in range(self.w):
-                    t[i] >>= 1
-
-    def increment(self, key: str, amount: int = 1):
-        h = hash(key)
-        for i in range(self.d):
-            idx = self._hash(h, i)
-            v = self.tables[i][idx] + amount
-            if v > 255:
-                v = 255
-            self.tables[i][idx] = v
-        self._maybe_age()
-
-    def estimate(self, key: str) -> int:
-        h = hash(key)
-        est = 1 << 30
-        for i in range(self.d):
-            idx = self._hash(h, i)
-            v = self.tables[i][idx]
-            if v < est:
-                est = v
-        return est
-
-
-class _WTinyLFUPolicy:
-    """
-    Windowed TinyLFU + SLRU main with LRFU-style decayed scores:
-    - W: window LRU (recency buffer).
-    - M1: main probationary (first-time in main).
-    - M2: main protected (promoted on re-use).
-    - TinyLFU sketch for admission decisions.
-    - LRFU decayed scores for intra-segment victim selection and demotion.
-    """
 
     __slots__ = (
-        "W", "M1", "M2", "capacity",
-        "win_frac", "prot_frac", "sketch", "_sample_k",
-        "hits_w", "hits_main", "last_tune_time", "tune_period",
-        "score", "last_time", "decay_base", "decay_half_life"
+        # ARC segments
+        "T1", "T2", "B1", "B2", "p",
+        # TinyLFU sketch
+        "SKETCH_DEPTH", "sketch_w", "sketch", "sketch_ops", "age_threshold",
+        # LRFU metadata
+        "score", "last_time", "decay_half_life", "decay_base",
+        # run/misc
+        "last_access_seen", "miss_streak",
+        # victim bookkeeping
+        "last_victim_key", "last_victim_from",
+        # sampling
+        "_sample_k",
     )
 
     def __init__(self):
-        self.W = OrderedDict()
-        self.M1 = OrderedDict()
-        self.M2 = OrderedDict()
-        self.capacity = None
-        # Targets as fractions of capacity
-        self.win_frac = 0.2   # 20% window
-        self.prot_frac = 0.8  # 80% of main reserved for protected
-        self.sketch = _CmSketch(width_power=12, d=3)
-        self._sample_k = 6
-        # Adaptive tuning state
-        self.hits_w = 0
-        self.hits_main = 0
-        self.last_tune_time = 0
-        self.tune_period = 0
-        # LRFU decayed score state
-        self.score = {}     # key -> float decayed score
-        self.last_time = {} # key -> last access_count
+        # Resident and ghost sets
+        self.T1 = OrderedDict()
+        self.T2 = OrderedDict()
+        self.B1 = OrderedDict()
+        self.B2 = OrderedDict()
+        self.p = 0.0
+
+        # TinyLFU CMS
+        self.SKETCH_DEPTH = 4
+        self.sketch_w = 0
+        self.sketch = []
+        self.sketch_ops = 0
+        self.age_threshold = 0
+
+        # LRFU decayed scoring
+        self.score = {}
+        self.last_time = {}
         self.decay_half_life = 16
-        self.decay_base = 2 ** (-1.0 / self.decay_half_life)
-
-    # ----- helpers -----
-
-    def _ensure_capacity(self, cap: int):
-        if self.capacity is None:
-            self.capacity = max(int(cap), 1)
-            self._sample_k = max(4, min(12, (self.capacity // 8) or 4))
-            # Age faster for smaller caches
-            try:
-                self.sketch.age_period = max(512, min(16384, self.capacity * 8))
-            except Exception:
-                pass
-            # Set adaptive tuning period relative to capacity
-            self.tune_period = max(256, self.capacity * 4)
-            self.last_tune_time = 0
-            # LRFU decay tuned to capacity: shorter half-life for small caches
-            self.decay_half_life = max(8, min(64, (self.capacity // 2) or 8))
+        self.decay_base = 2 ** (-1.0 / float(self.decay_half_life))
+
+        # Misc
+        self.last_access_seen = -1
+        self.miss_streak = 0
+
+        # Victim tracking
+        self.last_victim_key = None
+        self.last_victim_from = None
+
+        # Sampling window from LRU side
+        self._sample_k = 8
+
+    # ---------- lifecycle / setup ----------
+
+    def _cap(self, cache_snapshot):
+        return max(1, int(cache_snapshot.capacity))
+
+    def _reset_if_new_run(self, cache_snapshot):
+        if cache_snapshot.access_count <= 1 or self.last_access_seen > cache_snapshot.access_count:
+            self.T1.clear(); self.T2.clear()
+            self.B1.clear(); self.B2.clear()
+            self.p = 0.0
+            self.sketch_w = 0
+            self.sketch = []
+            self.sketch_ops = 0
+            self.age_threshold = 0
+            self.score.clear(); self.last_time.clear()
+            self.decay_half_life = 16
             self.decay_base = 2 ** (-1.0 / float(self.decay_half_life))
+            self.miss_streak = 0
+            self.last_victim_key = None
+            self.last_victim_from = None
+            self._sample_k = 8
+        self.last_access_seen = cache_snapshot.access_count
+
+    def _prune_metadata(self, cache_snapshot):
+        # Keep resident sets consistent with actual cache
+        cache_keys = cache_snapshot.cache.keys()
+        for seg in (self.T1, self.T2):
+            stale = [k for k in seg.keys() if k not in cache_keys]
+            for k in stale:
+                seg.pop(k, None)
+        # Prune LRFU meta for non-resident non-ghost keys occasionally if needed
+        # (we remove on eviction; here we are conservative)
+
+    def _seed_from_cache(self, cache_snapshot):
+        # If both segments empty but cache has content, seed T1
+        if not self.T1 and not self.T2 and cache_snapshot.cache:
+            for k in cache_snapshot.cache.keys():
+                self.T1[k] = None
+
+    # ---------- TinyLFU ----------
+
+    def _ensure_sketch(self, cache_snapshot):
+        if self.sketch_w:
             return
-        if self.capacity != cap:
-            # Reset segments if external capacity changes to avoid desync.
-            self.W.clear(); self.M1.clear(); self.M2.clear()
-            self.capacity = max(int(cap), 1)
-            self._sample_k = max(4, min(12, (self.capacity // 8) or 4))
-            try:
-                self.sketch.age_period = max(512, min(16384, self.capacity * 8))
-            except Exception:
-                pass
-            self.tune_period = max(256, self.capacity * 4)
-            self.last_tune_time = 0
-            self.decay_half_life = max(8, min(64, (self.capacity // 2) or 8))
-            self.decay_base = 2 ** (-1.0 / float(self.decay_half_life))
-
-    def _targets(self):
-        cap = self.capacity or 1
-        w_tgt = max(1, int(round(cap * self.win_frac)))
-        main_cap = max(0, cap - w_tgt)
-        prot_tgt = int(round(main_cap * self.prot_frac))
-        prob_tgt = max(0, main_cap - prot_tgt)
-        return w_tgt, prob_tgt, prot_tgt
-
-    def _ensure_meta(self, k: str, now: int):
-        if k not in self.last_time:
-            self.last_time[k] = now
-        if k not in self.score:
-            self.score[k] = 0.0
-
-    def _decayed_score(self, k: str, now: int) -> float:
-        # Lazily decay the score to 'now'
-        self._ensure_meta(k, now)
-        old = self.last_time[k]
+        cap = self._cap(cache_snapshot)
+        target = max(512, 4 * cap)  # capacity-aware width
+        w = 1
+        while w < target:
+            w <<= 1
+        self.sketch_w = w
+        self.sketch = [[0] * self.sketch_w for _ in range(self.SKETCH_DEPTH)]
+        self.sketch_ops = 0
+        # Age period within [4C,16C], mid by default
+        self.age_threshold = max(4 * cap, min(16 * cap, 8 * cap))
+        # Tune LRFU decay relative to capacity (shorter for small caches)
+        self.decay_half_life = max(8, min(64, (cap // 2) or 8))
+        self.decay_base = 2 ** (-1.0 / float(self.decay_half_life))
+        # Sample size scales mildly with capacity
+        self._sample_k = max(4, min(12, (cap // 8) or 4))
+
+    def _hash_idx(self, key, i):
+        return (hash((key, i, 0x9E3779B97F4A7C15)) & (self.sketch_w - 1))
+
+    def _sketch_add(self, cache_snapshot, key, delta=1):
+        self._ensure_sketch(cache_snapshot)
+        if not self.sketch_w:
+            return
+        for i in range(self.SKETCH_DEPTH):
+            self.sketch[i][self._hash_idx(key, i)] += delta
+        self.sketch_ops += 1
+        if self.sketch_ops >= self.age_threshold:
+            for i in range(self.SKETCH_DEPTH):
+                row = self.sketch[i]
+                for j in range(self.sketch_w):
+                    row[j] >>= 1
+            self.sketch_ops = 0
+
+    def _sketch_est(self, cache_snapshot, key):
+        self._ensure_sketch(cache_snapshot)
+        if not self.sketch_w:
+            return 0
+        est = None
+        for i in range(self.SKETCH_DEPTH):
+            v = self.sketch[i][self._hash_idx(key, i)]
+            est = v if est is None or v < est else est
+        return est if est is not None else 0
+
+    # ---------- LRFU decayed score ----------
+
+    def _ensure_meta(self, key, now):
+        if key not in self.last_time:
+            self.last_time[key] = now
+        if key not in self.score:
+            self.score[key] = 0.0
+
+    def _decayed_score(self, key, now):
+        self._ensure_meta(key, now)
+        old = self.last_time[key]
         dt = now - old
         if dt > 0:
-            self.score[k] *= self.decay_base ** dt
-            self.last_time[k] = now
-        return self.score[k]
-
-    def _self_heal(self, cache_snapshot):
-        # Ensure all cached keys are tracked and no phantom entries remain.
+            self.score[key] *= self.decay_base ** dt
+            self.last_time[key] = now
+        return self.score[key]
+
+    # ---------- helpers ----------
+
+    def _move_to_mru(self, seg, key):
+        if key in seg:
+            seg.move_to_end(key, last=True)
+        else:
+            seg[key] = None
+
+    def _trim_ghosts(self, cache_snapshot):
+        cap = self._cap(cache_snapshot)
+        max_g = 2 * cap
+        while len(self.B1) + len(self.B2) > max_g:
+            if len(self.B1) > len(self.B2):
+                self.B1.popitem(last=False)
+            else:
+                self.B2.popitem(last=False)
+
+    def _eviction_sample(self, cache_snapshot, seg):
+        """
+        Sample up to K LRU keys from seg; choose with lexicographic min:
+        (TinyLFU estimate, LRFU decayed score). Lower is colder.
+        """
+        if not seg:
+            return None
         now = cache_snapshot.access_count
-        cache_keys = set(cache_snapshot.cache.keys())
-        for od in (self.W, self.M1, self.M2):
-            for k in list(od.keys()):
-                if k not in cache_keys:
-                    od.pop(k, None)
-        tracked = set(self.W.keys()) | set(self.M1.keys()) | set(self.M2.keys())
-        missing = cache_keys - tracked
-        if missing:
-            w_tgt, _, _ = self._targets()
-            # Place missing into W until target, then into M1
-            for k in missing:
-                if len(self.W) < w_tgt:
-                    self.W[k] = None
+        sample_k = min(self._sample_k, len(seg))
+        it = iter(seg.keys())  # LRU -> MRU
+        best_k, best_f, best_d = None, None, None
+        for _ in range(sample_k):
+            k = next(it)
+            f = self._sketch_est(cache_snapshot, k)
+            d = self._decayed_score(k, now)
+            if (best_k is None
+                or f < best_f
+                or (f == best_f and d < best_d)):
+                best_k, best_f, best_d = k, f, d
+                if best_f == 0 and best_d == 0.0:
+                    # Can't do better
+                    break
+        return best_k
+
+    def _replace_segment(self, cache_snapshot, incoming_key):
+        """
+        ARC Replace rule:
+        if |T1| >= 1 and ((incoming in B2 and |T1| == p) or |T1| > p) -> evict from T1
+        else evict from T2 (if non-empty), otherwise from T1.
+        """
+        t1 = len(self.T1)
+        t2 = len(self.T2)
+        cap = self._cap(cache_snapshot)
+        p_int = int(round(max(0.0, min(float(cap), self.p))))
+        if t1 >= 1 and ((incoming_key in self.B2 and t1 == p_int) or (t1 > p_int)):
+            return "T1"
+        if t2 == 0 and t1 > 0:
+            return "T1"
+        return "T2" if t2 > 0 else "T1"
+
+    # ---------- public API ----------
+
+    def evict(self, cache_snapshot, obj):
+        self._reset_if_new_run(cache_snapshot)
+        self._prune_metadata(cache_snapshot)
+        self._ensure_sketch(cache_snapshot)
+        self._seed_from_cache(cache_snapshot)
+
+        seg_name = self._replace_segment(cache_snapshot, obj.key)
+        victim = None
+
+        if seg_name == "T1" and self.T1:
+            victim = self._eviction_sample(cache_snapshot, self.T1)
+        elif seg_name == "T2" and self.T2:
+            cand_t2 = self._eviction_sample(cache_snapshot, self.T2)
+            if cand_t2 is not None:
+                # TinyLFU guard: protect much hotter T2 vs incoming
+                f_new = self._sketch_est(cache_snapshot, obj.key)
+                f_t2 = self._sketch_est(cache_snapshot, cand_t2)
+                if f_t2 > f_new + 1 and len(self.T1) > 0:
+                    alt = self._eviction_sample(cache_snapshot, self.T1)
+                    if alt is not None:
+                        victim = alt
+                        seg_name = "T1"
+                    else:
+                        victim = cand_t2
                 else:
-                    self.M1[k] = None
-                self._ensure_meta(k, now)
-
-    def _maybe_tune(self, now: int):
-        # Periodically adapt window size based on relative hits.
-        if self.tune_period <= 0:
-            return
-        if (now - self.last_tune_time) >= self.tune_period:
-            # If window is relatively more useful, grow it; otherwise shrink.
-            if self.hits_w > self.hits_main * 1.1:
-                self.win_frac = min(0.5, self.win_frac + 0.05)
-            elif self.hits_main > self.hits_w * 1.1:
-                self.win_frac = max(0.05, self.win_frac - 0.05)
-            # Decay counters and update tune timestamp
-            self.hits_w >>= 1
-            self.hits_main >>= 1
-            self.last_tune_time = now
-
-    def _lru(self, od: OrderedDict):
-        return next(iter(od)) if od else None
-
-    def _touch(self, od: OrderedDict, key: str):
-        od[key] = None
-        od.move_to_end(key)
-
-    def _sample_cold_candidate(self, od: OrderedDict, now: int):
-        """
-        Return (key, tiny_est, decayed) for the coldest among the k LRU keys,
-        using lexicographic min on (tiny_est, decayed_score).
-        """
-        if not od:
-            return None, None, None
-        k = min(self._sample_k, len(od))
-        it = iter(od.keys())  # from LRU to MRU
-        best_k, best_est, best_dec = None, None, None
-        for _ in range(k):
-            key = next(it)
-            est = self.sketch.estimate(key)
-            dec = self._decayed_score(key, now)
-            if (best_est is None
-                or est < best_est
-                or (est == best_est and dec < best_dec)):
-                best_k, best_est, best_dec = key, est, dec
-        return best_k, best_est, best_dec
-
-    # ----- policy decisions -----
-
-    def choose_victim(self, cache_snapshot, new_obj) -> str:
-        """
-        Hybrid eviction:
-        - TinyLFU admission: compare f(new) to a sampled cold candidate from M1.
-          * If f(new) > f(cand_M1) + bias: evict cand_M1 (admit new).
-          * Else: evict W's LRU (reject new from main this round).
-        - If M1 is empty, optionally compare against a cold candidate from M2
-          when protected is oversized or W is empty.
-        - Demotions/victim choices within segments rely on decayed scores.
-        """
-        self._ensure_capacity(cache_snapshot.capacity)
-        self._self_heal(cache_snapshot)
-
-        now = cache_snapshot.access_count
-
-        # Candidates
-        cand_w = self._lru(self.W)
-        cand_m1, f_m1, d_m1 = self._sample_cold_candidate(self.M1, now)
-        cand_m2, f_m2, d_m2 = (None, None, None)
-        if cand_m1 is None:
-            cand_m2, f_m2, d_m2 = self._sample_cold_candidate(self.M2, now)
-
-        f_new = self.sketch.estimate(new_obj.key)
-
-        # Prefer replacing a cold M1 entry if new is hotter (with slight bias)
-        if cand_m1 is not None and f_new > (f_m1 or 0) + 1:
-            return cand_m1
-
-        # Otherwise evict from the window to preserve main
-        if cand_w is not None:
-            return cand_w
-
-        # If no window/M1 option, consider replacing a cold protected entry
-        if cand_m2 is not None and f_new > (f_m2 or 0) + 2:
-            return cand_m2
-
-        # Fallbacks: evict coldest in M1 else M2 by decayed score
-        if self.M1:
-            k, _, _ = self._sample_cold_candidate(self.M1, now)
-            if k is not None:
-                return k
-            return self._lru(self.M1)
-        if self.M2:
-            k, _, _ = self._sample_cold_candidate(self.M2, now)
-            if k is not None:
-                return k
-            return self._lru(self.M2)
-
-        # Last resort: pick any key from cache
-        return next(iter(cache_snapshot.cache))
-
-    def on_hit(self, cache_snapshot, obj):
-        """
-        Hit processing:
-        - Increment TinyLFU and LRFU-decayed score.
-        - W hit: refresh or early promote if sufficiently hot.
-        - M1 hit: promote to M2.
-        - M2 hit: refresh in M2.
-        - If untracked but hit (desync): treat as warm and place into M2.
-        """
-        self._ensure_capacity(cache_snapshot.capacity)
+                    victim = cand_t2
+
+        if victim is None:
+            # Fallback to any cached key
+            for k in cache_snapshot.cache.keys():
+                victim = k
+                seg_name = "T1" if k in self.T1 else ("T2" if k in self.T2 else None)
+                break
+
+        self.last_victim_key = victim
+        self.last_victim_from = seg_name
+        return victim
+
+    def update_after_hit(self, cache_snapshot, obj):
+        self._reset_if_new_run(cache_snapshot)
+        self._prune_metadata(cache_snapshot)
+        self._ensure_sketch(cache_snapshot)
+
         now = cache_snapshot.access_count
         key = obj.key
-
-        # Update TinyLFU and LRFU score
-        self.sketch.increment(key, 1)
+        # Reset scan indicator and learn
+        self.miss_streak = 0
+        self._sketch_add(cache_snapshot, key, 1)
+        # Bump decayed score
         s = self._decayed_score(key, now)
         self.score[key] = s + 1.0
 
-        if key in self.W:
-            self.hits_w += 1
-            # Early promotion if strong frequency to avoid window churn
-            est = self.sketch.estimate(key)
-            dec = self._decayed_score(key, now)
-            if est >= 3 or dec >= 1.5:
-                # Move from window to protected
-                self.W.pop(key, None)
-                self._touch(self.M2, key)
-                # Keep protected region within target using decayed-aware demotion
-                _, _, prot_tgt = self._targets()
-                if len(self.M2) > prot_tgt:
-                    demote, _, _ = self._sample_cold_candidate(self.M2, now)
-                    if demote is not None:
-                        self.M2.pop(demote, None)
-                        self._touch(self.M1, demote)
-            else:
-                self._touch(self.W, key)
-            self._maybe_tune(now)
-            return
-
-        if key in self.M1:
-            self.hits_main += 1
-            # Promote to protected
-            self.M1.pop(key, None)
-            self._touch(self.M2, key)
-            # Rebalance protected size if needed (decayed-aware demotion)
-            _, _, prot_tgt = self._targets()
-            if len(self.M2) > prot_tgt:
-                demote, _, _ = self._sample_cold_candidate(self.M2, now)
-                if demote is not None:
-                    self.M2.pop(demote, None)
-                    self._touch(self.M1, demote)
-            self._maybe_tune(now)
-            return
-
-        if key in self.M2:
-            self.hits_main += 1
-            self._touch(self.M2, key)
-            self._maybe_tune(now)
-            return
-
-        # Desync: assume it's warm
-        self.hits_main += 1
-        self._touch(self.M2, key)
-        _, _, prot_tgt = self._targets()
-        if len(self.M2) > prot_tgt:
-            demote, _, _ = self._sample_cold_candidate(self.M2, now)
-            if demote is not None:
-                self.M2.pop(demote, None)
-                self._touch(self.M1, demote)
-        self._maybe_tune(now)
-
-    def on_insert(self, cache_snapshot, obj):
-        """
-        Insert (on miss) processing:
-        - Initialize LRFU metadata modestly (to reduce scan pollution).
-        - Increment TinyLFU.
-        - Insert new key into window W (MRU).
-        - If W exceeds target, move W's LRU to main probationary (M1).
-        - Keep protected region within target by demoting a decayed-cold entry if needed.
-        """
-        self._ensure_capacity(cache_snapshot.capacity)
+        if key in self.T2:
+            self._move_to_mru(self.T2, key)
+        elif key in self.T1:
+            # Promote T1 -> T2 on hit
+            self.T1.pop(key, None)
+            self._move_to_mru(self.T2, key)
+        else:
+            # Metadata miss but hit in cache: conservatively place in T1
+            self._move_to_mru(self.T1, key)
+
+    def update_after_insert(self, cache_snapshot, obj):
+        self._reset_if_new_run(cache_snapshot)
+        self._prune_metadata(cache_snapshot)
+        self._ensure_sketch(cache_snapshot)
+
         now = cache_snapshot.access_count
         key = obj.key
-        self.sketch.increment(key, 1)
-
-        # Initialize decayed metadata
+        self.miss_streak += 1
+        # Learn on admission and initialize decayed metadata
+        self._sketch_add(cache_snapshot, key, 1)
         self.last_time[key] = now
+        # Start with small score to reduce scan pollution
         self.score[key] = 0.5
 
-        # Ensure it's not tracked elsewhere
-        self.W.pop(key, None)
-        self.M1.pop(key, None)
-        self.M2.pop(key, None)
-
-        # Insert into window
-        self._touch(self.W, key)
-
-        # Rebalance: if W is beyond target, move W's LRU to M1 (admission path)
-        w_tgt, _, prot_tgt = self._targets()
-        if len(self.W) > w_tgt:
-            w_lru = self._lru(self.W)
-            if w_lru is not None and w_lru != key:
-                self.W.pop(w_lru, None)
-                # Move into M1 probationary
-                self._touch(self.M1, w_lru)
-
-        # Keep protected region within target (decayed-aware demotion)
-        if len(self.M2) > prot_tgt:
-            demote, _, _ = self._sample_cold_candidate(self.M2, now)
-            if demote is not None:
-                self.M2.pop(demote, None)
-                self._touch(self.M1, demote)
-
-        # Periodically tune window size
-        self._maybe_tune(now)
-
-    def on_evict(self, cache_snapshot, obj, evicted_obj):
-        """
-        Eviction post-processing:
-        - Remove evicted key from whichever segment it resides in and purge LRFU meta.
-        """
-        self._ensure_capacity(cache_snapshot.capacity)
-        k = evicted_obj.key
-        self.W.pop(k, None)
-        self.M1.pop(k, None)
-        self.M2.pop(k, None)
-        self.score.pop(k, None)
-        self.last_time.pop(k, None)
-
-
-# Single policy instance reused across calls
-_policy = _WTinyLFUPolicy()
+        cap = self._cap(cache_snapshot)
+        # ARC adaptive p tuning based on ghost refaults
+        if key in self.B1:
+            delta = max(1, len(self.B2) // max(1, len(self.B1)))
+            self.p = min(float(cap), self.p + float(delta))
+            self.B1.pop(key, None)
+            self._move_to_mru(self.T2, key)
+        elif key in self.B2:
+            delta = max(1, len(self.B1) // max(1, len(self.B2)))
+            self.p = max(0.0, self.p - float(delta))
+            self.B2.pop(key, None)
+            self._move_to_mru(self.T2, key)
+        else:
+            # Fresh miss: early promotion if clearly hot
+            if self._sketch_est(cache_snapshot, key) >= 4:
+                self._move_to_mru(self.T2, key)
+            else:
+                self._move_to_mru(self.T1, key)
+
+        # Bound ghosts
+        self._trim_ghosts(cache_snapshot)
+
+    def update_after_evict(self, cache_snapshot, obj, evicted_obj):
+        self._reset_if_new_run(cache_snapshot)
+        evk = evicted_obj.key
+
+        # Remove from resident sets, track origin
+        removed_from = None
+        if evk in self.T1:
+            self.T1.pop(evk, None)
+            removed_from = "T1"
+        elif evk in self.T2:
+            self.T2.pop(evk, None)
+            removed_from = "T2"
+        else:
+            removed_from = self.last_victim_from
+
+        # Place into ghost according to origin
+        if removed_from == "T1":
+            self.B1[evk] = None
+        elif removed_from == "T2":
+            self.B2[evk] = None
+
+        # Clean up LRFU metadata
+        self.score.pop(evk, None)
+        self.last_time.pop(evk, None)
+
+        self._trim_ghosts(cache_snapshot)
+        if self.last_victim_key == evk:
+            self.last_victim_key = None
+            self.last_victim_from = None
+
+
+# Singleton policy instance
+_policy = _ArcTinyLfuLrfu()
 
 
 def evict(cache_snapshot, obj):
-    """
-    Choose eviction victim key for the incoming obj.
-    """
-    return _policy.choose_victim(cache_snapshot, obj)
+    return _policy.evict(cache_snapshot, obj)
 
 
 def update_after_hit(cache_snapshot, obj):
-    """
-    Update policy state after a cache hit on obj.
-    """
-    _policy.on_hit(cache_snapshot, obj)
+    _policy.update_after_hit(cache_snapshot, obj)
 
 
 def update_after_insert(cache_snapshot, obj):
-    """
-    Update policy state after a new obj is inserted into the cache.
-    """
-    _policy.on_insert(cache_snapshot, obj)
+    _policy.update_after_insert(cache_snapshot, obj)
 
 
 def update_after_evict(cache_snapshot, obj, evicted_obj):
-    """
-    Update policy state after evicting evicted_obj to make room for obj.
-    """
-    _policy.on_evict(cache_snapshot, obj, evicted_obj)
+    _policy.update_after_evict(cache_snapshot, obj, evicted_obj)
 
 # EVOLVE-BLOCK-END
 
 # This part remains fixed (not evolved)
 def run_caching(trace_path: str, copy_code_dst: str):
     """Run the caching algorithm on a trace"""
     import os
     with open(os.path.abspath(__file__), 'r', encoding="utf-8") as f:
         code_str = f.read()
     with open(os.path.join(copy_code_dst), 'w') as f:
         f.write(code_str)
     from cache_utils import Cache, CacheConfig, CacheObj, Trace
     trace = Trace(trace_path=trace_path)
     cache_capacity = max(int(trace.get_ndv() * 0.1), 1)
     cache = Cache(CacheConfig(cache_capacity))
     for entry in trace.entries:
         obj = CacheObj(key=str(entry.key))
         cache.get(obj)
     with open(copy_code_dst, 'w') as f:
         f.write("")
     hit_rate = round(cache.hit_count / cache.access_count, 6)
     return hit_rate