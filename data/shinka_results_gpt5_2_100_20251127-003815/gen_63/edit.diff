--- a/original.py
+++ b/original.py
@@ -1,327 +1,376 @@
 # EVOLVE-BLOCK-START
-"""Cache eviction algorithm for optimizing hit rates across multiple workloads"""
+"""Window-TinyLFU with SLRU main (Caffeine-style).
+
+Public API:
+- evict(cache_snapshot, obj) -> key
+- update_after_hit(cache_snapshot, obj)
+- update_after_insert(cache_snapshot, obj)
+- update_after_evict(cache_snapshot, obj, evicted_obj)
+"""
 
 from collections import OrderedDict
 
-# Adaptive Replacement Cache (ARC)-inspired:
-# - m_probation (T1): recent entries (LRU)
-# - m_protected (T2): frequent/hot entries (LRU)
-# - m_b1 (B1): ghost list of keys evicted from T1 (LRU)
-# - m_b2 (B2): ghost list of keys evicted from T2 (LRU)
-# - m_p: adaptive target size for T1
-m_probation = OrderedDict()
-m_protected = OrderedDict()
-m_b1 = OrderedDict()
-m_b2 = OrderedDict()
-m_freq = dict()
-m_p = 0
-_m_last_seen_access = -1  # detect new traces to reset metadata
-
-# Sampling and light frequency aging
-m_sample_k = 6
-_age_ops = 0
-_age_period = 1024
-m_miss_streak = 0
-
-
-def _reset_if_new_run(cache_snapshot):
-    """Reset metadata when a new trace/cache run starts."""
-    global m_probation, m_protected, m_b1, m_b2, m_freq, m_p, _m_last_seen_access, m_sample_k, _age_ops, _age_period, m_miss_streak
-    # New run if access counter restarts or at very beginning
-    if cache_snapshot.access_count <= 1 or _m_last_seen_access > cache_snapshot.access_count:
-        m_probation.clear()
-        m_protected.clear()
-        m_b1.clear()
-        m_b2.clear()
-        m_freq.clear()
-        m_p = 0
-        _age_ops = 0
-        m_miss_streak = 0
-    # keep aging period and sample size responsive to capacity
-    cap = max(int(cache_snapshot.capacity), 1)
-    _age_period = max(512, cap * 8)
-    m_sample_k = max(4, min(12, (cap // 8) or 4))
-    _m_last_seen_access = cache_snapshot.access_count
-
-
-def _prune_metadata(cache_snapshot):
-    """Keep metadata consistent with actual cache content."""
-    cache_keys = cache_snapshot.cache.keys()
-    for seg in (m_probation, m_protected):
-        to_del = [k for k in seg.keys() if k not in cache_keys]
-        for k in to_del:
-            seg.pop(k, None)
-
-
-def _protected_target_size(cache_snapshot):
-    """Aim to keep most entries protected while leaving room in probation."""
-    cap = max(int(cache_snapshot.capacity), 1)
-    return max(1, int(cap * 0.8))
-
-
-def _maybe_age_freq(cache_snapshot):
-    """Periodically halve frequency counters to forget stale history."""
-    global _age_ops, _age_period, m_freq
-    _age_ops += 1
-    if _age_ops % max(1, _age_period) == 0:
-        for k in list(m_freq.keys()):
-            v = m_freq.get(k, 0) >> 1
-            if v <= 0:
-                # keep dictionary small
-                m_freq.pop(k, None)
+
+class _WTinyLFU_SLRU:
+    """
+    Windowed TinyLFU + SLRU main cache (metadata only).
+    Segments:
+      - W: window (recency) LRU
+      - M1: main probation (LRU)
+      - M2: main protected (LRU)
+    Admission:
+      - Count-Min Sketch TinyLFU with exponential aging
+      - Eviction-time competitive admission W_LRU vs sampled M1 tail
+    Promotion:
+      - W hit -> M1
+      - M1 hit -> M2
+      - M2 hit -> recency refresh
+    Adaptation:
+      - EMA of miss rate drives window fraction and sampling
+    """
+
+    def __init__(self):
+        # Segments
+        self.W = OrderedDict()
+        self.M1 = OrderedDict()
+        self.M2 = OrderedDict()
+
+        # TinyLFU sketch
+        self.depth = 4
+        self.width = 0
+        self.sketch = []
+        self.ops_since_age = 0
+        self.age_period = 0
+
+        # Recency timestamps
+        self.last_ts = {}
+
+        # Tuning
+        self.win_frac = 0.20  # window fraction (of capacity)
+        self.prot_frac = 0.80  # fraction of main kept protected
+        self.sample_k = 8
+        self.bias_m1 = 1  # bias to protect M1 vs W in comparator
+
+        # EMA of miss rate
+        self.ema_miss = 0.0
+        self.ema_alpha = 0.05
+
+        # Bookkeeping
+        self.last_seen_access = -1
+        self.plan_promote_key = None  # W candidate to promote to M1 after evicting an M1 victim
+
+    # ---------- utilities ----------
+
+    def _cap(self, cs):
+        return max(1, int(cs.capacity))
+
+    def _reset_if_new_run(self, cs):
+        if cs.access_count <= 1 or self.last_seen_access > cs.access_count:
+            self.W.clear(); self.M1.clear(); self.M2.clear()
+            self.width = 0; self.sketch = []; self.ops_since_age = 0; self.age_period = 0
+            self.last_ts.clear()
+            self.win_frac = 0.20
+            self.prot_frac = 0.80
+            self.sample_k = 8
+            self.bias_m1 = 1
+            self.ema_miss = 0.0
+            self.plan_promote_key = None
+        self.last_seen_access = cs.access_count
+
+    def _ensure_sketch(self, cs):
+        if self.width:
+            return
+        cap = self._cap(cs)
+        # width is power of two â‰¥ 4C (bounded)
+        target = max(256, min(1 << 20, 4 * cap))
+        w = 1
+        while w < target:
+            w <<= 1
+        self.width = w
+        self.sketch = [[0] * self.width for _ in range(self.depth)]
+        # Age period between [4C,16C], start mid
+        self.age_period = max(4 * cap, min(16 * cap, 8 * cap))
+        # Initial sample size
+        self.sample_k = max(4, min(12, (cap // 8) or 4))
+
+    def _hash_idx(self, key, i):
+        return (hash((key, i, 0x9E3779B97F4A7C15)) & (self.width - 1))
+
+    def _sketch_add(self, cs, key, delta=1):
+        self._ensure_sketch(cs)
+        for i in range(self.depth):
+            self.sketch[i][self._hash_idx(key, i)] += delta
+        self.ops_since_age += 1
+        if self.ops_since_age >= self.age_period:
+            for i in range(self.depth):
+                row = self.sketch[i]
+                for j in range(self.width):
+                    row[j] >>= 1
+            self.ops_since_age = 0
+
+    def _sketch_est(self, cs, key):
+        self._ensure_sketch(cs)
+        est = None
+        for i in range(self.depth):
+            v = self.sketch[i][self._hash_idx(key, i)]
+            est = v if est is None or v < est else est
+        return est if est is not None else 0
+
+    def _touch_ts(self, cs, key):
+        self.last_ts[key] = cs.access_count
+
+    def _age(self, cs, key):
+        # Age = time since last access; larger means older/colder
+        last = self.last_ts.get(key)
+        if last is None:
+            return 1 << 30
+        return cs.access_count - last
+
+    def _prune_segments(self, cs):
+        ck = cs.cache.keys()
+        for seg in (self.W, self.M1, self.M2):
+            stale = [k for k in seg.keys() if k not in ck]
+            for k in stale:
+                seg.pop(k, None)
+        # keep timestamps compact
+        for k in list(self.last_ts.keys()):
+            if k not in ck:
+                self.last_ts.pop(k, None)
+
+    def _seed_from_cache(self, cs):
+        # If metadata empty but cache has entries, seed M1 (probation)
+        if not self.W and not self.M1 and not self.M2 and cs.cache:
+            for k in cs.cache.keys():
+                self.M1[k] = None
+
+    def _window_target(self, cs):
+        cap = self._cap(cs)
+        # clamp window fraction between 0.10 and 0.50
+        wf = max(0.10, min(0.50, self.win_frac))
+        return max(1, int(cap * wf))
+
+    def _protected_target(self, cs):
+        # protected target relative to main (M1+M2)
+        main = max(1, len(self.M1) + len(self.M2))
+        pf = max(0.60, min(0.90, self.prot_frac))
+        return max(1, int(main * pf))
+
+    def _ensure_protected_bounds(self, cs):
+        # Demote from M2 -> M1 until within target
+        target = self._protected_target(cs)
+        while len(self.M2) > target:
+            k, _ = self.M2.popitem(last=False)
+            self.M1[k] = None
+
+    def _sample_tail(self, cs, seg: OrderedDict):
+        if not seg:
+            return None
+        k = min(self.sample_k, len(seg))
+        it = iter(seg.keys())  # LRU -> MRU
+        best_k, best_f, best_age = None, None, None
+        for _ in range(k):
+            key = next(it)
+            f = self._sketch_est(cs, key)
+            age = self._age(cs, key)
+            # colder if TinyLFU estimate smaller; tie-break by older age (larger)
+            if (best_k is None
+                or f < best_f
+                or (f == best_f and age > best_age)):
+                best_k, best_f, best_age = key, f, age
+        return best_k
+
+    def _adjust_adaptation(self, cs):
+        # Adapt window size based on EMA miss rate and rough main stability
+        # Increase window under heavy misses (scan-like), shrink when stable
+        miss = self.ema_miss
+        if miss > 0.80:
+            self.win_frac = min(0.50, self.win_frac + 0.04)
+            self.sample_k = max(4, self.sample_k - 1)  # faster decisions
+        elif miss > 0.60:
+            self.win_frac = min(0.45, self.win_frac + 0.02)
+        elif miss < 0.30 and len(self.M2) > len(self.M1) and len(self.M2) > 0:
+            self.win_frac = max(0.12, self.win_frac - 0.01)
+            self.sample_k = min(12, self.sample_k + 1)
+
+    # ---------- public API ----------
+
+    def evict(self, cs, obj):
+        self._reset_if_new_run(cs)
+        self._prune_segments(cs)
+        self._ensure_sketch(cs)
+        self._seed_from_cache(cs)
+        self._adjust_adaptation(cs)
+
+        win_target = self._window_target(cs)
+
+        # Get candidates
+        w_lru = next(iter(self.W)) if self.W else None
+        m1_cand = self._sample_tail(cs, self.M1) if self.M1 else None
+
+        # Prefer competitive admission when window at/over target
+        if self.W and len(self.W) >= win_target and w_lru is not None:
+            # Compare W_LRU vs sampled M1
+            if m1_cand is None:
+                # No M1; evict from W
+                self.plan_promote_key = None
+                return w_lru
+            f_w = self._sketch_est(cs, w_lru)
+            f_m1 = self._sketch_est(cs, m1_cand)
+            age_w = self._age(cs, w_lru)
+            age_m1 = self._age(cs, m1_cand)
+
+            # Decide colder: TinyLFU ascending, tie by older age
+            w_colder = (f_w < f_m1) or (f_w == f_m1 and age_w > age_m1 - self.bias_m1)
+            if not w_colder and (f_w >= f_m1 + self.bias_m1):
+                # Evict M1 candidate; promote W_LRU into M1 after eviction
+                self.plan_promote_key = w_lru
+                return m1_cand
             else:
-                m_freq[k] = v
-
-
-def _sample_lowfreq(od: OrderedDict) -> str:
-    """Sample a few keys from the LRU side and pick the lowest-frequency candidate."""
-    if not od:
-        return None
-    k = min(m_sample_k, len(od))
-    it = iter(od.keys())  # LRU -> MRU
-    best_k = None
-    best_f = None
-    for _ in range(k):
-        key = next(it)
-        f = m_freq.get(key, 0)
-        if best_f is None or f < best_f:
-            best_f = f
-            best_k = key
-    return best_k if best_k is not None else next(iter(od))
-
-
-def _enforce_protected_target(cache_snapshot):
-    """Demote LRU of protected to probation until protected meets its target."""
-    target = _protected_target_size(cache_snapshot)
-    while len(m_protected) > target:
-        demote_k, _ = m_protected.popitem(last=False)  # LRU of protected
-        # place demoted key at MRU of probation to avoid immediate eviction
-        m_probation[demote_k] = None
-        m_probation.move_to_end(demote_k, last=True)
+                # Evict W_LRU
+                self.plan_promote_key = None
+                return w_lru
+
+        # Otherwise try to evict from M1 first to let window grow
+        if m1_cand is not None:
+            self.plan_promote_key = None
+            return m1_cand
+
+        # Fallbacks: evict from W; else from M2; else any
+        if w_lru is not None:
+            self.plan_promote_key = None
+            return w_lru
+        if self.M2:
+            k = self._sample_tail(cs, self.M2) or next(iter(self.M2))
+            self.plan_promote_key = None
+            return k
+
+        # Final fallback: any key from the cache
+        self.plan_promote_key = None
+        return next(iter(cs.cache)) if cs.cache else None
+
+    def update_after_hit(self, cs, obj):
+        self._reset_if_new_run(cs)
+        self._prune_segments(cs)
+        self._ensure_sketch(cs)
+
+        k = obj.key
+        # EMA miss update with hit=0
+        self.ema_miss = (1.0 - self.ema_alpha) * self.ema_miss + self.ema_alpha * 0.0
+
+        # Learn
+        self._sketch_add(cs, k, 1)
+        self._touch_ts(cs, k)
+
+        # Promotions and recency
+        if k in self.M2:
+            self.M2.move_to_end(k, last=True)
+        elif k in self.M1:
+            # Promote to protected
+            self.M1.pop(k, None)
+            self.M2[k] = None
+        elif k in self.W:
+            # Refresh in window; if clearly hot, promote to M1
+            self.W.move_to_end(k, last=True)
+            if self._sketch_est(cs, k) >= 3:
+                self.W.pop(k, None)
+                self.M1[k] = None
+        else:
+            # Metadata miss but cache hit: place into main based on estimate
+            if self._sketch_est(cs, k) >= 4:
+                self.M2[k] = None
+            else:
+                self.M1[k] = None
+
+        # Keep protected within target
+        self._ensure_protected_bounds(cs)
+
+    def update_after_insert(self, cs, obj):
+        self._reset_if_new_run(cs)
+        self._prune_segments(cs)
+        self._ensure_sketch(cs)
+
+        k = obj.key
+        # EMA miss update with miss=1
+        self.ema_miss = (1.0 - self.ema_alpha) * self.ema_miss + self.ema_alpha * 1.0
+
+        # Learn on admission
+        self._sketch_add(cs, k, 1)
+        self._touch_ts(cs, k)
+
+        # Remove any stale placements
+        self.W.pop(k, None); self.M1.pop(k, None); self.M2.pop(k, None)
+
+        # Admission: bypass to M2 if very hot; else admit to window
+        if self._sketch_est(cs, k) >= 5:
+            self.M2[k] = None
+        else:
+            self.W[k] = None
+
+        # Maintain protected size
+        self._ensure_protected_bounds(cs)
+
+    def update_after_evict(self, cs, obj, evicted_obj):
+        self._reset_if_new_run(cs)
+        evk = evicted_obj.key
+
+        # Remove evicted from segments
+        if evk in self.W:
+            self.W.pop(evk, None)
+        elif evk in self.M1:
+            self.M1.pop(evk, None)
+        elif evk in self.M2:
+            self.M2.pop(evk, None)
+
+        # If we planned to promote window LRU in lieu of an M1 victim, do it here
+        if self.plan_promote_key is not None and self.plan_promote_key in self.W:
+            w = self.plan_promote_key
+            self.W.pop(w, None)
+            self.M1[w] = None
+        self.plan_promote_key = None
+
+        # Keep protected bounds
+        self._ensure_protected_bounds(cs)
+        # Light adaptation after eviction as well
+        self._adjust_adaptation(cs)
+
+
+# Singleton policy
+_policy = _WTinyLFU_SLRU()
 
 
 def evict(cache_snapshot, obj):
-    '''
-    This function defines how the algorithm chooses the eviction victim.
-    - Args:
-        - `cache_snapshot`: A snapshot of the current cache state.
-        - `obj`: The new object that needs to be inserted into the cache.
-    - Return:
-        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
-    '''
-    global m_probation, m_protected, m_b1, m_b2, m_freq, m_p, m_miss_streak
-    _reset_if_new_run(cache_snapshot)
-    _prune_metadata(cache_snapshot)
-
-    # Seed metadata if empty by placing all current cache keys into probation.
-    if not m_probation and not m_protected and cache_snapshot.cache:
-        for k0 in cache_snapshot.cache.keys():
-            m_probation[k0] = None
-
-    # ARC: adjust target m_p based on ghost hit of incoming key
-    cap = max(int(cache_snapshot.capacity), 1)
-    k = obj.key
-    if k in m_b1:
-        delta = max(1, len(m_b2) // max(1, len(m_b1)))
-        m_p = min(cap, m_p + delta)
-    elif k in m_b2:
-        delta = max(1, len(m_b1) // max(1, len(m_b2)))
-        m_p = max(0, m_p - delta)
-
-    in_scan = m_miss_streak > cap
-
-    # Candidates from segments (LRU-side, low-frequency)
-    cand_t1 = _sample_lowfreq(m_probation) if m_probation else None
-    cand_t2 = _sample_lowfreq(m_protected) if m_protected else None
-
-    # During scans, protect T2 by evicting from T1 when possible
-    if in_scan and cand_t1 is not None:
-        return cand_t1
-
-    # ARC replacement rule: if T1 oversized or (new in B2 and |T1| == p), evict from T1
-    if m_probation and ((k in m_b2 and len(m_probation) == m_p) or (len(m_probation) > m_p)):
-        return cand_t1 if cand_t1 is not None else (cand_t2 if cand_t2 is not None else next(iter(cache_snapshot.cache)))
-
-    # If only one segment has candidates
-    if cand_t1 is None and cand_t2 is not None:
-        return cand_t2
-    if cand_t2 is None and cand_t1 is not None:
-        return cand_t1
-
-    # Both segments have candidates: competitive decision using incoming frequency
-    if cand_t1 is not None and cand_t2 is not None:
-        f_new = m_freq.get(k, 0)
-        f_t2 = m_freq.get(cand_t2, 0)
-        bias = 2 if in_scan else 1
-        # If new clearly hotter than T2's cold candidate, replace from T2; else evict from T1
-        if f_new >= f_t2 + bias:
-            return cand_t2
-        return cand_t1
-
-    # Fallback: choose any key from the cache
-    return next(iter(cache_snapshot.cache))
+    return _policy.evict(cache_snapshot, obj)
 
 
 def update_after_hit(cache_snapshot, obj):
-    '''
-    This function defines how the algorithm update the metadata it maintains immediately after a cache hit.
-    - Args:
-        - `cache_snapshot`: A snapshot of the current cache state.
-        - `obj`: The object accessed during the cache hit.
-    - Return: `None`
-    '''
-    global m_probation, m_protected, m_b1, m_b2, m_freq, m_miss_streak
-    _reset_if_new_run(cache_snapshot)
-    _prune_metadata(cache_snapshot)
-    _maybe_age_freq(cache_snapshot)
-
-    k = obj.key
-    # Bump lightweight frequency
-    m_freq[k] = m_freq.get(k, 0) + 1
-
-    # Any hit breaks a miss streak
-    m_miss_streak = 0
-
-    if k in m_protected:
-        # Refresh recency in protected
-        m_protected.move_to_end(k, last=True)
-    elif k in m_probation:
-        # Gate promotion by current protected pressure and scan bias
-        target = _protected_target_size(cache_snapshot)
-        cap = max(int(cache_snapshot.capacity), 1)
-        in_scan = (m_miss_streak > (cap // 2))  # after reset this is False, but keeps structure consistent
-        promote_thr = 3 if len(m_protected) >= target else 2
-        if in_scan:
-            promote_thr += 1
-        if m_freq.get(k, 0) >= promote_thr:
-            m_probation.pop(k, None)
-            m_protected[k] = None
-        else:
-            # Refresh recency in probation
-            m_probation.move_to_end(k, last=True)
-    else:
-        # Metadata miss but cache hit: treat as hot and place into protected
-        m_protected[k] = None
-
-    # Keep protected within target by demoting LRU when necessary
-    _enforce_protected_target(cache_snapshot)
+    _policy.update_after_hit(cache_snapshot, obj)
 
 
 def update_after_insert(cache_snapshot, obj):
-    '''
-    This function defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
-    - Args:
-        - `cache_snapshot`: A snapshot of the current cache state.
-        - `obj`: The object that was just inserted into the cache.
-    - Return: `None`
-    '''
-    global m_probation, m_protected, m_b1, m_b2, m_freq, m_miss_streak
-    _reset_if_new_run(cache_snapshot)
-    _prune_metadata(cache_snapshot)
-    _maybe_age_freq(cache_snapshot)
-
-    k = obj.key
-    # Remove any stale placements
-    m_protected.pop(k, None)
-    m_probation.pop(k, None)
-
-    cap = max(int(cache_snapshot.capacity), 1)
-    in_scan = m_miss_streak > cap
-
-    # ARC admission for ghosts: insert to protected (T2)
-    if k in m_b1:
-        m_b1.pop(k, None)
-        m_protected[k] = None
-    elif k in m_b2:
-        m_b2.pop(k, None)
-        m_protected[k] = None
-    else:
-        # Non-ghost admission uses competitive TinyLFU-like decision against T2's cold tail.
-        if in_scan:
-            # Avoid polluting protected during scans
-            m_probation[k] = None
-        else:
-            f_new = m_freq.get(k, 0)
-            if len(m_protected) > 0:
-                cand_t2 = _sample_lowfreq(m_protected)
-                f_t2 = m_freq.get(cand_t2, 0) if cand_t2 is not None else 0
-                if f_new > f_t2:
-                    m_protected[k] = None
-                else:
-                    m_probation[k] = None
-            else:
-                # Mild threshold when no protected entries exist
-                if f_new >= 2:
-                    m_protected[k] = None
-                else:
-                    m_probation[k] = None
-
-    # Light frequency credit and miss streak for scan detection
-    m_freq[k] = m_freq.get(k, 0) + 1
-    m_miss_streak += 1
-
-    # Keep protected within target by demoting LRU when necessary
-    _enforce_protected_target(cache_snapshot)
-
-    # Bound combined ghost sizes to capacity
-    while (len(m_b1) + len(m_b2)) > cap:
-        if len(m_b1) > len(m_b2):
-            m_b1.popitem(last=False)
-        else:
-            m_b2.popitem(last=False)
+    _policy.update_after_insert(cache_snapshot, obj)
 
 
 def update_after_evict(cache_snapshot, obj, evicted_obj):
-    '''
-    This function defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
-    - Args:
-        - `cache_snapshot`: A snapshot of the current cache state.
-        - `obj`: The object to be inserted into the cache.
-        - `evicted_obj`: The object that was just evicted from the cache.
-    - Return: `None`
-    '''
-    global m_probation, m_protected, m_b1, m_b2
-    _reset_if_new_run(cache_snapshot)
-    # Move evicted object into appropriate ghost list
-    k = evicted_obj.key
-    if k in m_probation:
-        m_probation.pop(k, None)
-        m_b1.pop(k, None)
-        m_b1[k] = None  # MRU of B1
-    elif k in m_protected:
-        m_protected.pop(k, None)
-        m_b2.pop(k, None)
-        m_b2[k] = None  # MRU of B2
-    else:
-        # No segment info; do nothing
-        pass
-
-    # Bound combined ghost sizes to capacity
-    cap = max(int(cache_snapshot.capacity), 1)
-    while (len(m_b1) + len(m_b2)) > cap:
-        if len(m_b1) > len(m_b2):
-            m_b1.popitem(last=False)
-        else:
-            m_b2.popitem(last=False)
+    _policy.update_after_evict(cache_snapshot, obj, evicted_obj)
 
 # EVOLVE-BLOCK-END
 
 # This part remains fixed (not evolved)
 def run_caching(trace_path: str, copy_code_dst: str):
     """Run the caching algorithm on a trace"""
     import os
     with open(os.path.abspath(__file__), 'r', encoding="utf-8") as f:
         code_str = f.read()
     with open(os.path.join(copy_code_dst), 'w') as f:
         f.write(code_str)
     from cache_utils import Cache, CacheConfig, CacheObj, Trace
     trace = Trace(trace_path=trace_path)
     cache_capacity = max(int(trace.get_ndv() * 0.1), 1)
     cache = Cache(CacheConfig(cache_capacity))
     for entry in trace.entries:
         obj = CacheObj(key=str(entry.key))
         cache.get(obj)
     with open(copy_code_dst, 'w') as f:
         f.write("")
     hit_rate = round(cache.hit_count / cache.access_count, 6)
     return hit_rate