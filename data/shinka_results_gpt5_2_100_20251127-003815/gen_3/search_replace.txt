<NAME>
slru_with_adaptive_protected_ratio
</NAME>

<DESCRIPTION>
I replace the pure LRU policy with a segmented LRU (SLRU) that is well-known to be more scan-resistant and to better preserve frequently reused objects. The idea is to split the cache into two segments:
- probationary (cold): newly inserted items live here
- protected (hot): items promoted here after being hit in probationary

Eviction prefers the LRU item in the probationary segment, thus shielding the protected segment from scans and one-hit wonders. On hit, items in probationary are promoted to protected; if the protected segment exceeds its target size, we demote its LRU back to probationary (not evict). This preserves high-value items while allowing adaptation.

To improve robustness across varied traces, I make the protected segment size adapt to the observed hit rate: more scanning (low hit rate) reduces protected size, while strong locality increases it. All updates are maintained via simple dictionaries/sets; LRU is approximated via access timestamps and selecting the minimal timestamp within the relevant set.

These changes update:
- evict: choose LRU from probation first, else protected, with safe fallbacks
- update_after_hit: promote/demote across segments and refresh timestamps
- update_after_insert: add new keys into probation
- update_after_evict: cleanup metadata

This SLRU with adaptive protected ratio typically yields lower miss rates than plain LRU on mixed and scan-heavy workloads while remaining simple and efficient.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
"""Cache eviction algorithm for optimizing hit rates across multiple workloads"""

m_key_timestamp = dict()

def evict(cache_snapshot, obj):
    '''
    This function defines how the algorithm chooses the eviction victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    candid_obj_key = None
    min_ts = min(m_key_timestamp.values())
    candid_obj_keys = list(key for key in cache_snapshot.cache if m_key_timestamp[key] == min_ts)
    candid_obj_key = candid_obj_keys[0]
    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the algorithm update the metadata it maintains immediately after a cache hit.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    global m_key_timestamp
    assert obj.key in m_key_timestamp
    m_key_timestamp[obj.key] = cache_snapshot.access_count

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    global m_key_timestamp
    assert obj.key not in m_key_timestamp
    m_key_timestamp[obj.key] = cache_snapshot.access_count

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    global m_key_timestamp
    assert obj.key not in m_key_timestamp
    assert evicted_obj.key in m_key_timestamp
    m_key_timestamp.pop(evicted_obj.key)
=======
"""Cache eviction algorithm for optimizing hit rates across multiple workloads"""

# Segmented LRU (SLRU) with adaptive protected ratio.
# - m_key_timestamp: last access time (LRU ordering)
# - m_key_segment: key -> 'prob' (probationary) or 'prot' (protected)
# - m_probationary_keys / m_protected_keys: membership sets
m_key_timestamp = dict()
m_key_segment = dict()
m_probationary_keys = set()
m_protected_keys = set()

def _current_keys(cache_snapshot):
    return set(cache_snapshot.cache.keys())

def _get_lru_key(key_set, cache_snapshot):
    # Return the key with the minimum timestamp among candidates;
    # fall back to all current keys if key_set has no valid candidates.
    current = _current_keys(cache_snapshot)
    candidates = [k for k in key_set if k in current and k in m_key_timestamp]
    if not candidates:
        candidates = [k for k in current if k in m_key_timestamp]
    if not candidates:
        return None
    min_k = candidates[0]
    min_ts = m_key_timestamp.get(min_k, float('inf'))
    for k in candidates[1:]:
        ts = m_key_timestamp.get(k, float('inf'))
        if ts < min_ts:
            min_ts = ts
            min_k = k
    return min_k

def _protected_limit(cache_snapshot):
    # Adapt the protected target size to observed hit rate.
    cap = max(int(cache_snapshot.capacity), 1)
    hr = (cache_snapshot.hit_count / cache_snapshot.access_count) if cache_snapshot.access_count > 0 else 0.0
    if hr < 0.1:
        ratio = 0.4
    elif hr < 0.3:
        ratio = 0.6
    else:
        ratio = 0.8
    limit = max(1, int(cap * ratio))
    if limit >= cap:
        limit = cap - 1 if cap > 1 else 1
    return limit

def evict(cache_snapshot, obj):
    '''
    This function defines how the algorithm chooses the eviction victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    current = _current_keys(cache_snapshot)
    # Prefer evicting from probationary to protect frequently reused items.
    prob_candidates = m_probationary_keys & current
    if prob_candidates:
        victim = _get_lru_key(prob_candidates, cache_snapshot)
    else:
        # If probationary is empty, evict LRU from protected.
        victim = _get_lru_key(m_protected_keys, cache_snapshot)
        if victim is None:
            # Fallback: choose any LRU from current cache keys.
            victim = _get_lru_key(set(), cache_snapshot)
    return victim

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the algorithm update the metadata it maintains immediately after a cache hit.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    global m_key_timestamp, m_key_segment, m_probationary_keys, m_protected_keys
    # Refresh LRU timestamp
    m_key_timestamp[obj.key] = cache_snapshot.access_count

    seg = m_key_segment.get(obj.key)
    # Promote from probationary to protected on hit
    if seg == 'prob':
        m_probationary_keys.discard(obj.key)
        m_protected_keys.add(obj.key)
        m_key_segment[obj.key] = 'prot'

    # Enforce protected segment target size by demoting its LRU back to probationary
    prot_limit = _protected_limit(cache_snapshot)
    while len(m_protected_keys) > prot_limit:
        demote_key = _get_lru_key(m_protected_keys, cache_snapshot)
        if demote_key is None:
            break
        m_protected_keys.discard(demote_key)
        m_probationary_keys.add(demote_key)
        m_key_segment[demote_key] = 'prob'

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    global m_key_timestamp, m_key_segment, m_probationary_keys, m_protected_keys
    # New objects enter probationary. Initialize timestamp.
    m_key_timestamp[obj.key] = cache_snapshot.access_count
    m_key_segment[obj.key] = 'prob'
    m_probationary_keys.add(obj.key)
    # Ensure not double-listed in protected
    m_protected_keys.discard(obj.key)

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    global m_key_timestamp, m_key_segment, m_probationary_keys, m_protected_keys
    # Remove evicted object's metadata
    evk = evicted_obj.key
    m_key_timestamp.pop(evk, None)
    seg = m_key_segment.pop(evk, None)
    if seg == 'prob':
        m_probationary_keys.discard(evk)
    elif seg == 'prot':
        m_protected_keys.discard(evk)
    else:
        # If unknown, ensure it's not in either set
        m_probationary_keys.discard(evk)
        m_protected_keys.discard(evk)
    # Make sure the incoming object's key doesn't have stale metadata
    m_key_timestamp.pop(obj.key, None)
    stale_seg = m_key_segment.pop(obj.key, None)
    if stale_seg == 'prob':
        m_probationary_keys.discard(obj.key)
    elif stale_seg == 'prot':
        m_protected_keys.discard(obj.key)
>>>>>>> REPLACE

</DIFF>