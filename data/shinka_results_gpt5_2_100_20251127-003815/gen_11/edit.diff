--- a/original.py
+++ b/original.py
@@ -1,122 +1,207 @@
 # EVOLVE-BLOCK-START
-"""Adaptive LRFU-like eviction: combine recency and frequency with exponential decay"""
+"""Adaptive SLRU+LRFU eviction: probation/protected segments with exponential-decay score"""
 
 # Configuration: half-life in number of accesses for score decay.
 # After DECAY_HALF_LIFE accesses without a hit, a key's score halves.
-DECAY_HALF_LIFE = 16
+DECAY_HALF_LIFE = 8
 DECAY_BASE = 2 ** (-1.0 / DECAY_HALF_LIFE)
 
 # Per-key metadata for cached objects
 _key_score = dict()      # key -> float decayed frequency score
 _key_last_time = dict()  # key -> int last access_count when we updated its score
 
+# Segmented resident sets
+_probation = set()       # keys admitted recently or with single hit
+_protected = set()       # keys with demonstrated frequency
+_prot_cap = 0            # adaptive target size (in number of keys) for protected segment
+
+def _prune_membership(cache_snapshot):
+    """Remove keys from segment sets that are no longer resident in the cache."""
+    cache_keys = set(cache_snapshot.cache.keys())
+    for seg in (_probation, _protected):
+        stale = [k for k in seg if k not in cache_keys]
+        for k in stale:
+            seg.discard(k)
+
+def _ensure_meta(k, now):
+    """Ensure metadata exists for key k and lazily decay its score to 'now'."""
+    if k not in _key_last_time:
+        _key_last_time[k] = now
+    if k not in _key_score:
+        _key_score[k] = 0.0
+    dt = now - _key_last_time[k]
+    if dt > 0:
+        _key_score[k] *= pow(DECAY_BASE, dt)
+        _key_last_time[k] = now
+    return _key_score[k], _key_last_time[k]
+
+def _pick_min_by_score(candidates, now):
+    """Pick key with minimal decayed score from candidates; tie-break on older last access."""
+    min_key = None
+    min_score = None
+    min_old_time = None
+    for k in candidates:
+        old_time = _key_last_time.get(k, now)
+        # decay lazily
+        s, _ = _ensure_meta(k, now)
+        if (min_score is None) or (s < min_score) or (s == min_score and old_time < (min_old_time if min_old_time is not None else old_time)):
+            min_score = s
+            min_key = k
+            min_old_time = old_time
+    return min_key
+
+def _enforce_protected_cap(now):
+    """If protected exceeds target cap, demote lowest-score protected key to probation."""
+    global _prot_cap
+    while _protected and len(_protected) > _prot_cap:
+        k = _pick_min_by_score(_protected, now)
+        if k is None:
+            break
+        _protected.discard(k)
+        _probation.add(k)
+
 def evict(cache_snapshot, obj):
     '''
     This function defines how the algorithm chooses the eviction victim.
     - Args:
         - `cache_snapshot`: A snapshot of the current cache state.
         - `obj`: The new object that needs to be inserted into the cache.
     - Return:
         - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
     '''
-    global _key_score, _key_last_time
+    global _prot_cap
     now = cache_snapshot.access_count
 
-    # Choose the object with the minimum decayed score; tie-break on older last access (LRU fallback).
-    min_key = None
-    min_score = None
-    min_old_time = None
-
-    # Lazily decay scores to "now" during victim selection to avoid global walks elsewhere.
-    for k in cache_snapshot.cache.keys():
-        # Initialize metadata if missing (robustness)
-        if k not in _key_last_time:
-            _key_last_time[k] = now
-        if k not in _key_score:
-            _key_score[k] = 0.0
-
-        old_time = _key_last_time[k]
-        dt = now - old_time
-        if dt > 0:
-            _key_score[k] *= pow(DECAY_BASE, dt)
-            _key_last_time[k] = now
-        s = _key_score[k]
-
-        if (min_score is None) or (s < min_score) or (s == min_score and old_time < min_old_time):
-            min_score = s
-            min_key = k
-            min_old_time = old_time
-
-    return min_key
+    # Keep sets consistent with actual cache content
+    _prune_membership(cache_snapshot)
+
+    # Initialize protected capacity target if unset
+    cur_cap = max(1, len(cache_snapshot.cache))
+    if _prot_cap <= 0:
+        _prot_cap = max(1, cur_cap // 2)
+
+    # Prefer evicting from probation; if empty, from protected; else fallback to any key
+    prob_candidates = [k for k in _probation if k in cache_snapshot.cache]
+    if prob_candidates:
+        return _pick_min_by_score(prob_candidates, now)
+
+    prot_candidates = [k for k in _protected if k in cache_snapshot.cache]
+    if prot_candidates:
+        return _pick_min_by_score(prot_candidates, now)
+
+    # Fallback: choose globally minimal score among resident keys
+    return _pick_min_by_score(list(cache_snapshot.cache.keys()), now)
 
 def update_after_hit(cache_snapshot, obj):
     '''
     This function defines how the algorithm update the metadata it maintains immediately after a cache hit.
     - Args:
         - `cache_snapshot`: A snapshot of the current cache state.
         - `obj`: The object accessed during the cache hit.
     - Return: `None`
     '''
-    global _key_score, _key_last_time
+    global _prot_cap
     now = cache_snapshot.access_count
 
-    # Ensure metadata exists
-    if obj.key not in _key_last_time:
-        _key_last_time[obj.key] = now
-    if obj.key not in _key_score:
-        _key_score[obj.key] = 0.0
-
-    dt = now - _key_last_time[obj.key]
-    if dt > 0:
-        _key_score[obj.key] *= pow(DECAY_BASE, dt)
-    _key_score[obj.key] += 1.0  # frequency boost
-    _key_last_time[obj.key] = now
+    _prune_membership(cache_snapshot)
+
+    # Initialize protected capacity target if unset
+    cur_cap = max(1, len(cache_snapshot.cache))
+    if _prot_cap <= 0:
+        _prot_cap = max(1, cur_cap // 2)
+
+    # Update decayed score and last time
+    _ensure_meta(obj.key, now)
+
+    # Promotion logic and adaptive protected sizing
+    if obj.key in _probation:
+        # Promote to protected on first observed hit
+        _probation.discard(obj.key)
+        _protected.add(obj.key)
+        # Bias toward larger protected region when we observe probation hits
+        if _prot_cap < cur_cap:
+            _prot_cap += 1
+    else:
+        # If unknown to segments, treat as protected (robustness)
+        _protected.add(obj.key)
+        _probation.discard(obj.key)
+        # Slightly reduce protected target on protected hits to keep room for recency
+        if _prot_cap > 1:
+            _prot_cap -= 1
+
+    # Frequency boost; slightly stronger in protected
+    if obj.key in _protected:
+        _key_score[obj.key] += 1.5
+    else:
+        _key_score[obj.key] += 1.0
+
+    # Enforce protected capacity by demoting weakest protected key
+    _enforce_protected_cap(now)
 
 def update_after_insert(cache_snapshot, obj):
     '''
     This function defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
     - Args:
         - `cache_snapshot`: A snapshot of the current cache state.
         - `obj`: The object that was just inserted into the cache.
     - Return: `None`
     '''
-    global _key_score, _key_last_time
+    global _prot_cap
     now = cache_snapshot.access_count
+
+    _prune_membership(cache_snapshot)
+
+    # Initialize protected capacity on cold start
+    cur_cap = max(1, len(cache_snapshot.cache))
+    if _prot_cap <= 0:
+        _prot_cap = max(1, cur_cap // 2)
+
+    # Admit into probation with a small initial score to reduce scan pollution.
+    _probation.add(obj.key)
+    _protected.discard(obj.key)
+
     _key_last_time[obj.key] = now
-    # Start with a modest score to reduce scan pollution; frequent re-references will quickly boost it.
-    _key_score[obj.key] = 0.5
+    _key_score[obj.key] = 0.1
 
 def update_after_evict(cache_snapshot, obj, evicted_obj):
     '''
     This function defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
     - Args:
         - `cache_snapshot`: A snapshot of the current cache state.
         - `obj`: The object to be inserted into the cache.
         - `evicted_obj`: The object that was just evicted from the cache.
     - Return: `None`
     '''
-    global _key_score, _key_last_time
+    global _prot_cap
+    # Clear all metadata for the evicted key
     _key_score.pop(evicted_obj.key, None)
     _key_last_time.pop(evicted_obj.key, None)
+    _probation.discard(evicted_obj.key)
+    _protected.discard(evicted_obj.key)
+
+    # Make sure protected cap does not exceed current possible size
+    cur_cap = max(1, len(cache_snapshot.cache))
+    if _prot_cap > cur_cap:
+        _prot_cap = cur_cap
 
 # EVOLVE-BLOCK-END
 
 # This part remains fixed (not evolved)
 def run_caching(trace_path: str, copy_code_dst: str):
     """Run the caching algorithm on a trace"""
     import os
     with open(os.path.abspath(__file__), 'r', encoding="utf-8") as f:
         code_str = f.read()
     with open(os.path.join(copy_code_dst), 'w') as f:
         f.write(code_str)
     from cache_utils import Cache, CacheConfig, CacheObj, Trace
     trace = Trace(trace_path=trace_path)
     cache_capacity = max(int(trace.get_ndv() * 0.1), 1)
     cache = Cache(CacheConfig(cache_capacity))
     for entry in trace.entries:
         obj = CacheObj(key=str(entry.key))
         cache.get(obj)
     with open(copy_code_dst, 'w') as f:
         f.write("")
     hit_rate = round(cache.hit_count / cache.access_count, 6)
     return hit_rate