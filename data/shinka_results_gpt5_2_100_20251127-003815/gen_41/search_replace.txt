<NAME>
arc_tiny_competitive_eviction
</NAME>

<DESCRIPTION>
I introduce competitive admission and scan-aware bias into the existing ARC-inspired policy using the lightweight frequency dictionary already maintained. The key improvements are:

- Eviction: After respecting core ARC rules (T1 oversized or B2 condition), I sample a low-frequency candidate from both probation (T1) and protected (T2) and decide competitively based on the incoming key’s estimated frequency. If the incoming object is hotter than the sampled T2-candidate by a small bias, we evict from T2; otherwise from T1. During detected scans (long miss streak), a stronger bias protects T2 by evicting from T1 whenever possible.

- Insert: On non-ghost inserts, I add TinyLFU-like competitive admission: compare the incoming key’s frequency to a sampled T2 tail; if hotter, admit directly into protected, else probation. During scan, avoid direct T2 admissions to prevent pollution. Ghost hits still go to protected as before.

- Hit: Promotion from probation to protected becomes scan-aware by raising the promotion threshold during scans, reducing protected pollution in streaming phases.

- All changes reuse existing metadata (m_freq, ghosts, miss-streak) and keep protected size bounded via the existing enforcement function.

This blend preserves ARC’s adaptability while leveraging frequency signals to reduce unnecessary churn, improving hit rates across mixed workloads.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
def evict(cache_snapshot, obj):
    '''
    This function defines how the algorithm chooses the eviction victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    global m_probation, m_protected, m_b1, m_b2, m_freq, m_p
    _reset_if_new_run(cache_snapshot)
    _prune_metadata(cache_snapshot)

    # Seed metadata if empty by placing all current cache keys into probation.
    if not m_probation and not m_protected and cache_snapshot.cache:
        for k0 in cache_snapshot.cache.keys():
            m_probation[k0] = None

    # ARC: adjust target m_p based on ghost hit of incoming key
    cap = max(int(cache_snapshot.capacity), 1)
    k = obj.key
    if k in m_b1:
        delta = max(1, len(m_b2) // max(1, len(m_b1)))
        m_p = min(cap, m_p + delta)
    elif k in m_b2:
        delta = max(1, len(m_b1) // max(1, len(m_b2)))
        m_p = max(0, m_p - delta)

    # ARC replacement decision (do not mutate structures here)
    if m_probation and ((k in m_b2 and len(m_probation) == m_p) or (len(m_probation) > m_p)):
        # Evict low-frequency among LRU tail of probation (T1)
        candid_obj_key = _sample_lowfreq(m_probation)
    elif m_protected:
        # Evict low-frequency among LRU tail of protected (T2)
        candid_obj_key = _sample_lowfreq(m_protected)
    elif m_probation:
        candid_obj_key = _sample_lowfreq(m_probation)
    else:
        # Fallback: choose any key from the cache
        candid_obj_key = next(iter(cache_snapshot.cache))
    return candid_obj_key
=======
def evict(cache_snapshot, obj):
    '''
    This function defines how the algorithm chooses the eviction victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    global m_probation, m_protected, m_b1, m_b2, m_freq, m_p, m_miss_streak
    _reset_if_new_run(cache_snapshot)
    _prune_metadata(cache_snapshot)

    # Seed metadata if empty by placing all current cache keys into probation.
    if not m_probation and not m_protected and cache_snapshot.cache:
        for k0 in cache_snapshot.cache.keys():
            m_probation[k0] = None

    # ARC: adjust target m_p based on ghost hit of incoming key
    cap = max(int(cache_snapshot.capacity), 1)
    k = obj.key
    if k in m_b1:
        delta = max(1, len(m_b2) // max(1, len(m_b1)))
        m_p = min(cap, m_p + delta)
    elif k in m_b2:
        delta = max(1, len(m_b1) // max(1, len(m_b2)))
        m_p = max(0, m_p - delta)

    in_scan = m_miss_streak > cap

    # Candidates from segments (LRU-side, low-frequency)
    cand_t1 = _sample_lowfreq(m_probation) if m_probation else None
    cand_t2 = _sample_lowfreq(m_protected) if m_protected else None

    # During scans, protect T2 by evicting from T1 when possible
    if in_scan and cand_t1 is not None:
        return cand_t1

    # ARC replacement rule: if T1 oversized or (new in B2 and |T1| == p), evict from T1
    if m_probation and ((k in m_b2 and len(m_probation) == m_p) or (len(m_probation) > m_p)):
        return cand_t1 if cand_t1 is not None else (cand_t2 if cand_t2 is not None else next(iter(cache_snapshot.cache)))

    # If only one segment has candidates
    if cand_t1 is None and cand_t2 is not None:
        return cand_t2
    if cand_t2 is None and cand_t1 is not None:
        return cand_t1

    # Both segments have candidates: competitive decision using incoming frequency
    if cand_t1 is not None and cand_t2 is not None:
        f_new = m_freq.get(k, 0)
        f_t2 = m_freq.get(cand_t2, 0)
        bias = 2 if in_scan else 1
        # If new clearly hotter than T2's cold candidate, replace from T2; else evict from T1
        if f_new >= f_t2 + bias:
            return cand_t2
        return cand_t1

    # Fallback: choose any key from the cache
    return next(iter(cache_snapshot.cache))
>>>>>>> REPLACE
</DIFF>

<DIFF>
<<<<<<< SEARCH
def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the algorithm update the metadata it maintains immediately after a cache hit.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    global m_probation, m_protected, m_b1, m_b2, m_freq, m_miss_streak
    _reset_if_new_run(cache_snapshot)
    _prune_metadata(cache_snapshot)
    _maybe_age_freq(cache_snapshot)

    k = obj.key
    # Bump lightweight frequency
    m_freq[k] = m_freq.get(k, 0) + 1

    # Any hit breaks a miss streak
    m_miss_streak = 0

    if k in m_protected:
        # Refresh recency in protected
        m_protected.move_to_end(k, last=True)
    elif k in m_probation:
        # Gate promotion by current protected pressure
        target = _protected_target_size(cache_snapshot)
        promote_thr = 3 if len(m_protected) >= target else 2
        if m_freq.get(k, 0) >= promote_thr:
            m_probation.pop(k, None)
            m_protected[k] = None
        else:
            # Refresh recency in probation
            m_probation.move_to_end(k, last=True)
    else:
        # Metadata miss but cache hit: treat as hot and place into protected
        m_protected[k] = None

    # Keep protected within target by demoting LRU when necessary
    _enforce_protected_target(cache_snapshot)
=======
def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the algorithm update the metadata it maintains immediately after a cache hit.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    global m_probation, m_protected, m_b1, m_b2, m_freq, m_miss_streak
    _reset_if_new_run(cache_snapshot)
    _prune_metadata(cache_snapshot)
    _maybe_age_freq(cache_snapshot)

    k = obj.key
    # Bump lightweight frequency
    m_freq[k] = m_freq.get(k, 0) + 1

    # Any hit breaks a miss streak
    m_miss_streak = 0

    if k in m_protected:
        # Refresh recency in protected
        m_protected.move_to_end(k, last=True)
    elif k in m_probation:
        # Gate promotion by current protected pressure and scan bias
        target = _protected_target_size(cache_snapshot)
        cap = max(int(cache_snapshot.capacity), 1)
        in_scan = (m_miss_streak > (cap // 2))  # after reset this is False, but keeps structure consistent
        promote_thr = 3 if len(m_protected) >= target else 2
        if in_scan:
            promote_thr += 1
        if m_freq.get(k, 0) >= promote_thr:
            m_probation.pop(k, None)
            m_protected[k] = None
        else:
            # Refresh recency in probation
            m_probation.move_to_end(k, last=True)
    else:
        # Metadata miss but cache hit: treat as hot and place into protected
        m_protected[k] = None

    # Keep protected within target by demoting LRU when necessary
    _enforce_protected_target(cache_snapshot)
>>>>>>> REPLACE
</DIFF>

<DIFF>
<<<<<<< SEARCH
def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    global m_probation, m_protected, m_b1, m_b2, m_freq, m_miss_streak
    _reset_if_new_run(cache_snapshot)
    _prune_metadata(cache_snapshot)
    _maybe_age_freq(cache_snapshot)

    k = obj.key
    # Remove any stale placements
    m_protected.pop(k, None)
    m_probation.pop(k, None)

    # ARC admission: if key was in ghosts, insert to protected (T2); else to probation (T1)
    if k in m_b1:
        m_b1.pop(k, None)
        m_protected[k] = None
    elif k in m_b2:
        m_b2.pop(k, None)
        m_protected[k] = None
    else:
        m_probation[k] = None

    # Light frequency credit and miss streak for scan detection
    m_freq[k] = m_freq.get(k, 0) + 1
    m_miss_streak += 1

    # Keep protected within target by demoting LRU when necessary
    _enforce_protected_target(cache_snapshot)

    # Bound combined ghost sizes to capacity
    cap = max(int(cache_snapshot.capacity), 1)
    while (len(m_b1) + len(m_b2)) > cap:
        if len(m_b1) > len(m_b2):
            m_b1.popitem(last=False)
        else:
            m_b2.popitem(last=False)
=======
def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    global m_probation, m_protected, m_b1, m_b2, m_freq, m_miss_streak
    _reset_if_new_run(cache_snapshot)
    _prune_metadata(cache_snapshot)
    _maybe_age_freq(cache_snapshot)

    k = obj.key
    # Remove any stale placements
    m_protected.pop(k, None)
    m_probation.pop(k, None)

    cap = max(int(cache_snapshot.capacity), 1)
    in_scan = m_miss_streak > cap

    # ARC admission for ghosts: insert to protected (T2)
    if k in m_b1:
        m_b1.pop(k, None)
        m_protected[k] = None
    elif k in m_b2:
        m_b2.pop(k, None)
        m_protected[k] = None
    else:
        # Non-ghost admission uses competitive TinyLFU-like decision against T2's cold tail.
        if in_scan:
            # Avoid polluting protected during scans
            m_probation[k] = None
        else:
            f_new = m_freq.get(k, 0)
            if len(m_protected) > 0:
                cand_t2 = _sample_lowfreq(m_protected)
                f_t2 = m_freq.get(cand_t2, 0) if cand_t2 is not None else 0
                if f_new > f_t2:
                    m_protected[k] = None
                else:
                    m_probation[k] = None
            else:
                # Mild threshold when no protected entries exist
                if f_new >= 2:
                    m_protected[k] = None
                else:
                    m_probation[k] = None

    # Light frequency credit and miss streak for scan detection
    m_freq[k] = m_freq.get(k, 0) + 1
    m_miss_streak += 1

    # Keep protected within target by demoting LRU when necessary
    _enforce_protected_target(cache_snapshot)

    # Bound combined ghost sizes to capacity
    while (len(m_b1) + len(m_b2)) > cap:
        if len(m_b1) > len(m_b2):
            m_b1.popitem(last=False)
        else:
            m_b2.popitem(last=False)
>>>>>>> REPLACE
</DIFF>