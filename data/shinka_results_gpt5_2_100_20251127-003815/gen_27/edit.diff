--- a/original.py
+++ b/original.py
@@ -1,437 +1,427 @@
 # EVOLVE-BLOCK-START
-"""W-TinyLFU with windowed recency and SLRU main segments.
+"""ARC + TinyLFU hybrid with EMA-tuned p and frequency-guided victim sampling.
 
 Public API:
 - evict(cache_snapshot, obj) -> key
 - update_after_hit(cache_snapshot, obj)
 - update_after_insert(cache_snapshot, obj)
 - update_after_evict(cache_snapshot, obj, evicted_obj)
 """
 
 from collections import OrderedDict
 
 
 class _CmSketch:
     """
     Count-Min Sketch with conservative aging (TinyLFU).
     - d hash functions, width w (power-of-two).
     - Periodic right-shift halves counters to forget stale history.
     """
     __slots__ = ("d", "w", "tables", "mask", "ops", "age_period", "seeds")
 
     def __init__(self, width_power=12, d=3):
         self.d = int(max(1, d))
         w = 1 << int(max(8, width_power))  # min 256
         self.w = w
         self.mask = w - 1
         self.tables = [[0] * w for _ in range(self.d)]
         self.ops = 0
         self.age_period = max(1024, w)
         self.seeds = (0x9e3779b1, 0x85ebca77, 0xc2b2ae3d, 0x27d4eb2f)
 
     def _hash(self, key_hash: int, i: int) -> int:
         h = key_hash ^ self.seeds[i % len(self.seeds)]
         h ^= (h >> 33) & 0xFFFFFFFFFFFFFFFF
         h *= 0xff51afd7ed558ccd
         h &= 0xFFFFFFFFFFFFFFFF
         h ^= (h >> 33)
         h *= 0xc4ceb9fe1a85ec53
         h &= 0xFFFFFFFFFFFFFFFF
         h ^= (h >> 33)
         return h & self.mask
 
     def _maybe_age(self):
         self.ops += 1
         if self.ops % self.age_period == 0:
             for t in self.tables:
                 for i in range(self.w):
                     t[i] >>= 1
 
     def increment(self, key: str, amount: int = 1):
         h = hash(key)
         for i in range(self.d):
             idx = self._hash(h, i)
             v = self.tables[i][idx] + amount
             if v > 255:
                 v = 255
             self.tables[i][idx] = v
         self._maybe_age()
 
     def estimate(self, key: str) -> int:
         h = hash(key)
         est = 1 << 30
         for i in range(self.d):
             idx = self._hash(h, i)
             v = self.tables[i][idx]
             if v < est:
                 est = v
         return est
 
 
-class _WTinyLFUPolicy:
-    """
-    Windowed TinyLFU with SLRU main:
-    - W: window LRU (recency buffer).
-    - M1: main probationary (first-time in main).
-    - M2: main protected (promoted on re-use).
-    - TinyLFU sketch for frequency-based admission and candidate selection.
+class _ARCTinyLFU:
+    """
+    Adaptive Replacement Cache (ARC) with:
+    - T1: recent/probationary resident list (LRU).
+    - T2: frequent/protected resident list (LRU).
+    - B1: ghost list of keys evicted from T1 (LRU).
+    - B2: ghost list of keys evicted from T2 (LRU).
+    Adaptation:
+    - Parameter p (target size for T1) tuned by EMA on B1/B2 ghost hits.
+    TinyLFU:
+    - Count-Min Sketch to estimate frequency.
+    - Victim selection samples k LRU-side keys from chosen list and evicts the one with lowest estimate.
     """
 
     __slots__ = (
-        "W", "M1", "M2", "capacity",
-        "win_frac", "prot_frac", "sketch", "_sample_k",
-        "hits_w", "hits_main", "last_tune_time", "tune_period",
-        "miss_streak", "scan_cooldown"
+        "T1", "T2", "B1", "B2",
+        "capacity", "p", "ema_alpha",
+        "sketch", "_sample_k", "_pending_evict"
     )
 
     def __init__(self):
-        self.W = OrderedDict()
-        self.M1 = OrderedDict()
-        self.M2 = OrderedDict()
+        self.T1 = OrderedDict()
+        self.T2 = OrderedDict()
+        self.B1 = OrderedDict()
+        self.B2 = OrderedDict()
         self.capacity = None
-        # Targets as fractions of capacity
-        self.win_frac = 0.2   # 20% window
-        self.prot_frac = 0.8  # 80% of main reserved for protected
+        self.p = 0.0
+        self.ema_alpha = 0.25
         self.sketch = _CmSketch(width_power=12, d=3)
         self._sample_k = 6
-        # Adaptive tuning state
-        self.hits_w = 0
-        self.hits_main = 0
-        self.last_tune_time = 0
-        self.tune_period = 0
-        # Scan detection
-        self.miss_streak = 0
-        self.scan_cooldown = 0
-
-    # ----- helpers -----
+        self._pending_evict = None  # (key, from_list: "T1"|"T2")
+
+    # ---------- helpers ----------
 
     def _ensure_capacity(self, cap: int):
+        cap = max(int(cap), 1)
         if self.capacity is None:
-            self.capacity = max(int(cap), 1)
-            self._sample_k = max(4, min(12, (self.capacity // 8) or 4))
-            # Age faster for smaller caches
+            self.capacity = cap
+            self.p = min(float(cap), max(0.0, cap * 0.25))
+            self._sample_k = max(4, min(8, (cap // 8) or 4))
             try:
-                self.sketch.age_period = max(512, min(16384, self.capacity * 8))
+                self.sketch.age_period = max(512, min(16384, cap * 8))
             except Exception:
                 pass
-            # Set adaptive tuning period relative to capacity
-            self.tune_period = max(256, self.capacity * 4)
-            self.last_tune_time = 0
             return
         if self.capacity != cap:
-            # Reset segments if external capacity changes to avoid desync.
-            self.W.clear(); self.M1.clear(); self.M2.clear()
-            self.capacity = max(int(cap), 1)
-            self._sample_k = max(4, min(12, (self.capacity // 8) or 4))
+            # Reset lists to avoid desync on capacity changes
+            self.T1.clear(); self.T2.clear(); self.B1.clear(); self.B2.clear()
+            self.capacity = cap
+            self.p = min(float(cap), max(0.0, cap * 0.25))
+            self._sample_k = max(4, min(8, (cap // 8) or 4))
             try:
-                self.sketch.age_period = max(512, min(16384, self.capacity * 8))
+                self.sketch.age_period = max(512, min(16384, cap * 8))
             except Exception:
                 pass
-            self.tune_period = max(256, self.capacity * 4)
-            self.last_tune_time = 0
-
-    def _targets(self):
-        cap = self.capacity or 1
-        w_tgt = max(1, int(round(cap * self.win_frac)))
-        main_cap = max(0, cap - w_tgt)
-        prot_tgt = int(round(main_cap * self.prot_frac))
-        prob_tgt = max(0, main_cap - prot_tgt)
-        return w_tgt, prob_tgt, prot_tgt
+            self._pending_evict = None
+
+    def _current_keys(self, cache_snapshot):
+        return set(cache_snapshot.cache.keys())
 
     def _self_heal(self, cache_snapshot):
-        # Ensure all cached keys are tracked and no phantom entries remain.
-        cache_keys = set(cache_snapshot.cache.keys())
-        for od in (self.W, self.M1, self.M2):
+        """
+        Ensure resident lists match cache contents; never allow ghosts to contain resident keys.
+        """
+        current = self._current_keys(cache_snapshot)
+        # Purge non-resident from T1/T2
+        for od in (self.T1, self.T2):
             for k in list(od.keys()):
-                if k not in cache_keys:
+                if k not in current:
                     od.pop(k, None)
-        tracked = set(self.W.keys()) | set(self.M1.keys()) | set(self.M2.keys())
-        missing = cache_keys - tracked
+        # Remove any resident from ghosts (ghost hygiene)
+        for k in list(self.B1.keys()):
+            if k in current:
+                self.B1.pop(k, None)
+        for k in list(self.B2.keys()):
+            if k in current:
+                self.B2.pop(k, None)
+        # Add any missing residents into T1 (conservative)
+        tracked = set(self.T1.keys()) | set(self.T2.keys())
+        missing = current - tracked
         if missing:
-            w_tgt, _, _ = self._targets()
-            # Place missing into W until target, then into M1
             for k in missing:
-                if len(self.W) < w_tgt:
-                    self.W[k] = None
+                self.T1[k] = None
+
+        # Bound ghost history: |B1| + |B2| <= C
+        self._bound_ghosts()
+
+    def _bound_ghosts(self):
+        c = self.capacity or 1
+        # While the sum exceeds capacity, evict from the larger ghost list's LRU
+        while len(self.B1) + len(self.B2) > c:
+            if len(self.B1) >= len(self.B2):
+                # Evict B1 LRU
+                if self.B1:
+                    self.B1.popitem(last=False)
                 else:
-                    self.M1[k] = None
-
-    def _maybe_tune(self, now: int):
-        # Periodically adapt window size based on relative hits.
-        if self.tune_period <= 0:
-            return
-        if (now - self.last_tune_time) >= self.tune_period:
-            # If window is relatively more useful, grow it; otherwise shrink.
-            if self.hits_w > self.hits_main * 1.1:
-                self.win_frac = min(0.5, self.win_frac + 0.05)
-            elif self.hits_main > self.hits_w * 1.1:
-                self.win_frac = max(0.05, self.win_frac - 0.05)
-            # Decay counters and update tune timestamp
-            self.hits_w >>= 1
-            self.hits_main >>= 1
-            self.last_tune_time = now
-
-    def _lru(self, od: OrderedDict):
-        return next(iter(od)) if od else None
-
-    def _touch(self, od: OrderedDict, key: str):
-        od[key] = None
-        od.move_to_end(key)
-
-    def _sample_lru_min_freq(self, od: OrderedDict) -> str:
+                    break
+            else:
+                if self.B2:
+                    self.B2.popitem(last=False)
+                else:
+                    break
+
+    def _sample_victim(self, od: OrderedDict) -> str:
+        """
+        Sample up to k LRU-side keys from 'od' and choose the one with the lowest TinyLFU estimate.
+        Falls back to pure LRU if estimates tie or not enough candidates.
+        """
         if not od:
             return None
         k = min(self._sample_k, len(od))
         it = iter(od.keys())  # from LRU to MRU
-        min_key, min_f = None, None
+        chosen = None
+        chosen_f = None
+        # Prefer low-frequency among the k LRU-end candidates
         for _ in range(k):
             key = next(it)
             f = self.sketch.estimate(key)
-            if min_f is None or f < min_f:
-                min_f, min_key = f, key
-        return min_key if min_key is not None else self._lru(od)
-
-    # ----- policy decisions -----
+            if chosen_f is None or f < chosen_f:
+                chosen_f = f
+                chosen = key
+        return chosen if chosen is not None else next(iter(od))
+
+    def _adapt_p(self, toward_recency: bool):
+        """
+        Smoothly adapt p using EMA toward a new target.
+        - toward_recency=True on B1 hit (grow T1 target)
+        - toward_recency=False on B2 hit (shrink T1 target)
+        Delta scales with opposite ghost size, per ARC intuition.
+        """
+        C = float(self.capacity or 1)
+        b1 = len(self.B1)
+        b2 = len(self.B2)
+        if toward_recency:
+            delta = max(1.0, b2 / max(1.0, float(b1)))
+            target = min(C, self.p + delta)
+        else:
+            delta = max(1.0, b1 / max(1.0, float(b2)))
+            target = max(0.0, self.p - delta)
+        self.p = (1.0 - self.ema_alpha) * self.p + self.ema_alpha * target
+        if self.p < 0.0:
+            self.p = 0.0
+        if self.p > C:
+            self.p = C
+
+    # ---------- policy decisions ----------
 
     def choose_victim(self, cache_snapshot, new_obj) -> str:
         """
-        W-TinyLFU eviction with scan-aware bias:
-        - Compare f(new) to a sampled low-frequency candidate from M1.
-          * If f(new) > f(cand_M1) + bias: evict cand_M1 (admit new to W).
-          * Else: evict W's LRU (reject new from main this round).
-        - If M1 is empty, fall back to comparing against M2 (with same bias), else use window LRU.
-        - bias = 1 normally; bias = 3 during scan cooldown to protect main.
+        ARC replace decision with frequency-guided victim sampling:
+        - If |T1| > p or (|T1| == p and new_obj in B2): evict from T1 (LRU-side).
+        - Else: evict from T2 (LRU-side).
+        Within the chosen list, sample k LRU-side candidates and pick the one with
+        the lowest TinyLFU estimate.
         """
         self._ensure_capacity(cache_snapshot.capacity)
         self._self_heal(cache_snapshot)
 
-        # Decay scan cooldown on each miss-driven eviction decision
-        if self.scan_cooldown > 0:
-            self.scan_cooldown -= 1
-
-        # Candidates
-        cand_w = self._lru(self.W)
-        cand_m1 = self._sample_lru_min_freq(self.M1)
-        cand_m2 = self._sample_lru_min_freq(self.M2) if cand_m1 is None else None
-
-        f_new = self.sketch.estimate(new_obj.key)
-        f_m1 = self.sketch.estimate(cand_m1) if cand_m1 is not None else -1
-        f_m2 = self.sketch.estimate(cand_m2) if cand_m2 is not None else -1
-        bias = 3 if self.scan_cooldown > 0 else 1
-
-        # Prefer replacing a cold M1 entry if new is sufficiently hotter
-        if cand_m1 is not None and f_new > (f_m1 + bias):
-            return cand_m1
-
-        # Otherwise evict from the window to preserve main
-        if cand_w is not None:
-            return cand_w
-
-        # If no window, consider replacing a cold protected entry if new is sufficiently hotter
-        if cand_m2 is not None and f_new > (f_m2 + bias):
-            return cand_m2
-
-        # Fallbacks
-        if self.M1:
-            return self._lru(self.M1)
-        if self.M2:
-            return self._lru(self.M2)
-
-        # Last resort: pick any key from cache
-        return next(iter(cache_snapshot.cache))
+        # Determine which list to evict from according to ARC replace
+        t1_len = len(self.T1)
+        p_int = int(self.p)  # use floor
+        new_in_b2 = new_obj.key in self.B2
+
+        evict_from_T1 = False
+        if t1_len > p_int or (new_in_b2 and t1_len == p_int and t1_len > 0):
+            evict_from_T1 = True
+
+        # Choose a victim using TinyLFU sampling
+        if evict_from_T1 and self.T1:
+            victim = self._sample_victim(self.T1)
+            self._pending_evict = (victim, "T1")
+            return victim
+        if (not evict_from_T1) and self.T2:
+            victim = self._sample_victim(self.T2)
+            self._pending_evict = (victim, "T2")
+            return victim
+
+        # Fallbacks if one list is empty
+        if self.T1:
+            victim = self._sample_victim(self.T1)
+            self._pending_evict = (victim, "T1")
+            return victim
+        if self.T2:
+            victim = self._sample_victim(self.T2)
+            self._pending_evict = (victim, "T2")
+            return victim
+
+        # Last resort: any key from cache
+        any_key = next(iter(cache_snapshot.cache))
+        # Unknown origin; default to T1
+        self._pending_evict = (any_key, "T1")
+        return any_key
 
     def on_hit(self, cache_snapshot, obj):
         """
-        Hit processing:
-        - Increment TinyLFU.
-        - W hit: refresh or conservatively promote if sufficiently hot.
-        - M1 hit: promote to M2.
-        - M2 hit: refresh in M2.
-        - If untracked but hit (desync): treat as warm and place into M2.
+        Hit processing (resident):
+        - TinyLFU increment.
+        - If in T1: promote to T2.
+        - If in T2: refresh MRU.
+        - Remove from ghosts if present.
         """
         self._ensure_capacity(cache_snapshot.capacity)
-        now = cache_snapshot.access_count
+        self._self_heal(cache_snapshot)
+
         key = obj.key
         self.sketch.increment(key, 1)
 
-        # Any hit resets the ongoing miss streak and cools down scan bias
-        self.miss_streak = 0
-        if self.scan_cooldown > 0:
-            self.scan_cooldown -= 1
-
-        if key in self.W:
-            self.hits_w += 1
-            # Early promotion if strongly frequent to avoid window churn
-            est = self.sketch.estimate(key)
-            thr = 4 if self.scan_cooldown > 0 else 3
-            if est >= thr:
-                # Move from window to protected
-                self.W.pop(key, None)
-                self._touch(self.M2, key)
-                # Keep protected region within target using frequency-aware demotion
-                _, _, prot_tgt = self._targets()
-                if len(self.M2) > prot_tgt:
-                    demote = self._sample_lru_min_freq(self.M2)
-                    if demote is not None:
-                        self.M2.pop(demote, None)
-                        self._touch(self.M1, demote)
-            else:
-                self._touch(self.W, key)
-            self._maybe_tune(now)
+        # Ghost hygiene: remove resident key from ghosts
+        self.B1.pop(key, None)
+        self.B2.pop(key, None)
+
+        if key in self.T2:
+            # Refresh MRU
+            self.T2.move_to_end(key, last=True)
             return
 
-        if key in self.M1:
-            self.hits_main += 1
-            # Promote to protected
-            self.M1.pop(key, None)
-            self._touch(self.M2, key)
-            # Rebalance protected size if needed (freq-aware demotion)
-            _, _, prot_tgt = self._targets()
-            if len(self.M2) > prot_tgt:
-                demote = self._sample_lru_min_freq(self.M2)
-                if demote is not None:
-                    self.M2.pop(demote, None)
-                    self._touch(self.M1, demote)
-            self._maybe_tune(now)
+        if key in self.T1:
+            # Promote to T2
+            self.T1.pop(key, None)
+            self.T2[key] = None
             return
 
-        if key in self.M2:
-            self.hits_main += 1
-            self._touch(self.M2, key)
-            self._maybe_tune(now)
-            return
-
-        # Desync: assume it's warm
-        self.hits_main += 1
-        self._touch(self.M2, key)
-        _, _, prot_tgt = self._targets()
-        if len(self.M2) > prot_tgt:
-            demote = self._sample_lru_min_freq(self.M2)
-            if demote is not None:
-                self.M2.pop(demote, None)
-                self._touch(self.M1, demote)
-        self._maybe_tune(now)
+        # Defensive: hit but not tracked; treat as protected touch
+        self.T2[key] = None
 
     def on_insert(self, cache_snapshot, obj):
         """
-        Insert (on miss) processing:
-        - Increment TinyLFU.
-        - Insert new key into window W (MRU).
-        - If W exceeds target, consider TinyLFU-gated move of W's LRU to M1.
-        - Keep protected region within target by demoting its LRU to M1 if needed.
-        - Maintain scan detector state.
+        Insert (miss) processing:
+        - TinyLFU increment.
+        - If key in B1: increase p, move to T2 (recency helpful).
+        - If key in B2: decrease p, move to T2 (frequency helpful).
+        - Else: insert into T1.
+        - Maintain ghost bounds.
         """
         self._ensure_capacity(cache_snapshot.capacity)
-        now = cache_snapshot.access_count
+        self._self_heal(cache_snapshot)
+
         key = obj.key
         self.sketch.increment(key, 1)
 
-        # Update scan detector: count consecutive misses
-        self.miss_streak += 1
-        if self.miss_streak > (self.capacity or 1):
-            # Enter/extend scan-biased cooldown
-            self.scan_cooldown = max(self.scan_cooldown, self.capacity or 1)
+        # Remove any stale resident placement
+        self.T1.pop(key, None)
+        self.T2.pop(key, None)
+
+        if key in self.B1:
+            # Recency useful: raise p, move to T2
+            self._adapt_p(toward_recency=True)
+            self.B1.pop(key, None)
+            self.T2[key] = None
+        elif key in self.B2:
+            # Frequency useful: lower p, move to T2
+            self._adapt_p(toward_recency=False)
+            self.B2.pop(key, None)
+            self.T2[key] = None
         else:
-            # Gradually cool down if not clearly scanning
-            if self.scan_cooldown > 0:
-                self.scan_cooldown -= 1
-
-        # Ensure it's not tracked elsewhere
-        self.W.pop(key, None)
-        self.M1.pop(key, None)
-        self.M2.pop(key, None)
-
-        # Insert into window
-        self._touch(self.W, key)
-
-        # Rebalance: if W is beyond target, TinyLFU-gated move of W's LRU to M1 (admission path)
-        w_tgt, _, prot_tgt = self._targets()
-        if len(self.W) > w_tgt:
-            w_lru = self._lru(self.W)
-            if w_lru is not None and w_lru != key:
-                cand_m1 = self._sample_lru_min_freq(self.M1)
-                f_w = self.sketch.estimate(w_lru)
-                f_m1 = self.sketch.estimate(cand_m1) if cand_m1 is not None else -1
-                bias = 3 if self.scan_cooldown > 0 else 1
-                if f_w >= (f_m1 + bias):
-                    # Admit into probationary
-                    self.W.pop(w_lru, None)
-                    self._touch(self.M1, w_lru)
-                else:
-                    # Keep in window; refresh to MRU to avoid immediate churn
-                    self._touch(self.W, w_lru)
-
-        # Keep protected region within target (freq-aware demotion)
-        if len(self.M2) > prot_tgt:
-            demote = self._sample_lru_min_freq(self.M2)
-            if demote is not None:
-                self.M2.pop(demote, None)
-                self._touch(self.M1, demote)
-
-        # Periodically tune window size
-        self._maybe_tune(now)
+            # New item: place in T1 (probationary)
+            self.T1[key] = None
+
+        # Ghost bounds after resident insertions
+        self._bound_ghosts()
 
     def on_evict(self, cache_snapshot, obj, evicted_obj):
         """
         Eviction post-processing:
-        - Remove evicted key from whichever segment it resides in.
+        - Move victim key from its resident list to the corresponding ghost list.
+        - Keep ghosts within capacity and clear pending marker.
         """
         self._ensure_capacity(cache_snapshot.capacity)
-        k = evicted_obj.key
-        self.W.pop(k, None)
-        self.M1.pop(k, None)
-        self.M2.pop(k, None)
+        key = evicted_obj.key
+
+        origin = None
+        if self._pending_evict and self._pending_evict[0] == key:
+            origin = self._pending_evict[1]
+        # Clear pending marker regardless
+        self._pending_evict = None
+
+        # Remove from resident lists (robust to unexpected states)
+        in_t1 = key in self.T1
+        in_t2 = key in self.T2
+        if origin is None:
+            if in_t1:
+                origin = "T1"
+            elif in_t2:
+                origin = "T2"
+            else:
+                # Unknown: assume T1 to avoid over-protecting T2
+                origin = "T1"
+
+        if in_t1:
+            self.T1.pop(key, None)
+        if in_t2:
+            self.T2.pop(key, None)
+
+        # Insert into corresponding ghost list MRU
+        if origin == "T1":
+            self.B1.pop(key, None)
+            self.B1[key] = None
+        else:
+            self.B2.pop(key, None)
+            self.B2[key] = None
+
+        # Bound ghosts
+        self._bound_ghosts()
 
 
 # Single policy instance reused across calls
-_policy = _WTinyLFUPolicy()
+_policy = _ARCTinyLFU()
 
 
 def evict(cache_snapshot, obj):
     """
     Choose eviction victim key for the incoming obj.
     """
     return _policy.choose_victim(cache_snapshot, obj)
 
 
 def update_after_hit(cache_snapshot, obj):
     """
     Update policy state after a cache hit on obj.
     """
     _policy.on_hit(cache_snapshot, obj)
 
 
 def update_after_insert(cache_snapshot, obj):
     """
     Update policy state after a new obj is inserted into the cache.
     """
     _policy.on_insert(cache_snapshot, obj)
 
 
 def update_after_evict(cache_snapshot, obj, evicted_obj):
     """
     Update policy state after evicting evicted_obj to make room for obj.
     """
     _policy.on_evict(cache_snapshot, obj, evicted_obj)
 
 # EVOLVE-BLOCK-END
 
 # This part remains fixed (not evolved)
 def run_caching(trace_path: str, copy_code_dst: str):
     """Run the caching algorithm on a trace"""
     import os
     with open(os.path.abspath(__file__), 'r', encoding="utf-8") as f:
         code_str = f.read()
     with open(os.path.join(copy_code_dst), 'w') as f:
         f.write(code_str)
     from cache_utils import Cache, CacheConfig, CacheObj, Trace
     trace = Trace(trace_path=trace_path)
     cache_capacity = max(int(trace.get_ndv() * 0.1), 1)
     cache = Cache(CacheConfig(cache_capacity))
     for entry in trace.entries:
         obj = CacheObj(key=str(entry.key))
         cache.get(obj)
     with open(copy_code_dst, 'w') as f:
         f.write("")
     hit_rate = round(cache.hit_count / cache.access_count, 6)
     return hit_rate