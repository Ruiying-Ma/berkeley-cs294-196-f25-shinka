--- a/original.py
+++ b/original.py
@@ -1,79 +1,182 @@
 # EVOLVE-BLOCK-START
 """Cache eviction algorithm for optimizing hit rates across multiple workloads"""
 
-m_key_timestamp = dict()
+from collections import OrderedDict
+
+# Segmented LRU with LFU bias:
+# - probation: new/cold entries, LRU ordered
+# - protected: hot/promoted entries, LRU ordered
+# - m_freq: frequency count used to bias eviction within probation
+m_probation = OrderedDict()
+m_protected = OrderedDict()
+m_freq = dict()
+_m_last_seen_access = -1  # detect new traces to reset metadata
+
+
+def _reset_if_new_run(cache_snapshot):
+    """Reset metadata when a new trace/cache run starts."""
+    global m_probation, m_protected, m_freq, _m_last_seen_access
+    # New run if access counter restarts or at very beginning
+    if cache_snapshot.access_count <= 1 or _m_last_seen_access > cache_snapshot.access_count:
+        m_probation.clear()
+        m_protected.clear()
+        m_freq.clear()
+    _m_last_seen_access = cache_snapshot.access_count
+
+
+def _prune_metadata(cache_snapshot):
+    """Keep metadata consistent with actual cache content."""
+    cache_keys = cache_snapshot.cache.keys()
+    for seg in (m_probation, m_protected):
+        to_del = [k for k in seg.keys() if k not in cache_keys]
+        for k in to_del:
+            seg.pop(k, None)
+
+
+def _protected_target_size(cache_snapshot):
+    """Aim to keep most entries protected while leaving room in probation."""
+    cap = max(int(cache_snapshot.capacity), 1)
+    return max(1, int(cap * 0.8))
+
 
 def evict(cache_snapshot, obj):
     '''
     This function defines how the algorithm chooses the eviction victim.
     - Args:
         - `cache_snapshot`: A snapshot of the current cache state.
         - `obj`: The new object that needs to be inserted into the cache.
     - Return:
         - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
     '''
+    global m_probation, m_protected, m_freq
+    _reset_if_new_run(cache_snapshot)
+    _prune_metadata(cache_snapshot)
+
+    # Seed metadata if empty by placing all current cache keys into probation.
+    if not m_probation and not m_protected and cache_snapshot.cache:
+        for k in cache_snapshot.cache.keys():
+            m_probation[k] = None
+
     candid_obj_key = None
-    min_ts = min(m_key_timestamp.values())
-    candid_obj_keys = list(key for key in cache_snapshot.cache if m_key_timestamp[key] == min_ts)
-    candid_obj_key = candid_obj_keys[0]
+    if m_probation:
+        # Evict the least frequent in probation; tie-broken by LRU order.
+        min_freq = None
+        for k in m_probation.keys():
+            f = m_freq.get(k, 0)
+            if min_freq is None or f < min_freq:
+                min_freq = f
+                candid_obj_key = k
+                if min_freq == 0:
+                    break
+        if candid_obj_key is None:
+            candid_obj_key = next(iter(m_probation))  # fallback to LRU
+    elif m_protected:
+        candid_obj_key = next(iter(m_protected))  # LRU from protected if probation empty
+    else:
+        # Fallback: choose any key from the cache
+        for k in cache_snapshot.cache.keys():
+            candid_obj_key = k
+            break
     return candid_obj_key
+
 
 def update_after_hit(cache_snapshot, obj):
     '''
     This function defines how the algorithm update the metadata it maintains immediately after a cache hit.
     - Args:
         - `cache_snapshot`: A snapshot of the current cache state.
         - `obj`: The object accessed during the cache hit.
     - Return: `None`
     '''
-    global m_key_timestamp
-    assert obj.key in m_key_timestamp
-    m_key_timestamp[obj.key] = cache_snapshot.access_count
+    global m_probation, m_protected, m_freq
+    _reset_if_new_run(cache_snapshot)
+    _prune_metadata(cache_snapshot)
+
+    k = obj.key
+    # Bump frequency
+    m_freq[k] = m_freq.get(k, 0) + 1
+
+    if k in m_protected:
+        # Refresh recency in protected
+        m_protected.move_to_end(k, last=True)
+    elif k in m_probation:
+        # Promote to protected on first hit
+        m_probation.pop(k, None)
+        m_protected[k] = None
+    else:
+        # Metadata miss but cache hit: treat as hot and place into protected
+        m_protected[k] = None
+
+    # Keep protected around its target size; demote LRU if it grows too large.
+    target = _protected_target_size(cache_snapshot)
+    if len(m_protected) > target:
+        demote_k, _ = m_protected.popitem(last=False)  # LRU of protected
+        m_probation[demote_k] = None
+
 
 def update_after_insert(cache_snapshot, obj):
     '''
     This function defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
     - Args:
         - `cache_snapshot`: A snapshot of the current cache state.
         - `obj`: The object that was just inserted into the cache.
     - Return: `None`
     '''
-    global m_key_timestamp
-    assert obj.key not in m_key_timestamp
-    m_key_timestamp[obj.key] = cache_snapshot.access_count
+    global m_probation, m_protected, m_freq
+    _reset_if_new_run(cache_snapshot)
+    _prune_metadata(cache_snapshot)
+
+    k = obj.key
+    # New items start in probation (to filter one-hit wonders)
+    if k in m_protected:
+        m_protected.pop(k, None)
+    if k in m_probation:
+        m_probation.pop(k, None)
+    m_probation[k] = None
+
+    # Give a small initial credit to favor quick repeats
+    m_freq[k] = m_freq.get(k, 0) + 1
+
+    # Ensure protected doesn't monopolize space
+    target = _protected_target_size(cache_snapshot)
+    while len(m_protected) > target:
+        demote_k, _ = m_protected.popitem(last=False)
+        m_probation[demote_k] = None
+
 
 def update_after_evict(cache_snapshot, obj, evicted_obj):
     '''
     This function defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
     - Args:
         - `cache_snapshot`: A snapshot of the current cache state.
         - `obj`: The object to be inserted into the cache.
         - `evicted_obj`: The object that was just evicted from the cache.
     - Return: `None`
     '''
-    global m_key_timestamp
-    assert obj.key not in m_key_timestamp
-    assert evicted_obj.key in m_key_timestamp
-    m_key_timestamp.pop(evicted_obj.key)
+    global m_probation, m_protected, m_freq
+    _reset_if_new_run(cache_snapshot)
+    # Remove evicted object from segments; retain frequency for long-term bias.
+    m_probation.pop(evicted_obj.key, None)
+    m_protected.pop(evicted_obj.key, None)
 
 # EVOLVE-BLOCK-END
 
 # This part remains fixed (not evolved)
 def run_caching(trace_path: str, copy_code_dst: str):
     """Run the caching algorithm on a trace"""
     import os
     with open(os.path.abspath(__file__), 'r', encoding="utf-8") as f:
         code_str = f.read()
     with open(os.path.join(copy_code_dst), 'w') as f:
         f.write(code_str)
     from cache_utils import Cache, CacheConfig, CacheObj, Trace
     trace = Trace(trace_path=trace_path)
     cache_capacity = max(int(trace.get_ndv() * 0.1), 1)
     cache = Cache(CacheConfig(cache_capacity))
     for entry in trace.entries:
         obj = CacheObj(key=str(entry.key))
         cache.get(obj)
     with open(copy_code_dst, 'w') as f:
         f.write("")
     hit_rate = round(cache.hit_count / cache.access_count, 6)
     return hit_rate