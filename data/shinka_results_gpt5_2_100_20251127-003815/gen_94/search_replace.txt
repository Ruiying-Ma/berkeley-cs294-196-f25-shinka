<NAME>
arc_tiny_lfu_dual_sampler_recency_tiebreak
</NAME>

<DESCRIPTION>
I introduce three synergistic improvements to reduce miss rate, based on known best practices from ARC/W-TinyLFU hybrids:

1) Dual-tail victim sampling with protected bias:
   - Instead of strictly following ARC’s replace decision, we sample candidates from both T1 and T2 tails and choose the eviction victim using TinyLFU frequency, applying a +1 bias to make it harder to evict from T2. This keeps truly hot items protected while still allowing removal of stale/low-frequency items that leak into T2.

2) Recency tie-breaker via lightweight last_touch timestamps:
   - Store a last_touch timestamp per resident key (using cache_snapshot.access_count). In victim sampling, if TinyLFU estimates tie, evict the older one. This helps avoid evicting recently touched items when frequencies are comparable.

3) Conservative direct admission to protected (T2) for very hot misses:
   - On a miss, if the new item’s TinyLFU estimate exceeds the sampled T2 tail by a margin (≥2), admit it directly to T2; otherwise put it in T1. This accelerates warming for items that are provably hot without over-polluting protected space.

Additionally, I slightly increase the sampling window k with capacity to improve selection quality, and ensure last_touch bookkeeping is consistent across capacity changes, self-heal, hits, inserts, and evictions. Together, these changes reduce churn on scans, better protect hot sets, and react faster to phase shifts, leading to lower miss rates across diverse traces.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    __slots__ = (
        "T1", "T2", "B1", "B2",
        "capacity", "p", "ema_alpha",
        "sketch", "_sample_k", "_pending_evict"
    )
=======
    __slots__ = (
        "T1", "T2", "B1", "B2",
        "capacity", "p", "ema_alpha",
        "sketch", "_sample_k", "_pending_evict",
        "last_touch"
    )
>>>>>>> REPLACE

</DIFF>

<DIFF>
<<<<<<< SEARCH
    def __init__(self):
        self.T1 = OrderedDict()
        self.T2 = OrderedDict()
        self.B1 = OrderedDict()
        self.B2 = OrderedDict()
        self.capacity = None
        self.p = 0.0
        self.ema_alpha = 0.25
        self.sketch = _CmSketch(width_power=12, d=3)
        self._sample_k = 6
        self._pending_evict = None  # (key, from_list: "T1"|"T2")
=======
    def __init__(self):
        self.T1 = OrderedDict()
        self.T2 = OrderedDict()
        self.B1 = OrderedDict()
        self.B2 = OrderedDict()
        self.capacity = None
        self.p = 0.0
        self.ema_alpha = 0.25
        self.sketch = _CmSketch(width_power=12, d=3)
        self._sample_k = 6
        self._pending_evict = None  # (key, from_list: "T1"|"T2")
        self.last_touch = {}
>>>>>>> REPLACE

</DIFF>

<DIFF>
<<<<<<< SEARCH
    def _ensure_capacity(self, cap: int):
        cap = max(int(cap), 1)
        if self.capacity is None:
            self.capacity = cap
            self.p = min(float(cap), max(0.0, cap * 0.25))
            self._sample_k = max(4, min(8, (cap // 8) or 4))
            try:
                self.sketch.age_period = max(512, min(16384, cap * 8))
            except Exception:
                pass
            return
        if self.capacity != cap:
            # Reset lists to avoid desync on capacity changes
            self.T1.clear(); self.T2.clear(); self.B1.clear(); self.B2.clear()
            self.capacity = cap
            self.p = min(float(cap), max(0.0, cap * 0.25))
            self._sample_k = max(4, min(8, (cap // 8) or 4))
            try:
                self.sketch.age_period = max(512, min(16384, cap * 8))
            except Exception:
                pass
            self._pending_evict = None
=======
    def _ensure_capacity(self, cap: int):
        cap = max(int(cap), 1)
        if self.capacity is None:
            self.capacity = cap
            self.p = min(float(cap), max(0.0, cap * 0.25))
            # Slightly larger sampling window for better candidate quality
            self._sample_k = max(6, min(12, (cap // 6) or 6))
            try:
                self.sketch.age_period = max(512, min(16384, cap * 8))
            except Exception:
                pass
            return
        if self.capacity != cap:
            # Reset lists to avoid desync on capacity changes
            self.T1.clear(); self.T2.clear(); self.B1.clear(); self.B2.clear()
            self.capacity = cap
            self.p = min(float(cap), max(0.0, cap * 0.25))
            self._sample_k = max(6, min(12, (cap // 6) or 6))
            try:
                self.sketch.age_period = max(512, min(16384, cap * 8))
            except Exception:
                pass
            self._pending_evict = None
            self.last_touch.clear()
>>>>>>> REPLACE

</DIFF>

<DIFF>
<<<<<<< SEARCH
    def _self_heal(self, cache_snapshot):
        """
        Ensure resident lists match cache contents; never allow ghosts to contain resident keys.
        """
        current = self._current_keys(cache_snapshot)
        # Purge non-resident from T1/T2
        for od in (self.T1, self.T2):
            for k in list(od.keys()):
                if k not in current:
                    od.pop(k, None)
        # Remove any resident from ghosts (ghost hygiene)
        for k in list(self.B1.keys()):
            if k in current:
                self.B1.pop(k, None)
        for k in list(self.B2.keys()):
            if k in current:
                self.B2.pop(k, None)
        # Add any missing residents into T1 (conservative)
        tracked = set(self.T1.keys()) | set(self.T2.keys())
        missing = current - tracked
        if missing:
            for k in missing:
                self.T1[k] = None

        # Bound ghost history: |B1| + |B2| <= C
        self._bound_ghosts()
=======
    def _self_heal(self, cache_snapshot):
        """
        Ensure resident lists match cache contents; never allow ghosts to contain resident keys.
        """
        current = self._current_keys(cache_snapshot)
        # Purge non-resident from T1/T2 and drop timestamps
        for od in (self.T1, self.T2):
            for k in list(od.keys()):
                if k not in current:
                    od.pop(k, None)
                    self.last_touch.pop(k, None)
        # Remove any resident from ghosts (ghost hygiene)
        for k in list(self.B1.keys()):
            if k in current:
                self.B1.pop(k, None)
        for k in list(self.B2.keys()):
            if k in current:
                self.B2.pop(k, None)
        # Add any missing residents into T1 (conservative) and set touch time
        tracked = set(self.T1.keys()) | set(self.T2.keys())
        missing = current - tracked
        if missing:
            for k in missing:
                self.T1[k] = None
                self.last_touch[k] = cache_snapshot.access_count

        # Bound ghost history: |B1| + |B2| <= C
        self._bound_ghosts()
>>>>>>> REPLACE

</DIFF>

<DIFF>
<<<<<<< SEARCH
    def _sample_victim(self, od: OrderedDict) -> str:
        """
        Sample up to k LRU-side keys from 'od' and choose the one with the lowest TinyLFU estimate.
        Falls back to pure LRU if estimates tie or not enough candidates.
        """
        if not od:
            return None
        k = min(self._sample_k, len(od))
        it = iter(od.keys())  # from LRU to MRU
        chosen = None
        chosen_f = None
        # Prefer low-frequency among the k LRU-end candidates
        for _ in range(k):
            key = next(it)
            f = self.sketch.estimate(key)
            if chosen_f is None or f < chosen_f:
                chosen_f = f
                chosen = key
        return chosen if chosen is not None else next(iter(od))
=======
    def _sample_victim(self, od: OrderedDict) -> str:
        """
        Sample up to k LRU-side keys from 'od' and choose the one with the lowest TinyLFU estimate.
        Tie-break by older last_touch to avoid evicting recently used items when frequencies tie.
        Falls back to pure LRU if no candidate found.
        """
        if not od:
            return None
        k = min(self._sample_k, len(od))
        it = iter(od.keys())  # from LRU to MRU
        chosen = None
        chosen_f = None
        chosen_lt = None
        # Prefer low-frequency among the k LRU-end candidates; tie-break by older last_touch
        for _ in range(k):
            try:
                key = next(it)
            except StopIteration:
                break
            f = self.sketch.estimate(key)
            lt = self.last_touch.get(key, 0)
            if chosen_f is None or f < chosen_f or (f == chosen_f and lt < chosen_lt):
                chosen_f = f
                chosen_lt = lt
                chosen = key
        return chosen if chosen is not None else next(iter(od))
>>>>>>> REPLACE

</DIFF>

<DIFF>
<<<<<<< SEARCH
    def choose_victim(self, cache_snapshot, new_obj) -> str:
        """
        ARC replace decision with frequency-guided victim sampling:
        - If |T1| > p or (|T1| == p and new_obj in B2): evict from T1 (LRU-side).
        - Else: evict from T2 (LRU-side).
        Within the chosen list, sample k LRU-side candidates and pick the one with
        the lowest TinyLFU estimate.
        """
        self._ensure_capacity(cache_snapshot.capacity)
        self._self_heal(cache_snapshot)

        # Determine which list to evict from according to ARC replace
        t1_len = len(self.T1)
        p_int = int(self.p)  # use floor
        new_in_b2 = new_obj.key in self.B2

        evict_from_T1 = False
        if t1_len > p_int or (new_in_b2 and t1_len == p_int and t1_len > 0):
            evict_from_T1 = True

        # Choose a victim using TinyLFU sampling
        if evict_from_T1 and self.T1:
            victim = self._sample_victim(self.T1)
            self._pending_evict = (victim, "T1")
            return victim
        if (not evict_from_T1) and self.T2:
            victim = self._sample_victim(self.T2)
            self._pending_evict = (victim, "T2")
            return victim

        # Fallbacks if one list is empty
        if self.T1:
            victim = self._sample_victim(self.T1)
            self._pending_evict = (victim, "T1")
            return victim
        if self.T2:
            victim = self._sample_victim(self.T2)
            self._pending_evict = (victim, "T2")
            return victim

        # Last resort: any key from cache
        any_key = next(iter(cache_snapshot.cache))
        # Unknown origin; default to T1
        self._pending_evict = (any_key, "T1")
        return any_key
=======
    def choose_victim(self, cache_snapshot, new_obj) -> str:
        """
        ARC replace decision with dual-list TinyLFU sampling and protected bias:
        - ARC decide preferred list (T1 vs T2) based on p and ghost state.
        - Sample k LRU-side candidates from both lists (if available) and consider frequency and recency.
        - Apply +1 bias to T2 so it's harder to evict protected items.
        """
        self._ensure_capacity(cache_snapshot.capacity)
        self._self_heal(cache_snapshot)

        # Determine preferred list per ARC replace
        t1_len = len(self.T1)
        p_int = int(self.p)  # use floor
        new_in_b2 = new_obj.key in self.B2

        evict_from_T1 = False
        if t1_len > p_int or (new_in_b2 and t1_len == p_int and t1_len > 0):
            evict_from_T1 = True

        # Sample candidates
        cand_t1 = self._sample_victim(self.T1) if self.T1 else None
        cand_t2 = self._sample_victim(self.T2) if self.T2 else None
        f_t1 = self.sketch.estimate(cand_t1) if cand_t1 is not None else None
        f_t2 = self.sketch.estimate(cand_t2) if cand_t2 is not None else None
        lt_t1 = self.last_touch.get(cand_t1, 0) if cand_t1 is not None else None
        lt_t2 = self.last_touch.get(cand_t2, 0) if cand_t2 is not None else None

        # Decide victim using ARC preference with dual sampling and bias to protect T2
        if evict_from_T1:
            if cand_t1 is None and cand_t2 is not None:
                victim, origin = cand_t2, "T2"
            elif cand_t1 is not None and cand_t2 is None:
                victim, origin = cand_t1, "T1"
            elif cand_t1 is not None and cand_t2 is not None:
                # Evict from T2 only if it's clearly colder: f_t2 + 1 < f_t1 (bias +1)
                if (f_t2 + 1) < f_t1 or ((f_t2 + 1) == f_t1 and lt_t2 < lt_t1):
                    victim, origin = cand_t2, "T2"
                else:
                    victim, origin = cand_t1, "T1"
            else:
                victim, origin = None, None
        else:
            if cand_t2 is None and cand_t1 is not None:
                victim, origin = cand_t1, "T1"
            elif cand_t2 is not None and cand_t1 is None:
                victim, origin = cand_t2, "T2"
            elif cand_t1 is not None and cand_t2 is not None:
                # Prefer T2 per ARC; but if T1 candidate is strictly colder, evict T1
                if (f_t1 < f_t2) or (f_t1 == f_t2 and lt_t1 < lt_t2):
                    victim, origin = cand_t1, "T1"
                else:
                    victim, origin = cand_t2, "T2"
            else:
                victim, origin = None, None

        if victim is not None:
            self._pending_evict = (victim, origin)
            return victim

        # Fallbacks if both lists empty: any key from cache
        any_key = next(iter(cache_snapshot.cache))
        # Unknown origin; default to T1
        self._pending_evict = (any_key, "T1")
        return any_key
>>>>>>> REPLACE

</DIFF>

<DIFF>
<<<<<<< SEARCH
    def on_hit(self, cache_snapshot, obj):
        """
        Hit processing (resident):
        - TinyLFU increment.
        - If in T1: promote to T2.
        - If in T2: refresh MRU.
        - Remove from ghosts if present.
        """
        self._ensure_capacity(cache_snapshot.capacity)
        self._self_heal(cache_snapshot)

        key = obj.key
        self.sketch.increment(key, 1)

        # Ghost hygiene: remove resident key from ghosts
        self.B1.pop(key, None)
        self.B2.pop(key, None)

        if key in self.T2:
            # Refresh MRU
            self.T2.move_to_end(key, last=True)
            return

        if key in self.T1:
            # Promote to T2
            self.T1.pop(key, None)
            self.T2[key] = None
            return

        # Defensive: hit but not tracked; treat as protected touch
        self.T2[key] = None
=======
    def on_hit(self, cache_snapshot, obj):
        """
        Hit processing (resident):
        - TinyLFU increment.
        - If in T1: promote to T2.
        - If in T2: refresh MRU.
        - Remove from ghosts if present.
        - Update last_touch timestamp for recency tie-breakers.
        """
        self._ensure_capacity(cache_snapshot.capacity)
        self._self_heal(cache_snapshot)

        key = obj.key
        self.sketch.increment(key, 1)

        # Ghost hygiene: remove resident key from ghosts
        self.B1.pop(key, None)
        self.B2.pop(key, None)

        # Update recency
        self.last_touch[key] = cache_snapshot.access_count

        if key in self.T2:
            # Refresh MRU
            self.T2.move_to_end(key, last=True)
            return

        if key in self.T1:
            # Promote to T2
            self.T1.pop(key, None)
            self.T2[key] = None
            return

        # Defensive: hit but not tracked; treat as protected touch
        self.T2[key] = None
>>>>>>> REPLACE

</DIFF>

<DIFF>
<<<<<<< SEARCH
    def on_insert(self, cache_snapshot, obj):
        """
        Insert (miss) processing:
        - TinyLFU increment.
        - If key in B1: increase p, move to T2 (recency helpful).
        - If key in B2: decrease p, move to T2 (frequency helpful).
        - Else: insert into T1.
        - Maintain ghost bounds.
        """
        self._ensure_capacity(cache_snapshot.capacity)
        self._self_heal(cache_snapshot)

        key = obj.key
        self.sketch.increment(key, 1)

        # Remove any stale resident placement
        self.T1.pop(key, None)
        self.T2.pop(key, None)

        if key in self.B1:
            # Recency useful: raise p, move to T2
            self._adapt_p(toward_recency=True)
            self.B1.pop(key, None)
            self.T2[key] = None
        elif key in self.B2:
            # Frequency useful: lower p, move to T2
            self._adapt_p(toward_recency=False)
            self.B2.pop(key, None)
            self.T2[key] = None
        else:
            # New item: place in T1 (probationary)
            self.T1[key] = None

        # Ghost bounds after resident insertions
        self._bound_ghosts()
=======
    def on_insert(self, cache_snapshot, obj):
        """
        Insert (miss) processing:
        - TinyLFU increment.
        - If key in B1: increase p, move to T2 (recency helpful).
        - If key in B2: decrease p, move to T2 (frequency helpful).
        - Else: insert into T1 by default, but allow conservative direct admission to T2
          if the new key's TinyLFU estimate is >= sampled T2-tail estimate + 2.
        - Maintain ghost bounds.
        - Update last_touch timestamp.
        """
        self._ensure_capacity(cache_snapshot.capacity)
        self._self_heal(cache_snapshot)

        key = obj.key
        self.sketch.increment(key, 1)

        # Remove any stale resident placement
        self.T1.pop(key, None)
        self.T2.pop(key, None)

        placed_in_T2 = False

        if key in self.B1:
            # Recency useful: raise p, move to T2
            self._adapt_p(toward_recency=True)
            self.B1.pop(key, None)
            self.T2[key] = None
            placed_in_T2 = True
        elif key in self.B2:
            # Frequency useful: lower p, move to T2
            self._adapt_p(toward_recency=False)
            self.B2.pop(key, None)
            self.T2[key] = None
            placed_in_T2 = True
        else:
            # New item: conservative direct admission for very hot keys
            f_new = self.sketch.estimate(key)
            if self.T2:
                t2_cand = self._sample_victim(self.T2)
                f_t2 = self.sketch.estimate(t2_cand) if t2_cand is not None else (1 << 30)
            else:
                f_t2 = 1 << 30
            if f_new >= (f_t2 + 2):
                self.T2[key] = None
                placed_in_T2 = True
            else:
                # Default probationary insert
                self.T1[key] = None

        # Update recency
        self.last_touch[key] = cache_snapshot.access_count

        # Ghost bounds after resident insertions
        self._bound_ghosts()
>>>>>>> REPLACE

</DIFF>

<DIFF>
<<<<<<< SEARCH
    def on_evict(self, cache_snapshot, obj, evicted_obj):
        """
        Eviction post-processing:
        - Move victim key from its resident list to the corresponding ghost list.
        - Keep ghosts within capacity and clear pending marker.
        """
        self._ensure_capacity(cache_snapshot.capacity)
        key = evicted_obj.key

        origin = None
        if self._pending_evict and self._pending_evict[0] == key:
            origin = self._pending_evict[1]
        # Clear pending marker regardless
        self._pending_evict = None

        # Remove from resident lists (robust to unexpected states)
        in_t1 = key in self.T1
        in_t2 = key in self.T2
        if origin is None:
            if in_t1:
                origin = "T1"
            elif in_t2:
                origin = "T2"
            else:
                # Unknown: assume T1 to avoid over-protecting T2
                origin = "T1"

        if in_t1:
            self.T1.pop(key, None)
        if in_t2:
            self.T2.pop(key, None)

        # Insert into corresponding ghost list MRU
        if origin == "T1":
            self.B1.pop(key, None)
            self.B1[key] = None
        else:
            self.B2.pop(key, None)
            self.B2[key] = None

        # Bound ghosts
        self._bound_ghosts()
=======
    def on_evict(self, cache_snapshot, obj, evicted_obj):
        """
        Eviction post-processing:
        - Move victim key from its resident list to the corresponding ghost list.
        - Keep ghosts within capacity and clear pending marker.
        - Drop last_touch for evicted key to limit metadata growth.
        """
        self._ensure_capacity(cache_snapshot.capacity)
        key = evicted_obj.key

        origin = None
        if self._pending_evict and self._pending_evict[0] == key:
            origin = self._pending_evict[1]
        # Clear pending marker regardless
        self._pending_evict = None

        # Remove from resident lists (robust to unexpected states)
        in_t1 = key in self.T1
        in_t2 = key in self.T2
        if origin is None:
            if in_t1:
                origin = "T1"
            elif in_t2:
                origin = "T2"
            else:
                # Unknown: assume T1 to avoid over-protecting T2
                origin = "T1"

        if in_t1:
            self.T1.pop(key, None)
        if in_t2:
            self.T2.pop(key, None)

        # Insert into corresponding ghost list MRU
        if origin == "T1":
            self.B1.pop(key, None)
            self.B1[key] = None
        else:
            self.B2.pop(key, None)
            self.B2[key] = None

        # Bound ghosts
        self._bound_ghosts()

        # Drop timestamp for non-resident key
        self.last_touch.pop(key, None)
>>>>>>> REPLACE

</DIFF>