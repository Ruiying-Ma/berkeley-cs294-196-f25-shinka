<NAME>
tiny_lfu_tail_sampling_and_protected_bias
</NAME>

<DESCRIPTION>
I introduce a lightweight TinyLFU Count-Min Sketch to estimate global (resident and non-resident) frequencies and use it consistently in victim selection, admission, and promotion decisions. The evict function now performs tail sampling in both probationary (T1) and protected (T2) segments and uses a lexicographic comparator based on TinyLFU estimates (with a small bias to protect T2) to choose colder victims. During scans, eviction is biased toward T1 to preserve hot sets.

I also improve update_after_hit and update_after_insert to increment TinyLFU, gate promotions based on estimated frequency, and perform competitive admission against T2â€™s tail candidate. Protected size enforcement demotes the coldest protected candidates (sampled by TinyLFU) instead of strict LRU, reducing churn of emerging hot items.

This brings the policy closer to a competitive Windowed-TinyLFU/ARC hybrid with decayed recency via LRU order and frequency via TinyLFU, which typically lowers miss rates across diverse workloads, especially under bursts and scans.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
m_sample_k = 6
_age_ops = 0
_age_period = 1024
m_miss_streak = 0
=======
m_sample_k = 6
_age_ops = 0
_age_period = 1024
m_miss_streak = 0

# TinyLFU Count-Min Sketch state
m_sketch_w = 0          # width (power-of-two)
m_sketch = []           # list of rows
m_sketch_ops = 0        # ops since last aging
m_sketch_age_period = 0 # aging period (capacity-aware)
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
def _reset_if_new_run(cache_snapshot):
    """Reset metadata when a new trace/cache run starts."""
    global m_probation, m_protected, m_b1, m_b2, m_freq, m_p, _m_last_seen_access, m_sample_k, _age_ops, _age_period, m_miss_streak
    # New run if access counter restarts or at very beginning
    if cache_snapshot.access_count <= 1 or _m_last_seen_access > cache_snapshot.access_count:
        m_probation.clear()
        m_protected.clear()
        m_b1.clear()
        m_b2.clear()
        m_freq.clear()
        m_p = 0
        _age_ops = 0
        m_miss_streak = 0
    # keep aging period and sample size responsive to capacity
    cap = max(int(cache_snapshot.capacity), 1)
    _age_period = max(512, cap * 8)
    m_sample_k = max(4, min(12, (cap // 8) or 4))
    _m_last_seen_access = cache_snapshot.access_count
=======
def _reset_if_new_run(cache_snapshot):
    """Reset metadata when a new trace/cache run starts."""
    global m_probation, m_protected, m_b1, m_b2, m_freq, m_p, _m_last_seen_access, m_sample_k, _age_ops, _age_period, m_miss_streak, m_sketch_w, m_sketch, m_sketch_ops, m_sketch_age_period
    # New run if access counter restarts or at very beginning
    if cache_snapshot.access_count <= 1 or _m_last_seen_access > cache_snapshot.access_count:
        m_probation.clear()
        m_protected.clear()
        m_b1.clear()
        m_b2.clear()
        m_freq.clear()
        m_p = 0
        _age_ops = 0
        m_miss_streak = 0
        # reset TinyLFU sketch
        m_sketch_w = 0
        m_sketch = []
        m_sketch_ops = 0
        m_sketch_age_period = 0
    # keep aging period and sample size responsive to capacity
    cap = max(int(cache_snapshot.capacity), 1)
    _age_period = max(512, cap * 8)
    m_sample_k = max(4, min(12, (cap // 8) or 4))
    _m_last_seen_access = cache_snapshot.access_count
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
def _maybe_age_freq(cache_snapshot):
    """Periodically halve frequency counters to forget stale history."""
    global _age_ops, _age_period, m_freq
    _age_ops += 1
    if _age_ops % max(1, _age_period) == 0:
        for k in list(m_freq.keys()):
            v = m_freq.get(k, 0) >> 1
            if v <= 0:
                # keep dictionary small
                m_freq.pop(k, None)
            else:
                m_freq[k] = v
=======
def _maybe_age_freq(cache_snapshot):
    """Periodically halve frequency counters to forget stale history."""
    global _age_ops, _age_period, m_freq
    _age_ops += 1
    if _age_ops % max(1, _age_period) == 0:
        for k in list(m_freq.keys()):
            v = m_freq.get(k, 0) >> 1
            if v <= 0:
                # keep dictionary small
                m_freq.pop(k, None)
            else:
                m_freq[k] = v


# ---- TinyLFU Count-Min Sketch helpers ----

def _ensure_sketch(cache_snapshot):
    """Initialize TinyLFU sketch lazily with capacity-aware width/aging."""
    global m_sketch_w, m_sketch, m_sketch_ops, m_sketch_age_period
    if m_sketch_w:
        return
    cap = max(int(cache_snapshot.capacity), 1)
    target = max(512, 4 * cap)
    w = 1
    while w < target:
        w <<= 1
    m_sketch_w = w
    m_sketch = [[0] * m_sketch_w for _ in range(3)]
    m_sketch_ops = 0
    # Age period within [4C,16C], use 8C mid by default
    m_sketch_age_period = max(4 * cap, min(16 * cap, 8 * cap))


def _sketch_idx(key, i):
    # Simple stable hashing across runs
    return (hash((key, i, 0x9E3779B97F4A7C15)) & (m_sketch_w - 1)) if m_sketch_w else 0


def _sketch_add(cache_snapshot, key, delta=1):
    """Add delta to TinyLFU counts (conservative, saturated at 255)."""
    global m_sketch_ops
    _ensure_sketch(cache_snapshot)
    for i in range(3):
        row = m_sketch[i]
        idx = _sketch_idx(key, i)
        v = row[idx] + delta
        row[idx] = 255 if v > 255 else v
    m_sketch_ops += 1
    if m_sketch_ops >= max(1, m_sketch_age_period):
        # Periodic halving to age out stale history
        for i in range(3):
            row = m_sketch[i]
            for j in range(m_sketch_w):
                row[j] >>= 1
        m_sketch_ops = 0


def _sketch_est(cache_snapshot, key):
    """Estimate count using CM minimum across rows."""
    _ensure_sketch(cache_snapshot)
    est = None
    for i in range(3):
        v = m_sketch[i][_sketch_idx(key, i)]
        est = v if est is None or v < est else est
    return est if est is not None else 0
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
def _sample_lowfreq(od: OrderedDict) -> str:
    """Sample a few keys from the LRU side and pick the lowest-frequency candidate."""
    if not od:
        return None
    k = min(m_sample_k, len(od))
    it = iter(od.keys())  # LRU -> MRU
    best_k = None
    best_f = None
    for _ in range(k):
        key = next(it)
        f = m_freq.get(key, 0)
        if best_f is None or f < best_f:
            best_f = f
            best_k = key
    return best_k if best_k is not None else next(iter(od))
=======
def _sample_lowfreq(cache_snapshot, od: OrderedDict) -> str:
    """Sample a few keys from the LRU side and pick the coldest by (TinyLFU, local freq)."""
    if not od:
        return None
    _ensure_sketch(cache_snapshot)
    k = min(m_sample_k, len(od))
    it = iter(od.keys())  # LRU -> MRU
    best_k = None
    best_tuple = None
    for _ in range(k):
        key = next(it)
        f_est = _sketch_est(cache_snapshot, key)
        f_loc = m_freq.get(key, 0)
        tup = (f_est, f_loc)
        if best_tuple is None or tup < best_tuple:
            best_tuple = tup
            best_k = key
    return best_k if best_k is not None else next(iter(od))
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
def _enforce_protected_target(cache_snapshot):
    """Demote LRU of protected to probation until protected meets its target."""
    target = _protected_target_size(cache_snapshot)
    while len(m_protected) > target:
        demote_k, _ = m_protected.popitem(last=False)  # LRU of protected
        # place demoted key at MRU of probation to avoid immediate eviction
        m_probation[demote_k] = None
        m_probation.move_to_end(demote_k, last=True)
=======
def _enforce_protected_target(cache_snapshot):
    """Demote cold candidates from protected to probation until protected meets its target."""
    target = _protected_target_size(cache_snapshot)
    _ensure_sketch(cache_snapshot)
    while len(m_protected) > target:
        demote_k = _sample_lowfreq(cache_snapshot, m_protected)
        if demote_k is None:
            # fallback to strict LRU if sampling fails
            demote_k, _ = m_protected.popitem(last=False)
        else:
            m_protected.pop(demote_k, None)
        # place demoted key at MRU of probation to avoid immediate eviction
        m_probation[demote_k] = None
        m_probation.move_to_end(demote_k, last=True)
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
def evict(cache_snapshot, obj):
    '''
    This function defines how the algorithm chooses the eviction victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    global m_probation, m_protected, m_b1, m_b2, m_freq, m_p
    _reset_if_new_run(cache_snapshot)
    _prune_metadata(cache_snapshot)

    # Seed metadata if empty by placing all current cache keys into probation.
    if not m_probation and not m_protected and cache_snapshot.cache:
        for k0 in cache_snapshot.cache.keys():
            m_probation[k0] = None

    cap = max(int(cache_snapshot.capacity), 1)
    k = obj.key

    # Scan bias: on long miss streaks, protect T2 by evicting from T1 when possible.
    in_scan = m_miss_streak > cap

    cand_t1 = _sample_lowfreq(m_probation) if m_probation else None
    cand_t2 = _sample_lowfreq(m_protected) if m_protected else None

    if in_scan and cand_t1 is not None:
        return cand_t1

    # ARC rule: if T1 is oversized vs its target p, evict from T1
    if m_probation and ((k in m_b2 and len(m_probation) == m_p) or (len(m_probation) > m_p)):
        return cand_t1 if cand_t1 is not None else (cand_t2 if cand_t2 is not None else next(iter(cache_snapshot.cache)))

    # If only one segment has candidates
    if cand_t1 is None and cand_t2 is not None:
        return cand_t2
    if cand_t2 is None and cand_t1 is not None:
        return cand_t1

    # Both segments have candidates: competitive decision
    if cand_t1 is not None and cand_t2 is not None:
        f_new = m_freq.get(k, 0)
        f_t1 = m_freq.get(cand_t1, 0)
        f_t2 = m_freq.get(cand_t2, 0)
        # If new is clearly hotter than T2's cold candidate, replace from T2; else evict from T1
        if f_new > (f_t2 + 1):
            return cand_t2
        # Otherwise, prefer evicting the colder of the two, defaulting to T1
        return cand_t1 if f_t1 <= f_t2 else cand_t2

    # Fallback: choose any key from the cache
    return next(iter(cache_snapshot.cache))
=======
def evict(cache_snapshot, obj):
    '''
    Choose a victim using TinyLFU-informed tail sampling:
    - Prefer evicting from T1, unless new is clearly hotter than T2's cold candidate.
    - During scans, always pick from T1 if possible to protect hot set.
    - Honor ARC-style pressure: if T1 is oversized vs p, evict from T1.
    '''
    global m_probation, m_protected, m_b1, m_b2, m_p
    _reset_if_new_run(cache_snapshot)
    _prune_metadata(cache_snapshot)
    _ensure_sketch(cache_snapshot)

    # Seed metadata if empty by placing all current cache keys into probation.
    if not m_probation and not m_protected and cache_snapshot.cache:
        for k0 in cache_snapshot.cache.keys():
            m_probation[k0] = None

    cap = max(int(cache_snapshot.capacity), 1)
    k = obj.key

    # Scan bias: on long miss streaks, protect T2 by evicting from T1 when possible.
    in_scan = m_miss_streak > cap

    cand_t1 = _sample_lowfreq(cache_snapshot, m_probation) if m_probation else None
    cand_t2 = _sample_lowfreq(cache_snapshot, m_protected) if m_protected else None

    if in_scan and cand_t1 is not None:
        return cand_t1

    # ARC rule: if T1 is oversized vs its target p, evict from T1
    if m_probation and ((k in m_b2 and len(m_probation) == m_p) or (len(m_probation) > m_p)):
        return cand_t1 if cand_t1 is not None else (cand_t2 if cand_t2 is not None else next(iter(cache_snapshot.cache)))

    # If only one segment has candidates
    if cand_t1 is None and cand_t2 is not None:
        return cand_t2
    if cand_t2 is None and cand_t1 is not None:
        return cand_t1

    # Both segments have candidates: competitive TinyLFU decision with protected bias
    if cand_t1 is not None and cand_t2 is not None:
        f_new = _sketch_est(cache_snapshot, k)
        f_t2 = _sketch_est(cache_snapshot, cand_t2)
        # Only replace from T2 if new is clearly hotter than its cold candidate
        if f_new > (f_t2 + 1):
            return cand_t2
        # otherwise evict from probation
        return cand_t1

    # Fallback: choose any key from the cache
    return next(iter(cache_snapshot.cache))
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the algorithm update the metadata it maintains immediately after a cache hit.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    global m_probation, m_protected, m_b1, m_b2, m_freq, m_miss_streak
    _reset_if_new_run(cache_snapshot)
    _prune_metadata(cache_snapshot)
    _maybe_age_freq(cache_snapshot)

    k = obj.key
    # Bump lightweight frequency
    m_freq[k] = m_freq.get(k, 0) + 1

    # Any hit breaks a miss streak
    m_miss_streak = 0

    if k in m_protected:
        # Refresh recency in protected
        m_protected.move_to_end(k, last=True)
    elif k in m_probation:
        # Gate promotion by current protected pressure and scan bias
        target = _protected_target_size(cache_snapshot)
        cap = max(int(cache_snapshot.capacity), 1)
        in_scan = m_miss_streak > (cap // 2)
        promote_thr = 3 if len(m_protected) >= target else 2
        if in_scan:
            promote_thr += 1
        if m_freq.get(k, 0) >= promote_thr:
            m_probation.pop(k, None)
            m_protected[k] = None
        else:
            # Refresh recency in probation
            m_probation.move_to_end(k, last=True)
    else:
        # Metadata miss but cache hit: treat as hot and place into protected
        m_protected[k] = None

    # Keep protected within target by demoting LRU when necessary
    _enforce_protected_target(cache_snapshot)
=======
def update_after_hit(cache_snapshot, obj):
    '''
    Update policy on hit:
    - Increment TinyLFU and lightweight local freq.
    - Promote from T1 to T2 if estimated hot; otherwise refresh recency.
    - Keep protected within target using frequency-aware demotion.
    '''
    global m_probation, m_protected, m_freq, m_miss_streak
    _reset_if_new_run(cache_snapshot)
    _prune_metadata(cache_snapshot)
    _maybe_age_freq(cache_snapshot)
    _ensure_sketch(cache_snapshot)

    k = obj.key
    # Learn frequency (TinyLFU + small local)
    _sketch_add(cache_snapshot, k, 1)
    m_freq[k] = m_freq.get(k, 0) + 1

    # Any hit breaks a miss streak
    m_miss_streak = 0

    if k in m_protected:
        # Refresh recency in protected
        m_protected.move_to_end(k, last=True)
    elif k in m_probation:
        # Gate promotion by protected pressure and hotness
        target = _protected_target_size(cache_snapshot)
        est = _sketch_est(cache_snapshot, k)
        # Easier promotion when protected underfilled
        base_thr = 2 if len(m_protected) < target else 3
        if est >= base_thr or m_freq.get(k, 0) >= base_thr:
            m_probation.pop(k, None)
            m_protected[k] = None
        else:
            # Refresh recency in probation
            m_probation.move_to_end(k, last=True)
    else:
        # Metadata miss but cache hit: treat as hot and place into protected
        m_protected[k] = None

    # Keep protected within target by demoting cold candidates
    _enforce_protected_target(cache_snapshot)
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    global m_probation, m_protected, m_b1, m_b2, m_freq, m_miss_streak, m_p
    _reset_if_new_run(cache_snapshot)
    _prune_metadata(cache_snapshot)
    _maybe_age_freq(cache_snapshot)

    k = obj.key
    cap = max(int(cache_snapshot.capacity), 1)
    in_scan = m_miss_streak > (cap // 2)

    # Remove any stale placements
    m_protected.pop(k, None)
    m_probation.pop(k, None)

    # ARC p-adaptation on ghost hits with damping
    alpha = 0.25
    if k in m_b1:
        delta = max(1, len(m_b2) // max(1, len(m_b1)))
        m_p = min(cap, max(0, int(round(m_p + alpha * delta))))
        m_b1.pop(k, None)
        m_protected[k] = None
    elif k in m_b2:
        delta = max(1, len(m_b1) // max(1, len(m_b2)))
        m_p = max(0, min(cap, int(round(m_p - alpha * delta))))
        m_b2.pop(k, None)
        m_protected[k] = None
    else:
        # Competitive TinyLFU-like admission for non-ghosts
        if in_scan:
            # Avoid protecting scan items
            m_probation[k] = None
        else:
            f_new = m_freq.get(k, 0)
            if len(m_protected) > 0:
                cand_t2 = _sample_lowfreq(m_protected)
                f_t2 = m_freq.get(cand_t2, 0) if cand_t2 is not None else 0
                if f_new > f_t2:
                    m_protected[k] = None
                else:
                    m_probation[k] = None
            else:
                # Mild threshold when T2 empty
                if f_new >= 2:
                    m_protected[k] = None
                else:
                    m_probation[k] = None

    # Light frequency credit and miss streak for scan detection
    m_freq[k] = m_freq.get(k, 0) + 1
    m_miss_streak += 1

    # Keep protected within target by demoting LRU when necessary
    _enforce_protected_target(cache_snapshot)

    # Bound combined ghost sizes to capacity
    while (len(m_b1) + len(m_b2)) > cap:
        if len(m_b1) > len(m_b2):
            m_b1.popitem(last=False)
        else:
            m_b2.popitem(last=False)
=======
def update_after_insert(cache_snapshot, obj):
    '''
    Update metadata on insert (miss path):
    - Increment TinyLFU and local freq.
    - ARC p-adaptation using ghosts.
    - Competitive admission vs T2 tail by TinyLFU with protected bias.
    - Scan-aware: avoid over-promoting during scans.
    '''
    global m_probation, m_protected, m_b1, m_b2, m_freq, m_miss_streak, m_p
    _reset_if_new_run(cache_snapshot)
    _prune_metadata(cache_snapshot)
    _maybe_age_freq(cache_snapshot)
    _ensure_sketch(cache_snapshot)

    k = obj.key
    cap = max(int(cache_snapshot.capacity), 1)
    in_scan = m_miss_streak > cap

    # Remove any stale placements
    m_protected.pop(k, None)
    m_probation.pop(k, None)

    # Learn on admission
    _sketch_add(cache_snapshot, k, 1)

    # ARC p-adaptation on ghost hits (no damping; already conservative with sampling)
    if k in m_b1:
        delta = max(1, len(m_b2) // max(1, len(m_b1)))
        m_p = min(cap, max(0, m_p + delta))
        m_b1.pop(k, None)
        # re-reference: favor protected unless scan and not hot
        if in_scan and _sketch_est(cache_snapshot, k) < 3:
            m_probation[k] = None
        else:
            m_protected[k] = None
    elif k in m_b2:
        delta = max(1, len(m_b1) // max(1, len(m_b2)))
        m_p = max(0, min(cap, m_p - delta))
        m_b2.pop(k, None)
        if in_scan and _sketch_est(cache_snapshot, k) < 3:
            m_probation[k] = None
        else:
            m_protected[k] = None
    else:
        # Competitive TinyLFU-like admission for non-ghosts
        if in_scan:
            # Avoid protecting scan items
            m_probation[k] = None
        else:
            f_new = _sketch_est(cache_snapshot, k)
            if len(m_protected) > 0:
                cand_t2 = _sample_lowfreq(cache_snapshot, m_protected)
                f_t2 = _sketch_est(cache_snapshot, cand_t2) if cand_t2 is not None else 0
                if f_new > (f_t2 + 1):
                    m_protected[k] = None
                else:
                    m_probation[k] = None
            else:
                # Mild threshold when T2 empty
                if f_new >= 3:
                    m_protected[k] = None
                else:
                    m_probation[k] = None

    # Light local frequency credit and miss streak for scan detection
    m_freq[k] = m_freq.get(k, 0) + 1
    m_miss_streak += 1

    # Keep protected within target by demoting cold candidates
    _enforce_protected_target(cache_snapshot)

    # Bound combined ghost sizes to capacity
    while (len(m_b1) + len(m_b2)) > cap:
        if len(m_b1) > len(m_b2):
            m_b1.popitem(last=False)
        else:
            m_b2.popitem(last=False)
>>>>>>> REPLACE

</DIFF>