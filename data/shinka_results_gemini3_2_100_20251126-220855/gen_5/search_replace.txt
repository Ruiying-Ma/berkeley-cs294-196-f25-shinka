<NAME>
lecar_eviction
</NAME>

<DESCRIPTION>
Implement LeCaR (Learning Cache Replacement) algorithm.
LeCaR adaptively switches between LRU and LFU policies based on a weight `w` that is updated using Reinforcement Learning (Regret Minimization).
It maintains two ghost lists (History of LRU and History of LFU).
If a hit occurs in the LRU history (meaning LRU evicted a useful item), the weight shifts towards LFU.
If a hit occurs in the LFU history (meaning LFU evicted a useful item), the weight shifts towards LRU.
This approach aims to capture both recency and frequency patterns dynamically.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
# ARC (Adaptive Replacement Cache) Global State
m_lru = {}    # key -> access_count (timestamp)
m_t1 = set()  # T1: Recent set (keys)
m_t2 = set()  # T2: Frequent set (keys)
m_b1 = set()  # B1: Ghost Recent set (keys)
m_b2 = set()  # B2: Ghost Frequent set (keys)
m_p = 0.0     # Adaptation parameter (target size of T1)
m_last_access_count = 0 # To detect trace resets

def check_reset(cache_snapshot):
    global m_last_access_count, m_lru, m_t1, m_t2, m_b1, m_b2, m_p
    current_count = cache_snapshot.access_count
    if current_count < m_last_access_count:
        # Trace reset detected
        m_lru.clear()
        m_t1.clear()
        m_t2.clear()
        m_b1.clear()
        m_b2.clear()
        m_p = 0.0
    m_last_access_count = current_count

def evict(cache_snapshot, obj):
    '''
    Choose eviction victim using ARC logic.
    '''
    check_reset(cache_snapshot)
    global m_p, m_t1, m_t2, m_b1, m_b2, m_lru

    # Adaptation of p
    if obj.key in m_b1:
        delta = 1.0
        if len(m_b1) < len(m_b2):
            delta = float(len(m_b2)) / len(m_b1)
        m_p = min(float(cache_snapshot.capacity), m_p + delta)
    elif obj.key in m_b2:
        delta = 1.0
        if len(m_b2) < len(m_b1):
            delta = float(len(m_b1)) / len(m_b2)
        m_p = max(0.0, m_p - delta)

    # Determine victim
    victim_key = None

    # ARC Replace Logic
    # We rely on m_t1 and m_t2 tracking the keys in cache.
    # We must filter by actual cache content to be safe against state drift or initialization.
    t1_candidates = [k for k in m_t1 if k in cache_snapshot.cache]
    t2_candidates = [k for k in m_t2 if k in cache_snapshot.cache]

    # Fallback if sets are empty but cache is not (should not happen if consistent)
    if not t1_candidates and not t2_candidates:
        # Use full cache as fallback
        t1_candidates = list(cache_snapshot.cache.keys())

    evict_from_t1 = False
    if len(t1_candidates) > 0:
        if len(t1_candidates) > m_p:
            evict_from_t1 = True
        elif (obj.key in m_b2) and (len(t1_candidates) == int(m_p)):
            evict_from_t1 = True

    # If T1 is chosen, or if T2 is empty, evict from T1
    if (evict_from_t1 or not t2_candidates) and t1_candidates:
        victim_key = min(t1_candidates, key=lambda k: m_lru.get(k, 0))
    else:
        # Otherwise evict from T2
        victim_key = min(t2_candidates, key=lambda k: m_lru.get(k, 0))

    return victim_key

def update_after_hit(cache_snapshot, obj):
    '''
    Update metadata after hit. Move to T2 (Frequent).
    '''
    check_reset(cache_snapshot)
    global m_lru, m_t1, m_t2
    m_lru[obj.key] = cache_snapshot.access_count

    if obj.key in m_t1:
        m_t1.remove(obj.key)
        m_t2.add(obj.key)
    # If in T2, it stays in T2. LRU updated.

def update_after_insert(cache_snapshot, obj):
    '''
    Update metadata after insert. Handle ghost hits.
    '''
    check_reset(cache_snapshot)
    global m_lru, m_t1, m_t2, m_b1, m_b2
    m_lru[obj.key] = cache_snapshot.access_count

    # Ghost hits promote to T2
    if obj.key in m_b1:
        m_b1.remove(obj.key)
        m_t2.add(obj.key)
    elif obj.key in m_b2:
        m_b2.remove(obj.key)
        m_t2.add(obj.key)
    else:
        # New object -> T1
        m_t1.add(obj.key)
        # Safety: ensure not in T2
        if obj.key in m_t2:
            m_t2.remove(obj.key)

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    Update metadata after eviction. Move to ghosts.
    '''
    check_reset(cache_snapshot)
    global m_t1, m_t2, m_b1, m_b2, m_lru

    if evicted_obj.key in m_t1:
        m_t1.remove(evicted_obj.key)
        m_b1.add(evicted_obj.key)
    elif evicted_obj.key in m_t2:
        m_t2.remove(evicted_obj.key)
        m_b2.add(evicted_obj.key)

    # Manage ghost size (limit total ghosts to capacity)
    target_ghost_size = cache_snapshot.capacity
    if len(m_b1) + len(m_b2) > target_ghost_size:
        ghost_keys = list(m_b1) + list(m_b2)
        if ghost_keys:
            victim_ghost = min(ghost_keys, key=lambda k: m_lru.get(k, 0))
            if victim_ghost in m_b1:
                m_b1.remove(victim_ghost)
            elif victim_ghost in m_b2:
                m_b2.remove(victim_ghost)
            if victim_ghost in m_lru:
                del m_lru[victim_ghost]
=======
import random

# LeCaR (Learning Cache Replacement) Global State
m_lru = {}       # key -> last_access_timestamp
m_freq = {}      # key -> access_frequency
m_h_lru = set()  # Ghost LRU keys (History of LRU victims)
m_h_lfu = set()  # Ghost LFU keys (History of LFU victims)
m_w = 0.5        # Weight for LRU policy (probability to use LRU)
m_learning_rate = 0.05
m_last_access_count = 0
m_action = None  # Store the last eviction decision ('LRU', 'LFU', 'BOTH')

def check_reset(cache_snapshot):
    global m_last_access_count, m_lru, m_freq, m_h_lru, m_h_lfu, m_w, m_action
    current_count = cache_snapshot.access_count
    if current_count < m_last_access_count:
        m_lru.clear()
        m_freq.clear()
        m_h_lru.clear()
        m_h_lfu.clear()
        m_w = 0.5
        m_action = None
    m_last_access_count = current_count

def evict(cache_snapshot, obj):
    '''
    LeCaR eviction logic.
    '''
    check_reset(cache_snapshot)
    global m_lru, m_freq, m_w, m_action

    candidates = list(cache_snapshot.cache.keys())
    if not candidates:
        return None

    # Identify victims under policies
    # LRU victim: min timestamp
    victim_lru = min(candidates, key=lambda k: m_lru.get(k, 0))
    # LFU victim: min frequency, tie-breaker LRU
    victim_lfu = min(candidates, key=lambda k: (m_freq.get(k, 1), m_lru.get(k, 0)))

    if victim_lru == victim_lfu:
        victim = victim_lru
        m_action = 'BOTH'
    else:
        if random.random() < m_w:
            victim = victim_lru
            m_action = 'LRU'
        else:
            victim = victim_lfu
            m_action = 'LFU'

    return victim

def update_after_hit(cache_snapshot, obj):
    '''
    Update metadata after hit.
    '''
    check_reset(cache_snapshot)
    global m_lru, m_freq
    m_lru[obj.key] = cache_snapshot.access_count
    m_freq[obj.key] = m_freq.get(obj.key, 0) + 1

def update_after_insert(cache_snapshot, obj):
    '''
    Update metadata after insert. Handle learning from ghost hits.
    '''
    check_reset(cache_snapshot)
    global m_lru, m_freq, m_w, m_h_lru, m_h_lfu, m_learning_rate

    m_lru[obj.key] = cache_snapshot.access_count
    m_freq[obj.key] = 1  # Reset frequency on new insertion

    # Learning
    if obj.key in m_h_lru:
        # Hit in LRU history -> LRU was bad -> favor LFU -> decrease w
        m_w = max(0.01, m_w - m_learning_rate)
        m_h_lru.remove(obj.key)
        if obj.key in m_h_lfu: m_h_lfu.remove(obj.key)

    elif obj.key in m_h_lfu:
        # Hit in LFU history -> LFU was bad -> favor LRU -> increase w
        m_w = min(0.99, m_w + m_learning_rate)
        m_h_lfu.remove(obj.key)
        if obj.key in m_h_lru: m_h_lru.remove(obj.key)

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    Update metadata after eviction. Add to history.
    '''
    check_reset(cache_snapshot)
    global m_action, m_h_lru, m_h_lfu, m_lru, m_freq

    key = evicted_obj.key

    if m_action == 'LRU':
        m_h_lru.add(key)
    elif m_action == 'LFU':
        m_h_lfu.add(key)
    elif m_action == 'BOTH':
        m_h_lru.add(key)
        m_h_lfu.add(key)

    # Manage Ghost Size
    cap = cache_snapshot.capacity

    while len(m_h_lru) > cap:
        victim = min(m_h_lru, key=lambda k: m_lru.get(k, 0))
        m_h_lru.remove(victim)
        if victim not in m_h_lfu and victim in m_lru:
            del m_lru[victim]
            if victim in m_freq: del m_freq[victim]

    while len(m_h_lfu) > cap:
        victim = min(m_h_lfu, key=lambda k: m_lru.get(k, 0))
        m_h_lfu.remove(victim)
        if victim not in m_h_lru and victim in m_lru:
            del m_lru[victim]
            if victim in m_freq: del m_freq[victim]
>>>>>>> REPLACE

</DIFF>