--- a/original.py
+++ b/original.py
@@ -1,151 +1,210 @@
 # EVOLVE-BLOCK-START
-"""Cache eviction algorithm for optimizing hit rates across multiple workloads"""
+"""Cache eviction algorithm using Simplified LIRS (Low Inter-reference Recency Set) logic."""
 
 from collections import OrderedDict
 
-# Global ARC State
-m_t1 = OrderedDict()  # T1: Recent (LRU)
-m_t2 = OrderedDict()  # T2: Frequent (LRU)
-m_b1 = OrderedDict()  # B1: Ghost Recent (FIFO/LRU)
-m_b2 = OrderedDict()  # B2: Ghost Frequent (FIFO/LRU)
-m_p = 0.0             # Adaptation parameter (Target T1 size)
+# Global LIRS State
+m_stack = OrderedDict()  # S: Recency stack (Keys -> None). Tracks LIR and Ghost/HIR.
+m_q = OrderedDict()      # Q: Resident HIR blocks (Keys -> None). Eviction candidates.
+m_lir = set()            # Set of keys that are LIR (resident and 'hot')
 m_last_access_count = 0
+m_h_lir_target = 1       # Target capacity for LIR blocks
+m_s_max_size = 100       # Maximum size of Stack S
 
 def check_reset(cache_snapshot):
-    '''Reset global state if a new trace is detected.'''
-    global m_t1, m_t2, m_b1, m_b2, m_p, m_last_access_count
+    '''Reset global state if a new trace is detected or capacity changes.'''
+    global m_stack, m_q, m_lir, m_last_access_count, m_h_lir_target, m_s_max_size
+    
+    # Detect trace change via timestamp reset
     if cache_snapshot.access_count < m_last_access_count:
-        m_t1.clear()
-        m_t2.clear()
-        m_b1.clear()
-        m_b2.clear()
-        m_p = 0.0
+        m_stack.clear()
+        m_q.clear()
+        m_lir.clear()
     m_last_access_count = cache_snapshot.access_count
+    
+    # Configure limits based on current capacity
+    cap = cache_snapshot.capacity
+    # LIRS typical tuning: 90-99% LIR.
+    # We use 95% to allow 5% buffer for new items (Q).
+    m_h_lir_target = max(1, int(cap * 0.95))
+    # Stack limit to prevent unbounded growth on scans. 3x cache size is usually sufficient.
+    m_s_max_size = cap * 3
+
+def prune_stack():
+    '''
+    Maintains the LIRS Stack invariant: The bottom of the stack must be a LIR block.
+    Removes any HIR (Resident or Ghost) blocks from the bottom until a LIR block is found
+    or the stack is empty.
+    '''
+    global m_stack, m_lir
+    while m_stack:
+        # Peek at bottom (first item)
+        k = next(iter(m_stack))
+        if k not in m_lir:
+            # It's HIR (resident or ghost), remove it from stack history
+            m_stack.popitem(last=False)
+        else:
+            # Found a LIR block, stop pruning
+            break
 
 def evict(cache_snapshot, obj):
     '''
-    ARC eviction logic:
-    - Adapts 'p' based on hits in ghost lists (B1, B2).
-    - Selects victim from T1 or T2 based on 'p' and current sizes.
-    '''
-    check_reset(cache_snapshot)
-    global m_p
+    Determines eviction victim.
+    Strategy:
+    1. Evict from Q (Resident HIR). These are cold/probationary blocks.
+    2. If Q is empty (rare, implies cache full of LIR), evict bottom LIR from Stack.
+    '''
+    check_reset(cache_snapshot)
+    global m_q, m_stack
+    
+    if m_q:
+        return next(iter(m_q))
+    elif m_stack:
+        # Q empty, stack bottom is guaranteed LIR due to pruning
+        return next(iter(m_stack))
+    else:
+        # Fallback for safety, though stack shouldn't be empty if cache is full
+        return next(iter(cache_snapshot.cache))
+
+def update_after_hit(cache_snapshot, obj):
+    '''
+    Update LIRS metadata on cache hit.
+    '''
+    check_reset(cache_snapshot)
+    global m_stack, m_q, m_lir, m_h_lir_target, m_s_max_size
     
     key = obj.key
-    capacity = cache_snapshot.capacity
-    
-    # 1. Adapt p if hitting ghost history
-    if key in m_b1:
-        delta = 1.0
-        if len(m_b1) < len(m_b2):
-            delta = len(m_b2) / len(m_b1)
-        m_p = min(float(capacity), m_p + delta)
-    elif key in m_b2:
-        delta = 1.0
-        if len(m_b2) < len(m_b1):
-            delta = len(m_b1) / len(m_b2)
-        m_p = max(0.0, m_p - delta)
-
-    # 2. Determine eviction policy (Replace T1 or T2)
-    # If we need to evict, cache is full.
-    # Logic: Evict T1 if |T1| > p. 
-    # Special ARC case: if x in B2 and |T1| == p, also evict T1 (to make room for x in T2).
-    
-    replace_t1 = False
-    len_t1 = len(m_t1)
-    
-    if len_t1 > 0:
-        if len_t1 > m_p:
-            replace_t1 = True
-        elif (key in m_b2) and (len_t1 == int(m_p)):
-            replace_t1 = True
+    is_in_stack = key in m_stack
+    
+    # 1. Update Recency: Move to top of Stack S
+    if is_in_stack:
+        m_stack.move_to_end(key)
+    else:
+        m_stack[key] = None
+        
+    # 2. Update Status
+    if key in m_lir:
+        # Case: Hit on LIR
+        # Prune stack in case this LIR was at the bottom
+        prune_stack()
+        
+    elif key in m_q:
+        # Case: Hit on Resident HIR
+        if is_in_stack:
+            # It was in Stack S -> It is hot (short IRR) -> Promote to LIR
+            m_lir.add(key)
+            del m_q[key] # Remove from Q
             
-    # Safety checks if one list is empty
-    if len(m_t1) == 0: replace_t1 = False
-    if len(m_t2) == 0: replace_t1 = True
-    
-    if replace_t1:
-        return next(iter(m_t1))
-    else:
-        return next(iter(m_t2))
-
-def update_after_hit(cache_snapshot, obj):
-    '''
-    Move hit items to MRU of T2 (Frequency list).
-    '''
-    check_reset(cache_snapshot)
+            # If LIR set exceeds target, demote the coldest LIR
+            if len(m_lir) > m_h_lir_target:
+                prune_stack() # Ensure bottom is LIR
+                if m_stack:
+                    bottom_lir = next(iter(m_stack))
+                    m_lir.remove(bottom_lir)
+                    # Move demoted LIR to Q (becomes Resident HIR)
+                    m_q[bottom_lir] = None
+                    m_q.move_to_end(bottom_lir) # MRU in Q
+                    # Note: It will be pruned from stack in next prune_stack call/loop
+            prune_stack()
+        else:
+            # Not in Stack S -> Still Cold/Probation -> Keep in Q but move to MRU
+            m_q.move_to_end(key)
+            
+    # 3. Stack Size Safety Check
+    if len(m_stack) > m_s_max_size:
+        # Stack too big, force remove bottom entry
+        k, _ = m_stack.popitem(last=False)
+        if k in m_lir:
+            # If we forced out a LIR, it loses LIR status
+            m_lir.remove(k)
+            # If resident, move to Q
+            if k in cache_snapshot.cache and k not in m_q:
+                m_q[k] = None
+                m_q.move_to_end(k)
+        prune_stack()
+
+def update_after_insert(cache_snapshot, obj):
+    '''
+    Update LIRS metadata on cache insert (Miss).
+    '''
+    check_reset(cache_snapshot)
+    global m_stack, m_q, m_lir, m_h_lir_target, m_s_max_size
+    
     key = obj.key
-    if key in m_t1:
-        del m_t1[key]
-        m_t2[key] = None
-    elif key in m_t2:
-        m_t2.move_to_end(key)
-    else:
-        # Should not happen if sync is perfect, but fallback to insert T2
-        m_t2[key] = None
-
-def update_after_insert(cache_snapshot, obj):
-    '''
-    Insert new item. 
-    - If from B1 (Ghost T1) -> T2
-    - If from B2 (Ghost T2) -> T2
-    - Else -> T1
-    '''
-    check_reset(cache_snapshot)
-    key = obj.key
-    
-    # Check ghost lists
-    if key in m_b1:
-        del m_b1[key]
-        m_t2[key] = None
-    elif key in m_b2:
-        del m_b2[key]
-        m_t2[key] = None
-    else:
-        # Completely new item
-        m_t1[key] = None
+    is_in_stack = key in m_stack
+    
+    # Add to Stack S
+    if is_in_stack:
+        m_stack.move_to_end(key)
+    else:
+        m_stack[key] = None
+        
+    if is_in_stack:
+        # Case: Ghost Hit (Non-resident HIR found in Stack)
+        # It had a short IRR (within stack lifetime) -> Promote to LIR
+        m_lir.add(key)
+        
+        # Enforce LIR limit
+        if len(m_lir) > m_h_lir_target:
+            prune_stack()
+            if m_stack:
+                bottom_lir = next(iter(m_stack))
+                m_lir.remove(bottom_lir)
+                m_q[bottom_lir] = None
+                m_q.move_to_end(bottom_lir)
+        prune_stack()
+    else:
+        # Case: Cold Miss -> Insert as Resident HIR in Q
+        m_q[key] = None
+        m_q.move_to_end(key)
+        
+    # Stack Size Safety Check
+    if len(m_stack) > m_s_max_size:
+        k, _ = m_stack.popitem(last=False)
+        if k in m_lir:
+            m_lir.remove(k)
+            if k in cache_snapshot.cache and k not in m_q:
+                m_q[k] = None
+                m_q.move_to_end(k)
+        prune_stack()
 
 def update_after_evict(cache_snapshot, obj, evicted_obj):
     '''
-    Move evicted items to ghost lists (B1 or B2).
-    Manage ghost list capacities.
-    '''
-    check_reset(cache_snapshot)
+    Update state after eviction.
+    '''
+    check_reset(cache_snapshot)
+    global m_q, m_lir
+    
     key = evicted_obj.key
-    
-    if key in m_t1:
-        del m_t1[key]
-        m_b1[key] = None
-    elif key in m_t2:
-        del m_t2[key]
-        m_b2[key] = None
-        
-    # Limit ghost size (scan resistance vs history depth)
-    # Using capacity as limit for each ghost list roughly matches ARC paper suggestions
-    cap = cache_snapshot.capacity
-    while len(m_b1) > cap:
-        m_b1.popitem(last=False)
-    while len(m_b2) > cap:
-        m_b2.popitem(last=False)
+    # Remove from Q if present
+    if key in m_q:
+        del m_q[key]
+    # Remove from LIR if present (rare, only if Q was empty)
+    if key in m_lir:
+        m_lir.remove(key)
+    
+    # Note: We do NOT remove from m_stack. 
+    # It remains as a "Ghost" (Non-resident HIR) to track recency.
+    # It will be removed from stack eventually via prune_stack or max size limit.
 
 # EVOLVE-BLOCK-END
 
 # This part remains fixed (not evolved)
 def run_caching(trace_path: str, copy_code_dst: str):
     """Run the caching algorithm on a trace"""
     import os
     with open(os.path.abspath(__file__), 'r', encoding="utf-8") as f:
         code_str = f.read()
     with open(os.path.join(copy_code_dst), 'w') as f:
         f.write(code_str)
     from cache_utils import Cache, CacheConfig, CacheObj, Trace
     trace = Trace(trace_path=trace_path)
     cache_capacity = max(int(trace.get_ndv() * 0.1), 1)
     cache = Cache(CacheConfig(cache_capacity))
     for entry in trace.entries:
         obj = CacheObj(key=str(entry.key))
         cache.get(obj)
     with open(copy_code_dst, 'w') as f:
         f.write("")
     hit_rate = round(cache.hit_count / cache.access_count, 6)
     return hit_rate