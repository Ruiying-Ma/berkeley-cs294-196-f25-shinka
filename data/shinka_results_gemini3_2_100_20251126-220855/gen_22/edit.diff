--- a/original.py
+++ b/original.py
@@ -1,168 +1,188 @@
 # EVOLVE-BLOCK-START
 """S3-FIFO Cache Eviction Algorithm"""
 
 from collections import OrderedDict
 
 # Global S3-FIFO State
-# S: Small queue (Probationary, 10% of cache)
-# M: Main queue (Protected, 90% of cache)
+# S: Small queue (Probationary, initially 10% of cache)
+# M: Main queue (Protected, initially 90% of cache)
 # G: Ghost queue (History of evicted S items)
 m_small = OrderedDict()
 m_main = OrderedDict()
 m_ghost = OrderedDict()
+m_ghost_main = OrderedDict() # History of evicted M items
 m_accessed = set()
 m_last_access_count = 0
+m_s_ratio = 0.1
 
 def check_reset(cache_snapshot):
-    global m_small, m_main, m_ghost, m_accessed, m_last_access_count
+    global m_small, m_main, m_ghost, m_ghost_main, m_accessed, m_last_access_count, m_s_ratio
     # Check for trace reset or new trace based on timestamp regression
     if cache_snapshot.access_count < m_last_access_count:
         m_small.clear()
         m_main.clear()
         m_ghost.clear()
+        m_ghost_main.clear()
         m_accessed.clear()
+        m_s_ratio = 0.1
     m_last_access_count = cache_snapshot.access_count
 
 def evict(cache_snapshot, obj):
     '''
-    S3-FIFO eviction policy.
-    - Moves accessed items from S to M (Promotion).
-    - Reinserts accessed items in M (Second Chance).
-    - Evicts unaccessed items from S or M.
+    S3-FIFO eviction policy with Adaptive Sizing and Randomized Window.
     '''
     check_reset(cache_snapshot)
-    global m_small, m_main, m_accessed
+    global m_small, m_main, m_accessed, m_s_ratio
+
+    import itertools
 
     capacity = cache_snapshot.capacity
-    # Target size for S is usually 10% of capacity
-    target_s = max(1, int(capacity * 0.1))
+    # Adaptive target size for S
+    target_s = max(1, int(capacity * m_s_ratio))
 
-    # We loop until we find a victim to evict.
-    # The loop modifies m_small/m_main by moving items (Promotion/Reinsertion)
-    # until an unaccessed victim is found at the tail of the selected queue.
     while True:
-        # Determine whether to process S (Small) or M (Main).
-        # Process S if it's larger than target OR if M is empty (startup/scan phase).
         process_s = False
         if len(m_small) > target_s:
             process_s = True
         elif len(m_main) == 0:
             process_s = True
 
         if process_s:
-            # Inspection of S (Small Queue)
             if not m_small:
-                # Safety fallback: if S is empty but M is not (logic overlap), switch to M
                 if m_main:
                     process_s = False
                 else:
-                    # Cache implies full, so at least one item must exist.
-                    # If this hits, something is wrong with state, pick arbitrary.
                     return next(iter(cache_snapshot.cache))
 
             if process_s:
-                # Peek at the tail (oldest) of S
+                # Randomized Window Eviction: Check bottom K items
+                # Breaking strict FIFO helps with synchronized looping traces
+                k = 5
+                window = list(itertools.islice(m_small, k))
+                victim = None
+
+                # Find first unaccessed item in window
+                for key in window:
+                    if key not in m_accessed:
+                        victim = key
+                        break
+
+                if victim:
+                    return victim
+
+                # All K items accessed? Process head to make progress.
                 key = next(iter(m_small))
-
                 if key in m_accessed:
-                    # Item was accessed in S: Promote to M
                     m_accessed.remove(key)
                     del m_small[key]
-                    m_main[key] = None # Insert at MRU of Main
-                    # Continue loop to find next candidate
+                    m_main[key] = None
                 else:
-                    # Item not accessed: Evict from S
                     return key
 
-        # If we didn't process S (or decided to switch to M), process M
         if not process_s:
             if not m_main:
-                # Should be covered by logic above, but restart loop if state shifts
                 continue
 
-            # Peek at the tail of M
+            # Randomized Window for M
+            k = 5
+            window = list(itertools.islice(m_main, k))
+            victim = None
+
+            for key in window:
+                if key not in m_accessed:
+                    victim = key
+                    break
+
+            if victim:
+                return victim
+
+            # All K items accessed? Process head.
             key = next(iter(m_main))
-
             if key in m_accessed:
-                # Item was accessed in M: Give Second Chance (Reinsert at MRU)
                 m_accessed.remove(key)
                 m_main.move_to_end(key)
             else:
-                # Item not accessed: Evict from M
                 return key
 
 def update_after_hit(cache_snapshot, obj):
     check_reset(cache_snapshot)
     global m_accessed
     # Lazy promotion: just mark as accessed.
     # Do not move in lists to keep overhead low and preserve FIFO order for scanning.
     m_accessed.add(obj.key)
 
 def update_after_insert(cache_snapshot, obj):
     '''
-    Handle new insertion.
-    Check ghost history to decide between S (Probation) and M (Main).
+    Handle new insertion with adaptive sizing logic.
     '''
     check_reset(cache_snapshot)
-    global m_small, m_main, m_ghost, m_accessed
+    global m_small, m_main, m_ghost, m_ghost_main, m_accessed, m_s_ratio
 
     key = obj.key
-    # Ensure clean slate for new object
     if key in m_accessed:
         m_accessed.remove(key)
 
+    # Adaptation logic: Adjust S target based on ghost hits
+    delta = max(0.01, 1.0 / cache_snapshot.capacity) if cache_snapshot.capacity > 0 else 0.01
+
     if key in m_ghost:
-        # Ghost Hit: It was evicted from S recently. Bypass S and insert to M.
+        # Ghost S hit -> S was too small, increase S target
+        m_s_ratio = min(0.9, m_s_ratio + delta)
         del m_ghost[key]
         m_main[key] = None
+    elif key in m_ghost_main:
+        # Ghost M hit -> M was too small (S too big), decrease S target
+        m_s_ratio = max(0.01, m_s_ratio - delta)
+        del m_ghost_main[key]
+        m_main[key] = None
     else:
-        # New Item: Insert into S.
+        # New Item: Insert into S
         m_small[key] = None
 
 def update_after_evict(cache_snapshot, obj, evicted_obj):
     '''
     Clean up internal structures after eviction.
-    Add evicted S-items to Ghost list.
+    Add evicted items to respective ghost lists.
     '''
     check_reset(cache_snapshot)
-    global m_small, m_main, m_ghost, m_accessed
+    global m_small, m_main, m_ghost, m_ghost_main, m_accessed
 
     key = evicted_obj.key
 
-    # Remove from the queue it was in
     if key in m_small:
         del m_small[key]
-        # Only add to ghost if evicted from S (Probation)
         m_ghost[key] = None
     elif key in m_main:
         del m_main[key]
-        # Evicted from M means it had its chance. No ghost entry.
+        m_ghost_main[key] = None
 
-    # Manage Ghost size (limit to Cache Capacity)
-    if len(m_ghost) > cache_snapshot.capacity:
-        m_ghost.popitem(last=False) # Remove oldest ghost
+    # Manage Ghost sizes
+    cap = cache_snapshot.capacity
+    while len(m_ghost) > cap:
+        m_ghost.popitem(last=False)
+    while len(m_ghost_main) > cap:
+        m_ghost_main.popitem(last=False)
 
-    # Clean accessed bit if it lingers
     if key in m_accessed:
         m_accessed.remove(key)
 # EVOLVE-BLOCK-END
 
 # This part remains fixed (not evolved)
 def run_caching(trace_path: str, copy_code_dst: str):
     """Run the caching algorithm on a trace"""
     import os
     with open(os.path.abspath(__file__), 'r', encoding="utf-8") as f:
         code_str = f.read()
     with open(os.path.join(copy_code_dst), 'w') as f:
         f.write(code_str)
     from cache_utils import Cache, CacheConfig, CacheObj, Trace
     trace = Trace(trace_path=trace_path)
     cache_capacity = max(int(trace.get_ndv() * 0.1), 1)
     cache = Cache(CacheConfig(cache_capacity))
     for entry in trace.entries:
         obj = CacheObj(key=str(entry.key))
         cache.get(obj)
     with open(copy_code_dst, 'w') as f:
         f.write("")
     hit_rate = round(cache.hit_count / cache.access_count, 6)
     return hit_rate