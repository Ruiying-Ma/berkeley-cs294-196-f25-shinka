--- a/original.py
+++ b/original.py
@@ -1,79 +1,154 @@
 # EVOLVE-BLOCK-START
 """Cache eviction algorithm for optimizing hit rates across multiple workloads"""
+from collections import OrderedDict
 
-m_key_timestamp = dict()
+# ARC Global State
+m_t1 = OrderedDict() # T1: Recent cache entries
+m_t2 = OrderedDict() # T2: Frequent cache entries
+m_b1 = OrderedDict() # B1: Ghost entries evicted from T1
+m_b2 = OrderedDict() # B2: Ghost entries evicted from T2
+m_p = 0              # Target size for T1
+m_last_access_count = -1
+
+def _check_reset(cache_snapshot):
+    """Resets global state if a new trace is detected based on access count rollback."""
+    global m_t1, m_t2, m_b1, m_b2, m_p, m_last_access_count
+    if cache_snapshot.access_count < m_last_access_count:
+        m_t1.clear()
+        m_t2.clear()
+        m_b1.clear()
+        m_b2.clear()
+        m_p = 0
+    m_last_access_count = cache_snapshot.access_count
 
 def evict(cache_snapshot, obj):
     '''
-    This function defines how the algorithm chooses the eviction victim.
-    - Args:
-        - `cache_snapshot`: A snapshot of the current cache state.
-        - `obj`: The new object that needs to be inserted into the cache.
-    - Return:
-        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
+    ARC Eviction Policy:
+    Selects a victim from T1 or T2 based on the target size 'p'.
+    Adjusts 'p' if the incoming object was observed in ghost lists B1/B2.
     '''
-    candid_obj_key = None
-    min_ts = min(m_key_timestamp.values())
-    candid_obj_keys = list(key for key in cache_snapshot.cache if m_key_timestamp[key] == min_ts)
-    candid_obj_key = candid_obj_keys[0]
-    return candid_obj_key
+    _check_reset(cache_snapshot)
+    global m_p
+
+    key = obj.key
+    capacity = cache_snapshot.capacity
+
+    # 1. Adapt p (target size of T1) based on hits in ghost lists
+    if key in m_b1:
+        delta = 1
+        if len(m_b1) > 0 and len(m_b2) > 0:
+            delta = max(1, len(m_b2) / len(m_b1))
+        m_p = min(capacity, m_p + delta)
+    elif key in m_b2:
+        delta = 1
+        if len(m_b1) > 0 and len(m_b2) > 0:
+            delta = max(1, len(m_b1) / len(m_b2))
+        m_p = max(0, m_p - delta)
+
+    # 2. Select victim
+    evict_t1 = False
+    if len(m_t1) > 0:
+        if len(m_t1) > m_p:
+            evict_t1 = True
+        elif key in m_b2 and len(m_t1) == int(m_p):
+            evict_t1 = True
+
+    # If T2 is empty, we must evict from T1 (if possible)
+    if len(m_t2) == 0:
+        evict_t1 = True
+
+    if evict_t1 and m_t1:
+        # Evict LRU from T1
+        return next(iter(m_t1))
+    else:
+        # Evict LRU from T2
+        # Fallback to T1 if T2 is empty (shouldn't happen here if logic holds)
+        return next(iter(m_t2)) if m_t2 else next(iter(m_t1))
 
 def update_after_hit(cache_snapshot, obj):
     '''
-    This function defines how the algorithm update the metadata it maintains immediately after a cache hit.
-    - Args:
-        - `cache_snapshot`: A snapshot of the current cache state.
-        - `obj`: The object accessed during the cache hit.
-    - Return: `None`
+    On Cache Hit:
+    - If in T1, move to T2 (MRU).
+    - If in T2, move to MRU of T2.
     '''
-    global m_key_timestamp
-    assert obj.key in m_key_timestamp
-    m_key_timestamp[obj.key] = cache_snapshot.access_count
+    _check_reset(cache_snapshot)
+    key = obj.key
+
+    if key in m_t1:
+        del m_t1[key]
+        m_t2[key] = 1
+        m_t2.move_to_end(key)
+    elif key in m_t2:
+        m_t2.move_to_end(key)
+    else:
+        # Should be in cache, but if missing from metadata, add to T2
+        m_t2[key] = 1
+        m_t2.move_to_end(key)
 
 def update_after_insert(cache_snapshot, obj):
     '''
-    This function defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
-    - Args:
-        - `cache_snapshot`: A snapshot of the current cache state.
-        - `obj`: The object that was just inserted into the cache.
-    - Return: `None`
+    On Cache Insert (Miss):
+    - If previously in ghost B1/B2, promote to T2.
+    - Otherwise, insert into T1.
     '''
-    global m_key_timestamp
-    assert obj.key not in m_key_timestamp
-    m_key_timestamp[obj.key] = cache_snapshot.access_count
+    _check_reset(cache_snapshot)
+    key = obj.key
+
+    if key in m_b1:
+        del m_b1[key]
+        m_t2[key] = 1
+        m_t2.move_to_end(key)
+    elif key in m_b2:
+        del m_b2[key]
+        m_t2[key] = 1
+        m_t2.move_to_end(key)
+    else:
+        # Totally new item
+        m_t1[key] = 1
+        m_t1.move_to_end(key)
 
 def update_after_evict(cache_snapshot, obj, evicted_obj):
     '''
-    This function defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
-    - Args:
-        - `cache_snapshot`: A snapshot of the current cache state.
-        - `obj`: The object to be inserted into the cache.
-        - `evicted_obj`: The object that was just evicted from the cache.
-    - Return: `None`
+    On Eviction:
+    - Move evicted key from T1/T2 to B1/B2.
+    - Maintain capacity of ghost lists.
     '''
-    global m_key_timestamp
-    assert obj.key not in m_key_timestamp
-    assert evicted_obj.key in m_key_timestamp
-    m_key_timestamp.pop(evicted_obj.key)
+    key = evicted_obj.key
+    capacity = cache_snapshot.capacity
+
+    if key in m_t1:
+        del m_t1[key]
+        m_b1[key] = 1
+        m_b1.move_to_end(key)
+    elif key in m_t2:
+        del m_t2[key]
+        m_b2[key] = 1
+        m_b2.move_to_end(key)
+
+    # Restrict size of ghost lists to capacity (simplification of ARC)
+    if len(m_b1) > capacity:
+        m_b1.popitem(last=False)
+    if len(m_b2) > capacity:
+        m_b2.popitem(last=False)
 
 # EVOLVE-BLOCK-END
 
 # This part remains fixed (not evolved)
 def run_caching(trace_path: str, copy_code_dst: str):
     """Run the caching algorithm on a trace"""
     import os
     with open(os.path.abspath(__file__), 'r', encoding="utf-8") as f:
         code_str = f.read()
     with open(os.path.join(copy_code_dst), 'w') as f:
         f.write(code_str)
     from cache_utils import Cache, CacheConfig, CacheObj, Trace
     trace = Trace(trace_path=trace_path)
     cache_capacity = max(int(trace.get_ndv() * 0.1), 1)
     cache = Cache(CacheConfig(cache_capacity))
     for entry in trace.entries:
         obj = CacheObj(key=str(entry.key))
         cache.get(obj)
     with open(copy_code_dst, 'w') as f:
         f.write("")
     hit_rate = round(cache.hit_count / cache.access_count, 6)
     return hit_rate