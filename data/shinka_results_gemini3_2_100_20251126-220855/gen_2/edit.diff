--- a/original.py
+++ b/original.py
@@ -1,127 +1,157 @@
 # EVOLVE-BLOCK-START
 """Cache eviction algorithm for optimizing hit rates across multiple workloads"""
 
-m_key_timestamp = dict()
-m_protected_keys = set()
-m_ghost_timestamp = dict()
+# ARC (Adaptive Replacement Cache) Global State
+m_lru = {}    # key -> access_count (timestamp)
+m_t1 = set()  # T1: Recent set (keys)
+m_t2 = set()  # T2: Frequent set (keys)
+m_b1 = set()  # B1: Ghost Recent set (keys)
+m_b2 = set()  # B2: Ghost Frequent set (keys)
+m_p = 0.0     # Adaptation parameter (target size of T1)
+m_last_access_count = 0 # To detect trace resets
+
+def check_reset(cache_snapshot):
+    global m_last_access_count, m_lru, m_t1, m_t2, m_b1, m_b2, m_p
+    current_count = cache_snapshot.access_count
+    if current_count < m_last_access_count:
+        # Trace reset detected
+        m_lru.clear()
+        m_t1.clear()
+        m_t2.clear()
+        m_b1.clear()
+        m_b2.clear()
+        m_p = 0.0
+    m_last_access_count = current_count
 
 def evict(cache_snapshot, obj):
     '''
-    This function defines how the algorithm chooses the eviction victim.
-    - Args:
-        - `cache_snapshot`: A snapshot of the current cache state.
-        - `obj`: The new object that needs to be inserted into the cache.
-    - Return:
-        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
+    Choose eviction victim using ARC logic.
     '''
-    global m_key_timestamp, m_protected_keys
+    check_reset(cache_snapshot)
+    global m_p, m_t1, m_t2, m_b1, m_b2, m_lru
 
-    # Calculate current size of A1in (items in cache but not protected)
-    a1in_keys = [k for k in cache_snapshot.cache if k not in m_protected_keys]
-    current_a1in_size = len(a1in_keys)
+    # Adaptation of p
+    if obj.key in m_b1:
+        delta = 1.0
+        if len(m_b1) < len(m_b2):
+            delta = float(len(m_b2)) / len(m_b1)
+        m_p = min(float(cache_snapshot.capacity), m_p + delta)
+    elif obj.key in m_b2:
+        delta = 1.0
+        if len(m_b2) < len(m_b1):
+            delta = float(len(m_b1)) / len(m_b2)
+        m_p = max(0.0, m_p - delta)
 
-    # Target size for A1in (Probation)
-    target_a1in = cache_snapshot.capacity * 0.25
+    # Determine victim
+    victim_key = None
 
-    victim_key = None
-    candidates = []
+    # ARC Replace Logic
+    # We rely on m_t1 and m_t2 tracking the keys in cache.
+    # We must filter by actual cache content to be safe against state drift or initialization.
+    t1_candidates = [k for k in m_t1 if k in cache_snapshot.cache]
+    t2_candidates = [k for k in m_t2 if k in cache_snapshot.cache]
 
-    # Decide whether to evict from A1in or Am (Protected)
-    # If A1in exceeds target, evict from A1in.
-    # Also if Am is empty (all items are probationary), must evict from A1in.
-    if current_a1in_size > target_a1in or current_a1in_size == len(cache_snapshot.cache):
-        candidates = a1in_keys
+    # Fallback if sets are empty but cache is not (should not happen if consistent)
+    if not t1_candidates and not t2_candidates:
+        # Use full cache as fallback
+        t1_candidates = list(cache_snapshot.cache.keys())
+
+    evict_from_t1 = False
+    if len(t1_candidates) > 0:
+        if len(t1_candidates) > m_p:
+            evict_from_t1 = True
+        elif (obj.key in m_b2) and (len(t1_candidates) == int(m_p)):
+            evict_from_t1 = True
+
+    # If T1 is chosen, or if T2 is empty, evict from T1
+    if (evict_from_t1 or not t2_candidates) and t1_candidates:
+        victim_key = min(t1_candidates, key=lambda k: m_lru.get(k, 0))
     else:
-        # Otherwise try to evict from Am
-        candidates = [k for k in cache_snapshot.cache if k in m_protected_keys]
-        # Fallback if candidates is empty (should be covered by condition above)
-        if not candidates:
-            candidates = a1in_keys
+        # Otherwise evict from T2
+        victim_key = min(t2_candidates, key=lambda k: m_lru.get(k, 0))
 
-    # LRU eviction within the chosen segment
-    victim_key = min(candidates, key=lambda k: m_key_timestamp.get(k, 0))
     return victim_key
 
 def update_after_hit(cache_snapshot, obj):
     '''
-    This function defines how the algorithm update the metadata it maintains immediately after a cache hit.
-    - Args:
-        - `cache_snapshot`: A snapshot of the current cache state.
-        - `obj`: The object accessed during the cache hit.
-    - Return: `None`
+    Update metadata after hit. Move to T2 (Frequent).
     '''
-    global m_key_timestamp
-    # Update access time (LRU)
-    # In 2Q, hits in A1in do NOT promote to Am. They just refresh position in A1in.
-    if obj.key in m_key_timestamp:
-        m_key_timestamp[obj.key] = cache_snapshot.access_count
+    check_reset(cache_snapshot)
+    global m_lru, m_t1, m_t2
+    m_lru[obj.key] = cache_snapshot.access_count
+
+    if obj.key in m_t1:
+        m_t1.remove(obj.key)
+        m_t2.add(obj.key)
+    # If in T2, it stays in T2. LRU updated.
 
 def update_after_insert(cache_snapshot, obj):
     '''
-    This function defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
-    - Args:
-        - `cache_snapshot`: A snapshot of the current cache state.
-        - `obj`: The object that was just inserted into the cache.
-    - Return: `None`
+    Update metadata after insert. Handle ghost hits.
     '''
-    global m_key_timestamp, m_protected_keys, m_ghost_timestamp
-    m_key_timestamp[obj.key] = cache_snapshot.access_count
+    check_reset(cache_snapshot)
+    global m_lru, m_t1, m_t2, m_b1, m_b2
+    m_lru[obj.key] = cache_snapshot.access_count
 
-    # Check if object was in ghost registry
-    if obj.key in m_ghost_timestamp:
-        # Promote to Protected (Am)
-        m_protected_keys.add(obj.key)
-        del m_ghost_timestamp[obj.key]
+    # Ghost hits promote to T2
+    if obj.key in m_b1:
+        m_b1.remove(obj.key)
+        m_t2.add(obj.key)
+    elif obj.key in m_b2:
+        m_b2.remove(obj.key)
+        m_t2.add(obj.key)
     else:
-        # Insert into Probation (A1in)
-        # Ensure it's not marked as protected (in case of re-use of key after long time)
-        if obj.key in m_protected_keys:
-            m_protected_keys.remove(obj.key)
+        # New object -> T1
+        m_t1.add(obj.key)
+        # Safety: ensure not in T2
+        if obj.key in m_t2:
+            m_t2.remove(obj.key)
 
 def update_after_evict(cache_snapshot, obj, evicted_obj):
     '''
-    This function defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
-    - Args:
-        - `cache_snapshot`: A snapshot of the current cache state.
-        - `obj`: The object to be inserted into the cache.
-        - `evicted_obj`: The object that was just evicted from the cache.
-    - Return: `None`
+    Update metadata after eviction. Move to ghosts.
     '''
-    global m_key_timestamp, m_protected_keys, m_ghost_timestamp
-    if evicted_obj.key in m_key_timestamp:
-        del m_key_timestamp[evicted_obj.key]
+    check_reset(cache_snapshot)
+    global m_t1, m_t2, m_b1, m_b2, m_lru
 
-    if evicted_obj.key in m_protected_keys:
-        m_protected_keys.remove(evicted_obj.key)
-        # Evicted from Am: usually not added to ghost in standard 2Q
-    else:
-        # Evicted from A1in: add to ghost registry
-        m_ghost_timestamp[evicted_obj.key] = cache_snapshot.access_count
+    if evicted_obj.key in m_t1:
+        m_t1.remove(evicted_obj.key)
+        m_b1.add(evicted_obj.key)
+    elif evicted_obj.key in m_t2:
+        m_t2.remove(evicted_obj.key)
+        m_b2.add(evicted_obj.key)
 
-        # Manage ghost size (limit to cache capacity)
-        if len(m_ghost_timestamp) > cache_snapshot.capacity:
-             # Remove oldest in ghost
-             oldest_ghost = min(m_ghost_timestamp, key=m_ghost_timestamp.get)
-             del m_ghost_timestamp[oldest_ghost]
+    # Manage ghost size (limit total ghosts to capacity)
+    target_ghost_size = cache_snapshot.capacity
+    if len(m_b1) + len(m_b2) > target_ghost_size:
+        ghost_keys = list(m_b1) + list(m_b2)
+        if ghost_keys:
+            victim_ghost = min(ghost_keys, key=lambda k: m_lru.get(k, 0))
+            if victim_ghost in m_b1:
+                m_b1.remove(victim_ghost)
+            elif victim_ghost in m_b2:
+                m_b2.remove(victim_ghost)
+            if victim_ghost in m_lru:
+                del m_lru[victim_ghost]
 
 # EVOLVE-BLOCK-END
 
 # This part remains fixed (not evolved)
 def run_caching(trace_path: str, copy_code_dst: str):
     """Run the caching algorithm on a trace"""
     import os
     with open(os.path.abspath(__file__), 'r', encoding="utf-8") as f:
         code_str = f.read()
     with open(os.path.join(copy_code_dst), 'w') as f:
         f.write(code_str)
     from cache_utils import Cache, CacheConfig, CacheObj, Trace
     trace = Trace(trace_path=trace_path)
     cache_capacity = max(int(trace.get_ndv() * 0.1), 1)
     cache = Cache(CacheConfig(cache_capacity))
     for entry in trace.entries:
         obj = CacheObj(key=str(entry.key))
         cache.get(obj)
     with open(copy_code_dst, 'w') as f:
         f.write("")
     hit_rate = round(cache.hit_count / cache.access_count, 6)
     return hit_rate