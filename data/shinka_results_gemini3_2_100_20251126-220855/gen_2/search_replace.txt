<NAME>
arc_eviction
</NAME>

<DESCRIPTION>
Implement the Adaptive Replacement Cache (ARC) algorithm. ARC dynamically balances between Recency (T1) and Frequency (T2) based on observed "ghost" hits (accesses to recently evicted items). This approach outperforms LRU and 2Q by adapting to the workload's recency vs. frequency characteristics.
I also included a mechanism to detect trace resets (via `access_count` drop) to clear global state, ensuring correctness across multiple sequential evaluations.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
# EVOLVE-BLOCK-START
"""Cache eviction algorithm for optimizing hit rates across multiple workloads"""

m_key_timestamp = dict()
m_protected_keys = set()
m_ghost_timestamp = dict()

def evict(cache_snapshot, obj):
    '''
    This function defines how the algorithm chooses the eviction victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    global m_key_timestamp, m_protected_keys

    # Calculate current size of A1in (items in cache but not protected)
    a1in_keys = [k for k in cache_snapshot.cache if k not in m_protected_keys]
    current_a1in_size = len(a1in_keys)

    # Target size for A1in (Probation)
    target_a1in = cache_snapshot.capacity * 0.25

    victim_key = None
    candidates = []

    # Decide whether to evict from A1in or Am (Protected)
    # If A1in exceeds target, evict from A1in.
    # Also if Am is empty (all items are probationary), must evict from A1in.
    if current_a1in_size > target_a1in or current_a1in_size == len(cache_snapshot.cache):
        candidates = a1in_keys
    else:
        # Otherwise try to evict from Am
        candidates = [k for k in cache_snapshot.cache if k in m_protected_keys]
        # Fallback if candidates is empty (should be covered by condition above)
        if not candidates:
            candidates = a1in_keys

    # LRU eviction within the chosen segment
    victim_key = min(candidates, key=lambda k: m_key_timestamp.get(k, 0))
    return victim_key

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the algorithm update the metadata it maintains immediately after a cache hit.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    global m_key_timestamp
    # Update access time (LRU)
    # In 2Q, hits in A1in do NOT promote to Am. They just refresh position in A1in.
    if obj.key in m_key_timestamp:
        m_key_timestamp[obj.key] = cache_snapshot.access_count

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    global m_key_timestamp, m_protected_keys, m_ghost_timestamp
    m_key_timestamp[obj.key] = cache_snapshot.access_count

    # Check if object was in ghost registry
    if obj.key in m_ghost_timestamp:
        # Promote to Protected (Am)
        m_protected_keys.add(obj.key)
        del m_ghost_timestamp[obj.key]
    else:
        # Insert into Probation (A1in)
        # Ensure it's not marked as protected (in case of re-use of key after long time)
        if obj.key in m_protected_keys:
            m_protected_keys.remove(obj.key)

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    global m_key_timestamp, m_protected_keys, m_ghost_timestamp
    if evicted_obj.key in m_key_timestamp:
        del m_key_timestamp[evicted_obj.key]

    if evicted_obj.key in m_protected_keys:
        m_protected_keys.remove(evicted_obj.key)
        # Evicted from Am: usually not added to ghost in standard 2Q
    else:
        # Evicted from A1in: add to ghost registry
        m_ghost_timestamp[evicted_obj.key] = cache_snapshot.access_count

        # Manage ghost size (limit to cache capacity)
        if len(m_ghost_timestamp) > cache_snapshot.capacity:
             # Remove oldest in ghost
             oldest_ghost = min(m_ghost_timestamp, key=m_ghost_timestamp.get)
             del m_ghost_timestamp[oldest_ghost]
=======
# EVOLVE-BLOCK-START
"""Cache eviction algorithm for optimizing hit rates across multiple workloads"""

# ARC (Adaptive Replacement Cache) Global State
m_lru = {}    # key -> access_count (timestamp)
m_t1 = set()  # T1: Recent set (keys)
m_t2 = set()  # T2: Frequent set (keys)
m_b1 = set()  # B1: Ghost Recent set (keys)
m_b2 = set()  # B2: Ghost Frequent set (keys)
m_p = 0.0     # Adaptation parameter (target size of T1)
m_last_access_count = 0 # To detect trace resets

def check_reset(cache_snapshot):
    global m_last_access_count, m_lru, m_t1, m_t2, m_b1, m_b2, m_p
    current_count = cache_snapshot.access_count
    if current_count < m_last_access_count:
        # Trace reset detected
        m_lru.clear()
        m_t1.clear()
        m_t2.clear()
        m_b1.clear()
        m_b2.clear()
        m_p = 0.0
    m_last_access_count = current_count

def evict(cache_snapshot, obj):
    '''
    Choose eviction victim using ARC logic.
    '''
    check_reset(cache_snapshot)
    global m_p, m_t1, m_t2, m_b1, m_b2, m_lru

    # Adaptation of p
    if obj.key in m_b1:
        delta = 1.0
        if len(m_b1) < len(m_b2):
            delta = float(len(m_b2)) / len(m_b1)
        m_p = min(float(cache_snapshot.capacity), m_p + delta)
    elif obj.key in m_b2:
        delta = 1.0
        if len(m_b2) < len(m_b1):
            delta = float(len(m_b1)) / len(m_b2)
        m_p = max(0.0, m_p - delta)

    # Determine victim
    victim_key = None

    # ARC Replace Logic
    # We rely on m_t1 and m_t2 tracking the keys in cache.
    # We must filter by actual cache content to be safe against state drift or initialization.
    t1_candidates = [k for k in m_t1 if k in cache_snapshot.cache]
    t2_candidates = [k for k in m_t2 if k in cache_snapshot.cache]

    # Fallback if sets are empty but cache is not (should not happen if consistent)
    if not t1_candidates and not t2_candidates:
        # Use full cache as fallback
        t1_candidates = list(cache_snapshot.cache.keys())

    evict_from_t1 = False
    if len(t1_candidates) > 0:
        if len(t1_candidates) > m_p:
            evict_from_t1 = True
        elif (obj.key in m_b2) and (len(t1_candidates) == int(m_p)):
            evict_from_t1 = True

    # If T1 is chosen, or if T2 is empty, evict from T1
    if (evict_from_t1 or not t2_candidates) and t1_candidates:
        victim_key = min(t1_candidates, key=lambda k: m_lru.get(k, 0))
    else:
        # Otherwise evict from T2
        victim_key = min(t2_candidates, key=lambda k: m_lru.get(k, 0))

    return victim_key

def update_after_hit(cache_snapshot, obj):
    '''
    Update metadata after hit. Move to T2 (Frequent).
    '''
    check_reset(cache_snapshot)
    global m_lru, m_t1, m_t2
    m_lru[obj.key] = cache_snapshot.access_count

    if obj.key in m_t1:
        m_t1.remove(obj.key)
        m_t2.add(obj.key)
    # If in T2, it stays in T2. LRU updated.

def update_after_insert(cache_snapshot, obj):
    '''
    Update metadata after insert. Handle ghost hits.
    '''
    check_reset(cache_snapshot)
    global m_lru, m_t1, m_t2, m_b1, m_b2
    m_lru[obj.key] = cache_snapshot.access_count

    # Ghost hits promote to T2
    if obj.key in m_b1:
        m_b1.remove(obj.key)
        m_t2.add(obj.key)
    elif obj.key in m_b2:
        m_b2.remove(obj.key)
        m_t2.add(obj.key)
    else:
        # New object -> T1
        m_t1.add(obj.key)
        # Safety: ensure not in T2
        if obj.key in m_t2:
            m_t2.remove(obj.key)

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    Update metadata after eviction. Move to ghosts.
    '''
    check_reset(cache_snapshot)
    global m_t1, m_t2, m_b1, m_b2, m_lru

    if evicted_obj.key in m_t1:
        m_t1.remove(evicted_obj.key)
        m_b1.add(evicted_obj.key)
    elif evicted_obj.key in m_t2:
        m_t2.remove(evicted_obj.key)
        m_b2.add(evicted_obj.key)

    # Manage ghost size (limit total ghosts to capacity)
    target_ghost_size = cache_snapshot.capacity
    if len(m_b1) + len(m_b2) > target_ghost_size:
        ghost_keys = list(m_b1) + list(m_b2)
        if ghost_keys:
            victim_ghost = min(ghost_keys, key=lambda k: m_lru.get(k, 0))
            if victim_ghost in m_b1:
                m_b1.remove(victim_ghost)
            elif victim_ghost in m_b2:
                m_b2.remove(victim_ghost)
            if victim_ghost in m_lru:
                del m_lru[victim_ghost]
>>>>>>> REPLACE
</DIFF>