<NAME>
s3_fifo_lru_jitter
</NAME>

<DESCRIPTION>
I am proposing two modifications to the S3-FIFO algorithm to improve its hit rate and resistance to pathological patterns:

1.  **True LRU Policy for Main Segment**: The original implementation used a "Second Chance FIFO" for the Main queue (`s3_main`). I have updated `update_after_hit` to immediately move an item in the Main queue to the tail (MRU) upon access. This converts the Main segment into a Segmented LRU (SLRU) protected tier, which reacts faster to changes in the working set than lazy reinsertion.
2.  **Jittered Partition Boundaries**: To address the 0.00 hit rate on Trace 14 (likely caused by a looping pattern synchronized with the static cache size), I introduced a randomized "jitter" to the `s_capacity` threshold calculation in `evict`. By varying the size of the Small queue slightly (approx +/- 1%), we desynchronize the eviction cycles from the access pattern loops.

I added `import random` to facilitate the jitter calculation.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
"""S3-FIFO with Multi-bit Frequency Counters"""

# S3-FIFO Metadata
# s3_small: FIFO queue for the small segment (probation)
# s3_main: FIFO queue for the main segment (protected)
# s3_ghost: Ghost cache for tracking eviction from small
# s3_freq: Frequency counter for objects (max 3)
s3_small = {}
s3_main = {}
s3_ghost = {}
s3_freq = {}

def evict(cache_snapshot, obj):
    '''
    S3-FIFO Eviction Policy with Multi-bit Clock:
    - Small Queue (S): FIFO. Hits promote to Main.
    - Main Queue (M): Segmented FIFO with frequency counters.
      - Items in M have a frequency count (0-3).
      - Eviction from M decrements frequency. Only evict if freq is 0.
      - This approximates a multi-bit clock / LFU-like retention.
    - Ghost Queue (G): Tracks items evicted from S to rescue them quickly.
    '''
    global s3_small, s3_main, s3_ghost, s3_freq

    capacity = cache_snapshot.capacity
    # Target size for Small queue (10% of capacity)
    s_capacity = max(1, int(capacity * 0.1))

    # Lazy cleanup of ghost
    while len(s3_ghost) > capacity:
        s3_ghost.pop(next(iter(s3_ghost)))

    while True:
        # Decision: Evict from Small or Main?
        # Rule: Evict from Small if it exceeds its target size, OR if Main is empty.
        if len(s3_small) >= s_capacity or not s3_main:
            if not s3_small:
                # Safety valve: if Main is empty and Small is empty (should not happen in full cache)
                return None

            candidate = next(iter(s3_small))
            freq = s3_freq.get(candidate, 0)

            if freq > 0:
                # Hit in Small: Promote to Main
                # Reset frequency to 0 upon entering Main (probation passed)
                # This ensures it doesn't stay in Main forever without new hits
                s3_small.pop(candidate)
                s3_main[candidate] = None
                s3_freq[candidate] = 0
                continue
            else:
                # Victim found in Small
                return candidate

        else:
            # Evict from Main
            candidate = next(iter(s3_main))
            freq = s3_freq.get(candidate, 0)

            if freq > 0:
                # Hit in Main: Decrement frequency and reinsert at tail (Second/Third Chance)
                # This distinguishes between "hot" (freq=3) and "warm" (freq=1) items.
                s3_main.pop(candidate)
                s3_main[candidate] = None
                s3_freq[candidate] = freq - 1
                continue
            else:
                # Victim found in Main
                return candidate

def update_after_hit(cache_snapshot, obj):
    '''
    On Hit: Increment frequency, capped at 3.
    This helps identify frequently accessed items.
    '''
    global s3_freq
    s3_freq[obj.key] = min(s3_freq.get(obj.key, 0) + 1, 3)
=======
"""S3-FIFO with Multi-bit Frequency Counters and Jittered LRU"""
import random

# S3-FIFO Metadata
# s3_small: FIFO queue for the small segment (probation)
# s3_main: LRU queue for the main segment (protected)
# s3_ghost: Ghost cache for tracking eviction from small
# s3_freq: Frequency counter for objects (max 3)
s3_small = {}
s3_main = {}
s3_ghost = {}
s3_freq = {}

def evict(cache_snapshot, obj):
    '''
    S3-FIFO Eviction Policy with Multi-bit Clock and Jittered LRU:
    - Small Queue (S): FIFO. Hits promote to Main.
    - Main Queue (M): LRU + Frequency.
      - Hits move to MRU (in update_after_hit).
      - Eviction checks LRU (head). If freq > 0, reinsert to MRU and decrement freq.
    - Ghost Queue (G): Tracks items evicted from S to rescue them quickly.
    - Jitter: Randomized capacity for S to avoid thrashing loops.
    '''
    global s3_small, s3_main, s3_ghost, s3_freq

    capacity = cache_snapshot.capacity
    # Target size for Small queue (10% of capacity) with Jitter
    # We add +/- 1% noise to the threshold to break pathological loops (e.g. Trace 14)
    noise_range = max(1, int(capacity * 0.01))
    s_capacity = max(1, int(capacity * 0.1) + random.randint(-noise_range, noise_range))

    # Lazy cleanup of ghost
    while len(s3_ghost) > capacity:
        s3_ghost.pop(next(iter(s3_ghost)))

    while True:
        # Decision: Evict from Small or Main?
        # Rule: Evict from Small if it exceeds its target size, OR if Main is empty.
        if len(s3_small) >= s_capacity or not s3_main:
            if not s3_small:
                # Safety valve: if Main is empty and Small is empty (should not happen in full cache)
                return None

            candidate = next(iter(s3_small))
            freq = s3_freq.get(candidate, 0)

            if freq > 0:
                # Hit in Small: Promote to Main
                # Reset frequency to 0 upon entering Main (probation passed)
                s3_small.pop(candidate)
                s3_main[candidate] = None
                s3_freq[candidate] = 0
                continue
            else:
                # Victim found in Small
                return candidate

        else:
            # Evict from Main
            candidate = next(iter(s3_main))
            freq = s3_freq.get(candidate, 0)

            if freq > 0:
                # Hit in Main: Decrement frequency and reinsert at tail
                s3_main.pop(candidate)
                s3_main[candidate] = None
                s3_freq[candidate] = freq - 1
                continue
            else:
                # Victim found in Main
                return candidate

def update_after_hit(cache_snapshot, obj):
    '''
    On Hit:
    - Increment frequency, capped at 3.
    - If in Main, move to MRU (True LRU).
    '''
    global s3_freq, s3_main
    key = obj.key
    s3_freq[key] = min(s3_freq.get(key, 0) + 1, 3)

    if key in s3_main:
        # Move to MRU to maintain LRU property
        val = s3_main.pop(key)
        s3_main[key] = val
>>>>>>> REPLACE
</DIFF>