--- a/original.py
+++ b/original.py
@@ -1,79 +1,131 @@
 # EVOLVE-BLOCK-START
 """Cache eviction algorithm for optimizing hit rates across multiple workloads"""
 
-m_key_timestamp = dict()
+m_key_metadata = dict()
 
 def evict(cache_snapshot, obj):
     '''
     This function defines how the algorithm chooses the eviction victim.
     - Args:
         - `cache_snapshot`: A snapshot of the current cache state.
         - `obj`: The new object that needs to be inserted into the cache.
     - Return:
         - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
     '''
-    candid_obj_key = None
-    min_ts = min(m_key_timestamp.values())
-    candid_obj_keys = list(key for key in cache_snapshot.cache if m_key_timestamp[key] == min_ts)
-    candid_obj_key = candid_obj_keys[0]
-    return candid_obj_key
+    # SLRU Implementation
+    # Segments: 0 = Probationary, 1 = Protected
+    PROTECTED_RATIO = 0.8
+    capacity = cache_snapshot.capacity
+    limit_prot = capacity * PROTECTED_RATIO
+
+    lru_prob_key = None
+    lru_prob_ts = float('inf')
+    lru_prot_key = None
+    lru_prot_ts = float('inf')
+    num_prot = 0
+
+    for key in cache_snapshot.cache:
+        # metadata: [segment, timestamp]
+        # Default to probationary if missing (safety)
+        meta = m_key_metadata.get(key, [0, 0])
+        segment = meta[0]
+        ts = meta[1]
+
+        if segment > 0:
+            num_prot += 1
+            if ts < lru_prot_ts:
+                lru_prot_ts = ts
+                lru_prot_key = key
+        else:
+            if ts < lru_prob_ts:
+                lru_prob_ts = ts
+                lru_prob_key = key
+
+    # Logic to enforce segment sizes and choose victim
+    if num_prot > limit_prot:
+        # Protected segment is full, demote LRU of Protected to Probationary
+        if lru_prot_key:
+            # Demote: Set segment to 0 and update timestamp to now (MRU of Prob)
+            m_key_metadata[lru_prot_key][0] = 0
+            m_key_metadata[lru_prot_key][1] = cache_snapshot.access_count
+
+        # After demotion (or if we couldn't demote), evict from Probationary
+        if lru_prob_key:
+            return lru_prob_key
+        else:
+            # If Probationary was empty (and we just demoted someone who is kept),
+            # strictly speaking, we need to evict.
+            # If we demoted lru_prot_key, it is now in Probationary.
+            # Ideally we pick the LRU of the NEW Probationary set.
+            # If Prob was empty, the demoted item is the ONLY item in Prob.
+            # So we would evict it.
+            return lru_prot_key
+    else:
+        # Protected not full, evict from Probationary if possible
+        if lru_prob_key:
+            return lru_prob_key
+        else:
+            # Probationary empty, must evict from Protected
+            return lru_prot_key
 
 def update_after_hit(cache_snapshot, obj):
     '''
     This function defines how the algorithm update the metadata it maintains immediately after a cache hit.
     - Args:
         - `cache_snapshot`: A snapshot of the current cache state.
         - `obj`: The object accessed during the cache hit.
     - Return: `None`
     '''
-    global m_key_timestamp
-    assert obj.key in m_key_timestamp
-    m_key_timestamp[obj.key] = cache_snapshot.access_count
+    global m_key_metadata
+    if obj.key in m_key_metadata:
+        # Promote to Protected (1) and update timestamp
+        m_key_metadata[obj.key] = [1, cache_snapshot.access_count]
+    else:
+        # Should normally exist, but handle gracefully
+        m_key_metadata[obj.key] = [1, cache_snapshot.access_count]
 
 def update_after_insert(cache_snapshot, obj):
     '''
     This function defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
     - Args:
         - `cache_snapshot`: A snapshot of the current cache state.
         - `obj`: The object that was just inserted into the cache.
     - Return: `None`
     '''
-    global m_key_timestamp
-    assert obj.key not in m_key_timestamp
-    m_key_timestamp[obj.key] = cache_snapshot.access_count
+    global m_key_metadata
+    # Insert into Probationary (0)
+    m_key_metadata[obj.key] = [0, cache_snapshot.access_count]
 
 def update_after_evict(cache_snapshot, obj, evicted_obj):
     '''
     This function defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
     - Args:
         - `cache_snapshot`: A snapshot of the current cache state.
         - `obj`: The object to be inserted into the cache.
         - `evicted_obj`: The object that was just evicted from the cache.
     - Return: `None`
     '''
-    global m_key_timestamp
-    assert obj.key not in m_key_timestamp
-    assert evicted_obj.key in m_key_timestamp
-    m_key_timestamp.pop(evicted_obj.key)
+    global m_key_metadata
+    m_key_metadata.pop(evicted_obj.key, None)
 
 # EVOLVE-BLOCK-END
 
 # This part remains fixed (not evolved)
 def run_caching(trace_path: str, copy_code_dst: str):
     """Run the caching algorithm on a trace"""
     import os
     with open(os.path.abspath(__file__), 'r', encoding="utf-8") as f:
         code_str = f.read()
     with open(os.path.join(copy_code_dst), 'w') as f:
         f.write(code_str)
     from cache_utils import Cache, CacheConfig, CacheObj, Trace
     trace = Trace(trace_path=trace_path)
     cache_capacity = max(int(trace.get_ndv() * 0.1), 1)
     cache = Cache(CacheConfig(cache_capacity))
     for entry in trace.entries:
         obj = CacheObj(key=str(entry.key))
         cache.get(obj)
     with open(copy_code_dst, 'w') as f:
         f.write("")
     hit_rate = round(cache.hit_count / cache.access_count, 6)
     return hit_rate