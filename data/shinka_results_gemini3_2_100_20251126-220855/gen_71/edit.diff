--- a/original.py
+++ b/original.py
@@ -1,139 +1,150 @@
 # EVOLVE-BLOCK-START
 from collections import OrderedDict
 
 # S3-FIFO Hybrid State
 # m_t1: Small Queue (Probationary)
 # m_t2: Main Queue (Protected)
 # m_b1: Frequency/Ghost Map (Key -> Count)
 # m_p: Last aging timestamp
 # m_last_access_count: Reset detection
 m_t1 = OrderedDict()
 m_t2 = OrderedDict()
 m_b1 = OrderedDict()
 m_b2 = OrderedDict() # Unused
 m_p = 0.0
 m_last_access_count = 0
 
 def check_reset(cache_snapshot):
     global m_t1, m_t2, m_b1, m_p, m_last_access_count
     if cache_snapshot.access_count < m_last_access_count:
         m_t1.clear()
         m_t2.clear()
         m_b1.clear()
         m_p = 0.0
     m_last_access_count = cache_snapshot.access_count
 
 def evict(cache_snapshot, obj):
     '''
     S3-FIFO with LIFO Probation and Frequency Gating.
     - T1 (Small): LIFO eviction to resist scan/loops.
-    - T2 (Main): LRU eviction.
-    - Promotion: T1 -> T2 if freq > 1.
+    - T2 (Main): Second-Chance LRU eviction.
+    - Extended Ghost and Slow Aging.
     '''
     check_reset(cache_snapshot)
     global m_p
 
     capacity = cache_snapshot.capacity
     current_time = cache_snapshot.access_count
 
-    # Global Frequency Aging (Div by 2 every capacity accesses)
-    if current_time - m_p > capacity:
+    # Global Frequency Aging (Div by 2 every 4*capacity accesses)
+    # Slowed down to retain history for larger loops
+    if current_time - m_p > capacity * 4:
         for k in m_b1:
             m_b1[k] //= 2
         m_p = float(current_time)
 
     # Target size for T1 (10%)
     t1_target = int(capacity * 0.1)
     if t1_target < 1: t1_target = 1
 
-    # Eviction Logic
-    # Prioritize evicting from T1 if it exceeds target
+    # 1. Evict from T1 (Probation) if above target
     if len(m_t1) >= t1_target:
         # Loop to handle promotions
         while len(m_t1) > 0:
-            # LIFO Eviction Candidate: Tail of T1
+            # LIFO Eviction Candidate: Tail of T1 (Small queue uses LIFO to break loops)
             victim_key = next(reversed(m_t1))
 
             # Frequency Gating (freq > 1 to promote)
             if m_b1.get(victim_key, 0) > 1:
                 # Promote to T2
                 del m_t1[victim_key]
                 m_t2[victim_key] = None # Adds to tail (MRU)
 
-                # If T1 is now small enough, stop promoting and evict from T2?
-                # We continue loop to possibly evict another from T1 or until T1 is small.
+                # Stop if T1 is healthy, otherwise continue checking
                 if len(m_t1) < t1_target:
                     break
             else:
                 # Evict from T1 (LIFO)
                 return victim_key
 
-    # Evict from T2 (LRU)
-    if m_t2:
-        return next(iter(m_t2))
+    # 2. Evict from T2 (Main)
+    # Second-Chance Mechanism:
+    # If the LRU victim has high frequency, give it a second chance (move to MRU, decay freq)
+    # Limit search to prevent scanning the whole list (Scan Resistance & Efficiency)
+    search_limit = 10
+    while m_t2:
+        candidate = next(iter(m_t2))
+
+        # Second chance if frequently accessed
+        if m_b1.get(candidate, 0) >= 2 and search_limit > 0:
+            m_t2.move_to_end(candidate) # Reinsert at MRU
+            m_b1[candidate] //= 2 # Decay frequency
+            search_limit -= 1
+        else:
+            return candidate
 
     # Fallback
     if m_t1:
         return next(reversed(m_t1))
     return obj.key
 
 def update_after_hit(cache_snapshot, obj):
     check_reset(cache_snapshot)
     key = obj.key
     # Update frequency
     m_b1[key] = m_b1.get(key, 0) + 1
     m_b1.move_to_end(key) # Keep ghost LRU
 
     if key in m_t1:
         # Promote if frequently used
         if m_b1[key] > 1:
             del m_t1[key]
             m_t2[key] = None
     elif key in m_t2:
         # Maintain LRU in Main
         m_t2.move_to_end(key)
 
 def update_after_insert(cache_snapshot, obj):
     check_reset(cache_snapshot)
     key = obj.key
     # Insert counts as 1 access
     m_b1[key] = m_b1.get(key, 0) + 1
     m_b1.move_to_end(key)
 
     # Always insert to T1 (Probation)
     m_t1[key] = None
 
 def update_after_evict(cache_snapshot, obj, evicted_obj):
     check_reset(cache_snapshot)
     key = evicted_obj.key
 
     if key in m_t1:
         del m_t1[key]
     elif key in m_t2:
         del m_t2[key]
 
-    # Limit ghost size
-    if len(m_b1) > cache_snapshot.capacity * 2:
+    # Limit ghost size (Expanded to 5x capacity for better loop capture)
+    if len(m_b1) > cache_snapshot.capacity * 5:
         m_b1.popitem(last=False) # Remove oldest ghost
 
 # EVOLVE-BLOCK-END
 
 # This part remains fixed (not evolved)
 def run_caching(trace_path: str, copy_code_dst: str):
     """Run the caching algorithm on a trace"""
     import os
     with open(os.path.abspath(__file__), 'r', encoding="utf-8") as f:
         code_str = f.read()
     with open(os.path.join(copy_code_dst), 'w') as f:
         f.write(code_str)
     from cache_utils import Cache, CacheConfig, CacheObj, Trace
     trace = Trace(trace_path=trace_path)
     cache_capacity = max(int(trace.get_ndv() * 0.1), 1)
     cache = Cache(CacheConfig(cache_capacity))
     for entry in trace.entries:
         obj = CacheObj(key=str(entry.key))
         cache.get(obj)
     with open(copy_code_dst, 'w') as f:
         f.write("")
     hit_rate = round(cache.hit_count / cache.access_count, 6)
     return hit_rate