--- a/original.py
+++ b/original.py
@@ -1,127 +1,152 @@
 # EVOLVE-BLOCK-START
-"""Cache eviction algorithm for optimizing hit rates across multiple workloads"""
+"""Cache eviction algorithm: S3-FIFO with Persistent Ghost and Probabilistic Survival"""
 
-# S3-FIFO Metadata
+# Global metadata
 # s3_small: FIFO queue for the small segment (probation)
 # s3_main: FIFO queue for the main segment (protected)
-# s3_ghost: Ghost cache for tracking eviction from small
-# s3_freq: Frequency counter for objects (max 3)
+# s3_ghost: Ghost queue (FIFO) tracking evictions from Small AND Main
+# s3_freq: Frequency counter for objects (persistent until ghost eviction)
 s3_small = {}
 s3_main = {}
 s3_ghost = {}
 s3_freq = {}
 
 def evict(cache_snapshot, obj):
     '''
-    S3-FIFO Eviction Policy:
-    - Keeps a small FIFO queue (S) for new items and a large FIFO queue (M) for popular items.
-    - Uses a Ghost queue (G) to track evicted items from S.
+    S3-FIFO with Persistent Ghost and Probabilistic Survival:
+    - Structure: Small (10%) + Main (90%).
+    - Ghost: Extended (5x capacity) and tracks evictions from both Small and Main.
+      This helps catch large loops that exceed cache size but fit in history.
+    - Freq: Persistent in Ghost. Decayed on recall.
+    - Probabilistic Survival: 1% chance to survive eviction. Breaks synchronization in loops.
     '''
     global s3_small, s3_main, s3_ghost, s3_freq
 
     capacity = cache_snapshot.capacity
-    # Target size for Small queue (10% of capacity)
     s_capacity = max(1, int(capacity * 0.1))
 
-    # Lazy cleanup of ghost
-    while len(s3_ghost) > capacity:
-        s3_ghost.pop(next(iter(s3_ghost)))
+    # Lazy cleanup of ghost - 5x capacity
+    # Clean freq only when item leaves ghost
+    while len(s3_ghost) > 5 * capacity:
+        k = next(iter(s3_ghost))
+        s3_ghost.pop(k)
+        if k in s3_freq:
+            del s3_freq[k]
 
     while True:
         # Decision: Evict from Small or Main?
         # If Small is larger than target, evict from Small.
         # Also if Main is empty, we must evict from Small.
         if len(s3_small) >= s_capacity or not s3_main:
             if not s3_small:
-                # Should not happen if cache is full and Main is empty
                 return None
 
             candidate = next(iter(s3_small))
             freq = s3_freq.get(candidate, 0)
 
             if freq > 0:
-                # Second Chance: Move to Main
+                # Promotion: Small -> Main
+                s3_small.pop(candidate)
+                s3_main[candidate] = None
+                s3_freq[candidate] = 0 # Reset freq to prove utility in Main
+                continue
+            
+            # Probabilistic Promotion (1% chance)
+            # Helps populate Main during large loops/scans to find valuable items.
+            if (hash(candidate) ^ cache_snapshot.access_count) % 100 == 0:
                 s3_small.pop(candidate)
                 s3_main[candidate] = None
                 s3_freq[candidate] = 0
                 continue
-            else:
-                # Victim found in Small
-                return candidate
+
+            # Victim found in Small
+            return candidate
 
         else:
             # Evict from Main
             candidate = next(iter(s3_main))
             freq = s3_freq.get(candidate, 0)
 
             if freq > 0:
                 # Second Chance: Reinsert to Main tail
                 s3_main.pop(candidate)
                 s3_main[candidate] = None
-                s3_freq[candidate] = 0
+                s3_freq[candidate] = freq - 1 # Gradual demotion
                 continue
-            else:
-                # Victim found in Main
-                return candidate
+            
+            # Probabilistic Survival (1% chance)
+            # Breaks loop synchronization
+            if (hash(candidate) ^ cache_snapshot.access_count) % 100 == 0:
+                s3_main.pop(candidate)
+                s3_main[candidate] = None
+                continue
+
+            # Victim found in Main
+            return candidate
 
 def update_after_hit(cache_snapshot, obj):
     '''
-    S3-FIFO Update on Hit:
+    Update on Hit:
     - Increment frequency (cap at 3).
+    - Do NOT move in Main (Preserve FIFO for scan resistance).
     '''
     global s3_freq
-    s3_freq[obj.key] = min(s3_freq.get(obj.key, 0) + 1, 3)
+    key = obj.key
+    s3_freq[key] = min(s3_freq.get(key, 0) + 1, 3)
 
 def update_after_insert(cache_snapshot, obj):
     '''
-    S3-FIFO Update on Insert:
-    - If in Ghost, insert to Main. Else insert to Small.
+    Update on Insert:
+    - If in Ghost, insert to Main (Recall). Restore freq with decay.
+    - Else insert to Small (New).
     '''
     global s3_small, s3_main, s3_ghost, s3_freq
     key = obj.key
-    s3_freq[key] = 0
 
     if key in s3_ghost:
         s3_main[key] = None
         s3_ghost.pop(key)
+        # Decayed restoration: Favor items that were hot.
+        # If it returns from ghost, it's valuable.
+        old_freq = s3_freq.get(key, 0)
+        s3_freq[key] = max(0, old_freq - 1)
     else:
         s3_small[key] = None
+        s3_freq[key] = 0
 
 def update_after_evict(cache_snapshot, obj, evicted_obj):
     '''
-    S3-FIFO Update on Evict:
-    - Remove from queues. If evicted from Small, add to Ghost.
+    Update on Evict:
+    - Track evictions from BOTH Small and Main in Ghost.
+    - Do NOT remove freq yet (wait for ghost eviction).
     '''
-    global s3_small, s3_main, s3_ghost, s3_freq
+    global s3_small, s3_main, s3_ghost
     key = evicted_obj.key
 
     if key in s3_small:
         s3_small.pop(key)
         s3_ghost[key] = None
     elif key in s3_main:
         s3_main.pop(key)
-
-    if key in s3_freq:
-        s3_freq.pop(key)
-
+        s3_ghost[key] = None # Main evictions also tracked
 # EVOLVE-BLOCK-END
 
 # This part remains fixed (not evolved)
 def run_caching(trace_path: str, copy_code_dst: str):
     """Run the caching algorithm on a trace"""
     import os
     with open(os.path.abspath(__file__), 'r', encoding="utf-8") as f:
         code_str = f.read()
     with open(os.path.join(copy_code_dst), 'w') as f:
         f.write(code_str)
     from cache_utils import Cache, CacheConfig, CacheObj, Trace
     trace = Trace(trace_path=trace_path)
     cache_capacity = max(int(trace.get_ndv() * 0.1), 1)
     cache = Cache(CacheConfig(cache_capacity))
     for entry in trace.entries:
         obj = CacheObj(key=str(entry.key))
         cache.get(obj)
     with open(copy_code_dst, 'w') as f:
         f.write("")
     hit_rate = round(cache.hit_count / cache.access_count, 6)
     return hit_rate