--- a/original.py
+++ b/original.py
@@ -1,172 +1,166 @@
 # EVOLVE-BLOCK-START
 """Cache eviction algorithm for optimizing hit rates across multiple workloads"""
 from collections import OrderedDict
 import random
 
-# Adaptive S3-FIFO Global State
-as3_small = OrderedDict()       # Small Queue (FIFO) for new items
-as3_main = OrderedDict()        # Main Queue (FIFO/LRU) for promoted items
-as3_ghost_small = OrderedDict() # Ghost for Small
-as3_ghost_main = OrderedDict()  # Ghost for Main
-as3_freq = {}                   # Frequency counter
-as3_ratio = 0.1                 # Target fraction for Small Queue (0.01 to 0.99)
+# S3-FIFO++ (S3-FIFO with True LRU Main, Jitter, and Aging)
+s3p_small = OrderedDict()
+s3p_main = OrderedDict()
+s3p_ghost = OrderedDict()
+s3p_freq = {}
 m_last_access_count = -1
+m_global_counter = 0
 
 def _check_reset(cache_snapshot):
     """Resets global state if a new trace is detected."""
-    global as3_small, as3_main, as3_ghost_small, as3_ghost_main, as3_freq, as3_ratio, m_last_access_count
+    global s3p_small, s3p_main, s3p_ghost, s3p_freq, m_last_access_count, m_global_counter
     if cache_snapshot.access_count < m_last_access_count:
-        as3_small.clear()
-        as3_main.clear()
-        as3_ghost_small.clear()
-        as3_ghost_main.clear()
-        as3_freq.clear()
-        as3_ratio = 0.1
+        s3p_small.clear()
+        s3p_main.clear()
+        s3p_ghost.clear()
+        s3p_freq.clear()
+        m_global_counter = 0
     m_last_access_count = cache_snapshot.access_count
 
 def evict(cache_snapshot, obj):
     '''
-    Adaptive S3-FIFO Eviction.
-    - S (Small) buffers new items. M (Main) holds frequent items.
-    - Dynamic sizing of S vs M based on ghost hits (ARC-like adaptivity).
-    - Randomized victim selection from head window (scan/loop resistance).
+    S3-FIFO++ Eviction Policy.
+    - S (Small): FIFO with randomized eviction and lazy promotion.
+    - M (Main): Strict LRU for better retention of working sets.
+    - Jittered S-partition to avoid loop synchronization.
     '''
     _check_reset(cache_snapshot)
     capacity = cache_snapshot.capacity
-    target_small = max(1, int(capacity * as3_ratio))
     
-    # Window size for randomized selection
-    k_window = 10 
+    # Jitter the partition size to prevent loop synchronization
+    # Range: +/- 2% of capacity (min 1)
+    jitter_mag = max(1, int(capacity * 0.02))
+    jitter = random.randint(-jitter_mag, jitter_mag)
+    target_s_size = max(1, int(capacity * 0.1) + jitter)
+
+    # Window size for scan
+    k_window = 5
 
     while True:
-        # 1. Determine eviction source queue
-        # Evict from Small if it exceeds target size OR if Main is empty
-        if len(as3_small) > target_small or not as3_main:
-            queue = as3_small
-            is_small = True
+        # Determine source queue
+        # Prioritize Small if it's too big or Main is empty
+        if len(s3p_small) > target_s_size or not s3p_main:
+            if not s3p_small:
+                return next(iter(cache_snapshot.cache)) if cache_snapshot.cache else None
+
+            # Scan window at head of Small
+            candidates = []
+            iterator = iter(s3p_small)
+            for _ in range(k_window):
+                try:
+                    candidates.append(next(iterator))
+                except StopIteration:
+                    break
+
+            # Check for promotions
+            promoted_key = None
+            for key in candidates:
+                if s3p_freq.get(key, 0) > 0:
+                    promoted_key = key
+                    break
+            
+            if promoted_key:
+                # Promote to Main (Tail/MRU)
+                del s3p_small[promoted_key]
+                s3p_main[promoted_key] = 1
+                s3p_freq[promoted_key] = 0 # Reset hit count
+                continue
+            
+            # No promotions -> Random Victim
+            victim_key = random.choice(candidates)
+            return victim_key
+
         else:
-            queue = as3_main
-            is_small = False
-        
-        # 2. Collect candidates from head of queue
-        candidates = []
-        iterator = iter(queue)
-        for _ in range(k_window):
-            try:
-                candidates.append(next(iterator))
-            except StopIteration:
-                break
-        
-        if not candidates:
-            # Fallback (should not happen if cache is full)
-            return next(iter(cache_snapshot.cache)) if cache_snapshot.cache else None
-
-        # 3. Check for Promotions / Reinsertions
-        promoted = False
-        for key in candidates:
-            freq = as3_freq.get(key, 0)
-            if freq > 0:
-                # Promotion/Reinsertion logic
-                if is_small:
-                    # Promote Small -> Main
-                    del as3_small[key]
-                    as3_main[key] = 1
-                else:
-                    # Reinsert Main -> Main (Tail)
-                    as3_main.move_to_end(key)
-                
-                as3_freq[key] = 0 # Reset frequency
-                promoted = True
-                break # Restart loop
-        
-        if promoted:
-            continue
-
-        # 4. No promotions in window -> Evict one
-        # Randomized selection from candidates breaks synchronization
-        victim_key = random.choice(candidates)
-        return victim_key
+            # Evict from Main (Strict LRU)
+            # Just take the head (LRU)
+            return next(iter(s3p_main))
 
 def update_after_hit(cache_snapshot, obj):
     '''
-    On Hit: Increment frequency.
+    On Hit:
+    - Update frequency.
+    - Move to MRU if in Main (True LRU).
     '''
     _check_reset(cache_snapshot)
     key = obj.key
-    as3_freq[key] = min(3, as3_freq.get(key, 0) + 1)
+    s3p_freq[key] = min(3, s3p_freq.get(key, 0) + 1)
+    
+    if key in s3p_main:
+        s3p_main.move_to_end(key)
 
 def update_after_insert(cache_snapshot, obj):
     '''
     On Insert:
-    - Check Ghost lists to adapt S/M ratio.
-    - Insert into Small or Main.
+    - Handle Ghost recall.
+    - Perform global aging.
     '''
     _check_reset(cache_snapshot)
-    global as3_ratio
     key = obj.key
-    
-    delta = 0.05 # Adaptation step size
+    global m_global_counter
 
-    if key in as3_ghost_small:
-        # Hit in Ghost Small -> S was too small
-        as3_ratio = min(0.95, as3_ratio + delta)
-        del as3_ghost_small[key]
-        # Recall to Main
-        as3_main[key] = 1
-        as3_freq[key] = 0
-    elif key in as3_ghost_main:
-        # Hit in Ghost Main -> M was too small (S too big)
-        as3_ratio = max(0.05, as3_ratio - delta)
-        del as3_ghost_main[key]
-        # Recall to Main
-        as3_main[key] = 1
-        as3_freq[key] = 0
+    if key in s3p_ghost:
+        del s3p_ghost[key]
+        s3p_main[key] = 1
+        s3p_freq[key] = 0
     else:
-        # New Insert -> Small
-        as3_small[key] = 1
-        as3_freq[key] = 0
+        s3p_small[key] = 1
+        s3p_freq[key] = 0
+        
+    # Global Frequency Aging
+    m_global_counter += 1
+    if m_global_counter >= cache_snapshot.capacity:
+        m_global_counter = 0
+        # Decay frequencies
+        for k in list(s3p_freq):
+            s3p_freq[k] >>= 1
+            if s3p_freq[k] == 0:
+                del s3p_freq[k]
 
 def update_after_evict(cache_snapshot, obj, evicted_obj):
     '''
-    On Evict: Remove from queue and add to respective Ghost.
+    On Evict:
+    - Move Small victims to Ghost.
+    - Clean up frequency.
     '''
     key = evicted_obj.key
     
-    if key in as3_small:
-        del as3_small[key]
-        as3_ghost_small[key] = 1
-    elif key in as3_main:
-        del as3_main[key]
-        as3_ghost_main[key] = 1
+    if key in s3p_small:
+        del s3p_small[key]
+        s3p_ghost[key] = 1
+    elif key in s3p_main:
+        del s3p_main[key]
+        # Main victims are not ghosted in this version
     
-    if key in as3_freq:
-        del as3_freq[key]
+    if key in s3p_freq:
+        del s3p_freq[key]
 
-    # Limit Ghost Size to Capacity
-    capacity = cache_snapshot.capacity
-    if len(as3_ghost_small) > capacity:
-        as3_ghost_small.popitem(last=False)
-    if len(as3_ghost_main) > capacity:
-        as3_ghost_main.popitem(last=False)
+    # Limit Ghost Size
+    if len(s3p_ghost) > cache_snapshot.capacity:
+        s3p_ghost.popitem(last=False)
 
 # EVOLVE-BLOCK-END
 
 # This part remains fixed (not evolved)
 def run_caching(trace_path: str, copy_code_dst: str):
     """Run the caching algorithm on a trace"""
     import os
     with open(os.path.abspath(__file__), 'r', encoding="utf-8") as f:
         code_str = f.read()
     with open(os.path.join(copy_code_dst), 'w') as f:
         f.write(code_str)
     from cache_utils import Cache, CacheConfig, CacheObj, Trace
     trace = Trace(trace_path=trace_path)
     cache_capacity = max(int(trace.get_ndv() * 0.1), 1)
     cache = Cache(CacheConfig(cache_capacity))
     for entry in trace.entries:
         obj = CacheObj(key=str(entry.key))
         cache.get(obj)
     with open(copy_code_dst, 'w') as f:
         f.write("")
     hit_rate = round(cache.hit_count / cache.access_count, 6)
     return hit_rate