--- a/original.py
+++ b/original.py
@@ -1,127 +1,151 @@
 # EVOLVE-BLOCK-START
 """Cache eviction algorithm for optimizing hit rates across multiple workloads"""
 
-m_key_timestamp = dict()
-m_protected_keys = set()
-m_ghost_timestamp = dict()
+from collections import OrderedDict
+
+# Global ARC State
+m_t1 = OrderedDict()  # T1: Recent (LRU)
+m_t2 = OrderedDict()  # T2: Frequent (LRU)
+m_b1 = OrderedDict()  # B1: Ghost Recent (FIFO/LRU)
+m_b2 = OrderedDict()  # B2: Ghost Frequent (FIFO/LRU)
+m_p = 0.0             # Adaptation parameter (Target T1 size)
+m_last_access_count = 0
+
+def check_reset(cache_snapshot):
+    '''Reset global state if a new trace is detected.'''
+    global m_t1, m_t2, m_b1, m_b2, m_p, m_last_access_count
+    if cache_snapshot.access_count < m_last_access_count:
+        m_t1.clear()
+        m_t2.clear()
+        m_b1.clear()
+        m_b2.clear()
+        m_p = 0.0
+    m_last_access_count = cache_snapshot.access_count
 
 def evict(cache_snapshot, obj):
     '''
-    This function defines how the algorithm chooses the eviction victim.
-    - Args:
-        - `cache_snapshot`: A snapshot of the current cache state.
-        - `obj`: The new object that needs to be inserted into the cache.
-    - Return:
-        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
+    ARC eviction logic:
+    - Adapts 'p' based on hits in ghost lists (B1, B2).
+    - Selects victim from T1 or T2 based on 'p' and current sizes.
     '''
-    global m_key_timestamp, m_protected_keys
+    check_reset(cache_snapshot)
+    global m_p
+    
+    key = obj.key
+    capacity = cache_snapshot.capacity
+    
+    # 1. Adapt p if hitting ghost history
+    if key in m_b1:
+        delta = 1.0
+        if len(m_b1) < len(m_b2):
+            delta = len(m_b2) / len(m_b1)
+        m_p = min(float(capacity), m_p + delta)
+    elif key in m_b2:
+        delta = 1.0
+        if len(m_b2) < len(m_b1):
+            delta = len(m_b1) / len(m_b2)
+        m_p = max(0.0, m_p - delta)
 
-    # Calculate current size of A1in (items in cache but not protected)
-    a1in_keys = [k for k in cache_snapshot.cache if k not in m_protected_keys]
-    current_a1in_size = len(a1in_keys)
-
-    # Target size for A1in (Probation)
-    target_a1in = cache_snapshot.capacity * 0.25
-
-    victim_key = None
-    candidates = []
-
-    # Decide whether to evict from A1in or Am (Protected)
-    # If A1in exceeds target, evict from A1in.
-    # Also if Am is empty (all items are probationary), must evict from A1in.
-    if current_a1in_size > target_a1in or current_a1in_size == len(cache_snapshot.cache):
-        candidates = a1in_keys
+    # 2. Determine eviction policy (Replace T1 or T2)
+    # If we need to evict, cache is full.
+    # Logic: Evict T1 if |T1| > p. 
+    # Special ARC case: if x in B2 and |T1| == p, also evict T1 (to make room for x in T2).
+    
+    replace_t1 = False
+    len_t1 = len(m_t1)
+    
+    if len_t1 > 0:
+        if len_t1 > m_p:
+            replace_t1 = True
+        elif (key in m_b2) and (len_t1 == int(m_p)):
+            replace_t1 = True
+            
+    # Safety checks if one list is empty
+    if len(m_t1) == 0: replace_t1 = False
+    if len(m_t2) == 0: replace_t1 = True
+    
+    if replace_t1:
+        return next(iter(m_t1))
     else:
-        # Otherwise try to evict from Am
-        candidates = [k for k in cache_snapshot.cache if k in m_protected_keys]
-        # Fallback if candidates is empty (should be covered by condition above)
-        if not candidates:
-            candidates = a1in_keys
-
-    # LRU eviction within the chosen segment
-    victim_key = min(candidates, key=lambda k: m_key_timestamp.get(k, 0))
-    return victim_key
+        return next(iter(m_t2))
 
 def update_after_hit(cache_snapshot, obj):
     '''
-    This function defines how the algorithm update the metadata it maintains immediately after a cache hit.
-    - Args:
-        - `cache_snapshot`: A snapshot of the current cache state.
-        - `obj`: The object accessed during the cache hit.
-    - Return: `None`
+    Move hit items to MRU of T2 (Frequency list).
     '''
-    global m_key_timestamp
-    # Update access time (LRU)
-    # In 2Q, hits in A1in do NOT promote to Am. They just refresh position in A1in.
-    if obj.key in m_key_timestamp:
-        m_key_timestamp[obj.key] = cache_snapshot.access_count
+    check_reset(cache_snapshot)
+    key = obj.key
+    if key in m_t1:
+        del m_t1[key]
+        m_t2[key] = None
+    elif key in m_t2:
+        m_t2.move_to_end(key)
+    else:
+        # Should not happen if sync is perfect, but fallback to insert T2
+        m_t2[key] = None
 
 def update_after_insert(cache_snapshot, obj):
     '''
-    This function defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
-    - Args:
-        - `cache_snapshot`: A snapshot of the current cache state.
-        - `obj`: The object that was just inserted into the cache.
-    - Return: `None`
+    Insert new item. 
+    - If from B1 (Ghost T1) -> T2
+    - If from B2 (Ghost T2) -> T2
+    - Else -> T1
     '''
-    global m_key_timestamp, m_protected_keys, m_ghost_timestamp
-    m_key_timestamp[obj.key] = cache_snapshot.access_count
-
-    # Check if object was in ghost registry
-    if obj.key in m_ghost_timestamp:
-        # Promote to Protected (Am)
-        m_protected_keys.add(obj.key)
-        del m_ghost_timestamp[obj.key]
+    check_reset(cache_snapshot)
+    key = obj.key
+    
+    # Check ghost lists
+    if key in m_b1:
+        del m_b1[key]
+        m_t2[key] = None
+    elif key in m_b2:
+        del m_b2[key]
+        m_t2[key] = None
     else:
-        # Insert into Probation (A1in)
-        # Ensure it's not marked as protected (in case of re-use of key after long time)
-        if obj.key in m_protected_keys:
-            m_protected_keys.remove(obj.key)
+        # Completely new item
+        m_t1[key] = None
 
 def update_after_evict(cache_snapshot, obj, evicted_obj):
     '''
-    This function defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
-    - Args:
-        - `cache_snapshot`: A snapshot of the current cache state.
-        - `obj`: The object to be inserted into the cache.
-        - `evicted_obj`: The object that was just evicted from the cache.
-    - Return: `None`
+    Move evicted items to ghost lists (B1 or B2).
+    Manage ghost list capacities.
     '''
-    global m_key_timestamp, m_protected_keys, m_ghost_timestamp
-    if evicted_obj.key in m_key_timestamp:
-        del m_key_timestamp[evicted_obj.key]
-
-    if evicted_obj.key in m_protected_keys:
-        m_protected_keys.remove(evicted_obj.key)
-        # Evicted from Am: usually not added to ghost in standard 2Q
-    else:
-        # Evicted from A1in: add to ghost registry
-        m_ghost_timestamp[evicted_obj.key] = cache_snapshot.access_count
-
-        # Manage ghost size (limit to cache capacity)
-        if len(m_ghost_timestamp) > cache_snapshot.capacity:
-             # Remove oldest in ghost
-             oldest_ghost = min(m_ghost_timestamp, key=m_ghost_timestamp.get)
-             del m_ghost_timestamp[oldest_ghost]
+    check_reset(cache_snapshot)
+    key = evicted_obj.key
+    
+    if key in m_t1:
+        del m_t1[key]
+        m_b1[key] = None
+    elif key in m_t2:
+        del m_t2[key]
+        m_b2[key] = None
+        
+    # Limit ghost size (scan resistance vs history depth)
+    # Using capacity as limit for each ghost list roughly matches ARC paper suggestions
+    cap = cache_snapshot.capacity
+    while len(m_b1) > cap:
+        m_b1.popitem(last=False)
+    while len(m_b2) > cap:
+        m_b2.popitem(last=False)
 
 # EVOLVE-BLOCK-END
 
 # This part remains fixed (not evolved)
 def run_caching(trace_path: str, copy_code_dst: str):
     """Run the caching algorithm on a trace"""
     import os
     with open(os.path.abspath(__file__), 'r', encoding="utf-8") as f:
         code_str = f.read()
     with open(os.path.join(copy_code_dst), 'w') as f:
         f.write(code_str)
     from cache_utils import Cache, CacheConfig, CacheObj, Trace
     trace = Trace(trace_path=trace_path)
     cache_capacity = max(int(trace.get_ndv() * 0.1), 1)
     cache = Cache(CacheConfig(cache_capacity))
     for entry in trace.entries:
         obj = CacheObj(key=str(entry.key))
         cache.get(obj)
     with open(copy_code_dst, 'w') as f:
         f.write("")
     hit_rate = round(cache.hit_count / cache.access_count, 6)
     return hit_rate