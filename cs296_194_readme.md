## Setup ShinkaEvolve
Please check [README](./README.md)

## How to run evolution for caching
```bash
$ python examples/caching/run_evo.py
```

You can set the LLM model to use in `LLM_MODEL`, and the number of iterations in `NUM_ITER` in [run_evo.py](./examples/caching/run_evo.py).

## Results
Check [data/](./data/) for 3 runs with gemini-3-pro and gpt-5.