evaluate_function:
  _target_: examples.txn_scheduling.evaluate.main
  program_path: ???
  results_dir: ???

distributed_job_config:
  _target_: shinka.launch.SlurmCondaJobConfig
  modules:
  - "cuda/12.4"
  - "cudnn/8.9.7"
  - "hpcx/2.20"
  eval_program_path: "shinka/eval_hydra.py"
  conda_env: "shinka"
  time: "00:10:00" 
  cpus: 1
  gpus: 0
  mem: "8G"

evo_config:
  task_sys_msg: |
    You are an expert in transaction scheduling and database optimization. The goal is to minimize the total makespan across three different workload types by optimizing the scheduling algorithm.

    Key directions to explore:
    1. The greedy cost sampling strategy can be improved with better sampling techniques
    2. Consider different starting point selection strategies beyond random
    3. Explore adaptive sampling rates based on workload characteristics
    4. The cost calculation function can be optimized for different workload patterns
    5. Consider workload-aware scheduling that adapts to transaction patterns
    6. Explore hybrid approaches combining multiple scheduling strategies
    7. The random sampling component can be replaced with more intelligent selection
    8. Consider parallel processing opportunities for independent transactions
    9. Explore dynamic parameter tuning based on workload characteristics
    10. Consider machine learning approaches for pattern recognition in transaction sequences

    The algorithm should handle three workload types:
    - Workload 1: Complex mixed read/write transactions with varying lengths
    - Workload 2: Simple read-then-write pattern transactions  
    - Workload 3: Minimal read/write operations

    Make sure that all schedules are valid (no duplicates, all transactions included) and the algorithm runs efficiently.

    Be creative and try to find new scheduling strategies that outperform the baseline greedy approach.
  language: "python"
  init_program_path: "examples/txn_scheduling/initial.py"
  job_type: "slurm_conda"
  llm_models:
    - "o4-mini"
    - "gpt-5"
    - "gpt-5-mini"
    - "gpt-5-nano"
  llm_dynamic_selection: ucb
  llm_kwargs:
    temperatures:
      - 0.0
      - 0.5
      - 1.0
    max_tokens: 16384
  meta_rec_interval: 10
  meta_llm_models:
    - "gpt-5-nano"
  meta_llm_kwargs:
    temperatures:
      - 0.0
  embedding_model: "text-embedding-3-small"

exp_name: "shinka_txn_scheduling"
