# OpenEvolve Island-Based Evolution Configuration
# This configuration demonstrates the proper use of island-based evolution

# General settings
max_iterations: 100
checkpoint_interval: 10
log_level: "INFO"
random_seed: 42

# LLM configuration
llm:
  primary_model: "####MODEL_NAME####"
  primary_model_weight: 1.0
  temperature: 0.7
  top_p: 0.95
  max_tokens: 32000
  timeout: 600

# Database configuration with proper island settings
database:
  population_size: 100
  archive_size: 20
  
  # Island-based evolution settings
  num_islands: 5                   # Number of separate populations
  migration_interval: 5            # Migrate every 50 generations
  migration_rate: 0.1               # Migrate 10% of top programs
  
  # Selection parameters
  elite_selection_ratio: 0.1
  exploration_ratio: 0.3
  exploitation_ratio: 0.7
  # Note: diversity_metric fixed to "edit_distance"
  
  # Feature map dimensions for MAP-Elites
  # Default if not specified: ["complexity", "diversity"]
  # Comment out the line below to use the defaults
  # feature_dimensions: ["complexity", "diversity"]
  feature_bins: 10
  # Can also use per-dimension bins:
  # feature_bins:
  #   performance: 20
  #   correctness: 10

# Prompt configuration
prompt:
  system_message: |
    You are an expert in network telemetry repair algorithms.
    
    # RESEARCH CONTEXT
    The following research provides important background on network input validation:
    
    ## Core Problem
    Network controllers often receive **incorrect inputs** that don't accurately reflect network state, causing major outages. Over 1/3 of production outages are caused by incorrect inputs to SDN controllers.
    
    ## Key Validation Principles
    
    ### Three-Step Validation Approach (Hodor System):
    1. **Signal Collection**: Gather redundant signals from network devices
    2. **Signal Hardening**: Use redundancy to detect and correct faulty measurements  
    3. **Dynamic Checking**: Verify inputs against hardened network state
    
    ### Critical Network Invariants for Validation:
    1. **Link Symmetry (R3)**: `my_tx_rate ≈ their_rx_rate` for connected interfaces
    2. **Flow Conservation (R1)**: `Σ(incoming_traffic) = Σ(outgoing_traffic)` at each router
    3. **Interface Consistency**: Status should be consistent across connected pairs
    
    ## Repair Strategy from Research
    - **Detection**: Compare outgoing interface count to incoming interface count on each side of links
    - **Repair**: Use flow conservation principle - traffic into a router must equal traffic out
    - **Confidence**: Higher confidence when multiple redundant signals agree
    - **Hardening threshold** (τh ≈ 2%) to account for measurement timing differences
    
    # TASK SPECIFICATION
    
    Your task is to evolve a Python function called `repair_network_telemetry` that takes 
    potentially corrupted network interface data and repairs it while providing confidence scores.

    Context about networks: the transmission and receiving rates are the number of bytes sent and received per second. 
    In a healthy state, packets are not dropped on links or at routers. An interface that is down cannot be sending or receiving.
    
    FUNCTION SIGNATURE:
      def repair_network_telemetry(telemetry: Dict[str, Dict[str, Any]], 
                             topology: Dict[str, List[str]]) -> Dict[str, Dict[str, Tuple]]:
    
    INPUT FORMAT:
    - Dictionary of interface_id -> telemetry data
            - interface_status: "up" or "down" 
            - rx_rate: receive rate in Mbps
            - tx_rate: transmit rate in Mbps
            - connected_to: interface_id this interface connects to
            - local_router: router_id this interface belongs to
            - remote_router: router_id on the other side
    - Dictionary of topology where key is router_id and value contains a list of interface_ids. You can use this
      to find or check relationships that should apply to counters at a single router.
    - Telemetry data may be corrupted (wrong rates, inconsistent with connected interfaces)
    
    OUTPUT FORMAT:
     - Same structure as telemetry, but telemetry values become (original_value, repaired_value, confidence) tuples
     - confidence ranges from 0.0 (very uncertain) to 1.0 (very confident in repair)
     - Non-telemetry fields (connected_to, etc.) are copied unchanged
     
     REPAIR STRATEGY:
    - The best algorithm would be one that leaves correct telemetry unchanged, but detects and
      repairs telemetry that is wrong to be correct again. 
    - You can use the topology to help you repair telemetry. 
    
    CONFIDENCE CALIBRATION:
    Your confidence scores will be evaluated for calibration - they must reflect repair accuracy:
    - That is, the confidence score should be high when the repaired value is very close to the ground truth value.
    - The confidence score should be low when the repaired value is very different from the ground truth value.
    - Your solution will be penalised for overconfidence in bad repairs (dangerous)
    - Your solution will be penalised for underconfidence in good repairs (wasteful)
    
    EVALUATION METRICS:
    1. counter_repair_accuracy: How close repaired rx/tx rates are to ground truth
    2. status_repair_accuracy: How well interface status is repaired  
    3. confidence_calibration: How well confidence scores reflect actual repair quality
    4. combined_score: Weighted combination (75% counter + 5% status + 20% confidence)
    
    Focus on algorithms that both repair accurately AND provide accurate indiciations of confidence.

    Think out-loud and reason step-by-step conceptually about what idea you want to try and why. Be detailed in your reasoning. Consider what will
    make implementing that idea difficult or tricky, and how to do it elegantly. Then provide your code.

    If you *don't* use the topology, please leave a comment in the code explaining why not. It ought to be useful.
  num_top_programs: 3
  num_diverse_programs: 2
  use_template_stochasticity: true

# Evaluator configuration
evaluator:
  timeout: 300
  max_retries: 3
  cascade_evaluation: false
  parallel_evaluations: 4

# Evolution settings
diff_based_evolution: true
allow_full_rewrites: false
max_code_length: 60000

